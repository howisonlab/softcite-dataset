{
    "level": "sentence",
    "abstract": [
        {
            "text": "We describe a method based on the CLs approach to present results in searches of new physics, under the condition that the relevant parameter space is continuous. ",
            "paragraph_rank": 1,
            "section_rank": 1
        },
        {
            "text": "Our method relies on a class of test statistics developed for non-nested hypotheses testing problems, denoted by \u2206T , which has a Gaussian approximation to its parent distribution when the sample size is large. ",
            "paragraph_rank": 1,
            "section_rank": 1
        },
        {
            "text": "This leads to a simple procedure of forming exclusion sets for the parameters of interest, which we call the Gaussian CLs method. ",
            "paragraph_rank": 1,
            "section_rank": 1
        },
        {
            "text": "Our work provides a self-contained mathematical proof for the Gaussian CLs method, that explicitly outlines the required conditions. ",
            "paragraph_rank": 1,
            "section_rank": 1
        },
        {
            "text": "These conditions are milder than that required by the Wilks' theorem to set confidence intervals (CIs). ",
            "paragraph_rank": 1,
            "section_rank": 1
        },
        {
            "text": "We illustrate the Gaussian CLs method in an example of searching for a sterile neutrino, where the CLs approach was rarely used before. ",
            "paragraph_rank": 1,
            "section_rank": 1
        },
        {
            "text": "We also compare data analysis results produced by the Gaussian CLs method and various CI methods to showcase their differences.",
            "paragraph_rank": 1,
            "section_rank": 1
        }
    ],
    "body_text": [
        {
            "text": "I. INTRODUCTION",
            "section_rank": 2
        },
        {
            "text": "The Standard Model of particle physics has been extremely successful since its establishment in the mid-1970s. ",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 2,
            "section_rank": 2
        },
        {
            "text": "In particular, the Higgs particle discovered at LHC in 2012 [1,2] completed the list of fundamental particles predicted by the minimal Standard Model. ",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 2,
            "section_rank": 2,
            "ref_spans": [
                {
                    "start": 60,
                    "end": 63,
                    "type": "bibr",
                    "ref_id": "b0",
                    "text": "[1,"
                },
                {
                    "start": 63,
                    "end": 65,
                    "type": "bibr",
                    "ref_id": "b1",
                    "text": "2]"
                }
            ]
        },
        {
            "text": "On the other hand, there has been experimental evidence that point to new physics beyond the Standard Model: neutrino oscillations indicate non-zero neutrino mass; various gravitational effects indicate the existence of nonbaryonic dark matter; the accelerating expansion of our universe indicates the existence of dark energy; the large observed matter-anti-matter asymmetry in the universe indicates the existence of additional CP violation source beyond that in the quark mixing matrix, etc. ",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 2,
            "section_rank": 2
        },
        {
            "text": "Searches for new physics beyond the Standard Model have been and still are at the frontier of high energy particle physics.",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 2,
            "section_rank": 2
        },
        {
            "text": "Given experiment data, a problem of searching for new physics often turns into a parameter estimation problem, and the findings are presented in the form of constraints on some continuous parameter(s). ",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 3,
            "section_rank": 2
        },
        {
            "text": "One example is the search for sterile neutrino suggested by LSND [3], MiniBooNE [4], and reactor antineutrino anomalies [5]. ",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 3,
            "section_rank": 2,
            "ref_spans": [
                {
                    "start": 65,
                    "end": 68,
                    "type": "bibr",
                    "ref_id": "b2",
                    "text": "[3]"
                },
                {
                    "start": 80,
                    "end": 83,
                    "type": "bibr",
                    "ref_id": "b3",
                    "text": "[4]"
                },
                {
                    "start": 120,
                    "end": 123,
                    "type": "bibr",
                    "ref_id": "b4",
                    "text": "[5]"
                }
            ],
            "entity_spans": [
                {
                    "start": 70,
                    "end": 80,
                    "type": "software",
                    "rawForm": "MiniBooNE",
                    "resp": "service",
                    "id": "software-simple-s1"
                }
            ]
        },
        {
            "text": "1 In this case, data collected from an experiment consists of neutrino interaction counts in multiple energy bins, x = (N 1 , \u2022 \u2022 \u2022 , N n ). ",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 3,
            "section_rank": 2,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 1,
                    "type": "bibr",
                    "ref_id": "b0",
                    "text": "1"
                }
            ]
        },
        {
            "text": "Data analysis results are generally shown as constraints in the two-dimensional parameter space of (sin 2 2\u03b8, |\u2206m 2 |), where \u03b8 is the mixing angle involving the sterile neutrino, and |\u2206m 2 | is the mass-squared difference of neutrino mass eigenstate beyond three generations.",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 3,
            "section_rank": 2
        },
        {
            "text": "One way to set constraints is to form confidence intervals 2 (CI), which contains parameter values that are compatible with the data. ",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 4,
            "section_rank": 2
        },
        {
            "text": "Let \u03b2 denote the parameter(s), such as \u03b2 = (sin 2 2\u03b8, |\u2206m 2 |) in the neutrino oscillation problem. ",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 4,
            "section_rank": 2
        },
        {
            "text": "A CI can be obtained by inverting a testing procedure. ",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 4,
            "section_rank": 2
        },
        {
            "text": "Specifically, the set of all \u03b2 1 such that the hypothesis H 0 : \u03b2 = \u03b2 1 is not rejected at level 1 \u2212 c, forms a level-c CI. ",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 4,
            "section_rank": 2
        },
        {
            "text": "A testing procedure is often performed by thresholding a test statistic, which is a user-chosen function that, for any given \u03b2 1 , defines a criterion to order all possible values of x. ",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 4,
            "section_rank": 2
        },
        {
            "text": "To test H 0 : \u03b2 = \u03b2 1 , a commonly used type of test statistic takes the form",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 4,
            "section_rank": 2
        },
        {
            "text": "where \u03c7 2 is a function that measures the compatibility between \u03b2 1 and x. ",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 5,
            "section_rank": 2
        },
        {
            "text": "One important example of \u03c7 2 is the negative-two-log-likelihood function, and the corresponding \u2206\u03c7 2 is called the likelihood ratio (LR) test statistic.",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 5,
            "section_rank": 2
        },
        {
            "text": "In the field of high energy physics, the unified approach to construct CIs advocated by Feldman and Cousins [6] is indeed based on the likelihood ratio test statistic. ",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 6,
            "section_rank": 2,
            "ref_spans": [
                {
                    "start": 108,
                    "end": 111,
                    "type": "bibr",
                    "ref_id": "b5",
                    "text": "[6]"
                }
            ]
        },
        {
            "text": "A parameter value \u03b2 1 is included in a level-c CI if \u2206\u03c7 2 (\u03b2 1 ; x) is below a threshold t c , such that Prob \u03b21 (\u2206\u03c7 2 (\u03b2 1 ; X) \u2264 t c ) \u2265 c. ",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 6,
            "section_rank": 2
        },
        {
            "text": "Here, the subscript \u03b2 1 means that X is a random outcome from a model with true parameter value \u03b2 1 . ",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 6,
            "section_rank": 2
        },
        {
            "text": "In general, Monte Carlo (MC) simulation can be used 3 to approximate the parent dis-tribution of \u2206\u03c7 2 . ",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 6,
            "section_rank": 2,
            "ref_spans": [
                {
                    "start": 52,
                    "end": 53,
                    "type": "bibr",
                    "ref_id": "b2",
                    "text": "3"
                },
                {
                    "start": 100,
                    "end": 101,
                    "type": "bibr",
                    "ref_id": "b1",
                    "text": "2"
                }
            ]
        },
        {
            "text": "We refer to the corresponding method of constructing CIs as the MC CI method. ",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 6,
            "section_rank": 2
        },
        {
            "text": "An example of the MC CI method, tailored for the LR test statistic, can be found in section V.B of Feldman and Cousins [6]. ",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 6,
            "section_rank": 2,
            "ref_spans": [
                {
                    "start": 119,
                    "end": 122,
                    "type": "bibr",
                    "ref_id": "b5",
                    "text": "[6]"
                }
            ]
        },
        {
            "text": "The MC CI method is often computationally intensive. ",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 6,
            "section_rank": 2
        },
        {
            "text": "Alternatively, t c can be approximated using a Chi-square distribution, a summary of its usage in particle physics is provided by the Particle Data Group [8]. ",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 6,
            "section_rank": 2,
            "ref_spans": [
                {
                    "start": 154,
                    "end": 157,
                    "type": "bibr",
                    "ref_id": "b7",
                    "text": "[8]"
                }
            ]
        },
        {
            "text": "This method is simple to carry out, but the approximation is only valid under relatively stringent conditions. ",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 6,
            "section_rank": 2
        },
        {
            "text": "Specifically, the Chi-square thresholds are justified by the Wilks' theorem [9] for the LR test statistic under regularity conditions C1-C3 in Sec. ",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 6,
            "section_rank": 2,
            "ref_spans": [
                {
                    "start": 76,
                    "end": 79,
                    "type": "bibr",
                    "ref_id": "b8",
                    "text": "[9]"
                }
            ]
        },
        {
            "text": "II, and they are justified for the variations of \u2206\u03c7 2 listed in Sec. ",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 6,
            "section_rank": 2
        },
        {
            "text": "IV A under similar conditions [10,11]. ",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 6,
            "section_rank": 2,
            "ref_spans": [
                {
                    "start": 30,
                    "end": 34,
                    "type": "bibr",
                    "ref_id": "b9",
                    "text": "[10,"
                },
                {
                    "start": 34,
                    "end": 37,
                    "type": "bibr",
                    "ref_id": "b10",
                    "text": "11]"
                }
            ]
        },
        {
            "text": "We conveniently refer to any method that constructs approximate CIs based on Chi-square thresholds as a Wilks' CI method.",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 6,
            "section_rank": 2
        },
        {
            "text": "In theory, forming CIs using test statistics of the form \u2206\u03c7 2 (\u03b2; X) is desirable, because it leads to a unified approach in setting limits in the absence of new physics signals and in estimating parameters after the discovery of new physics [6]. ",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 7,
            "section_rank": 2,
            "ref_spans": [
                {
                    "start": 242,
                    "end": 245,
                    "type": "bibr",
                    "ref_id": "b5",
                    "text": "[6]"
                }
            ]
        },
        {
            "text": "However, in the problem of searching for sterile neutrinos, the computationally expensive MC CI method is usually necessary to obtain valid thresholds t c for the \u2206\u03c7 2 statistic, making the application difficult.",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 7,
            "section_rank": 2
        },
        {
            "text": "Compared to \u2206\u03c7 2 , the following test statistic, \u2206T , has a parent distribution that is easy to approximate under mild conditions. ",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 8,
            "section_rank": 2
        },
        {
            "text": "An example of \u2206T is the negative-two-log-likelihood ratio statistic for H 0 and H 1 . ",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 9,
            "section_rank": 2
        },
        {
            "text": "Given observed data x and a fixed \u03b2 ref , all \u03b2 1 values that result in Prob \u03b21 (\u2206T (\u03b2 ref , \u03b2 1 ; X) \u2264 t \u2032 c ) \u2265 c constitute a level-c CI. ",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 9,
            "section_rank": 2
        },
        {
            "text": "It is proven in Sec. ",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 9,
            "section_rank": 2
        },
        {
            "text": "III B that under fairly mild conditions, one can approximate t \u2032 c using quantiles of a Gaussian distribution. ",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 9,
            "section_rank": 2
        },
        {
            "text": "Specifically, we show that when the data size is large, the distribution of \u2206T (X), where X represents potential data from a model that satisfies either one of the two hypotheses, say H, can be approximated by the Gaussian distribution with mean \u2206T H and standard deviation 2",
            "section": "I. INTRODUCTION",
            "paragraph_rank": 9,
            "section_rank": 2
        },
        {
            "text": "\u221a",
            "section_rank": 3
        },
        {
            "text": "|\u2206T H |. ",
            "section": "\u221a",
            "paragraph_rank": 10,
            "section_rank": 3
        },
        {
            "text": "Here, \u2206T H is defined to be \u2206T (x Asimov H ) as in Eq. ",
            "section": "\u221a",
            "paragraph_rank": 10,
            "section_rank": 3
        },
        {
            "text": "(19), where x Asimov H is the Asimov data set [12] as introduced in Sec. ",
            "section": "\u221a",
            "paragraph_rank": 10,
            "section_rank": 3,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 4,
                    "type": "bibr",
                    "ref_id": "b18",
                    "text": "(19)"
                },
                {
                    "start": 46,
                    "end": 50,
                    "type": "bibr",
                    "ref_id": "b11",
                    "text": "[12]"
                }
            ]
        },
        {
            "text": "III.",
            "section": "\u221a",
            "paragraph_rank": 10,
            "section_rank": 3
        },
        {
            "text": "However, CIs constructed from \u2206T can exclude \u03b2 1 values that are not much less compatible with the data than \u03b2 ref is, which we demonstrate in Sec. ",
            "section": "\u221a",
            "paragraph_rank": 11,
            "section_rank": 3
        },
        {
            "text": "V D. To avoid counter-intuitive results based on \u2206T , we take the CL s approach of setting exclusion sets [13][14][15] as an alternative to the CI approach. ",
            "section": "\u221a",
            "paragraph_rank": 11,
            "section_rank": 3,
            "ref_spans": [
                {
                    "start": 106,
                    "end": 110,
                    "type": "bibr",
                    "ref_id": "b12",
                    "text": "[13]"
                },
                {
                    "start": 110,
                    "end": 114,
                    "type": "bibr",
                    "ref_id": "b13",
                    "text": "[14]"
                },
                {
                    "start": 114,
                    "end": 118,
                    "type": "bibr",
                    "ref_id": "b14",
                    "text": "[15]"
                }
            ]
        },
        {
            "text": "We refer to the simple procedure of setting exclusion sets based on the \u2206T statistic using a Gaussian approximation as the Gaussian CL s method.",
            "section": "\u221a",
            "paragraph_rank": 11,
            "section_rank": 3
        },
        {
            "text": "Note that an exclusion set imposes a different kind of constraint than that of (the complement of) a CI. ",
            "section": "\u221a",
            "paragraph_rank": 12,
            "section_rank": 3
        },
        {
            "text": "An exclusion set aims at identifying parameter values that fit the data much worse than the reference model. ",
            "section": "\u221a",
            "paragraph_rank": 12,
            "section_rank": 3
        },
        {
            "text": "Consequently, the CL s approach is more reluctant than the CI approach to exclude models where the experiment has little sensitivity. ",
            "section": "\u221a",
            "paragraph_rank": 12,
            "section_rank": 3
        },
        {
            "text": "An example comparing the two can be found in Sec. ",
            "section": "\u221a",
            "paragraph_rank": 12,
            "section_rank": 3
        },
        {
            "text": "V D.",
            "section": "\u221a",
            "paragraph_rank": 12,
            "section_rank": 3
        },
        {
            "text": "The main contribution of this paper is to provide a mathematical proof for a Gaussian approximation to the distribution of \u2206T . ",
            "section": "\u221a",
            "paragraph_rank": 13,
            "section_rank": 3
        },
        {
            "text": "This result justifies the Gaussian CL s method, which requires a computational load similar to that of the Wilks' CI method, and the former is valid in situations where the latter is not. ",
            "section": "\u221a",
            "paragraph_rank": 13,
            "section_rank": 3
        },
        {
            "text": "Results similar to ours can be found in Ref. ",
            "section": "\u221a",
            "paragraph_rank": 13,
            "section_rank": 3
        },
        {
            "text": "[12] in the context of searching new particles, and in Ref. ",
            "section": "\u221a",
            "paragraph_rank": 13,
            "section_rank": 3,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 4,
                    "type": "bibr",
                    "ref_id": "b11",
                    "text": "[12]"
                }
            ]
        },
        {
            "text": "[16,17] in the context of neutrino mass hierarchy determinations. ",
            "section": "\u221a",
            "paragraph_rank": 13,
            "section_rank": 3,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 4,
                    "type": "bibr",
                    "ref_id": "b15",
                    "text": "[16,"
                },
                {
                    "start": 4,
                    "end": 7,
                    "type": "bibr",
                    "ref_id": "b16",
                    "text": "17]"
                }
            ]
        },
        {
            "text": "The self-contained proof provided in this paper makes it easier to fully articulate the required conditions, which were missing in the previous work. ",
            "section": "\u221a",
            "paragraph_rank": 13,
            "section_rank": 3
        },
        {
            "text": "Also, we make a more general and realistic assumption in accordance with the physics problem of interest than that of Ref. ",
            "section": "\u221a",
            "paragraph_rank": 13,
            "section_rank": 3
        },
        {
            "text": "[12] and the paper by Wald [10] cited therein. ",
            "section": "\u221a",
            "paragraph_rank": 13,
            "section_rank": 3,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 4,
                    "type": "bibr",
                    "ref_id": "b11",
                    "text": "[12]"
                },
                {
                    "start": 27,
                    "end": 31,
                    "type": "bibr",
                    "ref_id": "b9",
                    "text": "[10]"
                }
            ]
        },
        {
            "text": "For details, see assumptions [A0] and [A1] in Sec. ",
            "section": "\u221a",
            "paragraph_rank": 13,
            "section_rank": 3
        },
        {
            "text": "III B 2.",
            "section": "\u221a",
            "paragraph_rank": 13,
            "section_rank": 3
        },
        {
            "text": "Another contribution of this paper is that we compare various methods that take the CI approach or the CL s approach in a problem of searching for neutrino oscillations, where the CL s approach was rarely used before. ",
            "section": "\u221a",
            "paragraph_rank": 14,
            "section_rank": 3
        },
        {
            "text": "Based on the comparisons, we advocate the Gaussian CL s as an attractive alternative method to the CI approach in the application of searching for new physics through precision measurements. ",
            "section": "\u221a",
            "paragraph_rank": 14,
            "section_rank": 3
        },
        {
            "text": "First, the Gaussian CL s method is inexpensive to carry out and is valid in very general setups. ",
            "section": "\u221a",
            "paragraph_rank": 14,
            "section_rank": 3
        },
        {
            "text": "Secondly, researchers often need to combine results from different experiments. ",
            "section": "\u221a",
            "paragraph_rank": 14,
            "section_rank": 3
        },
        {
            "text": "When conditions in the Wilks' theorem are not satisfied, it is simple to combine the test statistics from different experiments and form an overall CI using the Wilks' method. ",
            "section": "\u221a",
            "paragraph_rank": 14,
            "section_rank": 3
        },
        {
            "text": "Otherwise, expensive MC methods have to be used to form CIs for each experiment, and there is no rigorous way to combine these results together other than to rerun a more expensive MC for the combined data. ",
            "section": "\u221a",
            "paragraph_rank": 14,
            "section_rank": 3
        },
        {
            "text": "In contrast, we explain in Sec. ",
            "section": "\u221a",
            "paragraph_rank": 14,
            "section_rank": 3
        },
        {
            "text": "VI that experimental results can be easily combined using the Gaussian CL s method, and is valid under mild conditions. ",
            "section": "\u221a",
            "paragraph_rank": 14,
            "section_rank": 3
        },
        {
            "text": "This paper is organized as follows. ",
            "section": "\u221a",
            "paragraph_rank": 14,
            "section_rank": 3
        },
        {
            "text": "In Sec. ",
            "section": "\u221a",
            "paragraph_rank": 14,
            "section_rank": 3
        },
        {
            "text": "II, we briefly review the CI approach that utilizes a class of statistics, \u2206\u03c7 2 . ",
            "section": "\u221a",
            "paragraph_rank": 14,
            "section_rank": 3
        },
        {
            "text": "We look at both the Wilks' CI method and the MC CI method, and discuss their advantages and limitations. ",
            "section": "\u221a",
            "paragraph_rank": 14,
            "section_rank": 3
        },
        {
            "text": "In Sec. ",
            "section": "\u221a",
            "paragraph_rank": 14,
            "section_rank": 3
        },
        {
            "text": "III, we describe an alternative class of statistics, \u2206T . ",
            "section": "\u221a",
            "paragraph_rank": 14,
            "section_rank": 3
        },
        {
            "text": "In Sec. ",
            "section": "\u221a",
            "paragraph_rank": 14,
            "section_rank": 3
        },
        {
            "text": "IV, we describe the CL s approach based on the \u2206T statistic, and outline a simple procedure to carry it out using the Gaussian approximation. ",
            "section": "\u221a",
            "paragraph_rank": 14,
            "section_rank": 3
        },
        {
            "text": "In Sec. ",
            "section": "\u221a",
            "paragraph_rank": 14,
            "section_rank": 3
        },
        {
            "text": "V, using an example of the search for a sterile neutrino, we check the validity of the approximation in the Gaussian CL s method, and compare different methods of forming constraints in the parameter space. ",
            "section": "\u221a",
            "paragraph_rank": 14,
            "section_rank": 3
        },
        {
            "text": "Finally, we present discussions and summaries in Sec. ",
            "section": "\u221a",
            "paragraph_rank": 14,
            "section_rank": 3
        },
        {
            "text": "VI and Sec. ",
            "section": "\u221a",
            "paragraph_rank": 14,
            "section_rank": 3
        },
        {
            "text": "VII, respectively.",
            "section": "\u221a",
            "paragraph_rank": 14,
            "section_rank": 3
        },
        {
            "text": "II. ",
            "section_rank": 4
        },
        {
            "text": "THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "section_rank": 4
        },
        {
            "text": "In this section, we briefly review the traditional method of setting CIs in the context of neutrino oscillations. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 15,
            "section_rank": 4
        },
        {
            "text": "We consider a neutrino energy spectrum that consists of n energy bins, and assume that the mean number of counts in each bin is a function of the vector of parameters of main interest, \u03b2 = (sin 2 2\u03b8, |\u2206m 2 |), and a vector of nuisance parameters (such as the overall normalization), \u03b7. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 15,
            "section_rank": 4
        },
        {
            "text": "Let \u0398, M , and H denote the parameter space of sin 2 2\u03b8, |\u2206m 2 |, and \u03b7, respectively. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 15,
            "section_rank": 4
        },
        {
            "text": "There are two further physical constraints: sin 2 2\u03b8 \u2265 0 and |\u2206m 2 | \u2265 0. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 15,
            "section_rank": 4
        },
        {
            "text": "Then for the i-th bin, \u03bb i (sin 2 2\u03b8, |\u2206m 2 |, \u03b7) and N i represent the mean and the observed counts of neutrino induced interactions, respectively. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 15,
            "section_rank": 4
        },
        {
            "text": "When \u03bb i is large enough, the distribution of N i can be well approximated by a Gaussian distribution with mean \u03bb i and standard deviation \u221a \u03bb i . ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 15,
            "section_rank": 4
        },
        {
            "text": "Given any specific guess of the value of the parameters (sin 2 2\u03b8, |\u2206m 2 |, \u03b7), once the data x = {N i , i = 1, . . . , n} are observed, one can calculate the deviation of the data from the mean values \u03bb i to measure the compatibility of the hypothesized parameter values to x. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 15,
            "section_rank": 4
        },
        {
            "text": "Commonly used deviations include negative-two-log-likelihood ratio, Pearson chi-square and Neyman chi-square. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 15,
            "section_rank": 4
        },
        {
            "text": "Further, when certain knowledge concerning the nuisance parameter \u03b7 (e.g. knowledge of detecting efficiency and neutrino flux) is available, it can be reflected in the definition of the deviation. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 15,
            "section_rank": 4
        },
        {
            "text": "For example, to modify the Pearson Chisquare, denoted by \u03c7 2 P , when previous experiments suggest an estimate of \u03b7 to be \u03b7 0 with standard deviation \u03c3 \u03b7 , one can define the following deviation function:",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 15,
            "section_rank": 4
        },
        {
            "text": "Below, we use the notation arg min w h(w) to denote the value of w that minimizes any given function h, and the standard set-builder notation {h(w) : restriction w} to denote a set that is made up of all the points h(w) such that w satisfies the restriction to the right of the colon. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 16,
            "section_rank": 4
        },
        {
            "text": "Let",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 16,
            "section_rank": 4
        },
        {
            "text": "that is, the value of ( sin 2 2\u03b8, |\u2206m 2 |, \u03b7 ) \u2208 \u0398 \u00d7 M \u00d7 H that best fits the data according to the deviation \u03c7 2 . ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 17,
            "section_rank": 4
        },
        {
            "text": "Also, let",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 17,
            "section_rank": 4
        },
        {
            "text": "And for any given (sin 2 2\u03b8, |\u2206m",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 18,
            "section_rank": 4
        },
        {
            "text": "Then we can define a test statistic that reflects how much worse (sin 2 2\u03b8, |\u2206m 2 |) is than that of the best fit, namely,",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 19,
            "section_rank": 4
        },
        {
            "text": "The corresponding CI with confidence level c is defined to be",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 20,
            "section_rank": 4
        },
        {
            "text": "The term t c represents the threshold value such that,",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 21,
            "section_rank": 4
        },
        {
            "text": "The key in constructing a CI is to specify t c correctly for a given confidence level c.",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 22,
            "section_rank": 4
        },
        {
            "text": "Most commonly examined confidence levels use c = 68.3% (1\u03c3), 95.5% (2\u03c3), 99.7% (3\u03c3), which are often linked to threshold values t c = 2.31, 5.99, 11.8, respectively [8]. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 23,
            "section_rank": 4,
            "ref_spans": [
                {
                    "start": 165,
                    "end": 168,
                    "type": "bibr",
                    "ref_id": "b7",
                    "text": "[8]"
                }
            ]
        },
        {
            "text": "Note that these three values are the 68.3%, 95.5% and 99.7% quantiles of the Chi-square distribution with two degrees of freedom, respectively. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 23,
            "section_rank": 4
        },
        {
            "text": "The reason why these threshold values are used is that, CI c is indeed constructed upon screening the entire param-eter space by inspecting one point at a time, denoted by (sin 2 2\u03b8 1 , |\u2206m 2 1 |), and testing the pair of hypotheses, H 0 : (sin 2 2\u03b8, |\u2206m 2 |) = (sin 2 2\u03b8 1 , |\u2206m 2 1 |) versus H 1 : otherwise. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 23,
            "section_rank": 4,
            "ref_spans": [
                {
                    "start": 190,
                    "end": 191,
                    "type": "bibr",
                    "ref_id": "b1",
                    "text": "2"
                },
                {
                    "start": 280,
                    "end": 281,
                    "type": "bibr",
                    "ref_id": "b1",
                    "text": "2"
                }
            ]
        },
        {
            "text": "To test the above hypotheses using the Chisquare statistic \u2206\u03c7 2 in Eq. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 23,
            "section_rank": 4
        },
        {
            "text": "(7), the full parameter space for (sin 2 2\u03b8, |\u2206m 2 |, \u03b7) is \u0398 \u00d7 M \u00d7 H, and the null hypothesis space is {(sin 2 2\u03b8 1 , |\u2206m 2 1 |)} \u00d7 H. According to the Wilks' theorem [9], if certain regularity conditions hold, mainly C1. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 23,
            "section_rank": 4,
            "ref_spans": [
                {
                    "start": 123,
                    "end": 124,
                    "type": "bibr",
                    "ref_id": "b1",
                    "text": "2"
                },
                {
                    "start": 168,
                    "end": 171,
                    "type": "bibr",
                    "ref_id": "b8",
                    "text": "[9]"
                }
            ]
        },
        {
            "text": "the full parameter space \u0398 \u00d7 M \u00d7 H is a continuous space, and the the model likelihood function is a smooth function (for example three times differen-tiable) in the parameters, C2. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 23,
            "section_rank": 4
        },
        {
            "text": "the full parameter space contains an open neighborhood around the true value (sin 2 2\u03b8 1 , |\u2206m 2 1 |, \u03b7 1 ), and C3. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 23,
            "section_rank": 4
        },
        {
            "text": "the data size N i is large for each i = 1, . . . , n, then the statistic \u2206\u03c7 2 (sin 2 2\u03b8 1 , |\u2206m 2 1 |; X) follows approximately a Chi-square distribution when X is data generated from H 0 . ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 23,
            "section_rank": 4,
            "ref_spans": [
                {
                    "start": 96,
                    "end": 97,
                    "type": "bibr",
                    "ref_id": "b1",
                    "text": "2"
                }
            ]
        },
        {
            "text": "Further, the degree of freedom of this Chi-square distribution equals the difference between the dimension of the full parameter space and that of the null hypothesis space, namely 2, in the current case. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 23,
            "section_rank": 4
        },
        {
            "text": "This procedure of constructing CIs and its extensions have been successfully applied in many studies in order to constrain various parameters in the field of neutrino physics (e.g. Ref. [18]).",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 23,
            "section_rank": 4,
            "ref_spans": [
                {
                    "start": 186,
                    "end": 190,
                    "type": "bibr",
                    "ref_id": "b17",
                    "text": "[18]"
                }
            ]
        },
        {
            "text": "Although the above Wilks' CI method has been widely used in analyzing experimental data, it does not always produce CIs that have correct coverage. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 24,
            "section_rank": 4
        },
        {
            "text": "Its limitations have been addressed by, for example, Feldman and Cousins [6]. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 24,
            "section_rank": 4,
            "ref_spans": [
                {
                    "start": 73,
                    "end": 76,
                    "type": "bibr",
                    "ref_id": "b5",
                    "text": "[6]"
                }
            ]
        },
        {
            "text": "One example is the searches for neutrino oscillations in the disappearance mode. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 24,
            "section_rank": 4
        },
        {
            "text": "The oscillation probability with (sin 2 2\u03b8, |\u2206m 2 |) in a 2-flavor framework is written as:",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 24,
            "section_rank": 4
        },
        {
            "text": "where L and E \u03bd i are the distance neutrino travels and the neutrino energy at the i-th bin, respectively. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 25,
            "section_rank": 4
        },
        {
            "text": "Then the mean bin counts",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 25,
            "section_rank": 4
        },
        {
            "text": ", where a i and b i are coefficients that depend on the vector of nuisance parameters \u03b7, and m represents the amount of accumulated data (e.g. the elapsed time for data collection).",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 26,
            "section_rank": 4
        },
        {
            "text": "The reason why the Wilks' CI method fails for the above neutrino oscillations example is the following. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 27,
            "section_rank": 4
        },
        {
            "text": "A key middle step in the proof of the Wilks' theorem is that conditions C1\u22123 together ensure that the estimator of (sin 2 2\u03b8, |\u2206m 2 |) based on minimizing \u03c7 2 , has a distribution close to a Gaussian distribution. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 27,
            "section_rank": 4
        },
        {
            "text": "This suggests two cases. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 27,
            "section_rank": 4
        },
        {
            "text": "(1) When testing a hypothesis H of the form: sin 2 2\u03b8 = 0 for any value of |\u2206m 2 |, C2 is violated, hence the Wilks' theorem does not apply no matter how large the data size is. (2) When testing hypotheses of all other forms, C1 and C2 are both satisfied, hence as the sample size grows to infinity, the distribution of \u2206\u03c7 2 will eventually converge to a Chi-square distribution. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 27,
            "section_rank": 4
        },
        {
            "text": "However, for instance if the true sin 2 2\u03b8 is close to 0, then there could be a non-ignorable probability that we observe a data set that results in sin 2 2\u03b8 min = 0. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 27,
            "section_rank": 4
        },
        {
            "text": "This clearly prevents the distribution of (sin 2 2\u03b8 min , |\u2206m 2 min |) from being closely approximated by a Gaussian distribution. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 27,
            "section_rank": 4,
            "ref_spans": [
                {
                    "start": 62,
                    "end": 63,
                    "type": "bibr",
                    "ref_id": "b1",
                    "text": "2"
                }
            ]
        },
        {
            "text": "Indeed, the closer sin 2 2\u03b8 0 is to 0, the larger the data size is needed to overcome the above phenomena.",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 27,
            "section_rank": 4
        },
        {
            "text": "The latter point can also be understood intuitively. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 28,
            "section_rank": 4
        },
        {
            "text": "The parameter space of sin 2 2\u03b8 vs. |\u2206m 2 |, as is usually displayed in Fig. 1a, is uniform. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 28,
            "section_rank": 4,
            "ref_spans": [
                {
                    "start": 72,
                    "end": 79,
                    "type": "figure",
                    "ref_id": "fig_1",
                    "text": "Fig. 1a"
                }
            ]
        },
        {
            "text": "But the effective parameter space of (sin 2 \u03b8, |\u2206m 2 |), in which the distance between any two points is measured by \u03c7 2 defined in Eq. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 28,
            "section_rank": 4
        },
        {
            "text": "3, is no longer uniform (Fig. 1b). ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 28,
            "section_rank": 4,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 1,
                    "text": "3"
                },
                {
                    "start": 24,
                    "end": 33,
                    "type": "figure",
                    "ref_id": "fig_1",
                    "text": "(Fig. 1b)"
                }
            ]
        },
        {
            "text": "Due to the functional form of the oscillation formula, the effective parameter space becomes more compact at smaller sin 2 2\u03b8, as the differences between spectra with different values of |\u2206m 2 | become smaller. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 28,
            "section_rank": 4
        },
        {
            "text": "Therefore, more data is needed to reach the large data limit required by the Wilks' theorem in order to maintain the open neighborhood around the true parameter values (regularity condition C2). ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 28,
            "section_rank": 4
        },
        {
            "text": "For example, the true sin 2 2\u03b8 = 0 hypothesis does not have an open neighborhood, as sin 2 2\u03b8 < 0 is not allowed. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 28,
            "section_rank": 4
        },
        {
            "text": "It is therefore impossible to reach the large data limit. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 28,
            "section_rank": 4
        },
        {
            "text": "Even for non-zero but small true value of sin 2 2\u03b8, the required data size could be well beyond the experimental reach.",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 28,
            "section_rank": 4
        },
        {
            "text": "When these regularity conditions are not satisfied, there are instances when the parent distribution of \u2206\u03c7 2 can have simple approximations that are not necessarily Chi-square. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 29,
            "section_rank": 4
        },
        {
            "text": "See, for e.g. Ref. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 29,
            "section_rank": 4
        },
        {
            "text": "[12,Sec. 3], where the parameter \u03b2 has dimension 1. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 29,
            "section_rank": 4,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 4,
                    "type": "bibr",
                    "ref_id": "b11",
                    "text": "[12,"
                },
                {
                    "start": 4,
                    "end": 11,
                    "type": "bibr",
                    "text": "Sec. 3]"
                }
            ]
        },
        {
            "text": "For more general cases, one needs the MC method to set CIs. ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 29,
            "section_rank": 4
        },
        {
            "text": "Below, we review how to produce a valid 1-\u03c3 (68%) CI of (sin 2 2\u03b8, |\u2206m 2 |) using MC, which can be easily generalized to build CIs of any level.",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 29,
            "section_rank": 4
        },
        {
            "text": "Having observed data ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 30,
            "section_rank": 4
        },
        {
            "text": "n } is generated from the model with true parameter value (sin 2 2\u03b8, |\u2206m 2 |).",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 31,
            "section_rank": 4
        },
        {
            "text": "Here, the nuisance parameters can be either randomly generated according to the common hybrid Bayesian/Frequentist approach [19] or fixed at the best-fit values from data according to the full Frequentist approach [7,20].",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 32,
            "section_rank": 4,
            "ref_spans": [
                {
                    "start": 124,
                    "end": 128,
                    "type": "bibr",
                    "ref_id": "b18",
                    "text": "[19]"
                },
                {
                    "start": 214,
                    "end": 217,
                    "type": "bibr",
                    "ref_id": "b6",
                    "text": "[7,"
                },
                {
                    "start": 217,
                    "end": 220,
                    "type": "bibr",
                    "ref_id": "b19",
                    "text": "20]"
                }
            ]
        },
        {
            "text": "For j = 1, . . . , T , calculate \u2206\u03c7 2 (sin 2 2\u03b8, |\u2206m 2 |; x (j) ). ",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 33,
            "section_rank": 4,
            "ref_spans": [
                {
                    "start": 60,
                    "end": 63,
                    "type": "bibr",
                    "text": "(j)"
                }
            ]
        },
        {
            "text": "This produces an empirical distribution of the statistic \u2206\u03c7 2 .",
            "section": "II. THE CONFIDENCE INTERVAL APPROACH BASED ON THE \u2206\u03c7 2 STATISTIC",
            "paragraph_rank": 33,
            "section_rank": 4
        },
        {
            "text": "Calculate the percentage of MC samples such that",
            "section_rank": 5
        },
        {
            "text": "is included in the 1-\u03c3 CI if and only if the percentage is smaller than 68%.",
            "section": "Calculate the percentage of MC samples such that",
            "paragraph_rank": 34,
            "section_rank": 5
        },
        {
            "text": "The key of the above procedure is to generate an empirical distribution of \u2206\u03c7 2 , which is not necessarily close to a Chi-square distribution. ",
            "section": "Calculate the percentage of MC samples such that",
            "paragraph_rank": 35,
            "section_rank": 5
        },
        {
            "text": "Unlike the Wilks' CI method, the MC CI method guarantees the validity of the resulting CIs when the MC sample size is large. ",
            "section": "Calculate the percentage of MC samples such that",
            "paragraph_rank": 35,
            "section_rank": 5
        },
        {
            "text": "However, the procedure can be very time-consuming when the dimension of the vector of unknown parameters is high and/or when a fine grid of the parameter space needs to be examined. ",
            "section": "Calculate the percentage of MC samples such that",
            "paragraph_rank": 35,
            "section_rank": 5
        },
        {
            "text": "In addition, the number of MC samples needed to produce an empirical distribution that leads to an accurate enough CI increases quickly as the required confidence level increases. ",
            "section": "Calculate the percentage of MC samples such that",
            "paragraph_rank": 35,
            "section_rank": 5
        },
        {
            "text": "The procedure can become prohibitively expensive if the minimization process used to find (sin 2 2\u03b8 min , |\u2206m 2 min |) is slow due to the existence of many nuisance parameters or other technical difficulties.",
            "section": "Calculate the percentage of MC samples such that",
            "paragraph_rank": 35,
            "section_rank": 5,
            "ref_spans": [
                {
                    "start": 110,
                    "end": 111,
                    "type": "bibr",
                    "ref_id": "b1",
                    "text": "2"
                }
            ]
        },
        {
            "text": "Furthermore, there is no simple recipe to strictly combine the CIs generated with the MC CI method from different experiments to form an overall CI. ",
            "section": "Calculate the percentage of MC samples such that",
            "paragraph_rank": 36,
            "section_rank": 5
        },
        {
            "text": "To see this, consider an example where several experiments are carried out to probe the parameter space of (sin 2 2\u03b8, |\u2206m 2 |). ",
            "section": "Calculate the percentage of MC samples such that",
            "paragraph_rank": 36,
            "section_rank": 5
        },
        {
            "text": "For any space point (sin 2 2\u03b8, |\u2206m 2 |), the \u2206\u03c7 2 statistic of the jth experiment is given by \u03c7 2 (sin 2 2\u03b8, |\u2206m 2 min | (j) ). ",
            "section": "Calculate the percentage of MC samples such that",
            "paragraph_rank": 36,
            "section_rank": 5,
            "ref_spans": [
                {
                    "start": 113,
                    "end": 114,
                    "type": "bibr",
                    "ref_id": "b1",
                    "text": "2"
                }
            ]
        },
        {
            "text": "Note that the minimum-value parameter space point, (sin 2 2\u03b8 min , |\u2206m 2 min |), based on different experiments are typically different. ",
            "section": "Calculate the percentage of MC samples such that",
            "paragraph_rank": 36,
            "section_rank": 5,
            "ref_spans": [
                {
                    "start": 71,
                    "end": 72,
                    "type": "bibr",
                    "ref_id": "b1",
                    "text": "2"
                }
            ]
        },
        {
            "text": "Once the experiments are combined, a strict implementation of the MC CI method requires to know the global minimumvalue parameter space point, which is in general unattainable. ",
            "section": "Calculate the percentage of MC samples such that",
            "paragraph_rank": 36,
            "section_rank": 5
        },
        {
            "text": "Indeed, one has to redo MC simulations for the combined data, which is expensive in computation since minimization has to be done for each MC sample.",
            "section": "Calculate the percentage of MC samples such that",
            "paragraph_rank": 36,
            "section_rank": 5
        },
        {
            "text": "In the next section, we introduce a different test statistic from \u2206\u03c7 2 , which allows for a simple approximation to its distribution under mild conditions. ",
            "section": "Calculate the percentage of MC samples such that",
            "paragraph_rank": 37,
            "section_rank": 5
        },
        {
            "text": "Using this new test statistic helps circumvent the computational problems mentioned above.",
            "section": "Calculate the percentage of MC samples such that",
            "paragraph_rank": 37,
            "section_rank": 5
        },
        {
            "text": "III. ",
            "section_rank": 6
        },
        {
            "text": "THE \u2206T STATISTIC",
            "section_rank": 6
        },
        {
            "text": "A. Non-nested hypotheses testing",
            "section_rank": 7
        },
        {
            "text": "Recall that we used \u03b2 and \u03b7 to denote the parameter of interest and the nuisance parameter respec-tively. ",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 38,
            "section_rank": 7
        },
        {
            "text": "The corresponding model has mean bin counts",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 38,
            "section_rank": 7
        },
        {
            "text": "Let B denote the parameter space for \u03b2. ",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 39,
            "section_rank": 7
        },
        {
            "text": "In this section, we consider pairs of nonnested hypotheses H 0 : \u03b2 = \u03b2 0 and H 1 : \u03b2 = \u03b2 1 , one pair at a time, for any \u03b2 0 \u0338 = \u03b2 1 \u2208 B. For convenience and clarity, we update some of our notations and refer to the nuisance parameter under H 0 and H 1 as \u03b7 and \u03b6 respectively, and they can be of different dimensions. ",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 39,
            "section_rank": 7
        },
        {
            "text": "Also, we refer to the mean bin counts associated with \u03b2 0 and \u03b2 1 as \u00b5 and \u03bd respectively, that is, the mean count of the ith bin is",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 39,
            "section_rank": 7
        },
        {
            "text": "We now introduce a test statistic, denoted by \u2206T (\u03b2 0 , \u03b2 1 ; x), or simply \u2206T (x), for testing H 0 versus H 1 . ",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 40,
            "section_rank": 7
        },
        {
            "text": "More than one version of the definition of \u2206T will be listed below.",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 40,
            "section_rank": 7
        },
        {
            "text": "We start with either the Poisson or the Normal distribution to model the data x, and use the general notation L(x, \u03bb) to denote the corresponding likelihood, where \u03bb equals to \u00b5(\u03b7) under H 0 , and \u03bd(\u03b6) under H 1 , respectively. ",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 41,
            "section_rank": 7
        },
        {
            "text": "Following the practice of Ref. ",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 41,
            "section_rank": 7
        },
        {
            "text": "[21, sec. 2], we convert 4 the likelihood functions under H 0 and H 1 into T H0 (\u03b7; x) and T H1 (\u03b7; x) respectively. ",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 41,
            "section_rank": 7,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 12,
                    "type": "bibr",
                    "text": "[21, sec. 2]"
                }
            ]
        },
        {
            "text": "Let",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 41,
            "section_rank": 7
        },
        {
            "text": "and define",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 42,
            "section_rank": 7
        },
        {
            "text": ", and (11)",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 43,
            "section_rank": 7
        },
        {
            "text": "both of which can be interpreted as likelihood ratios. ",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 44,
            "section_rank": 7
        },
        {
            "text": "Take the Poisson model for example, we have",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 44,
            "section_rank": 7
        },
        {
            "text": "and",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 45,
            "section_rank": 7
        },
        {
            "text": "Then, looking at the definition of T H0 for instance, we have",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 46,
            "section_rank": 7
        },
        {
            "text": "In practice, when there are prior experiments carried out to study the nuisance parameters, an additional term that reflects deviation from this prior knowledge is added to the definition of T H0 (\u03b7; x). ",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 47,
            "section_rank": 7
        },
        {
            "text": "We denote this term by \u03c7 2 penalty (\u03b7), an example of which is the term",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 47,
            "section_rank": 7
        },
        {
            "text": "in Eq. ",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 48,
            "section_rank": 7
        },
        {
            "text": "3. ",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 48,
            "section_rank": 7,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 1,
                    "text": "3"
                }
            ]
        },
        {
            "text": "And when the data size is large, terms of smaller order are sometimes omitted from the definition of T H0 (\u03b7; x). ",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 48,
            "section_rank": 7
        },
        {
            "text": "There are at least four common variations for T H0 (\u03b7; x) used in practice:",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 48,
            "section_rank": 7
        },
        {
            "text": "Here, Eq. ",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 49,
            "section_rank": 7
        },
        {
            "text": "15 . ",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 49,
            "section_rank": 7,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 2,
                    "ref_id": "formula_24",
                    "text": "15"
                }
            ]
        },
        {
            "text": "We can define four versions of T H1 (\u03b6; x) similarly. ",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 49,
            "section_rank": 7
        },
        {
            "text": "En route to form the test statistic \u2206T , T H0 (\u03b7; x) and T H1 (\u03b6; x) are further minimized over all nuisance parameters, to obtain T min H0 (x) = min \u03b7 T H0 (\u03b7; x) and T min H1 (x) = min \u03b6 T H1 (\u03b6; x), respectively. ",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 49,
            "section_rank": 7
        },
        {
            "text": "Finally, we define the test statistic",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 49,
            "section_rank": 7
        },
        {
            "text": "Note that \u2206T (x) has the interpretation of being a loglikelihood ratio test statistic (or certain variations of it, depending on which version of the definition of T H0 and 5 As summarized in Ref. ",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 50,
            "section_rank": 7,
            "ref_spans": [
                {
                    "start": 173,
                    "end": 174,
                    "type": "bibr",
                    "ref_id": "b4",
                    "text": "5"
                }
            ]
        },
        {
            "text": "[21], all the above estimators had a set of properties which the authors considered optimal. ",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 50,
            "section_rank": 7,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 4,
                    "type": "bibr",
                    "ref_id": "b20",
                    "text": "[21]"
                }
            ]
        },
        {
            "text": "They called them \"best asymptotically normal\" (BAN) estimators. ",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 50,
            "section_rank": 7
        },
        {
            "text": "The versions of test statistics based directly on likelihood functions are considered superior due to their faster convergence to the limiting chi-square distributions.",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 50,
            "section_rank": 7
        },
        {
            "text": "T H1 are used) between the two hypotheses. ",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 51,
            "section_rank": 7
        },
        {
            "text": "It is easy to see that a positive \u2206T (x) would favor H 0 , and a negative \u2206T (x) would favor H 1 . ",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 51,
            "section_rank": 7
        },
        {
            "text": "In addition, the absolute size of \u2206T (x) reflects how much one hypothesis is favored over the other. ",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 51,
            "section_rank": 7
        },
        {
            "text": "6 Remark. ",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 51,
            "section_rank": 7,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 1,
                    "type": "bibr",
                    "ref_id": "b5",
                    "text": "6"
                }
            ]
        },
        {
            "text": "We emphasize that \u2206T (x) is a different type of test statistic than \u2206\u03c7 2 (x) in Eq. ",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 51,
            "section_rank": 7
        },
        {
            "text": "7. ",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 51,
            "section_rank": 7,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 1,
                    "ref_id": "formula_6",
                    "text": "7"
                }
            ]
        },
        {
            "text": "Specifically, \u2206T (x) involves the best fit under the restrictions H 0 and H 1 , respectively, while \u2206\u03c7 2 (x) involves the best fit under the restrictions H 0 and over the full parameter space, respectively. ",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 51,
            "section_rank": 7
        },
        {
            "text": "The way \u2206T is defined is key to why there is a Gaussian approximation that works under very general setups, even in the cases where simple approximations for the conventional \u2206\u03c7 2 statistic fails. ",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 51,
            "section_rank": 7
        },
        {
            "text": "Nevertheless, we should note that, when the computing is affordable, forming CIs using \u2206\u03c7 2 is more desirable because it leads to a unified approach for setting limits in absence of new physics signals and in estimating parameters after the discovery of new physics [6].",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 51,
            "section_rank": 7,
            "ref_spans": [
                {
                    "start": 266,
                    "end": 269,
                    "type": "bibr",
                    "ref_id": "b5",
                    "text": "[6]"
                }
            ]
        },
        {
            "text": "Next, we introduce the concept of the Asimov data set [12]. ",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 52,
            "section_rank": 7,
            "ref_spans": [
                {
                    "start": 54,
                    "end": 58,
                    "type": "bibr",
                    "ref_id": "b11",
                    "text": "[12]"
                }
            ]
        },
        {
            "text": "Let x Asimov",
            "section": "A. Non-nested hypotheses testing",
            "paragraph_rank": 52,
            "section_rank": 7
        },
        {
            "text": "H0",
            "section_rank": 8
        },
        {
            "text": "denote the Asimov data set under H 0 , which is, loosely speaking, the mean counts corresponding to the true model in H 0 without any statistical fluctuation nor variations of systematics (change in nuisance parameters from their true value). ",
            "section": "H0",
            "paragraph_rank": 53,
            "section_rank": 8
        },
        {
            "text": "In mathematical symbols, x Asimov",
            "section": "H0",
            "paragraph_rank": 53,
            "section_rank": 8
        },
        {
            "text": "H0",
            "section_rank": 9
        },
        {
            "text": "= \u00b5(\u03b7 0 ), where \u03b7 0 stands for the true value of the nuisance parameter. ",
            "section": "H0",
            "paragraph_rank": 54,
            "section_rank": 9
        },
        {
            "text": "In practice, we do not know \u03b7 0 , so it is commonly approximated by an existing nominal value of the nuisance parameter (such as the term \u03b7 0 in Eq. 3).",
            "section": "H0",
            "paragraph_rank": 54,
            "section_rank": 9,
            "ref_spans": [
                {
                    "start": 149,
                    "end": 150,
                    "text": "3"
                }
            ]
        },
        {
            "text": "Finally, we define a term that will help describe the distribution of the test statistic \u2206T under H 0 . ",
            "section": "H0",
            "paragraph_rank": 55,
            "section_rank": 9
        },
        {
            "text": "Assuming that H 0 is the correct hypothesis, define",
            "section": "H0",
            "paragraph_rank": 55,
            "section_rank": 9
        },
        {
            "text": "where the last step holds because T min H0 (x Asimov",
            "section": "H0",
            "paragraph_rank": 56,
            "section_rank": 9
        },
        {
            "text": "H0",
            "section_rank": 10
        },
        {
            "text": ") = 0 by the definition of T min H0 and x Asimov",
            "section": "H0",
            "paragraph_rank": 57,
            "section_rank": 10
        },
        {
            "text": "H0",
            "section_rank": 11
        },
        {
            "text": ":= \u00b5(\u03b7 0 ). ",
            "section": "H0",
            "paragraph_rank": 58,
            "section_rank": 11
        },
        {
            "text": "Analogously, let x Asimov",
            "section": "H0",
            "paragraph_rank": 58,
            "section_rank": 11
        },
        {
            "text": "H1",
            "section_rank": 12
        },
        {
            "text": "= \u03bd(\u03b6 0 ) denote the Asimov data set under H 1 , where we can approximate \u03b6 0 by an existing nominal value. ",
            "section": "H1",
            "paragraph_rank": 59,
            "section_rank": 12
        },
        {
            "text": "Then the following term will help describe the distribution of the test statistic \u2206T , had H 1 been the correct hypothesis:",
            "section": "H1",
            "paragraph_rank": 59,
            "section_rank": 12
        },
        {
            "text": "H1",
            "section_rank": 13
        },
        {
            "text": ").",
            "section": "H1",
            "paragraph_rank": 60,
            "section_rank": 13
        },
        {
            "text": "B. A Gaussian Approximation to the Distribution of \u2206T (X) with Large Data Size",
            "section_rank": 14
        },
        {
            "text": "In this section, we show that by omitting terms of relatively small orders, the distribution of \u2206T (X) under hypothesis H follows approximately a Gaussian distribution with mean \u2206T H and standard deviation 2",
            "section": "B. A Gaussian Approximation to the Distribution of \u2206T (X) with Large Data Size",
            "paragraph_rank": 61,
            "section_rank": 14
        },
        {
            "text": "\u221a",
            "section_rank": 15
        },
        {
            "text": "|\u2206T H |, where H could be either H 0 or H 1 .",
            "section": "\u221a",
            "paragraph_rank": 62,
            "section_rank": 15
        },
        {
            "text": "Description of the mathematical problem and notations",
            "section_rank": 16
        },
        {
            "text": "Recall that we defined four versions of (T H0 (\u03b7; x), T H1 (\u03b6; x)) that yield four different definitions of the test statistic \u2206T (X). ",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 63,
            "section_rank": 16
        },
        {
            "text": "In this section, we focus on studying \u2206T (X) based on Eq. ",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 63,
            "section_rank": 16
        },
        {
            "text": "(17), namely the Pearson Chi-square statistic. ",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 63,
            "section_rank": 16
        },
        {
            "text": "For clarity, we call it D(X) from here on. ",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 63,
            "section_rank": 16
        },
        {
            "text": "The main part of Sec. ",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 63,
            "section_rank": 16
        },
        {
            "text": "III B 2 will be devoted to develop a Gaussian approximation for the distribution of D(X) under H 0 . ",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 63,
            "section_rank": 16
        },
        {
            "text": "And in the remarks in the end of Sec. ",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 63,
            "section_rank": 16
        },
        {
            "text": "III B 2, we show that under H 0 , the differences between the other three versions of \u2206T (X) to D(X) are insignificant under fairly general conditions, so the approximate distribution derived for D(X) can also be used for all the different versions of \u2206T (X). ",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 63,
            "section_rank": 16
        },
        {
            "text": "Note that due to the symmetry between H 0 and H 1 , the aforementioned result also applies to D(X) and its variations under H 1 .",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 63,
            "section_rank": 16
        },
        {
            "text": "The mathematical problem concerning D(X) is the following. ",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 64,
            "section_rank": 16
        },
        {
            "text": "Let",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 64,
            "section_rank": 16
        },
        {
            "text": "and let\u03b7",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 65,
            "section_rank": 16
        },
        {
            "text": "Then the definition of D(X) is",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 66,
            "section_rank": 16
        },
        {
            "text": "Note that",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 67,
            "section_rank": 16
        },
        {
            "text": "that is based on Eq. ",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 68,
            "section_rank": 16
        },
        {
            "text": "17. ",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 68,
            "section_rank": 16,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 2,
                    "ref_id": "formula_26",
                    "text": "17"
                }
            ]
        },
        {
            "text": "Our goal is to obtain an approximation of the distribution of D(X) under H 0 , when the data size is large. ",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 68,
            "section_rank": 16
        },
        {
            "text": "Hence a specific quantity, say m, is needed to reflect the magnitude of the data, in order that we can describe how other quantities in the model change along with it. ",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 68,
            "section_rank": 16
        },
        {
            "text": "For example, m could be the duration of the experiment or the total number of events. ",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 68,
            "section_rank": 16
        },
        {
            "text": "For the ease of description, let m represent the duration of the experiment in this section. ",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 68,
            "section_rank": 16
        },
        {
            "text": "Then p = X m stands for the per unit time observed counts in a potential experiment, and it would remain stable (instead of tending to infinity or zero) as m grows. ",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 68,
            "section_rank": 16
        },
        {
            "text": "So we say p is of order O p (1) (with respect to m) 7 .",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 68,
            "section_rank": 16,
            "ref_spans": [
                {
                    "start": 52,
                    "end": 53,
                    "type": "bibr",
                    "ref_id": "b6",
                    "text": "7"
                }
            ]
        },
        {
            "text": "In order to describe the modeling of counts rigorously, we introduce a set of notations, a summary of which is provided in Table I. Recall that when H 0 is the correct hypothesis, we employed \u00b5(\u03b7) to denote the mean bin counts for models under this hypothesis, where \u03b7 is the vector of unknown nuisance parameters of dimension q. ",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 69,
            "section_rank": 16,
            "ref_spans": [
                {
                    "start": 123,
                    "end": 130,
                    "type": "table",
                    "text": "Table I"
                }
            ]
        },
        {
            "text": "Denote the true value of \u03b7 by \u03b7 0 , that is, \u00b5 0 = \u00b5(\u03b7 0 ) is the true mean counts of the observation such that",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 69,
            "section_rank": 16
        },
        {
            "text": "When the data size is large, a very good approximation to the model above is given by",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 70,
            "section_rank": 16
        },
        {
            "text": "Further, let \u03c0 := \u00b5/m denote the per unit time mean counts. ",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 71,
            "section_rank": 16
        },
        {
            "text": "To help explain these notations, take the example from Sec. ",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 71,
            "section_rank": 16
        },
        {
            "text": "IV B for instance, if H 0 : (sin 2 2\u03b8, |\u2206m",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 71,
            "section_rank": 16
        },
        {
            "text": "The terms a i and b i are functions of order O(1), and are determined by the con-figuration of the experiment. ",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 72,
            "section_rank": 16
        },
        {
            "text": "For example, a i can represent the detector efficiency, neutrino flux from reactor, target mass, etc., b i can represent the backgrounds. ",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 72,
            "section_rank": 16
        },
        {
            "text": "Also,",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 72,
            "section_rank": 16
        },
        {
            "text": "represents the survival probability in a disappearance model.",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 73,
            "section_rank": 16
        },
        {
            "text": "Meanwhile, a competing framework, namely the collection of models that satisfy H 1 , specifies the mean counts incorrectly as \u03bd(\u03b6), where \u03b6 is the unknown nuisance parameter of dimension q * . ",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 74,
            "section_rank": 16
        },
        {
            "text": "Also, define the per unit time mean counts under H 1 by \u03c4 = \u03bd/m. ",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 74,
            "section_rank": 16
        },
        {
            "text": "When H 0 is the correct hypothesis and that the true model is \u00b5 0 , there exists a unique \u03b6 0 , such that\u03b6 approaches \u03b6 0 as m \u2192 \u221e. ",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 74,
            "section_rank": 16
        },
        {
            "text": "We will show in Appendix A that \u03b6 0 has the interpretation that it corresponds to the model \u03bd(\u03b6) among all that belong to the alternative framework that is the closest to the true model \u00b5 0 in terms of the deviation",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 74,
            "section_rank": 16
        },
        {
            "text": ". Denote \u03bd 0 = \u03bd(\u03b6 0 ).",
            "section": "Description of the mathematical problem and notations",
            "paragraph_rank": 75,
            "section_rank": 16
        },
        {
            "text": "Approximating the distribution of the test statistic D(X)",
            "section_rank": 17
        },
        {
            "text": "In this section, we always assume that H 0 is the correct hypothesis, under which we study the distribution of D(X) defined in Eq. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 76,
            "section_rank": 17
        },
        {
            "text": "(24). ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 76,
            "section_rank": 17,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 4,
                    "type": "bibr",
                    "ref_id": "b23",
                    "text": "(24)"
                }
            ]
        },
        {
            "text": "For convenience, we will suppress the dependence on X in the notation, and write D = \u03c7 2 H1 (\u03b6) \u2212 \u03c7 2 H0 (\u03b7). ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 76,
            "section_rank": 17
        },
        {
            "text": "On one hand, it's well known that the distribution of \u03c7 2 H0 (\u03b7) approaches the Chi-square distribution with degree of freedom (n \u2212 q) as m increases. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 76,
            "section_rank": 17
        },
        {
            "text": "On the other hand, the limiting distribution of \u03c7 2 H1 (\u03b6) as m increases does not always exist. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 76,
            "section_rank": 17
        },
        {
            "text": "Indeed, the behavior of \u03c7 2 H1 (\u03b6) for large m is dependent on how far apart the mean counts of the best model under the alternative theoretical frameworks are from that of the true model. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 76,
            "section_rank": 17
        },
        {
            "text": "Denote the difference of per unit mean counts between the two models by \u03b4 = \u03c0 0 \u2212 \u03c4 0 . ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 76,
            "section_rank": 17
        },
        {
            "text": "First, we state a classical assumption made in many statistical literatures (such as Ref. [10] and Ref. [12]) in order to obtain the limiting distribution of test statistics analogous to \u03c7 2 H1 (\u03b6), that is, the different versions of T min H1 (X): ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 76,
            "section_rank": 17,
            "ref_spans": [
                {
                    "start": 90,
                    "end": 94,
                    "type": "bibr",
                    "ref_id": "b9",
                    "text": "[10]"
                },
                {
                    "start": 104,
                    "end": 108,
                    "type": "bibr",
                    "ref_id": "b11",
                    "text": "[12]"
                }
            ]
        },
        {
            "text": "2 ) terms are neglected. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 77,
            "section_rank": 17
        },
        {
            "text": "In contrast to [A1], we consider the following assumption, which is more general and realistic for the physics problem at hand:",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 77,
            "section_rank": 17
        },
        {
            "text": "In words, [A0] assumes that the difference in mean bin counts between the best model under the wrong hypothesis and the true model increases at the same rate as the data size m, or slower.  ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 78,
            "section_rank": 17
        },
        {
            "text": "probability. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 78,
            "section_rank": 17
        },
        {
            "text": "Take the likelihood ratio test statistic mentioned above for example, the non-centrality parameter in the previous approximation grows to infinity as m increases. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 78,
            "section_rank": 17
        },
        {
            "text": "Further, the differences between the different versions of \u03c7 2 H1 (\u03b6) usually do not converge to 0 as m increases.",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 78,
            "section_rank": 17
        },
        {
            "text": "Although the limiting distribution does not necessarily exist under assumption [A0], it is still possible to approximate the distribution of \u03c7 2 H1 (\u03b6) at a finite, but large enough m. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 79,
            "section_rank": 17
        },
        {
            "text": "We make such an attempt, but this certainly requires a different derivation than the existing proofs that assume [A1]. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 79,
            "section_rank": 17
        },
        {
            "text": "In our derivation, we keep track of the terms that have higher order than constants when the data size m grows. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 79,
            "section_rank": 17
        },
        {
            "text": "Our proof follows the lines of that of Ref. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 79,
            "section_rank": 17
        },
        {
            "text": "[23,Chap. 16], but with significant modifications. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 79,
            "section_rank": 17,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 4,
                    "type": "bibr",
                    "ref_id": "b22",
                    "text": "[23,"
                },
                {
                    "start": 4,
                    "end": 13,
                    "type": "bibr",
                    "text": "Chap. 16]"
                }
            ]
        },
        {
            "text": "Write",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 79,
            "section_rank": 17
        },
        {
            "text": "Here",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 80,
            "section_rank": 17
        },
        {
            "text": ", and ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 81,
            "section_rank": 17
        },
        {
            "text": "where the three terms in the above expression are of order",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 82,
            "section_rank": 17
        },
        {
            "text": "where",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 83,
            "section_rank": 17
        },
        {
            "text": ", and the two terms in the above expression are of order O p (1) and O p (m \u2212 1 2 ) respectively. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 84,
            "section_rank": 17,
            "ref_spans": [
                {
                    "start": 61,
                    "end": 64,
                    "type": "bibr",
                    "ref_id": "b0",
                    "text": "(1)"
                }
            ]
        },
        {
            "text": "Therefore",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 84,
            "section_rank": 17
        },
        {
            "text": "According to Eq. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 85,
            "section_rank": 17
        },
        {
            "text": "(40) of Lemma 1, the term in the closed bracket above reduces to 0. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 85,
            "section_rank": 17
        },
        {
            "text": "Hence",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 85,
            "section_rank": 17
        },
        {
            "text": "Denote the first term of D by",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 86,
            "section_rank": 17
        },
        {
            "text": "where the second to last equality follows from Appendix A.  ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 87,
            "section_rank": 17
        },
        {
            "text": "Remarks and Implications of Eq. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 88,
            "section_rank": 17
        },
        {
            "text": "261. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 88,
            "section_rank": 17,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 2,
                    "ref_id": "formula_54",
                    "text": "26"
                }
            ]
        },
        {
            "text": "For the common physics problem that we are interested in, additional simplification can be made to the approximating distribution, N(D, 4D + 4ms). ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 88,
            "section_rank": 17
        },
        {
            "text": "Specifically, in searching for new physics through precision measurements, the mean bin counts of the true model and that of the best model under the alternative hypothesis are relatively close to each other, that is,",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 88,
            "section_rank": 17
        },
        {
            "text": "In such situations, one can ignore the ms term in Eq. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 89,
            "section_rank": 17
        },
        {
            "text": "(26), because ms = \u2211",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 89,
            "section_rank": 17
        },
        {
            "text": "2. We claimed in Sec. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 90,
            "section_rank": 17
        },
        {
            "text": "IV A that, at large data limit, the three versions of \u2206T (X) = T min H1 (X) \u2212 T min H0 (X) based on the definition of T H0 (and the corresponding T H1 ) in Eq. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 90,
            "section_rank": 17
        },
        {
            "text": "15, (16), and Eq. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 90,
            "section_rank": 17,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 2,
                    "ref_id": "formula_24",
                    "text": "15"
                },
                {
                    "start": 4,
                    "end": 8,
                    "type": "bibr",
                    "ref_id": "b15",
                    "text": "(16)"
                }
            ]
        },
        {
            "text": "(18), each have negligible difference from the D(X). ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 90,
            "section_rank": 17,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 4,
                    "type": "bibr",
                    "ref_id": "b17",
                    "text": "(18)"
                }
            ]
        },
        {
            "text": "We validate this claim as follows.",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 90,
            "section_rank": 17
        },
        {
            "text": "For the moment, we drop the penalty term \u03c7 2 penalty (\u03b7) from Eq. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 91,
            "section_rank": 17
        },
        {
            "text": "(15)- (18) for simplicity. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 91,
            "section_rank": 17,
            "ref_spans": [
                {
                    "start": 6,
                    "end": 10,
                    "type": "bibr",
                    "ref_id": "b17",
                    "text": "(18)"
                }
            ]
        },
        {
            "text": "And we will address the issue of the penalty term in the next remark.",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 91,
            "section_rank": 17
        },
        {
            "text": "First, for Eq. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 92,
            "section_rank": 17
        },
        {
            "text": "(15), we have,",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 92,
            "section_rank": 17
        },
        {
            "text": "The last step was obtained through expanding log",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 93,
            "section_rank": 17
        },
        {
            "text": "2 )). ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 94,
            "section_rank": 17
        },
        {
            "text": "Next, for Eq. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 94,
            "section_rank": 17
        },
        {
            "text": "(16), we have,",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 94,
            "section_rank": 17
        },
        {
            "text": "Finally, for Eq. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 95,
            "section_rank": 17
        },
        {
            "text": "18, we have,",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 95,
            "section_rank": 17,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 2,
                    "ref_id": "formula_27",
                    "text": "18"
                }
            ]
        },
        {
            "text": "The differences between each version of T H0 (X) and \u2211",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 96,
            "section_rank": 17
        },
        {
            "text": "are negligible. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 97,
            "section_rank": 17
        },
        {
            "text": "Next we examine the differences between each version of T H1 (X) and \u2211",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 97,
            "section_rank": 17
        },
        {
            "text": ". We will only consider situations where condition Eq. (27) hold. If so, the term",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 98,
            "section_rank": 17,
            "ref_spans": [
                {
                    "start": 55,
                    "end": 59,
                    "type": "bibr",
                    "ref_id": "b26",
                    "text": "(27)"
                }
            ]
        },
        {
            "text": ") << 1, which will help validate the following three approximations. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 99,
            "section_rank": 17
        },
        {
            "text": "First, for Eq. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 99,
            "section_rank": 17
        },
        {
            "text": "15, we have,",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 99,
            "section_rank": 17,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 2,
                    "ref_id": "formula_24",
                    "text": "15"
                }
            ]
        },
        {
            "text": "Next, for Eq. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 100,
            "section_rank": 17
        },
        {
            "text": "(16), we have,",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 100,
            "section_rank": 17
        },
        {
            "text": ".",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 101,
            "section_rank": 17
        },
        {
            "text": "Finally, for Eq. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 102,
            "section_rank": 17
        },
        {
            "text": "(18), we have,",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 102,
            "section_rank": 17
        },
        {
            "text": "In situations where Eq. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 103,
            "section_rank": 17
        },
        {
            "text": "(27) is satisfied, the differences between each version of T H1 (X) and \u2211 ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 103,
            "section_rank": 17
        },
        {
            "text": "3. We emphasize that Eq. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 104,
            "section_rank": 17
        },
        {
            "text": "(24) is a specific form of T in Eq. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 104,
            "section_rank": 17
        },
        {
            "text": "(15), (16), (17), and Eq. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 104,
            "section_rank": 17,
            "ref_spans": [
                {
                    "start": 6,
                    "end": 10,
                    "type": "bibr",
                    "ref_id": "b15",
                    "text": "(16)"
                },
                {
                    "start": 12,
                    "end": 16,
                    "type": "bibr",
                    "ref_id": "b16",
                    "text": "(17)"
                }
            ]
        },
        {
            "text": "(18). ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 104,
            "section_rank": 17,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 4,
                    "type": "bibr",
                    "ref_id": "b17",
                    "text": "(18)"
                }
            ]
        },
        {
            "text": "The penalty term in T represents the constraint of systematic uncertainties, and is commonly obtained by dedicated measurements. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 104,
            "section_rank": 17
        },
        {
            "text": "When one includes the dedicated measurements as part of Chi-square definition, one naturally recovers Eq. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 104,
            "section_rank": 17
        },
        {
            "text": "(24). ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 104,
            "section_rank": 17,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 4,
                    "type": "bibr",
                    "ref_id": "b23",
                    "text": "(24)"
                }
            ]
        },
        {
            "text": "Therefore, our proof in Sec. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 104,
            "section_rank": 17
        },
        {
            "text": "III B is also valid for test statistics with the format of T in Eq. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 104,
            "section_rank": 17
        },
        {
            "text": "(15), (16), (17), and Eq. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 104,
            "section_rank": 17,
            "ref_spans": [
                {
                    "start": 6,
                    "end": 10,
                    "type": "bibr",
                    "ref_id": "b15",
                    "text": "(16)"
                },
                {
                    "start": 12,
                    "end": 16,
                    "type": "bibr",
                    "ref_id": "b16",
                    "text": "(17)"
                }
            ]
        },
        {
            "text": "(18).",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 104,
            "section_rank": 17
        },
        {
            "text": "4. We comment on the large data limit, which is required to reach the final conclusion (Eq. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 105,
            "section_rank": 17
        },
        {
            "text": "(28)) and to show the equivalence of Eq. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 105,
            "section_rank": 17
        },
        {
            "text": "15, (16), (17), and Eq. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 105,
            "section_rank": 17,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 2,
                    "ref_id": "formula_24",
                    "text": "15"
                },
                {
                    "start": 4,
                    "end": 8,
                    "type": "bibr",
                    "ref_id": "b15",
                    "text": "(16)"
                },
                {
                    "start": 10,
                    "end": 14,
                    "type": "bibr",
                    "ref_id": "b16",
                    "text": "(17)"
                }
            ]
        },
        {
            "text": "(18). ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 105,
            "section_rank": 17,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 4,
                    "type": "bibr",
                    "ref_id": "b17",
                    "text": "(18)"
                }
            ]
        },
        {
            "text": "For a single bin, Ni\u2212\u00b5i \u00b5i is negligible if N i is greater than about 100. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 105,
            "section_rank": 17
        },
        {
            "text": "For multiple bins, the contributions from each bin will likely cancel and the condition can be relaxed in practice to that the total number of events, \u2211 i N i , is greater than about 100.",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 105,
            "section_rank": 17
        },
        {
            "text": "In summary of this section, we showed the following result. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 106,
            "section_rank": 17
        },
        {
            "text": "Assume the following set of conditions hold: ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 106,
            "section_rank": 17
        },
        {
            "text": "Then a simple approximation for the distribution of \u2206T (X) under H j , for either j = 0 or 1, is the Gaussian distribution with mean \u2206T Hj and standard deviations 2 \u221a",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 107,
            "section_rank": 17
        },
        {
            "text": "|\u2206T Hj |. ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 108,
            "section_rank": 17
        },
        {
            "text": "Based on the Gaussian approximation, the CL s value is easily calculated with \u2206T (x), \u2206T H0 , and \u2206T H1 . ",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 108,
            "section_rank": 17
        },
        {
            "text": "In case any of the above conditions (CD1-CD3) breaks down, the distribution of \u2206T (X) is not necessarily well approximated by the Gaussian distribution, and should instead be estimated through Monte Carlo simulations.",
            "section": "Approximating the distribution of the test statistic D(X)",
            "paragraph_rank": 108,
            "section_rank": 17
        },
        {
            "text": "IV. ",
            "section_rank": 18
        },
        {
            "text": "THE CLs APPROACH BASED ON THE \u2206T STATISTIC",
            "section_rank": 18
        },
        {
            "text": "The \u2206T (x) statistic described in the previous section can be used to form both CIs and CL s , and they differ in how the associated p-values are utilized. ",
            "section": "IV. THE CLs APPROACH BASED ON THE \u2206T STATISTIC",
            "paragraph_rank": 109,
            "section_rank": 18
        },
        {
            "text": "Note that both procedures are easy to carry out because of the simple Gaussian approximation for the distribution of \u2206T (x). ",
            "section": "IV. THE CLs APPROACH BASED ON THE \u2206T STATISTIC",
            "paragraph_rank": 109,
            "section_rank": 18
        },
        {
            "text": "We will introduce the CL s approach with the \u2206T (x) statistic below. ",
            "section": "IV. THE CLs APPROACH BASED ON THE \u2206T STATISTIC",
            "paragraph_rank": 109,
            "section_rank": 18
        },
        {
            "text": "The principle of forming CIs with \u2206T (x) is the same as that with \u2206\u03c7 2 .",
            "section": "IV. THE CLs APPROACH BASED ON THE \u2206T STATISTIC",
            "paragraph_rank": 109,
            "section_rank": 18
        },
        {
            "text": "FIG. 2. ",
            "section_rank": 19
        },
        {
            "text": "(color online)",
            "section_rank": 19
        },
        {
            "text": "Illustration of the CLs approach with log-likelihood ratio \u2206T . ",
            "section": "FIG. 2. (color online)",
            "paragraph_rank": 110,
            "section_rank": 19
        },
        {
            "text": "In order to be consistent with the convention in Ref. ",
            "section": "FIG. 2. (color online)",
            "paragraph_rank": 110,
            "section_rank": 19
        },
        {
            "text": "[24], we plot the densities of \u2212\u2206T instead. ",
            "section": "FIG. 2. (color online)",
            "paragraph_rank": 110,
            "section_rank": 19,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 4,
                    "type": "bibr",
                    "ref_id": "b23",
                    "text": "[24]"
                }
            ]
        },
        {
            "text": "See text for more discussions.",
            "section": "FIG. 2. (color online)",
            "paragraph_rank": 110,
            "section_rank": 19
        },
        {
            "text": "A. The CLs Approach Based on the \u2206T Statistic",
            "section_rank": 20
        },
        {
            "text": "The CL s approach [13][14][15] is a popular approach to present searches for new physics beyond the Standard Model. ",
            "section": "A. The CLs Approach Based on the \u2206T Statistic",
            "paragraph_rank": 111,
            "section_rank": 20,
            "ref_spans": [
                {
                    "start": 18,
                    "end": 22,
                    "type": "bibr",
                    "ref_id": "b12",
                    "text": "[13]"
                },
                {
                    "start": 22,
                    "end": 26,
                    "type": "bibr",
                    "ref_id": "b13",
                    "text": "[14]"
                },
                {
                    "start": 26,
                    "end": 30,
                    "type": "bibr",
                    "ref_id": "b14",
                    "text": "[15]"
                }
            ]
        },
        {
            "text": "Recent examples of using this approach in neutrino physics can be found in Ref. ",
            "section": "A. The CLs Approach Based on the \u2206T Statistic",
            "paragraph_rank": 111,
            "section_rank": 20
        },
        {
            "text": "[25,26]. ",
            "section": "A. The CLs Approach Based on the \u2206T Statistic",
            "paragraph_rank": 111,
            "section_rank": 20,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 4,
                    "type": "bibr",
                    "ref_id": "b24",
                    "text": "[25,"
                },
                {
                    "start": 4,
                    "end": 7,
                    "type": "bibr",
                    "ref_id": "b25",
                    "text": "26]"
                }
            ]
        },
        {
            "text": "Examples of using this approach in LHC super particle search can be found at Ref. ",
            "section": "A. The CLs Approach Based on the \u2206T Statistic",
            "paragraph_rank": 111,
            "section_rank": 20
        },
        {
            "text": "[27,28]. ",
            "section": "A. The CLs Approach Based on the \u2206T Statistic",
            "paragraph_rank": 111,
            "section_rank": 20,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 4,
                    "type": "bibr",
                    "ref_id": "b26",
                    "text": "[27,"
                },
                {
                    "start": 4,
                    "end": 7,
                    "type": "bibr",
                    "ref_id": "b27",
                    "text": "28]"
                }
            ]
        },
        {
            "text": "We emphasize that, the CL s approach is a different way to present statistical results than the traditional approach of setting confidence intervals (CI). ",
            "section": "A. The CLs Approach Based on the \u2206T Statistic",
            "paragraph_rank": 111,
            "section_rank": 20
        },
        {
            "text": "The traditional CI approach is appropriate in treating established signals [15]. ",
            "section": "A. The CLs Approach Based on the \u2206T Statistic",
            "paragraph_rank": 111,
            "section_rank": 20,
            "ref_spans": [
                {
                    "start": 75,
                    "end": 79,
                    "type": "bibr",
                    "ref_id": "b14",
                    "text": "[15]"
                }
            ]
        },
        {
            "text": "Whereas the CL s approach is appropriate in setting exclusion limits, such that models with parameter values beyond the limits are much worse than the Standard Model in fitting the observed data. ",
            "section": "A. The CLs Approach Based on the \u2206T Statistic",
            "paragraph_rank": 111,
            "section_rank": 20
        },
        {
            "text": "In this section, we briefly review the principle of the CL s approach in a two-hypotheses testing problem. ",
            "section": "A. The CLs Approach Based on the \u2206T Statistic",
            "paragraph_rank": 111,
            "section_rank": 20
        },
        {
            "text": "Fig. 2 is a heuristic illustration of the distribution of the log-likelihood ratio \u2206T (X), where X stands for data from a potential repeat of the experiment. ",
            "section": "A. The CLs Approach Based on the \u2206T Statistic",
            "paragraph_rank": 111,
            "section_rank": 20,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 6,
                    "type": "figure",
                    "ref_id": "fig_7",
                    "text": "Fig. 2"
                }
            ]
        },
        {
            "text": "The black (red) curve stands for the density function of the expected distribution of \u2206T (X) under the assumption that the null (alternative) hypothesis is true. ",
            "section": "A. The CLs Approach Based on the \u2206T Statistic",
            "paragraph_rank": 111,
            "section_rank": 20
        },
        {
            "text": "The green line represents \u2206T (x) calculated from the observed data x. ",
            "section": "A. The CLs Approach Based on the \u2206T Statistic",
            "paragraph_rank": 111,
            "section_rank": 20
        },
        {
            "text": "A positive (negative) \u2206T (x) would favor H 0 (H 1 ) over H 1 (H 0 ). ",
            "section": "A. The CLs Approach Based on the \u2206T Statistic",
            "paragraph_rank": 111,
            "section_rank": 20
        },
        {
            "text": "The CL s value is then defined as:",
            "section": "A. The CLs Approach Based on the \u2206T Statistic",
            "paragraph_rank": 111,
            "section_rank": 20
        },
        {
            "text": "where 1 \u2212 p 1 (1 \u2212 p 0 ) is the probability that a potential repeat of the experiment will yield a \u2206T (X) value larger than \u2206T (x) when the alternate (null) hypothesis is true. ",
            "section": "A. The CLs Approach Based on the \u2206T Statistic",
            "paragraph_rank": 112,
            "section_rank": 20
        },
        {
            "text": "Hence, the definition of CL s in Eq. ",
            "section": "A. The CLs Approach Based on the \u2206T Statistic",
            "paragraph_rank": 112,
            "section_rank": 20
        },
        {
            "text": "(30) suggests that a CL s value close to zero would favor H 0 against H 1 . ",
            "section": "A. The CLs Approach Based on the \u2206T Statistic",
            "paragraph_rank": 112,
            "section_rank": 20,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 4,
                    "type": "bibr",
                    "ref_id": "b30",
                    "text": "(30)"
                }
            ]
        },
        {
            "text": "On the other hand, as illustrated in Fig. 3 space is typically defined as the set of parameter values of new physics that corresponds to CL s value smaller than \u03b1 = 0.05 [24], while other threshold values of the CL s can be used as well.",
            "section": "A. The CLs Approach Based on the \u2206T Statistic",
            "paragraph_rank": 112,
            "section_rank": 20,
            "ref_spans": [
                {
                    "start": 37,
                    "end": 43,
                    "type": "figure",
                    "text": "Fig. 3"
                },
                {
                    "start": 170,
                    "end": 174,
                    "type": "bibr",
                    "ref_id": "b23",
                    "text": "[24]"
                }
            ]
        },
        {
            "text": "Note that the CL s value is never smaller than (1 \u2212 p 1 ), the p-value used in the corresponding CI approach. ",
            "section": "A. The CLs Approach Based on the \u2206T Statistic",
            "paragraph_rank": 113,
            "section_rank": 20
        },
        {
            "text": "Hence, had the exclusion contour at \u03b1 been used to set a CI, it would have coverage probability over 1 \u2212 \u03b1. ",
            "section": "A. The CLs Approach Based on the \u2206T Statistic",
            "paragraph_rank": 113,
            "section_rank": 20
        },
        {
            "text": "Nevertheless, the CL s value appears to be a more reasonable measure of extremeness than (1\u2212p 1 ), in situations where H 0 and H 1 are very similar (see Fig. 3). ",
            "section": "A. The CLs Approach Based on the \u2206T Statistic",
            "paragraph_rank": 113,
            "section_rank": 20,
            "ref_spans": [
                {
                    "start": 153,
                    "end": 159,
                    "type": "figure",
                    "text": "Fig. 3"
                }
            ]
        },
        {
            "text": "For example, assuming the data x is an \"extreme\" measurement with respect to H 1 (i.e. small p 1 ), it will also be disfavored by H 0 (i.e. small p 0 ). ",
            "section": "A. The CLs Approach Based on the \u2206T Statistic",
            "paragraph_rank": 113,
            "section_rank": 20
        },
        {
            "text": "If only a single p-value, either p 0 or p 1 , is examined as in the CI approach, then one would draw the inappropriate conclusion of excluding H 0 or H 1 while favoring the other hypothesis. ",
            "section": "A. The CLs Approach Based on the \u2206T Statistic",
            "paragraph_rank": 113,
            "section_rank": 20
        },
        {
            "text": "However, since the hypotheses H 0 and H 1 are similar, the data does not carry enough information to differentiate them. ",
            "section": "A. The CLs Approach Based on the \u2206T Statistic",
            "paragraph_rank": 113,
            "section_rank": 20
        },
        {
            "text": "The CL s value, which is the ratio between 1 \u2212 p 1 and 1 \u2212 p 0 will protect against such situations.",
            "section": "A. The CLs Approach Based on the \u2206T Statistic",
            "paragraph_rank": 113,
            "section_rank": 20
        },
        {
            "text": "In order to obtain the value of p 0 and p 1 required to calculate the CL s , one needs to find the distribution of \u2206T (X) under H 0 and H 1 . ",
            "section": "A. The CLs Approach Based on the \u2206T Statistic",
            "paragraph_rank": 114,
            "section_rank": 20
        },
        {
            "text": "While Monte Carlo simulations can provide approximations to the distribution of \u2206T (X), simpler methods, such as Gaussian approximations, are desired to lower the computing burden.",
            "section": "A. The CLs Approach Based on the \u2206T Statistic",
            "paragraph_rank": 114,
            "section_rank": 20
        },
        {
            "text": "B. Setting Exclusion Sets with the Gaussian CLs Method",
            "section_rank": 21
        },
        {
            "text": "In this section, we illustrate the procedure of setting exclusion sets with the Gaussian CL s method for the neutrino oscillation example from Sec. ",
            "section": "B. Setting Exclusion Sets with the Gaussian CLs Method",
            "paragraph_rank": 115,
            "section_rank": 21
        },
        {
            "text": "II.",
            "section": "B. Setting Exclusion Sets with the Gaussian CLs Method",
            "paragraph_rank": 115,
            "section_rank": 21
        },
        {
            "text": "Here the parameter of interest is \u03b2 = (sin 2 2\u03b8, |\u2206m 2 |). ",
            "section": "B. Setting Exclusion Sets with the Gaussian CLs Method",
            "paragraph_rank": 116,
            "section_rank": 21
        },
        {
            "text": "The mean count for the ith bin is described as",
            "section": "B. Setting Exclusion Sets with the Gaussian CLs Method",
            "paragraph_rank": 116,
            "section_rank": 21
        },
        {
            "text": ", where a i and b i are coefficients that depend on the vector of nuisance parameters \u03b7, and m represents the amount of accumulated data. ",
            "section": "B. Setting Exclusion Sets with the Gaussian CLs Method",
            "paragraph_rank": 117,
            "section_rank": 21
        },
        {
            "text": "It is typical to use \u03b2 0 = (0, |\u2206m 2 0 |) as a reference parameter point, where |\u2206m 2 0 | can be any fixed value since it does not enter the model for bin counts when sin 2 2\u03b8 = 0. ",
            "section": "B. Setting Exclusion Sets with the Gaussian CLs Method",
            "paragraph_rank": 117,
            "section_rank": 21
        },
        {
            "text": "In this case, the null hypothesis is specified to be H 0 : \u03b2 = \u03b2 0 (i.e. the Standard Model with three light neutrinos). ",
            "section": "B. Setting Exclusion Sets with the Gaussian CLs Method",
            "paragraph_rank": 117,
            "section_rank": 21
        },
        {
            "text": "Next, for any \u03b2 1 = (sin 2 2\u03b8 1 , |\u2206m 2 1 |) from the parameter space \u0398 \u00d7 M , specify the alternative hypothesis to be H 1 : \u03b2 = \u03b2 1 , and perform the following procedure: ",
            "section": "B. Setting Exclusion Sets with the Gaussian CLs Method",
            "paragraph_rank": 117,
            "section_rank": 21,
            "ref_spans": [
                {
                    "start": 38,
                    "end": 39,
                    "type": "bibr",
                    "ref_id": "b1",
                    "text": "2"
                }
            ]
        },
        {
            "text": "where",
            "section": "B. Setting Exclusion Sets with the Gaussian CLs Method",
            "paragraph_rank": 118,
            "section_rank": 21
        },
        {
            "text": "dt is the Gaussian error function for any s \u2208 (\u2212\u221e, \u221e).",
            "section": "B. Setting Exclusion Sets with the Gaussian CLs Method",
            "paragraph_rank": 119,
            "section_rank": 21
        },
        {
            "text": "Similarly, from the Asimov data set x Asimov",
            "section_rank": 22
        },
        {
            "text": "H1",
            "section_rank": 23
        },
        {
            "text": ", obtain",
            "section": "H1",
            "paragraph_rank": 120,
            "section_rank": 23
        },
        {
            "text": "H1",
            "section_rank": 24
        },
        {
            "text": ") .",
            "section": "H1",
            "paragraph_rank": 121,
            "section_rank": 24
        },
        {
            "text": "according to Eq. ",
            "section": "H1",
            "paragraph_rank": 122,
            "section_rank": 24
        },
        {
            "text": "(21). ",
            "section": "H1",
            "paragraph_rank": 122,
            "section_rank": 24,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 4,
                    "type": "bibr",
                    "ref_id": "b20",
                    "text": "(21)"
                }
            ]
        },
        {
            "text": "Then one can approximate",
            "section": "H1",
            "paragraph_rank": 122,
            "section_rank": 24
        },
        {
            "text": "4. According to Eq. ",
            "section": "H1",
            "paragraph_rank": 123,
            "section_rank": 24
        },
        {
            "text": "(30), the CL s value at (sin 2 2\u03b8 1 , |\u2206m 2 1 |) can be approximated by",
            "section": "H1",
            "paragraph_rank": 123,
            "section_rank": 24
        },
        {
            "text": "The point (sin 2 2\u03b8 1 , |\u2206m 2 1 |) is assigned to the 95% CL s exclusion set if and only if its CL s value is smaller than 5%.",
            "section": "H1",
            "paragraph_rank": 124,
            "section_rank": 24
        },
        {
            "text": "In terms of the computing effort, the above CL s procedure requires the calculation of \u2206T (x), \u2206T H1 , and \u2206T H0 at each parameter point in \u0398 \u00d7 M . ",
            "section": "H1",
            "paragraph_rank": 125,
            "section_rank": 24
        },
        {
            "text": "In comparison, the standard Wilks CI method based on \u2206\u03c7 2 (x) in Eq. ",
            "section": "H1",
            "paragraph_rank": 125,
            "section_rank": 24
        },
        {
            "text": "(7) requires the calculation of \u2206\u03c7 2 (x) at each parameter point. ",
            "section": "H1",
            "paragraph_rank": 125,
            "section_rank": 24
        },
        {
            "text": "So the computing cost of the Gaussian CL s method is about three times that of the Wilks' CI method. ",
            "section": "H1",
            "paragraph_rank": 125,
            "section_rank": 24
        },
        {
            "text": "In summary, both methods are easily affordable computationally, but the CL s method is valid under much less restrictive conditions (CD1-CD3).",
            "section": "H1",
            "paragraph_rank": 125,
            "section_rank": 24
        },
        {
            "text": "V. AN EXAMPLE: SEARCH FOR STERILE NEUTRINO",
            "section_rank": 25
        },
        {
            "text": "In this section, we introduce an example based on the search for a sterile neutrino. ",
            "section": "V. AN EXAMPLE: SEARCH FOR STERILE NEUTRINO",
            "paragraph_rank": 126,
            "section_rank": 25
        },
        {
            "text": "In this example, various methods to carry out the CL s approach and the CI approach are compared.",
            "section": "V. AN EXAMPLE: SEARCH FOR STERILE NEUTRINO",
            "paragraph_rank": 126,
            "section_rank": 25
        },
        {
            "text": "A. Model Description",
            "section_rank": 26
        },
        {
            "text": "In this model, there are two detectors and one neutrino source. ",
            "section": "A. Model Description",
            "paragraph_rank": 127,
            "section_rank": 26
        },
        {
            "text": "One detector is located at 300 kilo-meters from the neutrino source and is called the near detector. ",
            "section": "A. Model Description",
            "paragraph_rank": 127,
            "section_rank": 26
        },
        {
            "text": "The other detector is located at 1000 kilo-meters from the neutrino source and is called the far detector. ",
            "section": "A. Model Description",
            "paragraph_rank": 127,
            "section_rank": 26
        },
        {
            "text": "As shown in Fig. 4, the neutrino energy E \u03bd covers from 1 GeV to 9 GeV, and a flat (energy independent) neutrino energy spectrum is assumed. ",
            "section": "A. Model Description",
            "paragraph_rank": 127,
            "section_rank": 26,
            "ref_spans": [
                {
                    "start": 12,
                    "end": 18,
                    "type": "figure",
                    "ref_id": "fig_9",
                    "text": "Fig. 4"
                }
            ]
        },
        {
            "text": "We further assume the detector can measure the spectrum with 20 energy bins equally spaced between 1 GeV and 9 GeV. ",
            "section": "A. Model Description",
            "paragraph_rank": 127,
            "section_rank": 26
        },
        {
            "text": "The mean number of neutrino events seen by the near (far) detector without any oscillation is 10 k (0.9 k) per bin. ",
            "section": "A. Model Description",
            "paragraph_rank": 127,
            "section_rank": 26
        },
        {
            "text": "We consider two types of oscillation measurements: a disappearance measurement with oscillation formula",
            "section": "A. Model Description",
            "paragraph_rank": 127,
            "section_rank": 26
        },
        {
            "text": "and an appearance measurement with oscillation formula",
            "section": "A. Model Description",
            "paragraph_rank": 128,
            "section_rank": 26
        },
        {
            "text": "where \u03b8 is the neutrino mixing angle, \u2206m 2 is the neutrino mass squared difference, and L is the distance that neutrino travels. ",
            "section": "A. Model Description",
            "paragraph_rank": 129,
            "section_rank": 26
        },
        {
            "text": "We further include a background with a linear dependence on E \u03bd . ",
            "section": "A. Model Description",
            "paragraph_rank": 129,
            "section_rank": 26
        },
        {
            "text": "The number of background events starts from 130 per bin for the first bin to 73 per bin for the last (20th) bin. ",
            "section": "A. Model Description",
            "paragraph_rank": 129,
            "section_rank": 26
        },
        {
            "text": "There are three nuisance parameters, \u03f5, \u03b7 n , and \u03b7 f . ",
            "section": "A. Model Description",
            "paragraph_rank": 129,
            "section_rank": 26
        },
        {
            "text": "The first one is associated with the detector efficiency and the neutrino flux, which is assumed to be accurate to 5%. ",
            "section": "A. Model Description",
            "paragraph_rank": 129,
            "section_rank": 26
        },
        {
            "text": "This uncertainty is assumed to be correlated between the near and the far detectors. ",
            "section": "A. Model Description",
            "paragraph_rank": 129,
            "section_rank": 26
        },
        {
            "text": "The second and the third nuisance parameters are associated with the background normalization factors for the near and the far detectors, respectively. ",
            "section": "A. Model Description",
            "paragraph_rank": 129,
            "section_rank": 26
        },
        {
            "text": "The normalization uncertainty is assumed to be 2% and uncorrelated between the two detectors. ",
            "section": "A. Model Description",
            "paragraph_rank": 129,
            "section_rank": 26
        },
        {
            "text": "Fig. 4 shows the expected neutrino spectra. ",
            "section": "A. Model Description",
            "paragraph_rank": 129,
            "section_rank": 26,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 6,
                    "type": "figure",
                    "ref_id": "fig_9",
                    "text": "Fig. 4"
                }
            ]
        },
        {
            "text": "For the disappearance measurement, we compare the nooscillation spectrum (the null hypothesis H 0 : sin 2 2\u03b8 = 0) with an oscillation spectrum (an alternative hypothesis H 1 : sin 2 2\u03b8 = 0.06 at \u2206m 2 = 2.5 \u00d7 10 \u22123 eV 2 ). ",
            "section": "A. Model Description",
            "paragraph_rank": 129,
            "section_rank": 26
        },
        {
            "text": "For the appearance measurement, we compare the no-oscillation spectrum (the null hypothesis H 0 : sin 2 2\u03b8 = 0) with two oscillation spectra (two alternative hypotheses H 1 : sin 2 2\u03b8 = 0.008 or sin 2 2\u03b8 = 0.03 at \u2206m 2 = 2.5 \u00d7 10 \u22123 eV 2 ). ",
            "section": "A. Model Description",
            "paragraph_rank": 129,
            "section_rank": 26
        },
        {
            "text": "Given a Monte Carlo (MC) sample N j i , we use the following test statistic based on the Poisson likelihood, in line of Eq. ",
            "section": "A. Model Description",
            "paragraph_rank": 129,
            "section_rank": 26
        },
        {
            "text": "(15):",
            "section": "A. Model Description",
            "paragraph_rank": 129,
            "section_rank": 26
        },
        {
            "text": "Here, i represents the bin number and ranges from 1 to 20. ",
            "section": "A. Model Description",
            "paragraph_rank": 130,
            "section_rank": 26
        },
        {
            "text": "j labels the near or the far detector. ",
            "section": "A. Model Description",
            "paragraph_rank": 130,
            "section_rank": 26
        },
        {
            "text": "\u00b5 j i is the mean number of events in i-th bin and j-th detector. ",
            "section": "A. Model Description",
            "paragraph_rank": 130,
            "section_rank": 26
        },
        {
            "text": "It depends on the oscillation parameters: sin 2 2\u03b8 and \u2206m 2 , and the nuisance parameters: \u03f5 for the detector efficiency and neutrino flux, and \u03b7 n (\u03b7 f ) for the near (far) detector background normalization factors.",
            "section": "A. Model Description",
            "paragraph_rank": 130,
            "section_rank": 26
        },
        {
            "text": "B. The Wilks' CI method vs. the MC CI method",
            "section_rank": 27
        },
        {
            "text": "For the example mentioned above, the Wilks' method is unsuitable for setting CI for the parameter sin 2 2\u03b8 because the conditions required are not satisfied as stated in Sec. ",
            "section": "B. The Wilks' CI method vs. the MC CI method",
            "paragraph_rank": 131,
            "section_rank": 27
        },
        {
            "text": "II. ",
            "section": "B. The Wilks' CI method vs. the MC CI method",
            "paragraph_rank": 131,
            "section_rank": 27
        },
        {
            "text": "In comparison, the computationally intensive MC CI method need to be used to set CI in this example. ",
            "section": "B. The Wilks' CI method vs. the MC CI method",
            "paragraph_rank": 131,
            "section_rank": 27
        },
        {
            "text": "The purpose of this section is to demonstrate the practical difference between the two methods. ",
            "section": "B. The Wilks' CI method vs. the MC CI method",
            "paragraph_rank": 131,
            "section_rank": 27
        },
        {
            "text": "Here, we examine the distribution of the test statistic in Eq. ",
            "section": "B. The Wilks' CI method vs. the MC CI method",
            "paragraph_rank": 131,
            "section_rank": 27
        },
        {
            "text": "(37) under the hypothesis H 0 : sin 2 2\u03b8 = 0, where the Wilks' method is especially problematic. ",
            "section": "B. The Wilks' CI method vs. the MC CI method",
            "paragraph_rank": 131,
            "section_rank": 27
        },
        {
            "text": "To implement the MC CI method, we generate a large number of MC samples assuming that sin 2 2\u03b8 = 0. ",
            "section": "B. The Wilks' CI method vs. the MC CI method",
            "paragraph_rank": 131,
            "section_rank": 27
        },
        {
            "text": "The MC samples have statistical fluctuations according to Poisson distributions, and systematic variations through randomizing the three nuisance parameters according to normal distributions. ",
            "section": "B. The Wilks' CI method vs. the MC CI method",
            "paragraph_rank": 131,
            "section_rank": 27
        },
        {
            "text": "While the minimization process in calculating T min follows the Frequentist's approach, the randomization of the nuisance parameters corresponds to a Bayesian integral over the nuisance parameters. ",
            "section": "B. The Wilks' CI method vs. the MC CI method",
            "paragraph_rank": 131,
            "section_rank": 27
        },
        {
            "text": "It is a common hybrid Bayesian/Frequentist approach [19]. ",
            "section": "B. The Wilks' CI method vs. the MC CI method",
            "paragraph_rank": 131,
            "section_rank": 27,
            "ref_spans": [
                {
                    "start": 52,
                    "end": 56,
                    "type": "bibr",
                    "ref_id": "b18",
                    "text": "[19]"
                }
            ]
        },
        {
            "text": "As a comparison, we also tried a full Frequentist approach as illustrated in Ref. ",
            "section": "B. The Wilks' CI method vs. the MC CI method",
            "paragraph_rank": 131,
            "section_rank": 27
        },
        {
            "text": "[7,20]. ",
            "section": "B. The Wilks' CI method vs. the MC CI method",
            "paragraph_rank": 131,
            "section_rank": 27,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 3,
                    "type": "bibr",
                    "ref_id": "b6",
                    "text": "[7,"
                },
                {
                    "start": 3,
                    "end": 6,
                    "type": "bibr",
                    "ref_id": "b19",
                    "text": "20]"
                }
            ]
        },
        {
            "text": "Results are very similar to that of the hybrid approach. ",
            "section": "B. The Wilks' CI method vs. the MC CI method",
            "paragraph_rank": 131,
            "section_rank": 27
        },
        {
            "text": "In the latter approach, MCs are generated using the best-fit nuisance parameters obtained in analyzing the data under the sin 2 2\u03b8 = 0 hypothesis. ",
            "section": "B. The Wilks' CI method vs. the MC CI method",
            "paragraph_rank": 131,
            "section_rank": 27
        },
        {
            "text": "For each MC sample, we find T min and T min H0 , where T min is the minimum value of T from Eq. ",
            "section": "B. The Wilks' CI method vs. the MC CI method",
            "paragraph_rank": 131,
            "section_rank": 27
        },
        {
            "text": "(36) in the 5dimensional parameter space of (sin 2 2\u03b8, \u2206m 2 , \u03f5, \u03b7 n , \u03b7 f ), and T min H0 is the minimum value of T under the restriction, sin 2 2\u03b8 true = 0. ",
            "section": "B. The Wilks' CI method vs. the MC CI method",
            "paragraph_rank": 131,
            "section_rank": 27
        },
        {
            "text": "Then we form the test statistic",
            "section": "B. The Wilks' CI method vs. the MC CI method",
            "paragraph_rank": 131,
            "section_rank": 27
        },
        {
            "text": "Fig . 5 shows the distribution of \u2206\u03c7 2 , which clearly does not follow a Chi-square distribution with two degrees of freedom. ",
            "section": "B. The Wilks' CI method vs. the MC CI method",
            "paragraph_rank": 132,
            "section_rank": 27,
            "ref_spans": [
                {
                    "start": 4,
                    "end": 7,
                    "type": "figure",
                    "text": ". 5"
                }
            ]
        },
        {
            "text": "In summary, for this example, the Wilks' method can not be used to correctly set CIs based on the test statistic \u2206\u03c7 2 . ",
            "section": "B. The Wilks' CI method vs. the MC CI method",
            "paragraph_rank": 132,
            "section_rank": 27
        },
        {
            "text": "It is possible to explore alternative formula than that of the Wilks' method, if one takes the hybrid approach in Ref. ",
            "section": "B. The Wilks' CI method vs. the MC CI method",
            "paragraph_rank": 132,
            "section_rank": 27
        },
        {
            "text": "[19] and finds an analytic approximation to the solution of t c for the equation Prob(\u2206\u03c7 2 \u2264 t c ) \u2265 c, where the probability is evaluated over the distribution of the nuisance parameters. ",
            "section": "B. The Wilks' CI method vs. the MC CI method",
            "paragraph_rank": 132,
            "section_rank": 27,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 4,
                    "type": "bibr",
                    "ref_id": "b18",
                    "text": "[19]"
                }
            ]
        },
        {
            "text": "Otherwise, one can always obtain the distribution of \u2206\u03c7 2 through the computationally intensive MC CI method.",
            "section": "B. The Wilks' CI method vs. the MC CI method",
            "paragraph_rank": 132,
            "section_rank": 27
        },
        {
            "text": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "section_rank": 28
        },
        {
            "text": "For the example in the previous section, there is no known way to set CI without computationally intensive MC simulations. ",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 133,
            "section_rank": 28
        },
        {
            "text": "This is the main motivation for using the Gaussian CL s method as an alternative. ",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 133,
            "section_rank": 28
        },
        {
            "text": "In this and \u2206m 2 = 2.5 \u00d7 10 \u22123 eV 2 . ",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 133,
            "section_rank": 28
        },
        {
            "text": "The histograms on the left (right) are made from the MC samples assuming H 1 (H 0 ) is true. ",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 133,
            "section_rank": 28
        },
        {
            "text": "We also compare them with the expected normal distribution N(\u2206T ,4\u2206T ) from the \u2206T H0 and \u2206T H1 calculated from the Asimov data sets. ",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 133,
            "section_rank": 28
        },
        {
            "text": "Good agreements are observed.",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 133,
            "section_rank": 28
        },
        {
            "text": "Similarly, we also check the appearance measurements. ",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 134,
            "section_rank": 28
        },
        {
            "text": "In Fig. 7, the null hypothesis H 0 corresponds to sin 2 2\u03b8 = 0, and the alternative hypothesis H 1 corresponds to (sin 2 2\u03b8, \u2206m 2 ) = (0.008, 2.5 \u00d7 10 \u22123 eV 2 ). ",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 134,
            "section_rank": 28,
            "ref_spans": [
                {
                    "start": 3,
                    "end": 9,
                    "type": "figure",
                    "text": "Fig. 7"
                }
            ]
        },
        {
            "text": "In Fig. 8, H 0 corresponds to sin 2 2\u03b8 = 0, and H 1 corresponds to (sin 2 2\u03b8, \u2206m 2 ) = (0.03, 2.5 \u00d7 10 \u22123 eV 2 ). ",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 134,
            "section_rank": 28,
            "ref_spans": [
                {
                    "start": 3,
                    "end": 9,
                    "type": "figure",
                    "text": "Fig. 8"
                }
            ]
        },
        {
            "text": "The agreement between the MCs and expectations in Fig. 7 is slightly worse than that in Fig. 6, but is still reasonably good. ",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 134,
            "section_rank": 28,
            "ref_spans": [
                {
                    "start": 50,
                    "end": 56,
                    "type": "figure",
                    "text": "Fig. 7"
                },
                {
                    "start": 88,
                    "end": 94,
                    "type": "figure",
                    "text": "Fig. 6"
                }
            ]
        },
        {
            "text": "However, the difference between the MCs and expectations in Fig. 8 becomes large. ",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 134,
            "section_rank": 28,
            "ref_spans": [
                {
                    "start": 60,
                    "end": 66,
                    "type": "figure",
                    "text": "Fig. 8"
                }
            ]
        },
        {
            "text": "This is because the third regularity condition CD3 \"when the prediction of two hypotheses (the null hypotheses H 0 and the alternative hypothesis H 1 are relatively close or |\u00b5 i \u2212 \u03bd i | << \u00b5 i \u223c \u03bd i \" is no longer met. ",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 134,
            "section_rank": 28
        },
        {
            "text": "In a disappearance search, CD3 can be easily satisfied. ",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 134,
            "section_rank": 28
        },
        {
            "text": "However, this may not be true in an appearance experiment as the mean number of signal events is zero when sin 2 2\u03b8 = 0. ",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 134,
            "section_rank": 28
        },
        {
            "text": "When H 0 and H 1 are sin 2 2\u03b8 = 0 and (sin 2 2\u03b8, \u2206m 2 ) = (0.008, 2.5 \u00d7 10 \u22123 eV 2 ), respectively, CD3 is still reasonably well satisfied with the existence of backgrounds. ",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 134,
            "section_rank": 28
        },
        {
            "text": "When H 0 and H 1 are sin 2 2\u03b8 = 0 and (sin 2 2\u03b8, \u2206m 2 ) = (0.03, 2.5 \u00d7 10 \u22123 eV 2 ), respectively, CD3 is severely violated. ",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 134,
            "section_rank": 28
        },
        {
            "text": "Note that in such situations where H 0 and H 1 are very different, the experimental data is most likely able to exclude one hypothesis easily, making it less interesting to carry out such a statistical test. ",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 134,
            "section_rank": 28
        },
        {
            "text": "Nevertheless, we emphasize it is crucial to validate Gaussian approximation with MCs in practice when any of CD1-CD3 listed in the end of Sec. ",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 134,
            "section_rank": 28
        },
        {
            "text": "III are marginally satisfied. ",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 134,
            "section_rank": 28
        },
        {
            "text": "Recall that the CL s approach is based on the test statistic \u2206T = T min H1 \u2212 T min H0 . ",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 134,
            "section_rank": 28
        },
        {
            "text": "Although typical methods to form CIs use a different type of test statistic, namely \u2206\u03c7 2 shown in the previous sections, one can in principle also set CIs based on \u2206T , which we refer to as the \u2206T -based CI method. ",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 134,
            "section_rank": 28
        },
        {
            "text": "Below, we use our example to compare the exclusion sets obtained from the Gaussian CL s method and the CIs obtained from the \u2206T -based CI method. ",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 134,
            "section_rank": 28
        },
        {
            "text": "For the former method, the exclusion set consists of parameter values that correspond to CL s values, specifically (1 \u2212 p 1 )/(1 \u2212 p 0 ), lower than 0.05; and for the latter method, the CI consists of parameter values that correspond to p-values, specifically (1 \u2212 p 1 ), over 0.05. ",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 134,
            "section_rank": 28
        },
        {
            "text": "The results are summarized in Fig. 9. In the example, the true sin 2 2\u03b8 is assumed to be zero. ",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 134,
            "section_rank": 28,
            "ref_spans": [
                {
                    "start": 30,
                    "end": 36,
                    "type": "figure",
                    "ref_id": "fig_12",
                    "text": "Fig. 9"
                }
            ]
        },
        {
            "text": "The sensitivity of the Gaussian CL s method is slightly worse than that of ",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 134,
            "section_rank": 28
        },
        {
            "text": "The true value of sin 2 2\u03b8 is 0. ",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 135,
            "section_rank": 28
        },
        {
            "text": "For the CI (CLs) method, the right side of the red (black) line has a p-value (CLs value) smaller than 0.05. ",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 135,
            "section_rank": 28
        },
        {
            "text": "The sensitivity curves are generated from a large number of Monte Carlo samples. ",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 135,
            "section_rank": 28
        },
        {
            "text": "At each \u2206m 2 , 50% (50%) of MC samples will have a better (worse) exclusion limit than the sensitivity curve.",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 135,
            "section_rank": 28
        },
        {
            "text": "\u2206T -based CI method, because the CL s value is by construction larger than the p-value used in the CI method. ",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 136,
            "section_rank": 28
        },
        {
            "text": "Despite the slightly worse sensitivity, the CL s produces smoother contours that agree better with intuition (not excluding hypotheses that are close to the null hypothesis) than the CI do. ",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 136,
            "section_rank": 28
        },
        {
            "text": "As shown in Fig. 9, the region that correspond to \u2206m 2 \u223c 5.5 \u00d7 10 \u22122 eV 2 and sin 2 2\u03b8 < 0.01 (also \u2206m 2 \u223c 0.1 eV 2 and sin 2 2\u03b8 < 0.01) is excluded from the 95% CI. ",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 136,
            "section_rank": 28,
            "ref_spans": [
                {
                    "start": 12,
                    "end": 18,
                    "type": "figure",
                    "ref_id": "fig_12",
                    "text": "Fig. 9"
                }
            ]
        },
        {
            "text": "This is inconsistent with intuition as the expected spectrum for small sin 2 2\u03b8 values should be very similar to that of sin 2 2\u03b8 = 0, and we do not expect to exclude regions with small sin 2 2\u03b8 values. ",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 136,
            "section_rank": 28
        },
        {
            "text": "This phenomenon can be understood as follows. ",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 136,
            "section_rank": 28
        },
        {
            "text": "With the test statistic \u2206T , we compare two hypotheses each time. ",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 136,
            "section_rank": 28
        },
        {
            "text": "Therefore, even when the two hypotheses are very similar, the chance of excluding one hypothesis with CI can still be large as illustrated in Fig. 3. ",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 136,
            "section_rank": 28,
            "ref_spans": [
                {
                    "start": 142,
                    "end": 148,
                    "type": "figure",
                    "text": "Fig. 3"
                }
            ]
        },
        {
            "text": "As we explained in Sec. ",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 136,
            "section_rank": 28
        },
        {
            "text": "IV A, the definition of the CL s value avoid this problem, giving it an advantage over the traditional CI when test statistic \u2206T is used.",
            "section": "C. Validity of the Gaussian Approximation in the Gaussian CLs method",
            "paragraph_rank": 136,
            "section_rank": 28
        },
        {
            "text": "E. The Gaussian CLs method vs. the MC CI method vs. the Raster-Scan MC CI method",
            "section_rank": 29
        },
        {
            "text": "The statistical interpretation of (the complement of) exclusion sets obtained using the CL s method is distinct from that of CIs. ",
            "section": "E. The Gaussian CLs method vs. the MC CI method vs. the Raster-Scan MC CI method",
            "paragraph_rank": 137,
            "section_rank": 29
        },
        {
            "text": "Indeed, if an exclusion contour based on thresholding the CL s value at \u03b1 is used to set a CI, its coverage probability will be over 1 \u2212 \u03b1. ",
            "section": "E. The Gaussian CLs method vs. the MC CI method vs. the Raster-Scan MC CI method",
            "paragraph_rank": 137,
            "section_rank": 29
        },
        {
            "text": "Nevertheless, it is still interesting to compare these two kinds of sets in specific physics problems, as seen in many literatures (for example, Ref. [15] and Ref. [29]). ",
            "section": "E. The Gaussian CLs method vs. the MC CI method vs. the Raster-Scan MC CI method",
            "paragraph_rank": 137,
            "section_rank": 29,
            "ref_spans": [
                {
                    "start": 150,
                    "end": 154,
                    "type": "bibr",
                    "ref_id": "b14",
                    "text": "[15]"
                },
                {
                    "start": 164,
                    "end": 168,
                    "type": "bibr",
                    "ref_id": "b29",
                    "text": "[29]"
                }
            ]
        },
        {
            "text": "Below, we perform such a comparison under the set up of our example. ",
            "section": "E. The Gaussian CLs method vs. the MC CI method vs. the Raster-Scan MC CI method",
            "paragraph_rank": 137,
            "section_rank": 29
        },
        {
            "text": "Besides the CL s approach and the standard \u2206\u03c7 2 -based CI approach, we also include results from another commonly used approach, the so-called raster-scan CI approach. ",
            "section": "E. The Gaussian CLs method vs. the MC CI method vs. the Raster-Scan MC CI method",
            "paragraph_rank": 137,
            "section_rank": 29
        },
        {
            "text": "In short, this approach scans through all values of the parameter |\u2206m 2 |, and at each fixed |\u2206m 2 |, it checks the compatibility of the other parameter sin 2 2\u03b8 to the data. ",
            "section": "E. The Gaussian CLs method vs. the MC CI method vs. the Raster-Scan MC CI method",
            "paragraph_rank": 137,
            "section_rank": 29
        },
        {
            "text": "A most popular method to carry out the raster scan approach uses the following statistic at each |\u2206m",
            "section": "E. The Gaussian CLs method vs. the MC CI method vs. the Raster-Scan MC CI method",
            "paragraph_rank": 137,
            "section_rank": 29
        },
        {
            "text": "which is similar to the \u2206\u03c7 2 statistic given in Eq. ",
            "section": "E. The Gaussian CLs method vs. the MC CI method vs. the Raster-Scan MC CI method",
            "paragraph_rank": 138,
            "section_rank": 29
        },
        {
            "text": "7except that the global minimum \u03c7 2 min (x) is replaced by the restricted minimum \u03c7 2 RS min (|\u2206m 2 |; x) = min sin 2 2\u03b8,\u03b7 \u03c7 2 (sin 2 2\u03b8, |\u2206m 2 |, \u03b7; x). ",
            "section": "E. The Gaussian CLs method vs. the MC CI method vs. the Raster-Scan MC CI method",
            "paragraph_rank": 138,
            "section_rank": 29,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 1,
                    "ref_id": "formula_6",
                    "text": "7"
                },
                {
                    "start": 84,
                    "end": 85,
                    "type": "bibr",
                    "ref_id": "b1",
                    "text": "2"
                }
            ]
        },
        {
            "text": "Given a fixed value of |\u2206m 2 |, the raster scan method examines all sin 2 2\u03b8 1 values, one at a time, and test the hypothesis H 0 : sin 2 2\u03b8 = sin 2 2\u03b8 1 based on the statistic \u2206\u03c7 2 RS (sin 2 2\u03b8 1 , |\u2206m 2 |; x). ",
            "section": "E. The Gaussian CLs method vs. the MC CI method vs. the Raster-Scan MC CI method",
            "paragraph_rank": 138,
            "section_rank": 29
        },
        {
            "text": "The raster scan approach is usually considered less ideal than the standard CI approach that we described in Sec. ",
            "section": "E. The Gaussian CLs method vs. the MC CI method vs. the Raster-Scan MC CI method",
            "paragraph_rank": 138,
            "section_rank": 29
        },
        {
            "text": "II, mainly because it does not make comparisons between hypotheses that have different values of |\u2206m 2 | and hence can not distinguish a likely value of this parameter from an unlikely one [6]. ",
            "section": "E. The Gaussian CLs method vs. the MC CI method vs. the Raster-Scan MC CI method",
            "paragraph_rank": 138,
            "section_rank": 29,
            "ref_spans": [
                {
                    "start": 189,
                    "end": 192,
                    "type": "bibr",
                    "ref_id": "b5",
                    "text": "[6]"
                }
            ]
        },
        {
            "text": "In addition, according to Eq. ",
            "section": "E. The Gaussian CLs method vs. the MC CI method vs. the Raster-Scan MC CI method",
            "paragraph_rank": 138,
            "section_rank": 29
        },
        {
            "text": "(34) and Eq. ",
            "section": "E. The Gaussian CLs method vs. the MC CI method vs. the Raster-Scan MC CI method",
            "paragraph_rank": 138,
            "section_rank": 29
        },
        {
            "text": "(35), when sin 2 2\u03b8 = 0, any value of |\u2206m 2 | will result in the same model, namely, the Standard Model. ",
            "section": "E. The Gaussian CLs method vs. the MC CI method vs. the Raster-Scan MC CI method",
            "paragraph_rank": 138,
            "section_rank": 29
        },
        {
            "text": "As a consequence, the Standard Model is tested many times against different new physics hypothe-ses that correspond to different values of |\u2206m 2 |, which makes it difficult to interpret the test results. ",
            "section": "E. The Gaussian CLs method vs. the MC CI method vs. the Raster-Scan MC CI method",
            "paragraph_rank": 138,
            "section_rank": 29
        },
        {
            "text": "Whereas in the standard CI approach, any model is tested only once. ",
            "section": "E. The Gaussian CLs method vs. the MC CI method vs. the Raster-Scan MC CI method",
            "paragraph_rank": 138,
            "section_rank": 29
        },
        {
            "text": "Similar to the case of \u2206\u03c7 2 , the regularity condition of the Wilks' theorem would also break for \u2206\u03c7 2",
            "section": "E. The Gaussian CLs method vs. the MC CI method vs. the Raster-Scan MC CI method",
            "paragraph_rank": 138,
            "section_rank": 29
        },
        {
            "text": "RS",
            "section_rank": 30
        },
        {
            "text": "when the true sin 2 2\u03b8 = 0. ",
            "section": "RS",
            "paragraph_rank": 139,
            "section_rank": 30
        },
        {
            "text": "Therefore, Monte Carlo is usually necessary to obtain the distribution of \u2206\u03c7 2 RS to compute CIs using the raster scan. ",
            "section": "RS",
            "paragraph_rank": 139,
            "section_rank": 30,
            "ref_spans": [
                {
                    "start": 77,
                    "end": 78,
                    "type": "bibr",
                    "ref_id": "b1",
                    "text": "2"
                }
            ]
        },
        {
            "text": "Fig. 10 compares the sensitivity of the Gaussian CL s method, the standard MC CI method, and the rasterscan MC CI method. ",
            "section": "RS",
            "paragraph_rank": 139,
            "section_rank": 30,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 7,
                    "type": "figure",
                    "ref_id": "fig_1",
                    "text": "Fig. 10"
                }
            ]
        },
        {
            "text": "We assumed that the true value of sin 2 2\u03b8 is 0 in generating MC. ",
            "section": "RS",
            "paragraph_rank": 139,
            "section_rank": 30
        },
        {
            "text": "At each \u2206m 2 , 50% (50%) of MC samples will have a better (worse) exclusion limit than the sensitivity curve. ",
            "section": "RS",
            "paragraph_rank": 139,
            "section_rank": 30
        },
        {
            "text": "Sensitivities from these three methods are similar. ",
            "section": "RS",
            "paragraph_rank": 139,
            "section_rank": 30
        },
        {
            "text": "The sensitivity of the 95% exclusion set from the Gaussian CL s method is slightly better than that of the 95% CI from the MC CI method, and is in fact Comparison of the sensitivity of the 95% Gaussian CLs method vs. that of the 95% and the 90% MC CI method. ",
            "section": "RS",
            "paragraph_rank": 139,
            "section_rank": 30
        },
        {
            "text": "We also added the 95% raster-scan MC CI for comparison. ",
            "section": "RS",
            "paragraph_rank": 139,
            "section_rank": 30
        },
        {
            "text": "The true value of sin 2 2\u03b8 is 0. ",
            "section": "RS",
            "paragraph_rank": 139,
            "section_rank": 30
        },
        {
            "text": "See texts for more explanations.",
            "section": "RS",
            "paragraph_rank": 139,
            "section_rank": 30
        },
        {
            "text": "close to that of the 90% CI from the MC CI method for this setup. ",
            "section": "RS",
            "paragraph_rank": 140,
            "section_rank": 30
        },
        {
            "text": "This is expected, since the test statistic \u2206T = T min H1 \u2212T min H0 used in the Gaussian CL s method is designed to focus on the differences between the new physics hypotheses (H 1 : sin 2 2\u03b8 = sin 2 2\u03b8 1 for some sin 2 2\u03b8 1 > 0), with the Standard Model (H 0 : sin 2 2\u03b8 = 0). ",
            "section": "RS",
            "paragraph_rank": 140,
            "section_rank": 30
        },
        {
            "text": "Therefore, when the true value of sin 2 2\u03b8 is 0, the Gaussian CL s method has larger power to exclude new physics hypotheses than the MC CI method. ",
            "section": "RS",
            "paragraph_rank": 140,
            "section_rank": 30
        },
        {
            "text": "In addition, the 95% sensitivity from the Gaussian CL s method is very close to that from the raster-scan MC CI method. ",
            "section": "RS",
            "paragraph_rank": 140,
            "section_rank": 30
        },
        {
            "text": "This is actually a coincidence, since the CL s method and the rasterscan method use the ratios of p-values and p-value to set limits, respectively. ",
            "section": "RS",
            "paragraph_rank": 140,
            "section_rank": 30
        },
        {
            "text": "The left panel of Fig. 11 shows the difference between the CL s sensitivity (CL s value) and raster-scan sensitivity (p-value) at each parameter point. ",
            "section": "RS",
            "paragraph_rank": 140,
            "section_rank": 30,
            "ref_spans": [
                {
                    "start": 18,
                    "end": 25,
                    "type": "figure",
                    "ref_id": "fig_1",
                    "text": "Fig. 11"
                }
            ]
        },
        {
            "text": "The difference is rather large at small values of sin 2 2\u03b8, which indicates that the similarity of the 95% lines between the CL s method and the raster-scan method is a coincidence. ",
            "section": "RS",
            "paragraph_rank": 140,
            "section_rank": 30
        },
        {
            "text": "The right panel of Fig. 11 shows the sensitivity difference between the raster-scan MC CI method and the standard MC CI method. ",
            "section": "RS",
            "paragraph_rank": 140,
            "section_rank": 30,
            "ref_spans": [
                {
                    "start": 19,
                    "end": 26,
                    "type": "figure",
                    "ref_id": "fig_1",
                    "text": "Fig. 11"
                }
            ]
        },
        {
            "text": "The sensitivity are also different, since the choice of test statistics are different between the raster-scan MC CI method and the standard MC CI method.",
            "section": "RS",
            "paragraph_rank": 140,
            "section_rank": 30
        },
        {
            "text": "When the new physics is indeed true, the standard MC CI method has clear advantage in constraining the parameter space over the other two methods. ",
            "section": "RS",
            "paragraph_rank": 141,
            "section_rank": 30
        },
        {
            "text": "This is shown in Fig. 12. ",
            "section": "RS",
            "paragraph_rank": 141,
            "section_rank": 30,
            "ref_spans": [
                {
                    "start": 17,
                    "end": 24,
                    "type": "figure",
                    "ref_id": "fig_1",
                    "text": "Fig. 12"
                }
            ]
        },
        {
            "text": "The MC sample is generated with sin 2 2\u03b8 true = 0.1 and \u2206m 2 true = 2.5\u00d710 \u22123 eV 2 with statistical fluctuations and systematic variations. ",
            "section": "RS",
            "paragraph_rank": 141,
            "section_rank": 30
        },
        {
            "text": "The 90% CI of the MC CI method were able to identify a small region close to the true value. ",
            "section": "RS",
            "paragraph_rank": 141,
            "section_rank": 30
        },
        {
            "text": "In comparison, the 95% CL s limit successfully excluded the region on the right, but failed to exclude regions (on the left of line) far away from the true value. ",
            "section": "RS",
            "paragraph_rank": 141,
            "section_rank": 30
        },
        {
            "text": "This again is due to the choice of the test statistic (\u2206T in the Gaussian CL s method vs. \u2206\u03c7 2 in the MC CI method). ",
            "section": "RS",
            "paragraph_rank": 141,
            "section_rank": 30
        },
        {
            "text": "The proposed test statistic \u2206T focuses on the difference between the new physics hypothesis and the Standard Model, while the test statistic \u2206\u03c7 2 takes into account all the likely values of (sin 2 2\u03b8, \u2206m 2 ). ",
            "section": "RS",
            "paragraph_rank": 141,
            "section_rank": 30
        },
        {
            "text": "Therefore, we confirm the conclusion from Ref. ",
            "section": "RS",
            "paragraph_rank": 141,
            "section_rank": 30
        },
        {
            "text": "[15]: \"the CL s technique for setting limits is appropriate for determining exclusion sets while the determination of CIs advocated by the Feldman-Cousins method is more appropriate for treating established signals\". ",
            "section": "RS",
            "paragraph_rank": 141,
            "section_rank": 30,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 4,
                    "type": "bibr",
                    "ref_id": "b14",
                    "text": "[15]"
                }
            ]
        },
        {
            "text": "For comparison, we also display the 95% raster-scan MC CI. ",
            "section": "RS",
            "paragraph_rank": 141,
            "section_rank": 30
        },
        {
            "text": "Since the raster scan can not distinguish likely and unlikely values of the parameter |\u2206m 2 |, it also failed to exclude some regions of the parameter space that are far away from the truth.",
            "section": "RS",
            "paragraph_rank": 141,
            "section_rank": 30
        },
        {
            "text": "VI. ",
            "section_rank": 31
        },
        {
            "text": "DISCUSSION",
            "section_rank": 31
        },
        {
            "text": "In order to use the Gaussian CL s method, it is important that the CD1-CD3 listed in the end of Sec. ",
            "section": "VI. DISCUSSION",
            "paragraph_rank": 142,
            "section_rank": 31
        },
        {
            "text": "III are met. ",
            "section": "VI. DISCUSSION",
            "paragraph_rank": 142,
            "section_rank": 31
        },
        {
            "text": "The first condition CD1 is continuity of the parameter space for the nuisance parameters, under both the null and the alternative hypotheses. ",
            "section": "VI. DISCUSSION",
            "paragraph_rank": 142,
            "section_rank": 31
        },
        {
            "text": "This requirement is easier to achieve compared to the first regularity condition required by the Wilks' theorem, since it concerns the nuisance parameters only, not the parameters of interest, (sin 2 2\u03b8, |\u2206m 2 |). ",
            "section": "VI. DISCUSSION",
            "paragraph_rank": 142,
            "section_rank": 31
        },
        {
            "text": "The second condition CD2 concerns large enough data size, which is also easier to reach compared to that required by the Wilks' theorem. ",
            "section": "VI. DISCUSSION",
            "paragraph_rank": 142,
            "section_rank": 31
        },
        {
            "text": "This is because in the Gaussian CL s method tests a simpler pair of hypotheses, in which the values of (sin 2 2\u03b8, |\u2206m 2 |) are fixed, and one automatically avoids the situation shown in Fig. 1b that involves minimization over a large range of |\u2206m 2 | in calculating the test statistic. ",
            "section": "VI. DISCUSSION",
            "paragraph_rank": 142,
            "section_rank": 31,
            "ref_spans": [
                {
                    "start": 186,
                    "end": 193,
                    "type": "figure",
                    "ref_id": "fig_1",
                    "text": "Fig. 1b"
                }
            ]
        },
        {
            "text": "The third condition CD3 is that the difference between the predictions of two hypotheses is small comparing to the predictions themselves. ",
            "section": "VI. DISCUSSION",
            "paragraph_rank": 142,
            "section_rank": 31
        },
        {
            "text": "In searching for new physics with precision measurements, the signal from the Standard Model is usually much larger than the potential signal from new physics. ",
            "section": "VI. DISCUSSION",
            "paragraph_rank": 142,
            "section_rank": 31
        },
        {
            "text": "Therefore, CD3 is generally satisfied. ",
            "section": "VI. DISCUSSION",
            "paragraph_rank": 142,
            "section_rank": 31
        },
        {
            "text": "In the case that CD3 is violated or marginally satisfied (see Fig. 8), one should use Monte Carlo simulation to derive the distribution of the test statistic.",
            "section": "VI. DISCUSSION",
            "paragraph_rank": 142,
            "section_rank": 31,
            "ref_spans": [
                {
                    "start": 62,
                    "end": 68,
                    "type": "figure",
                    "text": "Fig. 8"
                }
            ]
        },
        {
            "text": "Similar to the Wilks' CI method based on the test statistic \u2206\u03c7 2 and predefined constants, the Gaussian CL s method also allows easy combination of multiple independent experimental results that probe the same parameter space. ",
            "section": "VI. DISCUSSION",
            "paragraph_rank": 143,
            "section_rank": 31
        },
        {
            "text": "The CL s value at each alternative hypothesis H 1 ). ",
            "section": "VI. DISCUSSION",
            "paragraph_rank": 143,
            "section_rank": 31
        },
        {
            "text": "In practice, the main challenge in combining multiple experiment results arise from the potential correlation among different experiments and requires careful examinations.",
            "section": "VI. DISCUSSION",
            "paragraph_rank": 143,
            "section_rank": 31
        },
        {
            "text": "So far, we have argued that, in practice, the CL s method is often simple to use and allows easy combination of multiple results. ",
            "section": "VI. DISCUSSION",
            "paragraph_rank": 144,
            "section_rank": 31
        },
        {
            "text": "But it is important to remind the readers that the CL s is a limited method that aims at setting boundaries only. ",
            "section": "VI. DISCUSSION",
            "paragraph_rank": 144,
            "section_rank": 31
        },
        {
            "text": "The CL s based on \u2206T does not directly address the question \"do we see new physics or not\", nor does it provide estimate of parameters. ",
            "section": "VI. DISCUSSION",
            "paragraph_rank": 144,
            "section_rank": 31
        },
        {
            "text": "To help address the first question, we recommend reporting the p-value based on the test statistic \u2206\u03c7 2 assuming the Standard Model is true, in addition to the obtained exclusion sets. ",
            "section": "VI. DISCUSSION",
            "paragraph_rank": 144,
            "section_rank": 31
        },
        {
            "text": "To address the second question, the standard CI approach is needed. ",
            "section": "VI. DISCUSSION",
            "paragraph_rank": 144,
            "section_rank": 31
        },
        {
            "text": "Indeed, the standard CI approach is the preferred approach to take whenever one can afford to carry it out correctly, because the standard CI approach is a unified approach to set limits in the absence of new physics signals and to estimate parameters after the discovery of new physics [6].",
            "section": "VI. DISCUSSION",
            "paragraph_rank": 144,
            "section_rank": 31,
            "ref_spans": [
                {
                    "start": 287,
                    "end": 290,
                    "type": "bibr",
                    "ref_id": "b5",
                    "text": "[6]"
                }
            ]
        },
        {
            "text": "VII. ",
            "section_rank": 32
        },
        {
            "text": "SUMMARY",
            "section_rank": 32
        },
        {
            "text": "In this paper, we describe a method to present results in searching for new physics in a continuous parameter space. ",
            "section": "VII. SUMMARY",
            "paragraph_rank": 145,
            "section_rank": 32
        },
        {
            "text": "This method takes the CL s approach to obtain exclusion sets for parameters. ",
            "section": "VII. SUMMARY",
            "paragraph_rank": 145,
            "section_rank": 32
        },
        {
            "text": "Specifically, the method consists of testing many pairs of hypotheses. ",
            "section": "VII. SUMMARY",
            "paragraph_rank": 145,
            "section_rank": 32
        },
        {
            "text": "Each time, a new physics model is tested against the Standard Model using the log-likelihood ratio test statistic, or certain variations of it, denoted by \u2206T . ",
            "section": "VII. SUMMARY",
            "paragraph_rank": 145,
            "section_rank": 32
        },
        {
            "text": "We provide a mathematical proof to show that the distribution of \u2206T follows a Gaussian distribution at large data limit under either hypothesis, when the two hypotheses are relatively close. ",
            "section": "VII. SUMMARY",
            "paragraph_rank": 145,
            "section_rank": 32
        },
        {
            "text": "This result allows a simple alternative to the computationally intensive Monte Carlo method to calculate CL s values, and thus to set exclusion limits in one or multiple dimensional parameter spaces. ",
            "section": "VII. SUMMARY",
            "paragraph_rank": 145,
            "section_rank": 32
        },
        {
            "text": "This method can also be used to conveniently combine results from multiple experiments. ",
            "section": "VII. SUMMARY",
            "paragraph_rank": 145,
            "section_rank": 32
        },
        {
            "text": "where",
            "section": "VII. SUMMARY",
            "paragraph_rank": 146,
            "section_rank": 32
        },
        {
            "text": "and B * n\u00d7q * = \u2202\u03c4 0 \u2202\u03b6 .",
            "section": "VII. SUMMARY",
            "paragraph_rank": 147,
            "section_rank": 32
        },
        {
            "text": "Further,",
            "section": "VII. SUMMARY",
            "paragraph_rank": 148,
            "section_rank": 32
        },
        {
            "text": "Proof. ",
            "section": "VII. SUMMARY",
            "paragraph_rank": 149,
            "section_rank": 32
        },
        {
            "text": "By definition,\u03b6 is such that That is,",
            "section": "VII. SUMMARY",
            "paragraph_rank": 149,
            "section_rank": 32
        },
        {
            "text": "Note by delta's method",
            "section": "VII. SUMMARY",
            "paragraph_rank": 150,
            "section_rank": 32
        },
        {
            "text": "and",
            "section": "VII. SUMMARY",
            "paragraph_rank": 151,
            "section_rank": 32
        },
        {
            "text": "Hence, the lhs of Eq. ",
            "section": "VII. SUMMARY",
            "paragraph_rank": 152,
            "section_rank": 32
        },
        {
            "text": "(41) becomes",
            "section": "VII. SUMMARY",
            "paragraph_rank": 152,
            "section_rank": 32
        },
        {
            "text": "The rhs of Eq. ",
            "section": "VII. SUMMARY",
            "paragraph_rank": 153,
            "section_rank": 32
        },
        {
            "text": "(41) becomes",
            "section": "VII. SUMMARY",
            "paragraph_rank": 153,
            "section_rank": 32
        },
        {
            "text": "Hence, equating lhs and rhs leads to, for j = 1, ",
            "section": "VII. SUMMARY",
            "paragraph_rank": 154,
            "section_rank": 32
        },
        {
            "text": "That is",
            "section": "VII. SUMMARY",
            "paragraph_rank": 155,
            "section_rank": 32
        },
        {
            "text": "Therefore",
            "section": "VII. SUMMARY",
            "paragraph_rank": 156,
            "section_rank": 32
        },
        {
            "text": "Hence",
            "section": "VII. SUMMARY",
            "paragraph_rank": 157,
            "section_rank": 32
        },
        {
            "text": "By fixing a reference value of \u03b2, say \u03b2 ref , one can test a pair of non-nested hypotheses H 0 : \u03b2 = \u03b2 ref versus H 1 : \u03b2 = \u03b2 1 using a test statistic of the form \u2206T (\u03b2 ref , \u03b2 1 ; x) := \u03c7 2 (\u03b2 1 ; x) \u2212 \u03c7 2 (\u03b2 ref ; x) .",
            "paragraph_rank": 158,
            "section_rank": 33
        },
        {
            "text": "FIG. 1 .",
            "section_rank": 34
        },
        {
            "text": "FIG. 1. ",
            "section": "FIG. 1 .",
            "paragraph_rank": 159,
            "section_rank": 34
        },
        {
            "text": "(color online) ",
            "section": "FIG. 1 .",
            "paragraph_rank": 159,
            "section_rank": 34
        },
        {
            "text": "Left panel ",
            "section": "FIG. 1 .",
            "paragraph_rank": 159,
            "section_rank": 34
        },
        {
            "text": "(a): The parameter space of sin 2 2\u03b8 vs. |\u2206m 2 | in the Cartesian coordinate. ",
            "section": "FIG. 1 .",
            "paragraph_rank": 159,
            "section_rank": 34
        },
        {
            "text": "Physical constraints are sin 2 2\u03b8 \u2265 0 and |\u2206m 2 | \u2265 0. ",
            "section": "FIG. 1 .",
            "paragraph_rank": 159,
            "section_rank": 34
        },
        {
            "text": "Right panel ",
            "section": "FIG. 1 .",
            "paragraph_rank": 159,
            "section_rank": 34
        },
        {
            "text": "(b): Schematic illustration of the effective parameter space of sin 2 \u03b8 vs. |\u2206m 2 | taking into account the spectral difference measured by \u03c7 2 defined in Eq. ",
            "section": "FIG. 1 .",
            "paragraph_rank": 159,
            "section_rank": 34
        },
        {
            "text": "(3). ",
            "section": "FIG. 1 .",
            "paragraph_rank": 159,
            "section_rank": 34
        },
        {
            "text": "When sin 2 2\u03b8 = 0, points with different values of |\u2206m 2 | will converge into a single point. ",
            "section": "FIG. 1 .",
            "paragraph_rank": 159,
            "section_rank": 34
        },
        {
            "text": "This can be easily seen from Eq. ",
            "section": "FIG. 1 .",
            "paragraph_rank": 159,
            "section_rank": 34
        },
        {
            "text": "(9). ",
            "section": "FIG. 1 .",
            "paragraph_rank": 159,
            "section_rank": 34
        },
        {
            "text": "At sin 2 2\u03b8 = 0, |\u2206m 2 | has no impact on the neutrino spectrum. ",
            "section": "FIG. 1 .",
            "paragraph_rank": 159,
            "section_rank": 34
        },
        {
            "text": "Therefore, when sin 2 2\u03b8 = 0, there is no open neighborhood around the true value, leading to a failure of regularity conditions required by the Wilks' theorem.",
            "section": "FIG. 1 .",
            "paragraph_rank": 159,
            "section_rank": 34
        },
        {
            "text": "and Eq. ",
            "paragraph_rank": 160,
            "section_rank": 35
        },
        {
            "text": "(16) origin from the likelihood function of the Poisson and the Gaussian distribution, respectively. ",
            "paragraph_rank": 160,
            "section_rank": 35
        },
        {
            "text": "Eq. ",
            "paragraph_rank": 160,
            "section_rank": 35
        },
        {
            "text": "(17) and Eq. ",
            "paragraph_rank": 160,
            "section_rank": 35
        },
        {
            "text": "(18) are variations of Eq. ",
            "paragraph_rank": 160,
            "section_rank": 35
        },
        {
            "text": "(16), and are commonly referred to as the Pearson and the Neyman Chi-square, respectively 5 Note that Eq. ",
            "paragraph_rank": 160,
            "section_rank": 35
        },
        {
            "text": "(3) is a specific example of Eq. ",
            "paragraph_rank": 160,
            "section_rank": 35
        },
        {
            "text": "(17)",
            "paragraph_rank": 160,
            "section_rank": 35
        },
        {
            "text": "\u2022",
            "section_rank": 36
        },
        {
            "text": "Ym = op(Xm) if and only if Ym/Xm \u2192 0 in probability as m \u2192 \u221e, and \u2022 Ym = Op(Xm) if and only if Ym/Xm is bounded in probability as m \u2192 \u221e . ",
            "section": "\u2022",
            "paragraph_rank": 161,
            "section_rank": 36
        },
        {
            "text": "In the special case where {Xm} and {Ym} are deterministic sequences, the stochastic op and Op symbols reduce to the o and O symbols. ",
            "section": "\u2022",
            "paragraph_rank": 161,
            "section_rank": 36
        },
        {
            "text": "See Ref. ",
            "section": "\u2022",
            "paragraph_rank": 161,
            "section_rank": 36
        },
        {
            "text": "[22, sec 2.2] for details on the rules of calculus with these symbols.",
            "section": "\u2022",
            "paragraph_rank": 161,
            "section_rank": 36
        },
        {
            "text": "Under the correct hypothesis Under the alternative hypothesis General notation",
            "section_rank": 37
        },
        {
            "text": "Mean bin counts \u00b5(\u03b7) = (\u00b51(\u03b7), \u2022 \u2022 \u2022 , \u00b5N (\u03b7)) \u03bd(\u03b6) = (\u00b51(\u03b6), \u2022 \u2022 \u2022 , \u00b5N (\u03b6)) Per-unit mean counts \u03c0(\u03b7) = \u00b5(\u03b7)/m \u03c4 (\u03b6) = \u03bd(\u03b6)/m True values or their closest approximations under the give model nuisance parameter \u03b70 (a q-dim vector) \u03b60 (a q * -dim vector) Mean bin counts \u00b5 0 = \u00b5(\u03b70) \u03bd 0 = \u03bd(\u03b60) Per-unit mean counts \u03c0 0 = \u00b5 0 /m \u03c4 0 = \u03bd 0 /m Estimation based on observed data nuisance parameter\u03b7 = arg min \u03c7 2 H 0 (\u03b7; X)\u03b6 = arg min \u03c7 2 H 1 (\u03b6; X) Mean bin counts\u03bc = \u00b5(\u03b7)\u03bd = \u03bd(\u03b6) Per-unit mean counts\u03c0 =\u03bc/m\u03c4 =\u03bd/m TABLE I. Legend of symbols used in describing the correct model and the alternative model, respectively.",
            "section": "Under the correct hypothesis Under the alternative hypothesis General notation",
            "paragraph_rank": 162,
            "section_rank": 37
        },
        {
            "text": ", n. ",
            "paragraph_rank": 163,
            "section_rank": 38
        },
        {
            "text": "Then by the Taylor expansion of f = (f 1 , \u2022 \u2022 \u2022 , f n ) T and e = (e 1 , \u2022 \u2022 \u2022 , e n ) T around (a, b, c) = (0, 0, 0), we have",
            "paragraph_rank": 163,
            "section_rank": 38
        },
        {
            "text": "Note that under assumption [A0], D 1 = D is of order O(m). ",
            "paragraph_rank": 164,
            "section_rank": 39
        },
        {
            "text": "Next denote the second term of D by D 2 . ",
            "paragraph_rank": 164,
            "section_rank": 39
        },
        {
            "text": "The central limit theorem implies that as m increases to infinity, \u221a m (p \u2212 \u03c0 0 ) converges in distribution to the N(0",
            "paragraph_rank": 164,
            "section_rank": 39
        },
        {
            "text": "i (\u03bdi\u2212Ni) 2",
            "section_rank": 40
        },
        {
            "text": "\u03bdi are very small compared to the latter and are hence negligible. ",
            "section": "i (\u03bdi\u2212Ni) 2",
            "paragraph_rank": 165,
            "section_rank": 40
        },
        {
            "text": "It follows that the different versions of the test statistic \u2206T (X) will behave similarly as D(X). ",
            "section": "i (\u03bdi\u2212Ni) 2",
            "paragraph_rank": 165,
            "section_rank": 40
        },
        {
            "text": "Finally, it is easy to see that our definition for D in Eq. ",
            "section": "i (\u03bdi\u2212Ni) 2",
            "paragraph_rank": 165,
            "section_rank": 40
        },
        {
            "text": "(25) is equivalent to \u2206T (defined in Eq. ",
            "section": "i (\u03bdi\u2212Ni) 2",
            "paragraph_rank": 165,
            "section_rank": 40
        },
        {
            "text": "(20)) based on Eq. ",
            "section": "i (\u03bdi\u2212Ni) 2",
            "paragraph_rank": 165,
            "section_rank": 40
        },
        {
            "text": "(17). ",
            "section": "i (\u03bdi\u2212Ni) 2",
            "paragraph_rank": 165,
            "section_rank": 40
        },
        {
            "text": "Our main result in Eq. ",
            "section": "i (\u03bdi\u2212Ni) 2",
            "paragraph_rank": 165,
            "section_rank": 40
        },
        {
            "text": "(28) can be stated as \u2206T approx. ",
            "section": "i (\u03bdi\u2212Ni) 2",
            "paragraph_rank": 165,
            "section_rank": 40
        },
        {
            "text": "\u223c N (\u2206T , 4|\u2206T |).",
            "section": "i (\u03bdi\u2212Ni) 2",
            "paragraph_rank": 165,
            "section_rank": 40
        },
        {
            "text": "1 . ",
            "section_rank": 41
        },
        {
            "text": "2 .",
            "section_rank": 41
        },
        {
            "text": "From the observed data x, obtain \u2206T (x) := T min H1 (x) \u2212 T min H0 (x). ",
            "section": "1 . 2 .",
            "paragraph_rank": 166,
            "section_rank": 41
        },
        {
            "text": "From the Asimov data set x Asimov H0 , obtain \u2206T H0 = \u2206T (x Asimov H0 ) = T min H1 (x Asimov H0 ) according to Eq. ",
            "section": "1 . 2 .",
            "paragraph_rank": 166,
            "section_rank": 41
        },
        {
            "text": "(20). ",
            "section": "1 . 2 .",
            "paragraph_rank": 166,
            "section_rank": 41
        },
        {
            "text": "Then according to the main result that we prove in Sec. ",
            "section": "1 . 2 .",
            "paragraph_rank": 166,
            "section_rank": 41
        },
        {
            "text": "III B, under H 0 , \u2206T (X) follows approximately a Gaussian distribution with mean \u2206T H0 and standard deviation 2 \u221a |\u2206T H0 |. ",
            "section": "1 . 2 .",
            "paragraph_rank": 166,
            "section_rank": 41
        },
        {
            "text": "This suggests that one can approximate 1\u2212p 0 using",
            "section": "1 . 2 .",
            "paragraph_rank": 166,
            "section_rank": 41
        },
        {
            "text": "FIG. 4 .",
            "section_rank": 42
        },
        {
            "text": "FIG. 4. ",
            "section": "FIG. 4 .",
            "paragraph_rank": 167,
            "section_rank": 42
        },
        {
            "text": "(color online)Top panels show the mean number of events seen at the near and far detectors in a disappearance experiment. ",
            "section": "FIG. 4 .",
            "paragraph_rank": 167,
            "section_rank": 42
        },
        {
            "text": "Bottom panels show the mean number of events seen at near and far detectors in an appearance experiment. ",
            "section": "FIG. 4 .",
            "paragraph_rank": 167,
            "section_rank": 42
        },
        {
            "text": "Left and right panels show near and far detectors, respectively. ",
            "section": "FIG. 4 .",
            "paragraph_rank": 167,
            "section_rank": 42
        },
        {
            "text": "See text for more explanations.",
            "section": "FIG. 4 .",
            "paragraph_rank": 167,
            "section_rank": 42
        },
        {
            "text": "FIG. 5 .",
            "section_rank": 43
        },
        {
            "text": "FIG. ",
            "section_rank": 43
        },
        {
            "text": "6 .",
            "section_rank": 43
        },
        {
            "text": "FIG. 5. ",
            "section": "FIG. 5 .FIG. 6 .",
            "paragraph_rank": 168,
            "section_rank": 43
        },
        {
            "text": "(color online) ",
            "section": "FIG. 5 .FIG. 6 .",
            "paragraph_rank": 168,
            "section_rank": 43
        },
        {
            "text": "Distributions of \u2206\u03c7 2 = T (sin 2 2\u03b8 = 0) \u2212 Tmin is plotted for MCs with the true sin 2 2\u03b8 = 0. ",
            "section": "FIG. 5 .FIG. 6 .",
            "paragraph_rank": 168,
            "section_rank": 43
        },
        {
            "text": "Distributions based on the hybrid Bayesian/Frequentist and full Frequentist approaches are compared to the Chi-square distribution with two degrees of freedom.",
            "section": "FIG. 5 .FIG. 6 .",
            "paragraph_rank": 168,
            "section_rank": 43
        },
        {
            "text": "FIG. 7 .",
            "section_rank": 44
        },
        {
            "text": "FIG. ",
            "section_rank": 44
        },
        {
            "text": "8 .",
            "section_rank": 44
        },
        {
            "text": "FIG. 7. ",
            "section": "FIG. 7 .FIG. 8 .",
            "paragraph_rank": 169,
            "section_rank": 44
        },
        {
            "text": "(color online) ",
            "section": "FIG. 7 .FIG. 8 .",
            "paragraph_rank": 169,
            "section_rank": 44
        },
        {
            "text": "The test statistic \u2206T= T min H 1 \u2212 T min H 0is plotted for MCs (appearance) assuming the hypothesis H0 or H1 is true. ",
            "section": "FIG. 7 .FIG. 8 .",
            "paragraph_rank": 169,
            "section_rank": 44
        },
        {
            "text": "Here, the null hypothesis H0 corresponds to sin 2 2\u03b8 = 0. ",
            "section": "FIG. 7 .FIG. 8 .",
            "paragraph_rank": 169,
            "section_rank": 44
        },
        {
            "text": "The alternative hypothesis H1 corresponds to sin 2 2\u03b8 = 0.008 and \u2206m 2 = 2.5 \u00d7 10 \u22123 eV 2 .",
            "section": "FIG. 7 .FIG. 8 .",
            "paragraph_rank": 169,
            "section_rank": 44
        },
        {
            "text": "FIG. 9 .",
            "section_rank": 45
        },
        {
            "text": "FIG. 9. ",
            "section": "FIG. 9 .",
            "paragraph_rank": 170,
            "section_rank": 45
        },
        {
            "text": "(color online)Comparison of the exclusion sets determined by the Gaussian CLs method vs. the CI, both using the test statistic \u2206T = T min H 1 \u2212 T min H 0 . ",
            "section": "FIG. 9 .",
            "paragraph_rank": 170,
            "section_rank": 45
        },
        {
            "text": "The true value of sin 2 2\u03b8 is ",
            "section": "FIG. 9 .",
            "paragraph_rank": 170,
            "section_rank": 45
        },
        {
            "text": "0. For the CI (CLs) method, the right side of the red (black) line has a p-value (CLs value) smaller than 0.05. ",
            "section": "FIG. 9 .",
            "paragraph_rank": 170,
            "section_rank": 45
        },
        {
            "text": "The sensitivity curves are generated from a large number of Monte Carlo samples. ",
            "section": "FIG. 9 .",
            "paragraph_rank": 170,
            "section_rank": 45
        },
        {
            "text": "At each \u2206m 2 , 50% (50%) of MC samples will have a better (worse) exclusion limit than the sensitivity curve.",
            "section": "FIG. 9 .",
            "paragraph_rank": 170,
            "section_rank": 45
        },
        {
            "text": "FIG. 10",
            "section_rank": 46
        },
        {
            "text": "FIG. 10. ",
            "section": "FIG. 10",
            "paragraph_rank": 171,
            "section_rank": 46
        },
        {
            "text": "(color online)Comparison of the sensitivity of the 95% Gaussian CLs method vs. that of the 95% and the 90% MC CI method. ",
            "section": "FIG. 10",
            "paragraph_rank": 171,
            "section_rank": 46
        },
        {
            "text": "We also added the 95% raster-scan MC CI for comparison. ",
            "section": "FIG. 10",
            "paragraph_rank": 171,
            "section_rank": 46
        },
        {
            "text": "The true value of sin 2 2\u03b8 is 0. ",
            "section": "FIG. 10",
            "paragraph_rank": 171,
            "section_rank": 46
        },
        {
            "text": "See texts for more explanations.",
            "section": "FIG. 10",
            "paragraph_rank": 171,
            "section_rank": 46
        },
        {
            "text": "FIG. 12 .",
            "section_rank": 47
        },
        {
            "text": "FIG. 11. ",
            "section": "FIG. 12 .",
            "paragraph_rank": 172,
            "section_rank": 47
        },
        {
            "text": "(color online)Left panel: the difference between the CLs sensitivity and the raster-scan sensitivity is shown at each parameter point. ",
            "section": "FIG. 12 .",
            "paragraph_rank": 172,
            "section_rank": 47
        },
        {
            "text": "Right panel: the difference between the raster-scan sensitivity and the standard CI sensitivity is shown at each parameter point.",
            "section": "FIG. 12 .",
            "paragraph_rank": 172,
            "section_rank": 47
        },
        {
            "text": "Lemma 1 .",
            "section_rank": 48
        },
        {
            "text": "Assuming [A0], we have \u221a m ( p \u2212 \u03c0 0 \u03c4 \u2212 \u03c4 0",
            "section": "Lemma 1 .",
            "paragraph_rank": 173,
            "section_rank": 48
        },
        {
            "text": "j = 1, \u2022 \u2022 \u2022 , q * .",
            "paragraph_rank": 174,
            "section_rank": 49
        },
        {
            "text": "Note that, under assumption [A0], all the terms are O p (m \u2212 1 2 ) or smaller except for the first term on the lhs. ",
            "paragraph_rank": 175,
            "section_rank": 50
        },
        {
            "text": "Letting m grow to infinity in Eq. ",
            "paragraph_rank": 175,
            "section_rank": 50
        },
        {
            "text": "(42) implies that n . ",
            "paragraph_rank": 175,
            "section_rank": 50
        },
        {
            "text": "(40) of Lemma 1. ",
            "paragraph_rank": 175,
            "section_rank": 50
        },
        {
            "text": "Plugging this result back into Eq. ",
            "paragraph_rank": 175,
            "section_rank": 50
        },
        {
            "text": "(42), we have 0 + 2B * T diag",
            "paragraph_rank": 175,
            "section_rank": 50
        },
        {
            "text": ").",
            "paragraph_rank": 176,
            "section_rank": 51
        },
        {
            "text": "Assumption[A1]  means that the best model under the wrong hypothesis is just barely incorrect. ",
            "paragraph_rank": 176,
            "section_rank": 51
        },
        {
            "text": "For example, under [A1], Ref.",
            "paragraph_rank": 176,
            "section_rank": 51
        },
        {
            "text": "[10] showed that the likelihood ratio test statistic for testing H 1 against the full parameter space (that is, the statistic T min H1 (X) based on Eq. ",
            "paragraph_rank": 176,
            "section_rank": 51,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 4,
                    "type": "bibr",
                    "ref_id": "b9",
                    "text": "[10]"
                }
            ]
        },
        {
            "text": "(15) and Eq. ",
            "paragraph_rank": 176,
            "section_rank": 51
        },
        {
            "text": "(16)) has a limiting non-central Chi-square distribution. ",
            "paragraph_rank": 176,
            "section_rank": 51
        },
        {
            "text": "The noncentrality parameter has the same form as the test statistic, but with\u03bc and\u03bd replaced by \u00b5 0 and \u03bd 0 . ",
            "paragraph_rank": 176,
            "section_rank": 51
        },
        {
            "text": "For a simplified presentation of this result, see, for example, Ref.",
            "paragraph_rank": 176,
            "section_rank": 51
        },
        {
            "text": "[12, Sec. 3.1]. ",
            "paragraph_rank": 176,
            "section_rank": 51,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 4,
                    "type": "bibr",
                    "ref_id": "b11",
                    "text": "[12,"
                }
            ]
        },
        {
            "text": "Under [A1], the non-centrality parameter is finite and the non-central Chi-square approximations are accurate to the extent that the O p",
            "paragraph_rank": 176,
            "section_rank": 51
        },
        {
            "text": "Clearly, [A0] is a more relaxed condition than [A1], in the sense that [A1] implies [A0], but not vice versa. ",
            "paragraph_rank": 177,
            "section_rank": 52
        },
        {
            "text": "An example where [A0] holds and [A1] does not, is the case that the nuisance parameter is absent: each hypothesis allows exactly one model, such that the per unit mean bin counts of the model under H 0 is \u03c0 0 , and that under H 1 is \u03c4 0 , where \u03c0 0 and \u03c4 0 are vectors of constants that do not change with the data size m. ",
            "paragraph_rank": 177,
            "section_rank": 52
        },
        {
            "text": "As for general cases where there are nontrivial nuisance parameters, it is possible that the best model under H 1 can lead to \u03c4 0 values that move closer to the truth \u03c0 0 as more data become available. ",
            "paragraph_rank": 177,
            "section_rank": 52
        },
        {
            "text": "Hence [A1] may become satisfied, while [A0] is always satisfied. ",
            "paragraph_rank": 177,
            "section_rank": 52
        },
        {
            "text": "In situations where one is unwilling to assert a convergence rate as fast as O(m \u2212 1",
            "paragraph_rank": 177,
            "section_rank": 52
        },
        {
            "text": "2 ) for (\u03c4 0 \u2212 \u03c0 0 ), if the convergence occur at all, [A0] is more appropriate than [A1].",
            "paragraph_rank": 178,
            "section_rank": 52
        },
        {
            "text": "To see the impact of using [A0] instead of [A1], it turns out that when lim m\u2192\u221e m 1 2 \u03b4 = \u221e, various test statistics similar to \u03c7 2 H1 (\u03b6) (these are the different versions of T min H1 that we mentioned in Sec. III A) would be unbounded in",
            "paragraph_rank": 178,
            "section_rank": 52
        },
        {
            "text": "Rigorously speaking, the word \"confidence set\" should be used instead of \"confidence interval\" when the dimension of the parameter space is higher than one. ",
            "paragraph_rank": 179,
            "section_rank": 52
        },
        {
            "text": "But as long as there is no ambiguity, we will refer to all confidence sets as confidence intervals for simplicity.3 ",
            "paragraph_rank": 179,
            "section_rank": 52,
            "ref_spans": [
                {
                    "start": 114,
                    "end": 115,
                    "type": "bibr",
                    "ref_id": "b2",
                    "text": "3"
                }
            ]
        },
        {
            "text": "When the model contains nuisance parameters, extra care are needed in performing Monte Carlo simulation. ",
            "paragraph_rank": 179,
            "section_rank": 52
        },
        {
            "text": "See Ref. ",
            "paragraph_rank": 179,
            "section_rank": 52
        },
        {
            "text": "[7] for example. ",
            "paragraph_rank": 179,
            "section_rank": 52
        },
        {
            "text": "1 \u00a9 2016. ",
            "paragraph_rank": 179,
            "section_rank": 52
        },
        {
            "text": "This manuscript version is made available under the Elsevier user license http://www.elsevier.com/open-access/userlicense/1.0/",
            "paragraph_rank": 179,
            "section_rank": 52
        },
        {
            "text": "This is usually done in order that T H 0 (\u03b7; x) and T H 1 (\u03b7; x) are asymptotically equivalent under certain conditions to their counterparts in the classical Chi-square forms, namely, the Neyman and the Pearson Chi-square statistics.",
            "paragraph_rank": 180,
            "section_rank": 52
        },
        {
            "text": "An alternative way to define \u2206T (x) is to replace T min H 0 (x) and T min H 1 (x) by T mag H 0 (x) and T mag H 1 (x), respectively, which are the marginalized, or say integrated version of T H 0 (\u03b7; x) and T H 1 (\u03b7; x) over all nuisance parameters. ",
            "paragraph_rank": 181,
            "section_rank": 52
        },
        {
            "text": "These two methods generally give very similar results in practice. ",
            "paragraph_rank": 181,
            "section_rank": 52
        },
        {
            "text": "From the statistics point of view, while the minimization method adopts the Frequentist's philosophy, the marginalization method adopts the Bayesian philosophy.",
            "paragraph_rank": 181,
            "section_rank": 52
        },
        {
            "text": "The Big O, the small o, the Big Op, and the small op notation are standard mathematical symbols, such that for two sequences of random variables {Xm} and {Ym}, we write",
            "paragraph_rank": 182,
            "section_rank": 52
        },
        {
            "text": "We would like to thank Wei Wang for helpful discussions. ",
            "paragraph_rank": 183,
            "section_rank": 54
        },
        {
            "text": "This material is based upon work supported by the National Science Foundation and the U.S. Department of Energy, Office of Science, Office of High Energy Physics, Early Career Research program under contract number DE-SC0012704.",
            "paragraph_rank": 183,
            "section_rank": 54
        },
        {
            "text": "APPENDICES",
            "section_rank": 56
        },
        {
            "text": "A. A few basic properties of the fitted models under H0 and H1",
            "section_rank": 57
        },
        {
            "text": "Suppose H 0 is the correct hypothesis, that is, the data X came from H 0 . ",
            "section": "A. A few basic properties of the fitted models under H0 and H1",
            "paragraph_rank": 184,
            "section_rank": 57
        },
        {
            "text": "Having observed the data, the best fitting models under H 0 and H 1 have estimated nuisance parameters\u03b7 and\u03b6 respectively, as defined in Sec. ",
            "section": "A. A few basic properties of the fitted models under H0 and H1",
            "paragraph_rank": 184,
            "section_rank": 57
        },
        {
            "text": "IV. ",
            "section": "A. A few basic properties of the fitted models under H0 and H1",
            "paragraph_rank": 184,
            "section_rank": 57
        },
        {
            "text": "The corresponding per unit mean counts are denoted\u03c0 and\u03c4 respectively.",
            "section": "A. A few basic properties of the fitted models under H0 and H1",
            "paragraph_rank": 184,
            "section_rank": 57
        },
        {
            "text": "We show below that there is a unique limit of\u03b6 as the data size increases, and that it leads to the model \u03bd(\u03b6) that is the closest model under H 1 to the true model \u00b5 0 under a certain criteria. ",
            "section": "A. A few basic properties of the fitted models under H0 and H1",
            "paragraph_rank": 185,
            "section_rank": 57
        },
        {
            "text": "Indeed, let t m (\u03b6) = \u03c7 2",
            "section": "A. A few basic properties of the fitted models under H0 and H1",
            "paragraph_rank": 185,
            "section_rank": 57
        },
        {
            "text": ", and let",
            "section": "A. A few basic properties of the fitted models under H0 and H1",
            "paragraph_rank": 186,
            "section_rank": 57
        },
        {
            "text": ". Since p converges almost surely (a.s.) to \u03c0 0 as m increases, we have t m (\u03b6) converges a.s. to t m (\u03b6). Then under regularity conditions, such as t m being twice differentiable and convex in \u03b6,\u03b6 m = arg min \u03b6 t m (\u03b6) also converges a.s. to arg min \u03b6 t(\u03b6) as m increases. By denoting the limit of\u03b6 m by \u03b6 0 , we have mt(\u03b6 0 ) = min \u03b6 mt(\u03b6). That is, \u03b6 0 and \u03bd 0 := \u03bd(\u03b6 0 ) are such that",
            "section": "A. A few basic properties of the fitted models under H0 and H1",
            "paragraph_rank": 187,
            "section_rank": 57
        },
        {
            "text": "We list a few more properties that are useful in the proof of Lemma 1 and the proof of the result in Eq. ",
            "section": "A. A few basic properties of the fitted models under H0 and H1",
            "paragraph_rank": 188,
            "section_rank": 57
        },
        {
            "text": "(26). ",
            "section": "A. A few basic properties of the fitted models under H0 and H1",
            "paragraph_rank": 188,
            "section_rank": 57,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 4,
                    "type": "bibr",
                    "ref_id": "b25",
                    "text": "(26)"
                }
            ]
        },
        {
            "text": "It is well-known that\u03b7 \u2212 \u03b7 0 and\u03c0 \u2212 \u03c0 0 are both of order O p (m \u2212 1 2 ). ",
            "section": "A. A few basic properties of the fitted models under H0 and H1",
            "paragraph_rank": 188,
            "section_rank": 57,
            "ref_spans": [
                {
                    "start": 67,
                    "end": 70,
                    "type": "bibr",
                    "text": "1 2"
                }
            ]
        },
        {
            "text": "And\u03b6 \u2212 \u03b6 0 and\u03c4 \u2212 \u03c4 0 are also both of order O p (m \u2212 1 2 ) according to Ref. ",
            "section": "A. A few basic properties of the fitted models under H0 and H1",
            "paragraph_rank": 188,
            "section_rank": 57
        },
        {
            "text": "[30].",
            "section": "A. A few basic properties of the fitted models under H0 and H1",
            "paragraph_rank": 188,
            "section_rank": 57,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 4,
                    "type": "bibr",
                    "ref_id": "b30",
                    "text": "[30]"
                }
            ]
        }
    ]
}