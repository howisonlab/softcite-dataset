{
    "level": "sentence",
    "abstract": [
        {
            "text": "We present an overview of a comprehensive analysis framework aimed at performing direct extraction of all possible effective Higgs couplings to neutral electroweak gauge bosons in the decay to electrons and muons, the so called 'golden channel'. ",
            "paragraph_rank": 2,
            "section_rank": 1
        },
        {
            "text": "Our framework is based primarily on a maximum likelihood method constructed from analytic expressions of the fully differential cross sections for h \u2192 4 and for the dominant irreducible qq \u2192 4 background, where 4 = 2e2\u00b5, 4e, 4\u00b5. ",
            "paragraph_rank": 2,
            "section_rank": 1
        },
        {
            "text": "Detector effects are included by an explicit convolution of these analytic expressions with the appropriate transfer function over all center of mass variables. ",
            "paragraph_rank": 2,
            "section_rank": 1
        },
        {
            "text": "Utilizing the full set of observables, we construct an unbinned detector-level likelihood which is continuous in the effective couplings. ",
            "paragraph_rank": 2,
            "section_rank": 1
        },
        {
            "text": "We consider possible ZZ, Z\u03b3, and \u03b3\u03b3 couplings simultaneously, allowing for general CP odd/even admixtures. ",
            "paragraph_rank": 2,
            "section_rank": 1
        },
        {
            "text": "A broad overview is given of how the convolution is performed and we discuss the principles and theoretical basis of the framework. ",
            "paragraph_rank": 2,
            "section_rank": 1
        },
        {
            "text": "This framework can be used in a variety of ways to study Higgs couplings in the golden channel using data obtained at the LHC and other future colliders.",
            "paragraph_rank": 2,
            "section_rank": 1
        }
    ],
    "body_text": [
        {
            "text": "Introduction",
            "section_rank": 2
        },
        {
            "text": "The recent discovery of the Higgs boson at the LHC [1,2] with properties resembling those predicted by the Standard Model, shifts our attention to the determination of its precise nature and to establish whether or not the Higgs boson possesses any anomalous couplings to Standard Model particles. ",
            "section": "Introduction",
            "paragraph_rank": 3,
            "section_rank": 2,
            "ref_spans": [
                {
                    "start": 51,
                    "end": 54,
                    "type": "bibr",
                    "ref_id": "b0",
                    "text": "[1,"
                },
                {
                    "start": 54,
                    "end": 56,
                    "type": "bibr",
                    "ref_id": "b1",
                    "text": "2]"
                }
            ]
        },
        {
            "text": "In this study we focus on couplings to neutral electroweak gauge bosons. ",
            "section": "Introduction",
            "paragraph_rank": 3,
            "section_rank": 2
        },
        {
            "text": "Since these 'anomalous effects' are expected to be small if at all present, constraining or measuring of these couplings should preferably be done through direct parameter extraction with minimal theoretical assumptions. ",
            "section": "Introduction",
            "paragraph_rank": 3,
            "section_rank": 2
        },
        {
            "text": "The vast literature  on",
            "section": "Introduction",
            "paragraph_rank": 3,
            "section_rank": 2
        },
        {
            "text": "JHEP01(2015)125",
            "section_rank": 3
        },
        {
            "text": "Higgs decays to four charged leptons (electrons and muons) through neutral electroweak gauge bosons, suggests that the so called 'golden channel', can be a powerful means towards accomplishing this goal.",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 4,
            "section_rank": 3
        },
        {
            "text": "A number of frameworks have been established utilizing the Matrix Element Method to study the golden channel aiming to determine these potentially anomalous couplings. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 5,
            "section_rank": 3
        },
        {
            "text": "These primarily rely on Monte Carlo generators such as the JHU generator [13,17,32] or on Madgraph implementations [22,31]. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 5,
            "section_rank": 3,
            "ref_spans": [
                {
                    "start": 73,
                    "end": 77,
                    "type": "bibr",
                    "ref_id": "b12",
                    "text": "[13,"
                },
                {
                    "start": 77,
                    "end": 80,
                    "type": "bibr",
                    "ref_id": "b16",
                    "text": "17,"
                },
                {
                    "start": 80,
                    "end": 83,
                    "type": "bibr",
                    "ref_id": "b32",
                    "text": "32]"
                },
                {
                    "start": 115,
                    "end": 119,
                    "type": "bibr",
                    "ref_id": "b21",
                    "text": "[22,"
                },
                {
                    "start": 119,
                    "end": 122,
                    "type": "bibr",
                    "ref_id": "b31",
                    "text": "31]"
                }
            ]
        },
        {
            "text": "They have the advantage of flexibility to include various Higgs production and decay channels and are especially useful for constructing kinematic discriminators to distinguish between competing hypotheses.",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 5,
            "section_rank": 3
        },
        {
            "text": "Focusing on the golden channel only, 1 we propose a novel analysis framework largely based on an analytic implementation. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 6,
            "section_rank": 3,
            "ref_spans": [
                {
                    "start": 37,
                    "end": 38,
                    "type": "bibr",
                    "ref_id": "b0",
                    "text": "1"
                }
            ]
        },
        {
            "text": "It is designed to maximize the information contained in each event with the aim of direct extraction of the various effective Higgs couplings. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 6,
            "section_rank": 3
        },
        {
            "text": "It is generally acknowledged in the literature that analytic methods are optimal for performing this direct multi-parameter extraction within practical and reasonable computational processing resources [13,17,32]. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 6,
            "section_rank": 3,
            "ref_spans": [
                {
                    "start": 202,
                    "end": 206,
                    "type": "bibr",
                    "ref_id": "b12",
                    "text": "[13,"
                },
                {
                    "start": 206,
                    "end": 209,
                    "type": "bibr",
                    "ref_id": "b16",
                    "text": "17,"
                },
                {
                    "start": 209,
                    "end": 212,
                    "type": "bibr",
                    "ref_id": "b32",
                    "text": "32]"
                }
            ]
        },
        {
            "text": "In this work, we also demonstrate that within an analytic framework one can readily include the relevant detector effects and obtain a detector-level likelihood function in terms of the full set of observables available in the four lepton final state. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 6,
            "section_rank": 3
        },
        {
            "text": "This is accomplished by the explicit convolution of analytic expressions for the 'truth level' fully differential cross sections with a transfer function which parametrizes the detector resolution and acceptance effects.",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 6,
            "section_rank": 3
        },
        {
            "text": "This analysis framework has already proved useful in constraining effective Higgs couplings as demonstrated in a recent CMS analysis [38,39]. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 7,
            "section_rank": 3,
            "ref_spans": [
                {
                    "start": 133,
                    "end": 137,
                    "type": "bibr",
                    "ref_id": "b38",
                    "text": "[38,"
                },
                {
                    "start": 137,
                    "end": 140,
                    "type": "bibr",
                    "ref_id": "b39",
                    "text": "39]"
                }
            ]
        },
        {
            "text": "It was shown that for simplified cases of constraining one or two parameters, our framework gives comparable performance to other established analysis methods for the golden channel [13,17,22,31,32,38,39]. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 7,
            "section_rank": 3,
            "ref_spans": [
                {
                    "start": 182,
                    "end": 186,
                    "type": "bibr",
                    "ref_id": "b12",
                    "text": "[13,"
                },
                {
                    "start": 186,
                    "end": 189,
                    "type": "bibr",
                    "ref_id": "b16",
                    "text": "17,"
                },
                {
                    "start": 189,
                    "end": 192,
                    "type": "bibr",
                    "ref_id": "b21",
                    "text": "22,"
                },
                {
                    "start": 192,
                    "end": 195,
                    "type": "bibr",
                    "ref_id": "b31",
                    "text": "31,"
                },
                {
                    "start": 195,
                    "end": 198,
                    "type": "bibr",
                    "ref_id": "b32",
                    "text": "32,"
                },
                {
                    "start": 198,
                    "end": 201,
                    "type": "bibr",
                    "ref_id": "b38",
                    "text": "38,"
                },
                {
                    "start": 201,
                    "end": 204,
                    "type": "bibr",
                    "ref_id": "b39",
                    "text": "39]"
                }
            ]
        },
        {
            "text": "In this work we present an overview of the framework and discuss the principles and theoretical basis. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 7,
            "section_rank": 3
        },
        {
            "text": "In particular we sketch how the various components of the detector level likelihood are constructed with emphasis on how the convolution integral is performed as well as various validations. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 7,
            "section_rank": 3
        },
        {
            "text": "How the likelihood can then be used to perform multi-parameter extraction of effective Higgs couplings is also discussed. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 7,
            "section_rank": 3
        },
        {
            "text": "We hope that the additional features of our framework are also found useful in the next phase of the LHC and future colliders. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 7,
            "section_rank": 3
        },
        {
            "text": "Much more information on the framework including technical details can be found in [19,35,[37][38][39][40][41].",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 7,
            "section_rank": 3,
            "ref_spans": [
                {
                    "start": 83,
                    "end": 87,
                    "type": "bibr",
                    "ref_id": "b18",
                    "text": "[19,"
                },
                {
                    "start": 87,
                    "end": 90,
                    "type": "bibr",
                    "ref_id": "b35",
                    "text": "35,"
                },
                {
                    "start": 90,
                    "end": 94,
                    "type": "bibr",
                    "ref_id": "b37",
                    "text": "[37]"
                },
                {
                    "start": 94,
                    "end": 98,
                    "type": "bibr",
                    "ref_id": "b38",
                    "text": "[38]"
                },
                {
                    "start": 98,
                    "end": 102,
                    "type": "bibr",
                    "ref_id": "b39",
                    "text": "[39]"
                },
                {
                    "start": 102,
                    "end": 106,
                    "type": "bibr",
                    "ref_id": "b40",
                    "text": "[40]"
                },
                {
                    "start": 106,
                    "end": 110,
                    "type": "bibr",
                    "ref_id": "b41",
                    "text": "[41]"
                }
            ]
        },
        {
            "text": "Overview of framework",
            "section_rank": 4
        },
        {
            "text": "Though 'truth' level (or generator) studies of h \u2192 4 (4 = 2e2\u00b5, 4e, 4\u00b5) give a good approximate estimate of the expected sensitivity to the Higgs ZZ, Z\u03b3, and \u03b3\u03b3 couplings [37], when analyzing data obtained at the LHC (or future colliders) a detector level likelihood which accounts for the various detector effects is necessary. ",
            "section": "Overview of framework",
            "paragraph_rank": 8,
            "section_rank": 4,
            "ref_spans": [
                {
                    "start": 171,
                    "end": 175,
                    "type": "bibr",
                    "ref_id": "b37",
                    "text": "[37]"
                }
            ]
        },
        {
            "text": "Since generally detector level likelihoods are obtained via the use of Monte Carlo methods, it becomes difficult to obtain the full multi-dimensional likelihood for the 4 final state. ",
            "section": "Overview of framework",
            "paragraph_rank": 8,
            "section_rank": 4
        },
        {
            "text": "Typically one needs to fill large multi-dimensional templates that require an impractical amount of computing time. ",
            "section": "Overview of framework",
            "paragraph_rank": 8,
            "section_rank": 4
        },
        {
            "text": "There",
            "section": "Overview of framework",
            "paragraph_rank": 8,
            "section_rank": 4
        },
        {
            "text": "JHEP01(2015)125",
            "section_rank": 5
        },
        {
            "text": "are also potential collateral binning and 'smoothing' side-effects often associated with these methods. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 9,
            "section_rank": 5
        },
        {
            "text": "In the case of the golden channel this necessitates the use of kinematic discriminants which 'collapse' the fully multi-dimensional likelihood into two or perhaps three detector level observables [32]. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 9,
            "section_rank": 5,
            "ref_spans": [
                {
                    "start": 196,
                    "end": 200,
                    "type": "bibr",
                    "ref_id": "b32",
                    "text": "[32]"
                }
            ]
        },
        {
            "text": "This approach is normally taken to facilitate the inclusion of detector effects, but is not optimal when fitting to a large number of parameters simultaneously [17]. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 9,
            "section_rank": 5,
            "ref_spans": [
                {
                    "start": 160,
                    "end": 164,
                    "type": "bibr",
                    "ref_id": "b16",
                    "text": "[17]"
                }
            ]
        },
        {
            "text": "This is unfortunate in the case of the golden channel where in principle there are twelve observables which can be used to extract a large number of parameters at once, including their correlations. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 9,
            "section_rank": 5
        },
        {
            "text": "It would be satisfying and useful to have a framework which is free of these issues and capable of utilizing all available information in the four lepton final state at detector level.",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 9,
            "section_rank": 5
        },
        {
            "text": "From 'truth' to 'detector' level",
            "section_rank": 6
        },
        {
            "text": "This is accomplished in our framework by performing an explicit convolution of the generator ('truth') level probability density, formed out of the signal and background differential cross sections, with a transfer function which encapsulates the relevant detector effects. ",
            "section": "From 'truth' to 'detector' level",
            "paragraph_rank": 10,
            "section_rank": 6
        },
        {
            "text": "This can be represented schematically as follows,",
            "section": "From 'truth' to 'detector' level",
            "paragraph_rank": 10,
            "section_rank": 6
        },
        {
            "text": "Here we take X to represent the full set of center of mass variables, of which there are twelve in the golden channel, to be discussed more below, and A represents some set of lagrangian parameters. ",
            "section": "From 'truth' to 'detector' level",
            "paragraph_rank": 11,
            "section_rank": 6
        },
        {
            "text": "The transfer function T ( X R | X G ) takes us from generator (G) level to reconstructed (R) level observables and represents the probability of reconstructing the observables X R given the generator level observable X G . ",
            "section": "From 'truth' to 'detector' level",
            "paragraph_rank": 11,
            "section_rank": 6
        },
        {
            "text": "It is treated as a function of X R which takes X G as input. ",
            "section": "From 'truth' to 'detector' level",
            "paragraph_rank": 11,
            "section_rank": 6
        },
        {
            "text": "As will be described more in section 5.1, once the integration in eq. ",
            "section": "From 'truth' to 'detector' level",
            "paragraph_rank": 11,
            "section_rank": 6
        },
        {
            "text": "(2.1) is performed we must then normalize over all twelve reconstructed level observables to obtain the detector level pdf. ",
            "section": "From 'truth' to 'detector' level",
            "paragraph_rank": 11,
            "section_rank": 6
        },
        {
            "text": "The integral in eq. ",
            "section": "From 'truth' to 'detector' level",
            "paragraph_rank": 11,
            "section_rank": 6
        },
        {
            "text": "(2.1) is the defining feature of our framework and has been obtained for both the h \u2192 4 signal as well as the dominant qq \u2192 4 background, which have been computed analytically in accompanying studies [19,35,42]. ",
            "section": "From 'truth' to 'detector' level",
            "paragraph_rank": 11,
            "section_rank": 6,
            "ref_spans": [
                {
                    "start": 200,
                    "end": 204,
                    "type": "bibr",
                    "ref_id": "b18",
                    "text": "[19,"
                },
                {
                    "start": 204,
                    "end": 207,
                    "type": "bibr",
                    "ref_id": "b35",
                    "text": "35,"
                },
                {
                    "start": 207,
                    "end": 210,
                    "type": "bibr",
                    "ref_id": "b42",
                    "text": "42]"
                }
            ]
        },
        {
            "text": "We emphasize that the integral has not been obtained via Monte Carlo methods. ",
            "section": "From 'truth' to 'detector' level",
            "paragraph_rank": 11,
            "section_rank": 6
        },
        {
            "text": "Instead we have explicitly performed the integration by utilizing various analytic and well-established numerical methods [41,43] (for studies that perform similar convolutions using Monte Carlo methods see [31,[44][45][46]). ",
            "section": "From 'truth' to 'detector' level",
            "paragraph_rank": 11,
            "section_rank": 6,
            "ref_spans": [
                {
                    "start": 122,
                    "end": 126,
                    "type": "bibr",
                    "ref_id": "b41",
                    "text": "[41,"
                },
                {
                    "start": 126,
                    "end": 129,
                    "type": "bibr",
                    "ref_id": "b43",
                    "text": "43]"
                },
                {
                    "start": 207,
                    "end": 211,
                    "type": "bibr",
                    "ref_id": "b31",
                    "text": "[31,"
                },
                {
                    "start": 211,
                    "end": 215,
                    "type": "bibr",
                    "ref_id": "b44",
                    "text": "[44]"
                },
                {
                    "start": 215,
                    "end": 219,
                    "type": "bibr",
                    "ref_id": "b45",
                    "text": "[45]"
                },
                {
                    "start": 219,
                    "end": 223,
                    "type": "bibr",
                    "ref_id": "b46",
                    "text": "[46]"
                }
            ]
        },
        {
            "text": "This ensures that (arbitrarily) high precision is maintained at each step, producing what is effectively an 'analytic function' in terms of detector level variables once the convolution has been performed. ",
            "section": "From 'truth' to 'detector' level",
            "paragraph_rank": 11,
            "section_rank": 6
        },
        {
            "text": "After performing this 12-dimensional integration and normalizing, we are left with a probability density function (pdf ) from which we construct an un-binned twelve-dimensional detector level likelihood which is a continuous function of the effective couplings (or Lagrangian parameters) and takes as its input, up to twelve reconstructed (detector-level) center of mass observables. ",
            "section": "From 'truth' to 'detector' level",
            "paragraph_rank": 11,
            "section_rank": 6
        },
        {
            "text": "In the current implementation we will average over the four production variables to reduce the systematic uncertainties, thus obtaining an eight-dimensional likelihood in terms of just decay observables. ",
            "section": "From 'truth' to 'detector' level",
            "paragraph_rank": 11,
            "section_rank": 6
        },
        {
            "text": "However, this step is in principle not necessary.",
            "section": "From 'truth' to 'detector' level",
            "paragraph_rank": 11,
            "section_rank": 6
        },
        {
            "text": "JHEP01(2015)125",
            "section_rank": 7
        },
        {
            "text": "We also emphasize that the convolution integral is largely independent of detector transfer function and generator level differential cross section and in particular how accurate the descriptions of the 'truth' level pdfs or the detector properties are. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 12,
            "section_rank": 7
        },
        {
            "text": "This means the framework can in principle be adapted to any detector which studies h \u2192 4 (or any X \u2192 4 ) and, in addition, as theoretical calculations of the generator level differential cross sections improve they can easily be incorporated into the convolution integral. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 12,
            "section_rank": 7
        },
        {
            "text": "Thus, there is ample for room optimization in our framework as time goes on. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 12,
            "section_rank": 7
        },
        {
            "text": "The generality of the convolution also allows for other beyond the Standard Model physics such as exotic Higgs decays [47] to be easily be incorporated into the h \u2192 4 framework.",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 12,
            "section_rank": 7,
            "ref_spans": [
                {
                    "start": 118,
                    "end": 122,
                    "type": "bibr",
                    "ref_id": "b47",
                    "text": "[47]"
                }
            ]
        },
        {
            "text": "Analytic parameterizations",
            "section_rank": 8
        },
        {
            "text": "As we discuss below, it is essential to first have analytic parameterizations of the 'truth' level differential cross sections in order to perform the convolution integral in eq. ",
            "section": "Analytic parameterizations",
            "paragraph_rank": 13,
            "section_rank": 8
        },
        {
            "text": "(2.1). ",
            "section": "Analytic parameterizations",
            "paragraph_rank": 13,
            "section_rank": 8
        },
        {
            "text": "These can be obtained in essentially two different ways. ",
            "section": "Analytic parameterizations",
            "paragraph_rank": 13,
            "section_rank": 8
        },
        {
            "text": "The first is to simply analytically compute the differential cross section starting from Feynman diagrams, which of course is not always possible. ",
            "section": "Analytic parameterizations",
            "paragraph_rank": 13,
            "section_rank": 8
        },
        {
            "text": "The second is to obtain an 'analytic' parameterization by fitting to a large Monte Carlo sample with some appropriately parametrized function. ",
            "section": "Analytic parameterizations",
            "paragraph_rank": 13,
            "section_rank": 8
        },
        {
            "text": "This becomes quite difficult when the function is multi-dimensional as is the case in the golden channel with twelve center of mass observables and requires large samples and an accurate interpolation procedure. ",
            "section": "Analytic parameterizations",
            "paragraph_rank": 13,
            "section_rank": 8
        },
        {
            "text": "In this framework we have implemented a hybrid of these two approaches with the primary component coming from analytic expressions of the leading order h \u2192 4 and qq \u2192 4 fully differential cross sections [19,35,42].",
            "section": "Analytic parameterizations",
            "paragraph_rank": 13,
            "section_rank": 8,
            "ref_spans": [
                {
                    "start": 203,
                    "end": 207,
                    "type": "bibr",
                    "ref_id": "b18",
                    "text": "[19,"
                },
                {
                    "start": 207,
                    "end": 210,
                    "type": "bibr",
                    "ref_id": "b35",
                    "text": "35,"
                },
                {
                    "start": 210,
                    "end": 213,
                    "type": "bibr",
                    "ref_id": "b42",
                    "text": "42]"
                }
            ]
        },
        {
            "text": "Since NLO effects in the golden channel are generally small [48][49][50], these leading order differential cross sections represent the dominant contributions to the 4 'truth' level likelihood. ",
            "section": "Analytic parameterizations",
            "paragraph_rank": 14,
            "section_rank": 8,
            "ref_spans": [
                {
                    "start": 60,
                    "end": 64,
                    "type": "bibr",
                    "ref_id": "b49",
                    "text": "[48]"
                },
                {
                    "start": 64,
                    "end": 68,
                    "type": "bibr",
                    "ref_id": "b50",
                    "text": "[49]"
                },
                {
                    "start": 68,
                    "end": 72,
                    "type": "bibr",
                    "ref_id": "b51",
                    "text": "[50]"
                }
            ]
        },
        {
            "text": "There are however, a number of sub-dominant effects which appear at higher order and should be accounted for. ",
            "section": "Analytic parameterizations",
            "paragraph_rank": 14,
            "section_rank": 8
        },
        {
            "text": "These include production and additional background effects. ",
            "section": "Analytic parameterizations",
            "paragraph_rank": 14,
            "section_rank": 8
        },
        {
            "text": "In these cases, the second method of parametric fits to simulated data is typically the optimal route. ",
            "section": "Analytic parameterizations",
            "paragraph_rank": 14,
            "section_rank": 8
        },
        {
            "text": "To do this we follow a similar procedure as found in [32] while further details on the implementation into our framework can be found in [41]. ",
            "section": "Analytic parameterizations",
            "paragraph_rank": 14,
            "section_rank": 8,
            "ref_spans": [
                {
                    "start": 53,
                    "end": 57,
                    "type": "bibr",
                    "ref_id": "b32",
                    "text": "[32]"
                },
                {
                    "start": 137,
                    "end": 141,
                    "type": "bibr",
                    "ref_id": "b41",
                    "text": "[41]"
                }
            ]
        },
        {
            "text": "We emphasize however that the convolution integral is independent of these matters allowing for easy implementation of more precise 'truth' level likelihoods as they become available over time.",
            "section": "Analytic parameterizations",
            "paragraph_rank": 14,
            "section_rank": 8
        },
        {
            "text": "Of course when considering the detector level likelihood there are additional, but again sub-dominant, effects not present at 'truth' level which should be accounted for, such as detector momentum resolution and acceptance effects. ",
            "section": "Analytic parameterizations",
            "paragraph_rank": 15,
            "section_rank": 8
        },
        {
            "text": "These can be parametrized via transfer functions which can be optimized for a particular detector as done recently in [38,39] which incorporates a parameterization of the CMS detector into our framework. ",
            "section": "Analytic parameterizations",
            "paragraph_rank": 15,
            "section_rank": 8,
            "ref_spans": [
                {
                    "start": 118,
                    "end": 122,
                    "type": "bibr",
                    "ref_id": "b38",
                    "text": "[38,"
                },
                {
                    "start": 122,
                    "end": 125,
                    "type": "bibr",
                    "ref_id": "b39",
                    "text": "39]"
                }
            ]
        },
        {
            "text": "Since these typically would be supplied by the experimentalist we do not discuss their construction in detail here, but note that as knowledge of the detectors improves and parameterizations of the transfer functions become more accurate, they can easily be incorporated into the convolution integral in eq. ",
            "section": "Analytic parameterizations",
            "paragraph_rank": 15,
            "section_rank": 8
        },
        {
            "text": "(2.1), but again the integration is independent of these matters. ",
            "section": "Analytic parameterizations",
            "paragraph_rank": 15,
            "section_rank": 8
        },
        {
            "text": "More details on the construction and implementation, as well as the validation, of the transfer functions is found in [38,39,41].",
            "section": "Analytic parameterizations",
            "paragraph_rank": 15,
            "section_rank": 8,
            "ref_spans": [
                {
                    "start": 118,
                    "end": 122,
                    "type": "bibr",
                    "ref_id": "b38",
                    "text": "[38,"
                },
                {
                    "start": 122,
                    "end": 125,
                    "type": "bibr",
                    "ref_id": "b39",
                    "text": "39,"
                },
                {
                    "start": 125,
                    "end": 128,
                    "type": "bibr",
                    "ref_id": "b41",
                    "text": "41]"
                }
            ]
        },
        {
            "text": "JHEP01(2015)125 2.3 Fast parameter extraction",
            "section_rank": 9
        },
        {
            "text": "The convolution integral in eq. ",
            "section": "JHEP01(2015)125 2.3 Fast parameter extraction",
            "paragraph_rank": 16,
            "section_rank": 9
        },
        {
            "text": "(2.1) allows us to (effectively) obtain an analytic function in both detector level observables and lagrangian parameters. ",
            "section": "JHEP01(2015)125 2.3 Fast parameter extraction",
            "paragraph_rank": 16,
            "section_rank": 9
        },
        {
            "text": "This is because, via the explicit 12-dimensional integration over all center of mass variables, we are able to obtain a 1-to-1 mapping from the 'truth' level likelihood to the 'detector' level likelihood. ",
            "section": "JHEP01(2015)125 2.3 Fast parameter extraction",
            "paragraph_rank": 16,
            "section_rank": 9
        },
        {
            "text": "This allows us, during parameter extraction, to effectively work directly with the lagrangian parameters, but at detector level which gives us the ability to easily perform multi-parameter extraction with the same speed and flexibility as was done at generator level [35,37]. ",
            "section": "JHEP01(2015)125 2.3 Fast parameter extraction",
            "paragraph_rank": 16,
            "section_rank": 9,
            "ref_spans": [
                {
                    "start": 267,
                    "end": 271,
                    "type": "bibr",
                    "ref_id": "b35",
                    "text": "[35,"
                },
                {
                    "start": 271,
                    "end": 274,
                    "type": "bibr",
                    "ref_id": "b37",
                    "text": "37]"
                }
            ]
        },
        {
            "text": "Being able to fit to multiple parameters simultaneously is important since it allows for strong tests of models which often predict correlations between the various parameters. ",
            "section": "JHEP01(2015)125 2.3 Fast parameter extraction",
            "paragraph_rank": 16,
            "section_rank": 9
        },
        {
            "text": "We point out that our framework allows us to do this while avoiding relying on hypothesis testing or on the construction of kinematic discriminants which is less optimal when extracting multiple parameters than maximizing the full likelihood [51] where all observables are used. ",
            "section": "JHEP01(2015)125 2.3 Fast parameter extraction",
            "paragraph_rank": 16,
            "section_rank": 9,
            "ref_spans": [
                {
                    "start": 242,
                    "end": 246,
                    "type": "bibr",
                    "ref_id": "b52",
                    "text": "[51]"
                }
            ]
        },
        {
            "text": "Furthermore, the analytic nature of our framework allows for a great deal of flexibility in performing a variety of types of parameter extractions and re-parameterizations.",
            "section": "JHEP01(2015)125 2.3 Fast parameter extraction",
            "paragraph_rank": 16,
            "section_rank": 9
        },
        {
            "text": "Comments on assumptions and approximations",
            "section_rank": 10
        },
        {
            "text": "In performing the convolution integral in eq. ",
            "section": "Comments on assumptions and approximations",
            "paragraph_rank": 17,
            "section_rank": 10
        },
        {
            "text": "(2.1) we have relied on two key assumptions. ",
            "section": "Comments on assumptions and approximations",
            "paragraph_rank": 17,
            "section_rank": 10
        },
        {
            "text": "The first is that angular resolution effects due to detector smearing can be neglected, which is an excellent approximation for the LHC detectors [52][53][54]. ",
            "section": "Comments on assumptions and approximations",
            "paragraph_rank": 17,
            "section_rank": 10,
            "ref_spans": [
                {
                    "start": 146,
                    "end": 150,
                    "type": "bibr",
                    "ref_id": "b53",
                    "text": "[52]"
                },
                {
                    "start": 150,
                    "end": 154,
                    "type": "bibr",
                    "ref_id": "b54",
                    "text": "[53]"
                },
                {
                    "start": 154,
                    "end": 158,
                    "type": "bibr",
                    "text": "[54]"
                }
            ]
        },
        {
            "text": "Second, we have assumed in the transfer function that each lepton is independent of the others which again is a very good approximation since leptons are clean and well-measured objects in the CMS and ATLAS detectors once standard lepton selection criteria are imposed [52][53][54]. ",
            "section": "Comments on assumptions and approximations",
            "paragraph_rank": 17,
            "section_rank": 10,
            "ref_spans": [
                {
                    "start": 269,
                    "end": 273,
                    "type": "bibr",
                    "ref_id": "b53",
                    "text": "[52]"
                },
                {
                    "start": 273,
                    "end": 277,
                    "type": "bibr",
                    "ref_id": "b54",
                    "text": "[53]"
                },
                {
                    "start": 277,
                    "end": 281,
                    "type": "bibr",
                    "text": "[54]"
                }
            ]
        },
        {
            "text": "With these simplifying assumptions the convolution integral can then be performed as will be described below and in much more detail in [40] and [41].",
            "section": "Comments on assumptions and approximations",
            "paragraph_rank": 17,
            "section_rank": 10,
            "ref_spans": [
                {
                    "start": 136,
                    "end": 140,
                    "type": "bibr",
                    "ref_id": "b40",
                    "text": "[40]"
                },
                {
                    "start": 145,
                    "end": 149,
                    "type": "bibr",
                    "ref_id": "b41",
                    "text": "[41]"
                }
            ]
        },
        {
            "text": "Even after the convolution is performed however, we must still normalize the detector level differential cross section. ",
            "section": "Comments on assumptions and approximations",
            "paragraph_rank": 18,
            "section_rank": 10
        },
        {
            "text": "Since this can not be done analytically one must resort to Monte Carlo techniques. ",
            "section": "Comments on assumptions and approximations",
            "paragraph_rank": 18,
            "section_rank": 10
        },
        {
            "text": "Thus, strictly speaking the final pdf is not analytic. ",
            "section": "Comments on assumptions and approximations",
            "paragraph_rank": 18,
            "section_rank": 10
        },
        {
            "text": "However, as we will discuss more in section 5.1, due to the manner in which the analytic expressions are organized, a high precision on the normalization can be obtained in a short amount of computing time. ",
            "section": "Comments on assumptions and approximations",
            "paragraph_rank": 18,
            "section_rank": 10
        },
        {
            "text": "Furthermore, by fitting to ratios of couplings, we can circumvent the need for the absolute normalization which greatly simplifies the computational procedure and allows us to achieve a high precision [40,41] leading in the end to a detector level pdf which is effectively analytic in reconstructed observables and lagrangian parameters.",
            "section": "Comments on assumptions and approximations",
            "paragraph_rank": 18,
            "section_rank": 10,
            "ref_spans": [
                {
                    "start": 201,
                    "end": 205,
                    "type": "bibr",
                    "ref_id": "b40",
                    "text": "[40,"
                },
                {
                    "start": 205,
                    "end": 208,
                    "type": "bibr",
                    "ref_id": "b41",
                    "text": "41]"
                }
            ]
        },
        {
            "text": "Of course there are components of both the 'truth' and detector level likelihoods which can not be included in the convolution integral of eq. ",
            "section": "Comments on assumptions and approximations",
            "paragraph_rank": 19,
            "section_rank": 10
        },
        {
            "text": "(2.1). ",
            "section": "Comments on assumptions and approximations",
            "paragraph_rank": 19,
            "section_rank": 10
        },
        {
            "text": "These correspond to any components for which a sufficiently accurate analytic parameterization can not be obtained. ",
            "section": "Comments on assumptions and approximations",
            "paragraph_rank": 19,
            "section_rank": 10
        },
        {
            "text": "These may include potential higher order contributions to both signal and background differential cross sections as well as additional fake backgrounds such as Z + X. For these one must resort to more conventional Monte Carlo techniques and the construction of large (binned) 'look-up' tables. ",
            "section": "Comments on assumptions and approximations",
            "paragraph_rank": 19,
            "section_rank": 10
        },
        {
            "text": "The effects of binning can me mitigated through a linear multidimensional interpolation technique which is described in more detail in [41]. ",
            "section": "Comments on assumptions and approximations",
            "paragraph_rank": 19,
            "section_rank": 10,
            "ref_spans": [
                {
                    "start": 135,
                    "end": 139,
                    "type": "bibr",
                    "ref_id": "b41",
                    "text": "[41]"
                }
            ]
        },
        {
            "text": "Fortunately",
            "section": "Comments on assumptions and approximations",
            "paragraph_rank": 19,
            "section_rank": 10
        },
        {
            "text": "JHEP01(2015)125",
            "section_rank": 11
        },
        {
            "text": "these components are sub dominant in the golden channel and can be assigned systematics to study their effects [38,39,41].",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 20,
            "section_rank": 11,
            "ref_spans": [
                {
                    "start": 111,
                    "end": 115,
                    "type": "bibr",
                    "ref_id": "b38",
                    "text": "[38,"
                },
                {
                    "start": 115,
                    "end": 118,
                    "type": "bibr",
                    "ref_id": "b39",
                    "text": "39,"
                },
                {
                    "start": 118,
                    "end": 121,
                    "type": "bibr",
                    "ref_id": "b41",
                    "text": "41]"
                }
            ]
        },
        {
            "text": "There are also various other systematics associated with both detector and theoretical uncertainties which should properly be accounted for. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 21,
            "section_rank": 11
        },
        {
            "text": "Since these components do not have a large effect on the final sensitivity (especially once sizable data sets are accumulated) and are not directly related to the convolution, we will discuss them only briefly below, but see [38,39,41] for more details on how they are implemented into the framework in a real experimental analysis.",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 21,
            "section_rank": 11,
            "ref_spans": [
                {
                    "start": 225,
                    "end": 229,
                    "type": "bibr",
                    "ref_id": "b38",
                    "text": "[38,"
                },
                {
                    "start": 229,
                    "end": 232,
                    "type": "bibr",
                    "ref_id": "b39",
                    "text": "39,"
                },
                {
                    "start": 232,
                    "end": 235,
                    "type": "bibr",
                    "ref_id": "b41",
                    "text": "41]"
                }
            ]
        },
        {
            "text": "In constructing the detector level likelihood we have overcome many of the technical challenges which in the past have made it impossible to use the fully multi-dimensional likelihood during parameter fitting. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 22,
            "section_rank": 11
        },
        {
            "text": "Below we sketch in more detail how these various challenges have been overcome, but many of the details are technically beyond the scope of this paper so we refer the reader to [19,35,[37][38][39][40][41] for more details.",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 22,
            "section_rank": 11,
            "ref_spans": [
                {
                    "start": 177,
                    "end": 181,
                    "type": "bibr",
                    "ref_id": "b18",
                    "text": "[19,"
                },
                {
                    "start": 181,
                    "end": 184,
                    "type": "bibr",
                    "ref_id": "b35",
                    "text": "35,"
                },
                {
                    "start": 184,
                    "end": 188,
                    "type": "bibr",
                    "ref_id": "b37",
                    "text": "[37]"
                },
                {
                    "start": 188,
                    "end": 192,
                    "type": "bibr",
                    "ref_id": "b38",
                    "text": "[38]"
                },
                {
                    "start": 192,
                    "end": 196,
                    "type": "bibr",
                    "ref_id": "b39",
                    "text": "[39]"
                },
                {
                    "start": 196,
                    "end": 200,
                    "type": "bibr",
                    "ref_id": "b40",
                    "text": "[40]"
                },
                {
                    "start": 200,
                    "end": 204,
                    "type": "bibr",
                    "ref_id": "b41",
                    "text": "[41]"
                }
            ]
        },
        {
            "text": "The 'truth level' pdf",
            "section_rank": 12
        },
        {
            "text": "Before obtaining the detector level likelihood one must of course first construct the 'truth' level (or generator level) likelihood. ",
            "section": "The 'truth level' pdf",
            "paragraph_rank": 23,
            "section_rank": 12
        },
        {
            "text": "As we discuss, the generator level likelihood is composed of a 'decay' and 'production' differential spectrum. ",
            "section": "The 'truth level' pdf",
            "paragraph_rank": 23,
            "section_rank": 12
        },
        {
            "text": "In our framework, the primary component is constructed out of analytic expressions for the h \u2192 4 signal and the dominant qq \u2192 4 background differential cross sections. ",
            "section": "The 'truth level' pdf",
            "paragraph_rank": 23,
            "section_rank": 12
        },
        {
            "text": "Analytic expressions have been shown to be useful in likelihood methods where the full kinematics of an event can be exploited. ",
            "section": "The 'truth level' pdf",
            "paragraph_rank": 23,
            "section_rank": 12
        },
        {
            "text": "This is especially true for the golden channel as has been demonstrated in numerous studies [13-15, 17, 18, 29, 32, 35, 37]. ",
            "section": "The 'truth level' pdf",
            "paragraph_rank": 23,
            "section_rank": 12,
            "ref_spans": [
                {
                    "start": 92,
                    "end": 123,
                    "type": "bibr",
                    "text": "[13-15, 17, 18, 29, 32, 35, 37]"
                }
            ]
        },
        {
            "text": "For a detailed description of the analytic calculations for the signal and background fully differential cross sections as well as their validation we refer the reader to accompanying studies [19,35].",
            "section": "The 'truth level' pdf",
            "paragraph_rank": 23,
            "section_rank": 12,
            "ref_spans": [
                {
                    "start": 192,
                    "end": 196,
                    "type": "bibr",
                    "ref_id": "b18",
                    "text": "[19,"
                },
                {
                    "start": 196,
                    "end": 199,
                    "type": "bibr",
                    "ref_id": "b35",
                    "text": "35]"
                }
            ]
        },
        {
            "text": "Below we give an overview of how the 'truth' level likelihood is constructed and define the twelve center of mass variables in the four lepton final state. ",
            "section": "The 'truth level' pdf",
            "paragraph_rank": 24,
            "section_rank": 12
        },
        {
            "text": "We briefly discuss our parameterization of the Higgs couplings to electroweak gauge bosons and how the analytic expressions are combined with the appropriate production spectra to form the full truth level differential cross section. ",
            "section": "The 'truth level' pdf",
            "paragraph_rank": 24,
            "section_rank": 12
        },
        {
            "text": "We also discuss in this section how the production spectrum is obtained and comment on the additional backgrounds present in the golden channel.",
            "section": "The 'truth level' pdf",
            "paragraph_rank": 24,
            "section_rank": 12
        },
        {
            "text": "Center of mass observables",
            "section_rank": 13
        },
        {
            "text": "Here we describe the various center of mass variables which will be used as our set of observables when constructing the likelihood. ",
            "section": "Center of mass observables",
            "paragraph_rank": 25,
            "section_rank": 13
        },
        {
            "text": "The kinematics of four lepton events are illustrated in figure 1. ",
            "section": "Center of mass observables",
            "paragraph_rank": 25,
            "section_rank": 13
        },
        {
            "text": "The invariant masses are defined as the following:",
            "section": "Center of mass observables",
            "paragraph_rank": 25,
            "section_rank": 13
        },
        {
            "text": "The invariant mass of the four lepton system or the Higgs mass in case of signal.",
            "section": "Center of mass observables",
            "paragraph_rank": 26,
            "section_rank": 13
        },
        {
            "text": "\u2022 M 1 -The invariant mass of the lepton pair system which reconstructs closest to the Z mass.",
            "section": "Center of mass observables",
            "paragraph_rank": 27,
            "section_rank": 13
        },
        {
            "text": "JHEP01(2015)125",
            "section_rank": 14
        },
        {
            "text": "\u0398 Figure 1. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 28,
            "section_rank": 14,
            "ref_spans": [
                {
                    "start": 2,
                    "end": 10,
                    "type": "figure",
                    "text": "Figure 1"
                }
            ]
        },
        {
            "text": "Definition of angles in the four lepton center of mass frame X.",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 28,
            "section_rank": 14
        },
        {
            "text": "\u2022 M 2 -The invariant mass of the other lepton pair system and interpreted as M 2 < M 1 . ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 29,
            "section_rank": 14
        },
        {
            "text": "This condition holds as long as \u221a\u015d 2m Z .",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 29,
            "section_rank": 14
        },
        {
            "text": "These invariant masses are all independent subject to the constraint (M 1 + M 2 ) \u2264 \u221a\u015d and serve as the most strongly discriminating observables between different signal hypothesis as well as between signal and background. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 30,
            "section_rank": 14
        },
        {
            "text": "Note also that the 4e/4\u00b5 final state can be reconstructed in two different ways due to the identical final state interference. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 30,
            "section_rank": 14
        },
        {
            "text": "This is a quantum mechanical effect that occurs at the amplitude level and thus both reconstructions are valid. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 30,
            "section_rank": 14
        },
        {
            "text": "The definitions M 1 and M 2 remain unchanged however.",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 30,
            "section_rank": 14
        },
        {
            "text": "The angular variables are defined as:",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 31,
            "section_rank": 14
        },
        {
            "text": "\u2022 \u0398 -The production angle between the momentum vectors of the lepton pair which reconstructs to M 1 and the total 4 system momentum.",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 32,
            "section_rank": 14
        },
        {
            "text": "\u2022 \u03b8 1,2 -Polar angle of the momentum vectors of e \u2212 , \u00b5 \u2212 in the lepton pair rest frame.",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 33,
            "section_rank": 14
        },
        {
            "text": "\u2022 \u03a6 1 -The angle between the plane formed by the M 1 lepton pair and the 'production plane' formed out of the momenta of the incoming partons and the momenta of the two lepton pair systems.",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 34,
            "section_rank": 14
        },
        {
            "text": "\u2022 \u03a6 -The angle between the decay planes of the final state lepton pairs in the rest frame of the 4 system.",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 35,
            "section_rank": 14
        },
        {
            "text": "We group the angular variables as follows \u2126 = (\u0398, cos \u03b8 1 , cos \u03b8 2 , \u03a6 1 , \u03a6). ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 36,
            "section_rank": 14
        },
        {
            "text": "These angular variables are useful in aiding to distinguish different signal hypothesis and in particular between those with different CP properties, as well as in discriminating signal from background. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 36,
            "section_rank": 14
        },
        {
            "text": "There are also additional production variables associated with the initial partonic state four momentum:",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 36,
            "section_rank": 14
        },
        {
            "text": "\u2022 p T -The momentum in the transverse direction.",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 37,
            "section_rank": 14
        },
        {
            "text": "\u2022 Y -Defined as the motion along the longitudinal direction.",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 38,
            "section_rank": 14
        },
        {
            "text": "JHEP01(2015)125",
            "section_rank": 15
        },
        {
            "text": "\u2022 \u03c6 -Defines a global rotation of the event in the 4 rest frame and in general does not aid greatly in discriminating power.",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 39,
            "section_rank": 15
        },
        {
            "text": "Including Y and p T as observables in the likelihood increases the discriminating power of the golden channel. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 40,
            "section_rank": 15
        },
        {
            "text": "However, including these production variables can introduce large uncertainties since their spectra includes parton distribution functions as well as NLO contributions which should be included. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 40,
            "section_rank": 15
        },
        {
            "text": "Thus, they are often integrated out of the final likelihood [38,39] and not used during parameter extraction. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 40,
            "section_rank": 15,
            "ref_spans": [
                {
                    "start": 60,
                    "end": 64,
                    "type": "bibr",
                    "ref_id": "b38",
                    "text": "[38,"
                },
                {
                    "start": 64,
                    "end": 67,
                    "type": "bibr",
                    "ref_id": "b39",
                    "text": "39]"
                }
            ]
        },
        {
            "text": "This reduces the potential discriminating power, but this is compensated by the smaller systematic uncertainties one obtains by not including them in the likelihood (or averaging over them). ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 40,
            "section_rank": 15
        },
        {
            "text": "We will discuss more below how in our framework one can easily either include them in the final likelihood or average over them to mitigate the effects of the uncertainties associated with these variables. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 40,
            "section_rank": 15
        },
        {
            "text": "However as with \u03c6, it is crucial to include them when performing the convolution with the transfer function in order to obtain the proper detector level likelihood. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 40,
            "section_rank": 15
        },
        {
            "text": "These variables exhaust the twelve possible center of mass observables available in the golden channel.",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 40,
            "section_rank": 15
        },
        {
            "text": "Parameterization of scalar-tensor couplings",
            "section_rank": 16
        },
        {
            "text": "Assuming only Lorentz invariance, the general couplings of a spin-0 particle to two spin-1 vector bosons can be parametrized in terms of effective couplings by the following tensor structure,",
            "section": "Parameterization of scalar-tensor couplings",
            "paragraph_rank": 41,
            "section_rank": 16
        },
        {
            "text": "where in the golden channel i = ZZ, Z\u03b3, \u03b3\u03b3. ",
            "section": "Parameterization of scalar-tensor couplings",
            "paragraph_rank": 42,
            "section_rank": 16
        },
        {
            "text": "The variables k 1 and k 2 represent the four momentum of the intermediate vector bosons with v the Higgs vacuum expectation value (vev) which we have chosen as our overall normalization. ",
            "section": "Parameterization of scalar-tensor couplings",
            "paragraph_rank": 42,
            "section_rank": 16
        },
        {
            "text": "The A i n are dimensionless and in principle arbitrary complex form factors with possible momentum dependence (or more precisely a\u015d, k 2 1 , k 2 2 dependence) making eq. ",
            "section": "Parameterization of scalar-tensor couplings",
            "paragraph_rank": 42,
            "section_rank": 16
        },
        {
            "text": "(3.1) completely general. ",
            "section": "Parameterization of scalar-tensor couplings",
            "paragraph_rank": 42,
            "section_rank": 16
        },
        {
            "text": "Note that the tensor structure for A i 5 is only distinguishable from A i 1 for off-shell Higgs decays as discussed in [36]. ",
            "section": "Parameterization of scalar-tensor couplings",
            "paragraph_rank": 42,
            "section_rank": 16,
            "ref_spans": [
                {
                    "start": 119,
                    "end": 123,
                    "type": "bibr",
                    "ref_id": "b36",
                    "text": "[36]"
                }
            ]
        },
        {
            "text": "For a purely Standard Model Higgs we have A ZZ 1 = 2 at tree level while all other effective couplings are generated at higher loop order and at most O( 10 \u22122 ).",
            "section": "Parameterization of scalar-tensor couplings",
            "paragraph_rank": 42,
            "section_rank": 16
        },
        {
            "text": "Of course it is often possible to expand the A i n in a power series of momenta keeping only the leading (constant) terms. ",
            "section": "Parameterization of scalar-tensor couplings",
            "paragraph_rank": 43,
            "section_rank": 16
        },
        {
            "text": "By keeping the leading terms in this expansion there is a one-to-one mapping from this vertex onto the effective Lagrangian, 2",
            "section": "Parameterization of scalar-tensor couplings",
            "paragraph_rank": 43,
            "section_rank": 16
        },
        {
            "text": "where the A i no represent the leading, momentum independent coefficients and electromagnetic gauge invariance requires A Z\u03b3,\u03b3\u03b3 1o = A Z\u03b3,\u03b3\u03b3 4o = A Z\u03b3,\u03b3\u03b3 5o = 0. ",
            "section": "Parameterization of scalar-tensor couplings",
            "paragraph_rank": 44,
            "section_rank": 16
        },
        {
            "text": "We have defined Z \u00b5 and A \u00b5 as the Z and photon fields respectively while V \u00b5\u03bd = \u2202 \u00b5 V \u03bd \u2212 \u2202 \u03bd V \u00b5 are the usual bosonic field strengths and the dual field strengths are defined as V \u00b5\u03bd = 1 2 \u00b5\u03bd\u03c1\u03c3 V \u03c1\u03c3 . ",
            "section": "Parameterization of scalar-tensor couplings",
            "paragraph_rank": 44,
            "section_rank": 16
        },
        {
            "text": "The effective lagrangian in eq. ",
            "section": "Parameterization of scalar-tensor couplings",
            "paragraph_rank": 44,
            "section_rank": 16
        },
        {
            "text": "(32) is composed of the leading terms in a derivative expansion (up to two derivatives) and is useful for parametrizing potentially large new physics effects generated by loops of heavy particles and a convenient framework for assessing the potential sensitivity to the leading operators [37] involving photons and Z bosons.",
            "section": "Parameterization of scalar-tensor couplings",
            "paragraph_rank": 44,
            "section_rank": 16,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 2,
                    "text": "(3"
                },
                {
                    "start": 288,
                    "end": 292,
                    "type": "bibr",
                    "ref_id": "b37",
                    "text": "[37]"
                }
            ]
        },
        {
            "text": "Thus, although eq. ",
            "section": "Parameterization of scalar-tensor couplings",
            "paragraph_rank": 45,
            "section_rank": 16
        },
        {
            "text": "(3.1) is a redundant parameterization of the tensor structure, it is a convenient, yet more general, parametrization for fitting to effective Lagrangian parameters that might be generated in various models at dimension five or less as in eq. ",
            "section": "Parameterization of scalar-tensor couplings",
            "paragraph_rank": 45,
            "section_rank": 16
        },
        {
            "text": "(3.2). ",
            "section": "Parameterization of scalar-tensor couplings",
            "paragraph_rank": 45,
            "section_rank": 16
        },
        {
            "text": "The parameterization in eq. ",
            "section": "Parameterization of scalar-tensor couplings",
            "paragraph_rank": 45,
            "section_rank": 16
        },
        {
            "text": "(3.1) can of course be mapped, with appropriate translation of the parameters, onto Lagrangians with dimension greater than five or to an underlying dimension six lagrangian in a theory of electroweak symmetry breaking such as in the Standard Model. ",
            "section": "Parameterization of scalar-tensor couplings",
            "paragraph_rank": 45,
            "section_rank": 16
        },
        {
            "text": "We will work explicitly with the vertex in eq. ",
            "section": "Parameterization of scalar-tensor couplings",
            "paragraph_rank": 45,
            "section_rank": 16
        },
        {
            "text": "(3.1) which has been used to calculate the fully differential cross section for h \u2192 4 and when performing parameter extraction, but other parameterizations can be easily accommodated.",
            "section": "Parameterization of scalar-tensor couplings",
            "paragraph_rank": 45,
            "section_rank": 16
        },
        {
            "text": "This flexibility of parameterization also allows for other new physics, such as exotic Higgs decays involving exotic fermions or vector bosons [47], to be easily included in the framework. ",
            "section": "Parameterization of scalar-tensor couplings",
            "paragraph_rank": 46,
            "section_rank": 16,
            "ref_spans": [
                {
                    "start": 143,
                    "end": 147,
                    "type": "bibr",
                    "ref_id": "b47",
                    "text": "[47]"
                }
            ]
        },
        {
            "text": "Furthermore, by using this parameterization, explicit computations of either Standard Model or new physics loop effects which would generate these momentum dependent form factors can easily be included into the framework. ",
            "section": "Parameterization of scalar-tensor couplings",
            "paragraph_rank": 46,
            "section_rank": 16
        },
        {
            "text": "This allows for the ability to in principle extract the parameters from whichever underlying theory is responsible for generating them. ",
            "section": "Parameterization of scalar-tensor couplings",
            "paragraph_rank": 46,
            "section_rank": 16
        },
        {
            "text": "We leave a more detailed investigation of these loop effects to ongoing work.",
            "section": "Parameterization of scalar-tensor couplings",
            "paragraph_rank": 46,
            "section_rank": 16
        },
        {
            "text": "Signal and background fully differential cross sections",
            "section_rank": 17
        },
        {
            "text": "In the case of signal we have computed analytically the fully differential cross section in the observables described in section 3.1 for the process h \u2192 ZZ + Z\u03b3 + \u03b3\u03b3 \u2192 4 using the parameterization in eq. ",
            "section": "Signal and background fully differential cross sections",
            "paragraph_rank": 47,
            "section_rank": 17
        },
        {
            "text": "(3.1). ",
            "section": "Signal and background fully differential cross sections",
            "paragraph_rank": 47,
            "section_rank": 17
        },
        {
            "text": "We have included all possible interference effects between tensor structures as well as identical final states in the case of 4e/4\u00b5. ",
            "section": "Signal and background fully differential cross sections",
            "paragraph_rank": 47,
            "section_rank": 17
        },
        {
            "text": "For the irreducible background we have computed analytically the process qq \u2192 ZZ + Z\u03b3 + \u03b3\u03b3 \u2192 4 which includes the s-channel (resonant) 4 process as well as the t-channel (diboson production) 4 process and again have included all possible interference effects. ",
            "section": "Signal and background fully differential cross sections",
            "paragraph_rank": 47,
            "section_rank": 17
        },
        {
            "text": "All vector bosons are allowed to be on or off-shell and we do not distinguish between them in what follows. ",
            "section": "Signal and background fully differential cross sections",
            "paragraph_rank": 47,
            "section_rank": 17
        },
        {
            "text": "The details of these calculations can be found in [19,35,37,42] along with the validation procedures and studies of the distributions as well as the various interference effects. ",
            "section": "Signal and background fully differential cross sections",
            "paragraph_rank": 47,
            "section_rank": 17,
            "ref_spans": [
                {
                    "start": 50,
                    "end": 54,
                    "type": "bibr",
                    "ref_id": "b18",
                    "text": "[19,"
                },
                {
                    "start": 54,
                    "end": 57,
                    "type": "bibr",
                    "ref_id": "b35",
                    "text": "35,"
                },
                {
                    "start": 57,
                    "end": 60,
                    "type": "bibr",
                    "ref_id": "b37",
                    "text": "37,"
                },
                {
                    "start": 60,
                    "end": 63,
                    "type": "bibr",
                    "ref_id": "b42",
                    "text": "42]"
                }
            ]
        },
        {
            "text": "We have combined these analytic expressions with functions parametrizing the production spectra and implemented them into our analysis framework.",
            "section": "Signal and background fully differential cross sections",
            "paragraph_rank": 47,
            "section_rank": 17
        },
        {
            "text": "We note that it is important to include all possible Higgs couplings including the Z\u03b3 and \u03b3\u03b3 contributions in the signal differential cross section since the Higgs appears to be mostly Standard Model-like [58] and we are primarily searching for small anomalous deviations from the Standard Model prediction. ",
            "section": "Signal and background fully differential cross sections",
            "paragraph_rank": 48,
            "section_rank": 17,
            "ref_spans": [
                {
                    "start": 205,
                    "end": 209,
                    "type": "bibr",
                    "ref_id": "b58",
                    "text": "[58]"
                }
            ]
        },
        {
            "text": "Thus when attempting to extract specific",
            "section": "Signal and background fully differential cross sections",
            "paragraph_rank": 48,
            "section_rank": 17
        },
        {
            "text": "JHEP01(2015)125",
            "section_rank": 18
        },
        {
            "text": "couplings we must be sure that one small effect is not being mistaken for another. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 49,
            "section_rank": 18
        },
        {
            "text": "This is particularly relevant since many of the couplings may be correlated with one another.",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 49,
            "section_rank": 18
        },
        {
            "text": "Furthermore, it has been shown recently [37] that for 'true' points near the Standard Model, the greatest sensitivity to the anomalous couplings (non A ZZ 1o ) is for the Z\u03b3 and especially \u03b3\u03b3 operators (see eq. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 50,
            "section_rank": 18,
            "ref_spans": [
                {
                    "start": 40,
                    "end": 44,
                    "type": "bibr",
                    "ref_id": "b37",
                    "text": "[37]"
                }
            ]
        },
        {
            "text": "(3.2)). ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 50,
            "section_rank": 18
        },
        {
            "text": "Including all possible couplings and doing a simultaneous fit ensures that we minimize the possibility of misinterpretation or of introducing a bias when attempting to extract these couplings. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 50,
            "section_rank": 18
        },
        {
            "text": "Searching for these small effects is also why it is important to include the interference effects between the identical final state leptons as well as the relevant detector effects and background.",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 50,
            "section_rank": 18
        },
        {
            "text": "We also comment that in principal there are NLO contributions to the h \u2192 4 decay processes, but these are expected to be small at \u223c 125 GeV [48,49] and not relevant until higher precision is obtained once larger data sets are gathered. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 51,
            "section_rank": 18,
            "ref_spans": [
                {
                    "start": 140,
                    "end": 144,
                    "type": "bibr",
                    "ref_id": "b49",
                    "text": "[48,"
                },
                {
                    "start": 144,
                    "end": 147,
                    "type": "bibr",
                    "ref_id": "b50",
                    "text": "49]"
                }
            ]
        },
        {
            "text": "Eventually however, these effects should be included and their implementation into our framework is currently ongoing.",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 51,
            "section_rank": 18
        },
        {
            "text": "Combining production and decay",
            "section_rank": 19
        },
        {
            "text": "To be able to perform a fit for the effective Higgs couplings, we must first construct the fully differential cross section for the observables as a function of the undetermined parameters ( A). ",
            "section": "Combining production and decay",
            "paragraph_rank": 52,
            "section_rank": 19
        },
        {
            "text": "This differential cross section consists of two components which we assume to be factorized: the parton level ('decay') differential cross section as discussed in section 3.3, and the 'production' spectrum. ",
            "section": "Combining production and decay",
            "paragraph_rank": 52,
            "section_rank": 19
        },
        {
            "text": "The full production plus decay fully differential cross section can be expressed as the following,",
            "section": "Combining production and decay",
            "paragraph_rank": 52,
            "section_rank": 19
        },
        {
            "text": "where, since the Higgs is a spin-0 particle, we can explicitly assume that the decay process can be factorized from the production mechanism. ",
            "section": "Combining production and decay",
            "paragraph_rank": 53,
            "section_rank": 19
        },
        {
            "text": "For the background this explicit factorization does not occur, but still turns out to be an adequate approximation [41] especially if the p T and Y variables are averaged over once the convolution is performed. ",
            "section": "Combining production and decay",
            "paragraph_rank": 53,
            "section_rank": 19,
            "ref_spans": [
                {
                    "start": 115,
                    "end": 119,
                    "type": "bibr",
                    "ref_id": "b41",
                    "text": "[41]"
                }
            ]
        },
        {
            "text": "The parton level fully differential cross section (\u03c3 4 ) is treated as being at fixed\u015d where one obtains the input\u015d value from the production spectrum (W prod ). ",
            "section": "Combining production and decay",
            "paragraph_rank": 53,
            "section_rank": 19
        },
        {
            "text": "The production spectrum for the signal and background depend on the parton distribution functions and can not be computed analytically. ",
            "section": "Combining production and decay",
            "paragraph_rank": 53,
            "section_rank": 19
        },
        {
            "text": "For the signal which we assume decays on-shell, the\u015d spectrum is taken to be a delta function centered at m 2 h , which for a Standard Model Higgs at 125 GeV is an excellent approximation. ",
            "section": "Combining production and decay",
            "paragraph_rank": 53,
            "section_rank": 19
        },
        {
            "text": "Note however that this assumption can be relaxed in our framework to consider more general\u015d spectra as would be found for example in the case of a new heavy scalar with a large width.",
            "section": "Combining production and decay",
            "paragraph_rank": 53,
            "section_rank": 19
        },
        {
            "text": "Comments production spectra",
            "section_rank": 20
        },
        {
            "text": "Here we discuss how the W prod (\u015d, p T , Y, \u03c6) production spectrum in eq. ",
            "section": "Comments production spectra",
            "paragraph_rank": 54,
            "section_rank": 20
        },
        {
            "text": "(3.3) is obtained. ",
            "section": "Comments production spectra",
            "paragraph_rank": 54,
            "section_rank": 20
        },
        {
            "text": "This function involves higher order effects as well as parton distribution functions and thus can not be computed analytically. ",
            "section": "Comments production spectra",
            "paragraph_rank": 54,
            "section_rank": 20
        },
        {
            "text": "To include them in the total differential cross sections there are various options. ",
            "section": "Comments production spectra",
            "paragraph_rank": 54,
            "section_rank": 20
        },
        {
            "text": "One can in principal generate enough Monte Carlo events",
            "section": "Comments production spectra",
            "paragraph_rank": 54,
            "section_rank": 20
        },
        {
            "text": "JHEP01(2015)125",
            "section_rank": 21
        },
        {
            "text": "to accurately fill the full spectrum in the (\u015d, Y, p T , \u03c6) variables. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 55,
            "section_rank": 21
        },
        {
            "text": "As this is computationally intensive we take an approximate approach in which we interpolate analytic functions for the signal and background from one or two dimensional projections generated from the Madgraph [59] and POWHEG [60] Monte Carlo generators following a similar procedure as found in [32]. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 55,
            "section_rank": 21,
            "ref_spans": [
                {
                    "start": 210,
                    "end": 214,
                    "type": "bibr",
                    "ref_id": "b59",
                    "text": "[59]"
                },
                {
                    "start": 226,
                    "end": 230,
                    "type": "bibr",
                    "ref_id": "b60",
                    "text": "[60]"
                },
                {
                    "start": 296,
                    "end": 300,
                    "type": "bibr",
                    "ref_id": "b32",
                    "text": "[32]"
                }
            ]
        },
        {
            "text": "Having an analytic parameterization for these functions also allows for faster integration when implementing them into the convolution procedure described above. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 55,
            "section_rank": 21
        },
        {
            "text": "This procedure of interpolating the one or two dimensional projections neglects correlations between the production variables. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 55,
            "section_rank": 21
        },
        {
            "text": "However, since in the signal case there is an explicit factorization between production and decay, the effects of this approximation on parameter extraction in our analysis are small.",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 55,
            "section_rank": 21
        },
        {
            "text": "In addition, to mitigate these effects further, one can always average over Y and p T as well as fit to ratios of couplings while taking the Higgs mass and overall normalization as input from the total rate (so called 'geolocating' [36]) as was done in a recent implementation of our framework into a CMS experimental analysis [38,39]. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 56,
            "section_rank": 21,
            "ref_spans": [
                {
                    "start": 232,
                    "end": 236,
                    "type": "bibr",
                    "ref_id": "b36",
                    "text": "[36]"
                },
                {
                    "start": 327,
                    "end": 331,
                    "type": "bibr",
                    "ref_id": "b38",
                    "text": "[38,"
                },
                {
                    "start": 331,
                    "end": 334,
                    "type": "bibr",
                    "ref_id": "b39",
                    "text": "39]"
                }
            ]
        },
        {
            "text": "Note however, the overall normalization and Higgs mass can in principle be extracted in our framework, but as this requires extra careful treatment of the production spectra and additional backgrounds we defer a discussion of this to future work.",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 56,
            "section_rank": 21
        },
        {
            "text": "Comments on additional backgrounds",
            "section_rank": 22
        },
        {
            "text": "For the background there are also the higher order contributions such as the gg \u2192 4 and Z + X processes. ",
            "section": "Comments on additional backgrounds",
            "paragraph_rank": 57,
            "section_rank": 22
        },
        {
            "text": "These make up the parts of the likelihood which can not currently be included in the convolution integral since a sufficiently accurate analytic parameterization has yet to be obtained. ",
            "section": "Comments on additional backgrounds",
            "paragraph_rank": 57,
            "section_rank": 22
        },
        {
            "text": "Thus for these components we must resort to constructing large 'look-up' tables via Monte Carlo generation. ",
            "section": "Comments on additional backgrounds",
            "paragraph_rank": 57,
            "section_rank": 22
        },
        {
            "text": "Again, the effects of the necessary binning can be mitigated through a linear multi-dimensional interpolation technique [41]. ",
            "section": "Comments on additional backgrounds",
            "paragraph_rank": 57,
            "section_rank": 22,
            "ref_spans": [
                {
                    "start": 120,
                    "end": 124,
                    "type": "bibr",
                    "ref_id": "b41",
                    "text": "[41]"
                }
            ]
        },
        {
            "text": "Additionally, there will be systematic uncertainties associated with these components. ",
            "section": "Comments on additional backgrounds",
            "paragraph_rank": 57,
            "section_rank": 22
        },
        {
            "text": "Fortunately, the gg \u2192 4 component only makes up \u223c 3 \u2212 5% relative to qq \u2192 4 around 125 GeV [50]. ",
            "section": "Comments on additional backgrounds",
            "paragraph_rank": 57,
            "section_rank": 22,
            "ref_spans": [
                {
                    "start": 91,
                    "end": 95,
                    "type": "bibr",
                    "ref_id": "b51",
                    "text": "[50]"
                }
            ]
        },
        {
            "text": "The Z + X background on the other hand does make up a sizable contribution of the total background which is comparable to, but smaller than, the largest qq component (see table 2 in [38] or table 3 in [39]). ",
            "section": "Comments on additional backgrounds",
            "paragraph_rank": 57,
            "section_rank": 22,
            "ref_spans": [
                {
                    "start": 182,
                    "end": 186,
                    "type": "bibr",
                    "ref_id": "b38",
                    "text": "[38]"
                },
                {
                    "start": 201,
                    "end": 205,
                    "type": "bibr",
                    "ref_id": "b39",
                    "text": "[39]"
                }
            ]
        },
        {
            "text": "This component however can in principle be reduced further in the future by requiring more stringent lepton acceptance criteria once more data is collected. ",
            "section": "Comments on additional backgrounds",
            "paragraph_rank": 57,
            "section_rank": 22
        },
        {
            "text": "For now the use of the linearly interpolated 'look-up' templates and associated systematics is found to be sufficient. ",
            "section": "Comments on additional backgrounds",
            "paragraph_rank": 57,
            "section_rank": 22
        },
        {
            "text": "Once the templates are built, including these components in the final likelihood is straightforward as we briefly sketch in section 5.2 and discussed in more detail in [38,39,41].",
            "section": "Comments on additional backgrounds",
            "paragraph_rank": 57,
            "section_rank": 22,
            "ref_spans": [
                {
                    "start": 168,
                    "end": 172,
                    "type": "bibr",
                    "ref_id": "b38",
                    "text": "[38,"
                },
                {
                    "start": 172,
                    "end": 175,
                    "type": "bibr",
                    "ref_id": "b39",
                    "text": "39,"
                },
                {
                    "start": 175,
                    "end": 177,
                    "type": "bibr",
                    "ref_id": "b41",
                    "text": "41"
                }
            ]
        },
        {
            "text": "The 'detector level' pdf",
            "section_rank": 23
        },
        {
            "text": "The convolution integral in eq. ",
            "section": "The 'detector level' pdf",
            "paragraph_rank": 58,
            "section_rank": 23
        },
        {
            "text": "(2.1) is conceptually straightforward, but in practice is challenging to perform, both for computational and algorithmic reasons. ",
            "section": "The 'detector level' pdf",
            "paragraph_rank": 58,
            "section_rank": 23
        },
        {
            "text": "The key assumption which makes it possible is that the direction of lepton momenta are measured with infinite precision which at CMS and ATLAS is a very good approximation. ",
            "section": "The 'detector level' pdf",
            "paragraph_rank": 58,
            "section_rank": 23
        },
        {
            "text": "This allows",
            "section": "The 'detector level' pdf",
            "paragraph_rank": 58,
            "section_rank": 23
        },
        {
            "text": "JHEP01(2015)125",
            "section_rank": 24
        },
        {
            "text": "us, through a change of variables, to reduce the 12-dimensional integral into a more manageable 4-dimensional integral over the four energies of the leptons which are altered by detector resolution effects. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 59,
            "section_rank": 24
        },
        {
            "text": "Typically this 4-dimensional integral is done using Monte Carlo techniques [31], thus losing the advantage of having analytic control over the likelihood or assuming that the resolution effects can also be neglecting making the integral trivial. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 59,
            "section_rank": 24,
            "ref_spans": [
                {
                    "start": 75,
                    "end": 79,
                    "type": "bibr",
                    "ref_id": "b31",
                    "text": "[31]"
                }
            ]
        },
        {
            "text": "As discussed in section 2 we instead perform this integration explicitly using a combination of numerical and analytic methods which allow us to maintain arbitrarily high precision at each step involved. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 59,
            "section_rank": 24
        },
        {
            "text": "There are a number of technical details involved in this procedure which are beyond the scope of this 'overview' of the framework, but the details can be found in [40,41]. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 59,
            "section_rank": 24,
            "ref_spans": [
                {
                    "start": 163,
                    "end": 167,
                    "type": "bibr",
                    "ref_id": "b40",
                    "text": "[40,"
                },
                {
                    "start": 167,
                    "end": 170,
                    "type": "bibr",
                    "ref_id": "b41",
                    "text": "41]"
                }
            ]
        },
        {
            "text": "We instead briefly sketch an overview of the convolution integral and show its validation.",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 59,
            "section_rank": 24
        },
        {
            "text": "Transforming from CM basis to lepton smearing basis",
            "section_rank": 25
        },
        {
            "text": "Beginning from eq. ",
            "section": "Transforming from CM basis to lepton smearing basis",
            "paragraph_rank": 60,
            "section_rank": 25
        },
        {
            "text": "(2.1) we first discuss the construction of the background detector level pdf. ",
            "section": "Transforming from CM basis to lepton smearing basis",
            "paragraph_rank": 60,
            "section_rank": 25
        },
        {
            "text": "The construction of the signal will be discussed separately as there is a subtle, but important, difference in performing the convolution. ",
            "section": "Transforming from CM basis to lepton smearing basis",
            "paragraph_rank": 60,
            "section_rank": 25
        },
        {
            "text": "Since there are no undetermined parameters in the background the generator and detector-level (un-normalized) differential cross sections are given simply by P B ( X G ) and P B ( X R ) respectively and the convolution integral can be written schematically as,",
            "section": "Transforming from CM basis to lepton smearing basis",
            "paragraph_rank": 60,
            "section_rank": 25
        },
        {
            "text": "The set of variables",
            "section": "Transforming from CM basis to lepton smearing basis",
            "paragraph_rank": 61,
            "section_rank": 25
        },
        {
            "text": ", \u2126) exhausts the twelve degrees of freedom (note that p T has 2 components and \u2126 contains 5 angles) available to the four (massless) final state leptons. ",
            "section": "Transforming from CM basis to lepton smearing basis",
            "paragraph_rank": 62,
            "section_rank": 25
        },
        {
            "text": "The differential volume element is given by",
            "section": "Transforming from CM basis to lepton smearing basis",
            "paragraph_rank": 62,
            "section_rank": 25
        },
        {
            "text": "To perform this convolution with the transfer function we must first transform to the basis in which the detector smearing of the lepton momenta is parameterized. ",
            "section": "Transforming from CM basis to lepton smearing basis",
            "paragraph_rank": 63,
            "section_rank": 25
        },
        {
            "text": "This requires transforming from the basis of the twelve center of mass variables defined in section 3.1 to the three momentum basis for the four final state leptons. ",
            "section": "Transforming from CM basis to lepton smearing basis",
            "paragraph_rank": 63,
            "section_rank": 25
        },
        {
            "text": "In this basis the lepton three momenta p i can be decomposed in terms of the component of the lepton momentum parallel to the direction (p i|| ) of motion and the two components perpendicular to the direction of motion ( p i\u22a5 ) (which are zero at generator level). ",
            "section": "Transforming from CM basis to lepton smearing basis",
            "paragraph_rank": 63,
            "section_rank": 25
        },
        {
            "text": "We then make the assumption that detector smearing will only affect parallel components p i|| while the perpendicular components p i\u22a5 are left invariant. ",
            "section": "Transforming from CM basis to lepton smearing basis",
            "paragraph_rank": 63,
            "section_rank": 25
        },
        {
            "text": "Note that this assumption is equivalent to assuming angular resolution effects due to detector smearing can be neglected, which is an excellent approximation for the LHC detectors [52][53][54]. ",
            "section": "Transforming from CM basis to lepton smearing basis",
            "paragraph_rank": 63,
            "section_rank": 25,
            "ref_spans": [
                {
                    "start": 180,
                    "end": 184,
                    "type": "bibr",
                    "ref_id": "b53",
                    "text": "[52]"
                },
                {
                    "start": 184,
                    "end": 188,
                    "type": "bibr",
                    "ref_id": "b54",
                    "text": "[53]"
                },
                {
                    "start": 188,
                    "end": 192,
                    "type": "bibr",
                    "text": "[54]"
                }
            ]
        },
        {
            "text": "In the (p i|| , p i\u22a5 ) basis only the transfer function associated with p i|| is non-trivial while the one associated with the perpendicular components can be represented simply as a delta function for each perpendicular direction, thus allowing for trivial integration over the eight p i\u22a5 variables.",
            "section": "Transforming from CM basis to lepton smearing basis",
            "paragraph_rank": 63,
            "section_rank": 25
        },
        {
            "text": "With these assumptions the integral in eq. ",
            "section": "Transforming from CM basis to lepton smearing basis",
            "paragraph_rank": 64,
            "section_rank": 25
        },
        {
            "text": "(4.1) can then be represented as follows,",
            "section": "Transforming from CM basis to lepton smearing basis",
            "paragraph_rank": 64,
            "section_rank": 25
        },
        {
            "text": "2)",
            "section": "Transforming from CM basis to lepton smearing basis",
            "paragraph_rank": 65,
            "section_rank": 25
        },
        {
            "text": "JHEP01(2015)125",
            "section_rank": 26
        },
        {
            "text": "where we have defined the lepton momenta 'smearing factors'",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 66,
            "section_rank": 26
        },
        {
            "text": "We have also defined |J B | which is the 12 \u00d7 12 Jacobian which parametrizes the (nonlinear) transformation that takes us from the center of mass basis to the lepton smearing basis. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 67,
            "section_rank": 26
        },
        {
            "text": "The construction of this Jacobian is highly non trivial and requires a combination of analytic and numerical techniques which are beyond the scope of this overview, but the relevant details can be found in [40,41].",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 67,
            "section_rank": 26,
            "ref_spans": [
                {
                    "start": 206,
                    "end": 210,
                    "type": "bibr",
                    "ref_id": "b40",
                    "text": "[40,"
                },
                {
                    "start": 210,
                    "end": 213,
                    "type": "bibr",
                    "ref_id": "b41",
                    "text": "41]"
                }
            ]
        },
        {
            "text": "We thus see in eq. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 68,
            "section_rank": 26
        },
        {
            "text": "(42) that what started out as a twelve dimensional integral has been reduced to a much more manageable integration over four variables. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 68,
            "section_rank": 26,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 2,
                    "ref_id": "formula_8",
                    "text": "(4"
                }
            ]
        },
        {
            "text": "The details and validation of this four dimensional integration, which is done using a recursive numerical integration technique [43] can also be found in [40,41].",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 68,
            "section_rank": 26,
            "ref_spans": [
                {
                    "start": 129,
                    "end": 133,
                    "type": "bibr",
                    "ref_id": "b43",
                    "text": "[43]"
                },
                {
                    "start": 155,
                    "end": 159,
                    "type": "bibr",
                    "ref_id": "b40",
                    "text": "[40,"
                },
                {
                    "start": 159,
                    "end": 162,
                    "type": "bibr",
                    "ref_id": "b41",
                    "text": "41]"
                }
            ]
        },
        {
            "text": "To construct the detector level signal differential cross section (again un-normalized), which is now a function of the effective couplings A, we follow the same procedure as for the background starting from,",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 69,
            "section_rank": 26
        },
        {
            "text": "We again use the assumptions which allow us to perform the trivial integration over the eight p i\u22a5 variables, but instead transform to the following integration basis",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 70,
            "section_rank": 26
        },
        {
            "text": "We now also use the fact that, as mentioned below eq. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 71,
            "section_rank": 26
        },
        {
            "text": "(3.3), the\u015d spectrum for the signal is \u221d \u03b4(\u015d G \u2212 m 2 h ) (where m h is the generated Higgs mass), enabling us to perform the integration over d\u015d G as well. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 71,
            "section_rank": 26
        },
        {
            "text": "Thus, we have for the final signal detector level differential cross section,",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 71,
            "section_rank": 26
        },
        {
            "text": "where again |J S | represent the 12 \u00d7 12 Jacobian (which is different from |J B |) taking us from the CM basis to the lepton smearing basis. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 72,
            "section_rank": 26
        },
        {
            "text": "By using a delta function to model the width of the resonance, there is one less dimension to integrate over as compared to the background case. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 72,
            "section_rank": 26
        },
        {
            "text": "While this makes it easier computationally in one respect, an additional complication arises since we have to integrate along a trajectory in whic\u0125 s G is kept constant. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 72,
            "section_rank": 26
        },
        {
            "text": "This places an additional constraint when performing the",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 72,
            "section_rank": 26
        },
        {
            "text": "integration which further complicates matters and must be properly taken into account. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 73,
            "section_rank": 26
        },
        {
            "text": "Explicit details of this integration and its validation along with the derivation of the signal Jacobian |J S | in eq. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 73,
            "section_rank": 26
        },
        {
            "text": "(4.6) are given in [40,41].",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 73,
            "section_rank": 26,
            "ref_spans": [
                {
                    "start": 19,
                    "end": 23,
                    "type": "bibr",
                    "ref_id": "b40",
                    "text": "[40,"
                },
                {
                    "start": 23,
                    "end": 26,
                    "type": "bibr",
                    "ref_id": "b41",
                    "text": "41]"
                }
            ]
        },
        {
            "text": "Comments on transfer function",
            "section_rank": 27
        },
        {
            "text": "Detector response effects including effects from selection inefficiency may be parameterized into transfer functions in the following way,  The response function S, parameterizes the probability for a lepton with actual momentum p G i to be reconstructed with momentum p R i , while \u03b4 is the Dirac delta function in the perpendicular components, and is the selection efficiency. ",
            "section": "Comments on transfer function",
            "paragraph_rank": 74,
            "section_rank": 27
        },
        {
            "text": "With typical lepton selection criteria employed by the LHC experiments [53,54], it is a good approximation that each lepton is independent. ",
            "section": "Comments on transfer function",
            "paragraph_rank": 74,
            "section_rank": 27,
            "ref_spans": [
                {
                    "start": 71,
                    "end": 75,
                    "type": "bibr",
                    "ref_id": "b54",
                    "text": "[53,"
                },
                {
                    "start": 75,
                    "end": 78,
                    "type": "bibr",
                    "text": "54]"
                }
            ]
        },
        {
            "text": "Thus, the full transfer function for the event may be written as:",
            "section": "Comments on transfer function",
            "paragraph_rank": 74,
            "section_rank": 27
        },
        {
            "text": "We treat T ( c | P G ) as a function of c which takes the generator level momenta P G as input. ",
            "section": "Comments on transfer function",
            "paragraph_rank": 75,
            "section_rank": 27
        },
        {
            "text": "The only effect of imperfect momentum measurement on the production spectra is to provide a small smearing of the p T spectrum for the four lepton system. ",
            "section": "Comments on transfer function",
            "paragraph_rank": 75,
            "section_rank": 27
        },
        {
            "text": "We can mitigate the effects of the smearing by averaging over the production spectra when performing parameter extractions. ",
            "section": "Comments on transfer function",
            "paragraph_rank": 75,
            "section_rank": 27
        },
        {
            "text": "Further details on the construction and implementation of the transfer function can be found in [38,39,41].",
            "section": "Comments on transfer function",
            "paragraph_rank": 75,
            "section_rank": 27,
            "ref_spans": [
                {
                    "start": 96,
                    "end": 100,
                    "type": "bibr",
                    "ref_id": "b38",
                    "text": "[38,"
                },
                {
                    "start": 100,
                    "end": 103,
                    "type": "bibr",
                    "ref_id": "b39",
                    "text": "39,"
                },
                {
                    "start": 103,
                    "end": 106,
                    "type": "bibr",
                    "ref_id": "b41",
                    "text": "41]"
                }
            ]
        },
        {
            "text": "Validation of convolution integral",
            "section_rank": 28
        },
        {
            "text": "As validation of the convolution integral we first show in figures 2-5 projections for signal and background. ",
            "section": "Validation of convolution integral",
            "paragraph_rank": 76,
            "section_rank": 28
        },
        {
            "text": "We compare in these plots the distributions for a Madgraph sample which has had detector smearing and acceptance effects applied to it versus projections generated from our detector level differential cross sections obtained after the convolution described above.",
            "section": "Validation of convolution integral",
            "paragraph_rank": 76,
            "section_rank": 28
        },
        {
            "text": "We have obtained the signal and background production spectrum for the (\u015d, p T , Y, \u03c6) variables from POWHEG and boosted the Madgraph events and those from our projections accordingly. ",
            "section": "Validation of convolution integral",
            "paragraph_rank": 77,
            "section_rank": 28
        },
        {
            "text": "We have used the interpolation procedure described in section 3.   ",
            "section": "Validation of convolution integral",
            "paragraph_rank": 77,
            "section_rank": 28
        },
        {
            "text": "production spectra for the signal and background differential cross sections and combined them with the analytic expressions for the h \u2192 4 and qq \u2192 4 processes. ",
            "section": "Validation of convolution integral",
            "paragraph_rank": 77,
            "section_rank": 28
        },
        {
            "text": "For the signal we show the tree level Standard Model point where A ZZ 1 = 2 and all other couplings are set to zero. ",
            "section": "Validation of convolution integral",
            "paragraph_rank": 77,
            "section_rank": 28
        },
        {
            "text": "For both signal and background we show only the 2e2\u00b5 final state, but results for 4e (or 4\u00b5) are found in [38,39,41].",
            "section": "Validation of convolution integral",
            "paragraph_rank": 77,
            "section_rank": 28,
            "ref_spans": [
                {
                    "start": 106,
                    "end": 110,
                    "type": "bibr",
                    "ref_id": "b38",
                    "text": "[38,"
                },
                {
                    "start": 110,
                    "end": 113,
                    "type": "bibr",
                    "ref_id": "b39",
                    "text": "39,"
                },
                {
                    "start": 113,
                    "end": 116,
                    "type": "bibr",
                    "ref_id": "b41",
                    "text": "41]"
                }
            ]
        },
        {
            "text": "A further validation beyond these projections however is to look at the likelihoods (the differential cross section evaluated for a set of observables) for both the signal and background which contain the full correlations between the different variables. ",
            "section": "Validation of convolution integral",
            "paragraph_rank": 78,
            "section_rank": 28
        },
        {
            "text": "We show these in figure 6 for a CMS-like phase space and a very large number of events. ",
            "section": "Validation of convolution integral",
            "paragraph_rank": 78,
            "section_rank": 28,
            "ref_spans": [
                {
                    "start": 17,
                    "end": 25,
                    "type": "figure",
                    "text": "figure 6"
                }
            ]
        },
        {
            "text": "To obtain these likelihoods we have evaluated our detector-level differential cross section with the Madgraph sample which has had detector smearing and acceptance effects applied and plotted it on top of the result of evaluating our detector-level differential cross section with events generated from the expression itself. ",
            "section": "Validation of convolution integral",
            "paragraph_rank": 78,
            "section_rank": 28
        },
        {
            "text": "We find the agreement between the two results to be very good. ",
            "section": "Validation of convolution integral",
            "paragraph_rank": 78,
            "section_rank": 28
        },
        {
            "text": "Further details are found in the accompanying documents [40,41].",
            "section": "Validation of convolution integral",
            "paragraph_rank": 78,
            "section_rank": 28,
            "ref_spans": [
                {
                    "start": 56,
                    "end": 60,
                    "type": "bibr",
                    "ref_id": "b40",
                    "text": "[40,"
                },
                {
                    "start": 60,
                    "end": 63,
                    "type": "bibr",
                    "ref_id": "b41",
                    "text": "41]"
                }
            ]
        },
        {
            "text": "These plots should not be taken as validation of the complete detector-level differential cross sections which must be validated with full simulation and data. ",
            "section": "Validation of convolution integral",
            "paragraph_rank": 79,
            "section_rank": 28
        },
        {
            "text": "They are meant only to show the validation of the convolution procedure as well as the construction of the generator-level differential cross sections including the analytic computations. ",
            "section": "Validation of convolution integral",
            "paragraph_rank": 79,
            "section_rank": 28
        },
        {
            "text": "Complete validations of the full detector level likelihoods including the various production and background effects can be found in [38,39,41].  ",
            "section": "Validation of convolution integral",
            "paragraph_rank": 79,
            "section_rank": 28,
            "ref_spans": [
                {
                    "start": 132,
                    "end": 136,
                    "type": "bibr",
                    "ref_id": "b38",
                    "text": "[38,"
                },
                {
                    "start": 136,
                    "end": 139,
                    "type": "bibr",
                    "ref_id": "b39",
                    "text": "39,"
                },
                {
                    "start": 139,
                    "end": 142,
                    "type": "bibr",
                    "ref_id": "b41",
                    "text": "41]"
                }
            ]
        },
        {
            "text": "Figure 6. ",
            "section": "Validation of convolution integral",
            "paragraph_rank": 79,
            "section_rank": 28,
            "ref_spans": [
                {
                    "start": 0,
                    "end": 8,
                    "type": "figure",
                    "text": "Figure 6"
                }
            ]
        },
        {
            "text": "Validation of the convolution integrals described in eq. ",
            "section": "Validation of convolution integral",
            "paragraph_rank": 79,
            "section_rank": 28
        },
        {
            "text": "(4.1) and eq. ",
            "section": "Validation of convolution integral",
            "paragraph_rank": 79,
            "section_rank": 28
        },
        {
            "text": "(4.4). ",
            "section": "Validation of convolution integral",
            "paragraph_rank": 79,
            "section_rank": 28
        },
        {
            "text": "In blue we show the 'boosted' Madgraph sample with acceptance cuts and detector smearing applied while in red we show projections from our differential cross sections after the convolution integration for the tree level SM signal and background likelihood.",
            "section": "Validation of convolution integral",
            "paragraph_rank": 79,
            "section_rank": 28
        },
        {
            "text": "JHEP01(2015)125",
            "section_rank": 29
        },
        {
            "text": "Construction of likelihoods and parameter extraction",
            "section_rank": 30
        },
        {
            "text": "With the detector level differential cross sections obtained in eq. ",
            "section": "Construction of likelihoods and parameter extraction",
            "paragraph_rank": 80,
            "section_rank": 30
        },
        {
            "text": "(4.2) and eq. ",
            "section": "Construction of likelihoods and parameter extraction",
            "paragraph_rank": 80,
            "section_rank": 30
        },
        {
            "text": "(4.6) in hand we can then go on to construct the full likelihood for a particular dataset. ",
            "section": "Construction of likelihoods and parameter extraction",
            "paragraph_rank": 80,
            "section_rank": 30
        },
        {
            "text": "Before doing so, we must properly normalize the background and signal differential cross sections by performing the full integration over all twelve reconstructed X variables where from now on we drop the superscript R since we only deal with detector level observables in what follows. ",
            "section": "Construction of likelihoods and parameter extraction",
            "paragraph_rank": 80,
            "section_rank": 30
        },
        {
            "text": "In this section we present a schematic overview of the normalization procedure. ",
            "section": "Construction of likelihoods and parameter extraction",
            "paragraph_rank": 80,
            "section_rank": 30
        },
        {
            "text": "We also at this stage briefly discuss averaging over the production variables (Y, p T , \u03c6) and the implementation of systematic uncertainties through the use of nuisance parameters in the likelihood functions. ",
            "section": "Construction of likelihoods and parameter extraction",
            "paragraph_rank": 80,
            "section_rank": 30
        },
        {
            "text": "Further details can be found in [40,41].",
            "section": "Construction of likelihoods and parameter extraction",
            "paragraph_rank": 80,
            "section_rank": 30,
            "ref_spans": [
                {
                    "start": 32,
                    "end": 36,
                    "type": "bibr",
                    "ref_id": "b40",
                    "text": "[40,"
                },
                {
                    "start": 36,
                    "end": 39,
                    "type": "bibr",
                    "ref_id": "b41",
                    "text": "41]"
                }
            ]
        },
        {
            "text": "JHEP01(2015)125",
            "section_rank": 31
        },
        {
            "text": "Normalization of background and signal",
            "section_rank": 32
        },
        {
            "text": "One can reduce the effects of production uncertainties by averaging over the detector level production variables (Y, p T , \u03c6). ",
            "section": "Normalization of background and signal",
            "paragraph_rank": 81,
            "section_rank": 32
        },
        {
            "text": "This is straightforwardly done for the background differential cross sections by the following 4-dimensional integration,",
            "section": "Normalization of background and signal",
            "paragraph_rank": 81,
            "section_rank": 32
        },
        {
            "text": "An overall volume factor is not shown because for the purpose of likelihood maximization this constant factor is not relevant. ",
            "section": "Normalization of background and signal",
            "paragraph_rank": 82,
            "section_rank": 32
        },
        {
            "text": "What matters is that the relative normalization between all components in the likelihood is done consistently. ",
            "section": "Normalization of background and signal",
            "paragraph_rank": 82,
            "section_rank": 32
        },
        {
            "text": "With this differential cross sections in terms of the eight center of mass decay observables we can obtain the overall normalization via a Monte Carlo integration procedure described in [40,41],",
            "section": "Normalization of background and signal",
            "paragraph_rank": 82,
            "section_rank": 32,
            "ref_spans": [
                {
                    "start": 186,
                    "end": 190,
                    "type": "bibr",
                    "ref_id": "b40",
                    "text": "[40,"
                },
                {
                    "start": 190,
                    "end": 193,
                    "type": "bibr",
                    "ref_id": "b41",
                    "text": "41]"
                }
            ]
        },
        {
            "text": "which gives our final normalized background pdf as,",
            "section": "Normalization of background and signal",
            "paragraph_rank": 83,
            "section_rank": 32
        },
        {
            "text": "We have calculated the qq \u2192 4 expression as a sum of the separate individual contributions [19,35] making it possible to easily perform the integration on each smaller piece to obtain each normalization and then simply sum over them to obtain the overall normalization. ",
            "section": "Normalization of background and signal",
            "paragraph_rank": 84,
            "section_rank": 32,
            "ref_spans": [
                {
                    "start": 91,
                    "end": 95,
                    "type": "bibr",
                    "ref_id": "b18",
                    "text": "[19,"
                },
                {
                    "start": 95,
                    "end": 98,
                    "type": "bibr",
                    "ref_id": "b35",
                    "text": "35]"
                }
            ]
        },
        {
            "text": "Similarly for the signal we have for the averaging over (Y, p T , \u03c6) variables,",
            "section": "Normalization of background and signal",
            "paragraph_rank": 84,
            "section_rank": 32
        },
        {
            "text": "To obtain the overall normalization in the signal case we first note that it is a function of the underlying parameters A defined in eq. ",
            "section": "Normalization of background and signal",
            "paragraph_rank": 85,
            "section_rank": 32
        },
        {
            "text": "(3.1)). ",
            "section": "Normalization of background and signal",
            "paragraph_rank": 85,
            "section_rank": 32
        },
        {
            "text": "However, from the calculation of the parton level differential cross section presented in [19,35] or from considering eq. ",
            "section": "Normalization of background and signal",
            "paragraph_rank": 85,
            "section_rank": 32,
            "ref_spans": [
                {
                    "start": 90,
                    "end": 94,
                    "type": "bibr",
                    "ref_id": "b18",
                    "text": "[19,"
                },
                {
                    "start": 94,
                    "end": 97,
                    "type": "bibr",
                    "ref_id": "b35",
                    "text": "35]"
                }
            ]
        },
        {
            "text": "(3.1) it is clear (assuming constant effective couplings) that P S (\u015d, M 1 , M 2 , \u2126| A) is a sum over terms each of which is proportional to A i n A j * m . ",
            "section": "Normalization of background and signal",
            "paragraph_rank": 85,
            "section_rank": 32
        },
        {
            "text": "Thus we can write,",
            "section": "Normalization of background and signal",
            "paragraph_rank": 85,
            "section_rank": 32
        },
        {
            "text": "where",
            "section": "Normalization of background and signal",
            "paragraph_rank": 86,
            "section_rank": 32
        },
        {
            "text": ", \u2126) ij nm represents the individual differential cross sections with the couplings factored out. ",
            "section": "Normalization of background and signal",
            "paragraph_rank": 87,
            "section_rank": 32
        },
        {
            "text": "The separate normalizations for each term can now easily be obtained via,",
            "section": "Normalization of background and signal",
            "paragraph_rank": 87,
            "section_rank": 32
        },
        {
            "text": "from which we can now obtain the total overall normalization for the signal pdf as,",
            "section": "Normalization of background and signal",
            "paragraph_rank": 88,
            "section_rank": 32
        },
        {
            "text": "JHEP01(2015)125",
            "section_rank": 33
        },
        {
            "text": "This likelihood can also be combined with an appropriate poisson weighting factor to account for the probability of observing a given number of events [38,39,41]. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 89,
            "section_rank": 33,
            "ref_spans": [
                {
                    "start": 151,
                    "end": 155,
                    "type": "bibr",
                    "ref_id": "b38",
                    "text": "[38,"
                },
                {
                    "start": 155,
                    "end": 158,
                    "type": "bibr",
                    "ref_id": "b39",
                    "text": "39,"
                },
                {
                    "start": 158,
                    "end": 161,
                    "type": "bibr",
                    "ref_id": "b41",
                    "text": "41]"
                }
            ]
        },
        {
            "text": "In the case of multiple final states (for example 4e, 4\u00b5 and 2e2\u00b5), we build the likelihood function and implement the appropriate systematic uncertainties for each one separately. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 89,
            "section_rank": 33
        },
        {
            "text": "We now briefly discuss the implementation of the systematic uncertainties.",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 89,
            "section_rank": 33
        },
        {
            "text": "Including systematic uncertainties",
            "section_rank": 34
        },
        {
            "text": "Systematic uncertainties must be accounted for given our imperfect knowledge of various aspects of the analysis procedure. ",
            "section": "Including systematic uncertainties",
            "paragraph_rank": 90,
            "section_rank": 34
        },
        {
            "text": "The lepton momentum resolution, the size of the backgrounds, and the exact production spectra are some important examples. ",
            "section": "Including systematic uncertainties",
            "paragraph_rank": 90,
            "section_rank": 34
        },
        {
            "text": "For each of these systematic uncertainties we can associate an undetermined parameter which parametrizes our ignorance of the corresponding effect. ",
            "section": "Including systematic uncertainties",
            "paragraph_rank": 90,
            "section_rank": 34
        },
        {
            "text": "Since we are not directly interested in these parameters, but only use them to estimate our systematic uncertainties, they are deemed nuisance parameters and are subsequently profiled over [38,39]. ",
            "section": "Including systematic uncertainties",
            "paragraph_rank": 90,
            "section_rank": 34,
            "ref_spans": [
                {
                    "start": 189,
                    "end": 193,
                    "type": "bibr",
                    "ref_id": "b38",
                    "text": "[38,"
                },
                {
                    "start": 193,
                    "end": 196,
                    "type": "bibr",
                    "ref_id": "b39",
                    "text": "39]"
                }
            ]
        },
        {
            "text": "This is done by generating alternative pdfs using different values for the nuisance parameter of interest. ",
            "section": "Including systematic uncertainties",
            "paragraph_rank": 90,
            "section_rank": 34
        },
        {
            "text": "To give one important example, we generate pdfs with narrower or wider lepton response functions to parameterize our knowledge of the lepton momentum resolution. ",
            "section": "Including systematic uncertainties",
            "paragraph_rank": 90,
            "section_rank": 34
        },
        {
            "text": "If we define the nominal pdf to be P 0 (O) and the alternative as P 1 (O), one can parameterize the dependence of the likelihood on a nuisance parameter n by interpolating between the nominal and the alternative pdfs as follows:",
            "section": "Including systematic uncertainties",
            "paragraph_rank": 90,
            "section_rank": 34
        },
        {
            "text": "It is instructive to observe that, for all values of n, the normalization of the total pdf stays the same. ",
            "section": "Including systematic uncertainties",
            "paragraph_rank": 91,
            "section_rank": 34
        },
        {
            "text": "Given the asymmetric nature of many systematic uncertainties, it is more appropriate to generate many \"check-points\" along the axis of n and to do piece-wise interpolation without the need of worrying about the normalization. ",
            "section": "Including systematic uncertainties",
            "paragraph_rank": 91,
            "section_rank": 34
        },
        {
            "text": "Non-central values of n are a priori disfavored, therefore one can impose a prior on top of the interpolated likelihood: P(O|n) = P(O|n)G(n), (5.13) where G(n) is typically a Gaussian centered at the central value of n. ",
            "section": "Including systematic uncertainties",
            "paragraph_rank": 91,
            "section_rank": 34,
            "ref_spans": [
                {
                    "start": 142,
                    "end": 148,
                    "type": "bibr",
                    "text": "(5.13)"
                }
            ]
        },
        {
            "text": "In the case of multiple systematic uncertainties, one can replace n by a vector of nuisance parameters n, and the prior G(n) by G( n). ",
            "section": "Including systematic uncertainties",
            "paragraph_rank": 91,
            "section_rank": 34
        },
        {
            "text": "In general G( n) is a multivariate Gaussian-like function with primary axes which are some combination of different nuisance parameter directions. ",
            "section": "Including systematic uncertainties",
            "paragraph_rank": 91,
            "section_rank": 34
        },
        {
            "text": "However one can carefully define the nuisance parameters such that correlations between them are negligible. ",
            "section": "Including systematic uncertainties",
            "paragraph_rank": 91,
            "section_rank": 34
        },
        {
            "text": "In this limit G( n) can be written as the product of many Gaussian-like functions. ",
            "section": "Including systematic uncertainties",
            "paragraph_rank": 91,
            "section_rank": 34
        },
        {
            "text": "This procedure for including systematic uncertainties has been implemented in a recent CMS analysis utilizing our framework [38,39] and further details can be found in [41].",
            "section": "Including systematic uncertainties",
            "paragraph_rank": 91,
            "section_rank": 34,
            "ref_spans": [
                {
                    "start": 124,
                    "end": 128,
                    "type": "bibr",
                    "ref_id": "b38",
                    "text": "[38,"
                },
                {
                    "start": 128,
                    "end": 131,
                    "type": "bibr",
                    "ref_id": "b39",
                    "text": "39]"
                },
                {
                    "start": 168,
                    "end": 172,
                    "type": "bibr",
                    "ref_id": "b41",
                    "text": "[41]"
                }
            ]
        },
        {
            "text": "Comments on parameter extraction",
            "section_rank": 35
        },
        {
            "text": "As discussed in [13,17,32] the advantage of analytic approaches is that the likelihood can be maximized for a large set of parameters in the most optimal way without losing information. ",
            "section": "Comments on parameter extraction",
            "paragraph_rank": 92,
            "section_rank": 35,
            "ref_spans": [
                {
                    "start": 16,
                    "end": 20,
                    "type": "bibr",
                    "ref_id": "b12",
                    "text": "[13,"
                },
                {
                    "start": 20,
                    "end": 23,
                    "type": "bibr",
                    "ref_id": "b16",
                    "text": "17,"
                },
                {
                    "start": 23,
                    "end": 26,
                    "type": "bibr",
                    "ref_id": "b32",
                    "text": "32]"
                }
            ]
        },
        {
            "text": "Our framework allows for the 'analytic' nature of these approaches to be maintained",
            "section": "Comments on parameter extraction",
            "paragraph_rank": 92,
            "section_rank": 35
        },
        {
            "text": "JHEP01(2015)125",
            "section_rank": 36
        },
        {
            "text": "at detector level giving us the ability to perform fast and accurate multi-parameter fits for lagrangian parameters directly from the data. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 93,
            "section_rank": 36
        },
        {
            "text": "This is possible once the convolution in eq. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 93,
            "section_rank": 36
        },
        {
            "text": "(2.1) is performed and after normalization of the signal and background pdfs allowing us to obtain the full detector level likelihood L( A) for a particular dataset. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 93,
            "section_rank": 36
        },
        {
            "text": "With the likelihood in hand a maximization procedure to find the global maximum can be performed to obtain the value of the parameters for which the likelihood is maximized. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 93,
            "section_rank": 36
        },
        {
            "text": "For this task we have incorporated the well established MINUIT [61] function minimization/maximization code into our framework. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 93,
            "section_rank": 36,
            "ref_spans": [
                {
                    "start": 63,
                    "end": 67,
                    "type": "bibr",
                    "ref_id": "b61",
                    "text": "[61]"
                }
            ],
            "entity_spans": [
                {
                    "start": 56,
                    "end": 63,
                    "type": "software",
                    "rawForm": "MINUIT",
                    "resp": "service",
                    "id": "software-simple-s2"
                }
            ]
        },
        {
            "text": "We find excellent rates of convergence and a high degree of stability in locating the global maximum of the likelihood as well as accurate extraction of the parameters as demonstrated in [38][39][40][41] where more details can be found. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 93,
            "section_rank": 36,
            "ref_spans": [
                {
                    "start": 187,
                    "end": 191,
                    "type": "bibr",
                    "ref_id": "b38",
                    "text": "[38]"
                },
                {
                    "start": 191,
                    "end": 195,
                    "type": "bibr",
                    "ref_id": "b39",
                    "text": "[39]"
                },
                {
                    "start": 195,
                    "end": 199,
                    "type": "bibr",
                    "ref_id": "b40",
                    "text": "[40]"
                },
                {
                    "start": 199,
                    "end": 203,
                    "type": "bibr",
                    "ref_id": "b41",
                    "text": "[41]"
                }
            ]
        },
        {
            "text": "One important feature of the procedure is that the computationally intensive component of evaluating the likelihood only needs to be done for the events in the final dataset used in the fit for a given experiment. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 93,
            "section_rank": 36
        },
        {
            "text": "Therefore the computationally expensive pieces can be calculated on the computing grid prior to the analysis of the data, and the fit for parameter extraction itself is then completed within a few seconds. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 93,
            "section_rank": 36
        },
        {
            "text": "This allows for a great deal of flexibility, including testing alternative parameterizations, when fitting the undetermined parameters. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 93,
            "section_rank": 36
        },
        {
            "text": "Many examples of the types of parameter extractions which can be done within our framework, both at generator and at detector level, can be found in [35,[37][38][39]41].",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 93,
            "section_rank": 36,
            "ref_spans": [
                {
                    "start": 149,
                    "end": 153,
                    "type": "bibr",
                    "ref_id": "b35",
                    "text": "[35,"
                },
                {
                    "start": 153,
                    "end": 157,
                    "type": "bibr",
                    "ref_id": "b37",
                    "text": "[37]"
                },
                {
                    "start": 157,
                    "end": 161,
                    "type": "bibr",
                    "ref_id": "b38",
                    "text": "[38]"
                },
                {
                    "start": 161,
                    "end": 165,
                    "type": "bibr",
                    "ref_id": "b39",
                    "text": "[39]"
                },
                {
                    "start": 165,
                    "end": 168,
                    "type": "bibr",
                    "ref_id": "b41",
                    "text": "41]"
                }
            ]
        },
        {
            "text": "Summary and conclusions",
            "section_rank": 37
        },
        {
            "text": "In this study we build upon an earlier study [35] to construct a comprehensive analysis framework aimed at extracting as much information as possible from the Higgs golden channel. ",
            "section": "Summary and conclusions",
            "paragraph_rank": 94,
            "section_rank": 37,
            "ref_spans": [
                {
                    "start": 45,
                    "end": 49,
                    "type": "bibr",
                    "ref_id": "b35",
                    "text": "[35]"
                }
            ]
        },
        {
            "text": "Our framework is based on a maximum likelihood method constructed from analytic expressions of the fully differential cross sections for the h \u2192 4 decay as well as the dominant irreducible qq \u2192 4 background which were computed in [19,35]. ",
            "section": "Summary and conclusions",
            "paragraph_rank": 94,
            "section_rank": 37,
            "ref_spans": [
                {
                    "start": 230,
                    "end": 234,
                    "type": "bibr",
                    "ref_id": "b18",
                    "text": "[19,"
                },
                {
                    "start": 234,
                    "end": 237,
                    "type": "bibr",
                    "ref_id": "b35",
                    "text": "35]"
                }
            ]
        },
        {
            "text": "As our main result, we have constructed the full 12-dimensional detector level likelihood utilizing all observables available in the golden channel. ",
            "section": "Summary and conclusions",
            "paragraph_rank": 94,
            "section_rank": 37
        },
        {
            "text": "This allows us to perform parameter extraction of the various possible Higgs couplings, including general CP odd/even admixtures and any possible phases.",
            "section": "Summary and conclusions",
            "paragraph_rank": 94,
            "section_rank": 37
        },
        {
            "text": "The detector-level likelihood is obtained by the explicit convolution of a transfer function, encapsulating the relevant detector effects, with the generator-level probability density formed out of the signal and background differential cross sections. ",
            "section": "Summary and conclusions",
            "paragraph_rank": 95,
            "section_rank": 37
        },
        {
            "text": "After performing this 12-dimensional convolution integral and its normalization we obtain a probability density function from which we construct an un-binned detector-level likelihood which is a continuous function of the effective couplings.",
            "section": "Summary and conclusions",
            "paragraph_rank": 95,
            "section_rank": 37
        },
        {
            "text": "In summary we have given broad overview of a framework optimized for extracting Higgs couplings in the golden channel. ",
            "section": "Summary and conclusions",
            "paragraph_rank": 96,
            "section_rank": 37
        },
        {
            "text": "We have sketched how the convolution is performed and shown various validations as well as discussed the principles and theoretical basis of the framework. ",
            "section": "Summary and conclusions",
            "paragraph_rank": 96,
            "section_rank": 37
        },
        {
            "text": "Many of the technical details as well as results using our framework can be found in [19,35,37,38,40,41]. ",
            "section": "Summary and conclusions",
            "paragraph_rank": 96,
            "section_rank": 37,
            "ref_spans": [
                {
                    "start": 85,
                    "end": 89,
                    "type": "bibr",
                    "ref_id": "b18",
                    "text": "[19,"
                },
                {
                    "start": 89,
                    "end": 92,
                    "type": "bibr",
                    "ref_id": "b35",
                    "text": "35,"
                },
                {
                    "start": 92,
                    "end": 95,
                    "type": "bibr",
                    "ref_id": "b37",
                    "text": "37,"
                },
                {
                    "start": 95,
                    "end": 98,
                    "type": "bibr",
                    "ref_id": "b38",
                    "text": "38,"
                },
                {
                    "start": 98,
                    "end": 101,
                    "type": "bibr",
                    "ref_id": "b40",
                    "text": "40,"
                },
                {
                    "start": 101,
                    "end": 104,
                    "type": "bibr",
                    "ref_id": "b41",
                    "text": "41]"
                }
            ]
        },
        {
            "text": "This framework has already proved useful in a recent CMS analysis [38,39] and can be used in the future in a variety of ways to study Higgs couplings in the golden channel using data obtained at the LHC and other future colliders.",
            "section": "Summary and conclusions",
            "paragraph_rank": 96,
            "section_rank": 37,
            "ref_spans": [
                {
                    "start": 66,
                    "end": 70,
                    "type": "bibr",
                    "ref_id": "b38",
                    "text": "[38,"
                },
                {
                    "start": 70,
                    "end": 73,
                    "type": "bibr",
                    "ref_id": "b39",
                    "text": "39]"
                }
            ]
        },
        {
            "text": "7 )",
            "section_rank": 38
        },
        {
            "text": "Figure 2 .",
            "section_rank": 39
        },
        {
            "text": "Figure 2. ",
            "section": "Figure 2 .",
            "paragraph_rank": 98,
            "section_rank": 39
        },
        {
            "text": "Projections of the Y , | p T |, \u221a\u015d \u2261 M 4 and cos \u0398 (see section 3.1 for definitions) spectra showing validation of the convolution described in eq. ",
            "section": "Figure 2 .",
            "paragraph_rank": 98,
            "section_rank": 39
        },
        {
            "text": "(4.1) for the background. ",
            "section": "Figure 2 .",
            "paragraph_rank": 98,
            "section_rank": 39
        },
        {
            "text": "In blue we show the 'boosted' Madgraph sample with acceptance cuts and detector smearing applied while in red we show projections from our differential cross section after the convolution integration.",
            "section": "Figure 2 .",
            "paragraph_rank": 98,
            "section_rank": 39
        },
        {
            "text": "Figure 3 .",
            "section_rank": 40
        },
        {
            "text": "Figure 3. ",
            "section": "Figure 3 .",
            "paragraph_rank": 99,
            "section_rank": 40
        },
        {
            "text": "Projections of the M 1 , M 2 , cos \u03b8 1 , cos \u03b8 2 , \u03a6 and \u03a6 1 (see section 3.1 for definitions) spectra showing validation of the convolution described in eq. ",
            "section": "Figure 3 .",
            "paragraph_rank": 99,
            "section_rank": 40
        },
        {
            "text": "(4.1) for the background. ",
            "section": "Figure 3 .",
            "paragraph_rank": 99,
            "section_rank": 40
        },
        {
            "text": "In blue we show the 'boosted' Madgraph sample with acceptance cuts and detector smearing applied while in red we show projections from our differential cross section after the convolution integration.",
            "section": "Figure 3 .",
            "paragraph_rank": 99,
            "section_rank": 40
        },
        {
            "text": "Figure 4 .",
            "section_rank": 41
        },
        {
            "text": "Figure 5 .",
            "section_rank": 41
        },
        {
            "text": "Figure 4. ",
            "section": "Figure 4 .Figure 5 .",
            "paragraph_rank": 100,
            "section_rank": 41
        },
        {
            "text": "Projections of the Y , | p T |, \u221a\u015d \u2261 M 4 and cos \u0398 (see section 3.1 for definitions) spectra showing validation of the convolution described in eq. ",
            "section": "Figure 4 .Figure 5 .",
            "paragraph_rank": 100,
            "section_rank": 41
        },
        {
            "text": "(4.4) for the tree level SM signal. ",
            "section": "Figure 4 .Figure 5 .",
            "paragraph_rank": 100,
            "section_rank": 41
        },
        {
            "text": "In blue we show the 'boosted' Madgraph sample with acceptance cuts and detector smearing applied while in red we show projections from our differential cross section after the convolution integration.",
            "section": "Figure 4 .Figure 5 .",
            "paragraph_rank": 100,
            "section_rank": 41
        },
        {
            "text": "Though we will not discuss it explicitly here, we are also able to extend our framework to the h \u2192 \u03b3\u03b3 and h \u2192 2 \u03b3 channels.",
            "section": "Figure 4 .Figure 5 .",
            "paragraph_rank": 101,
            "section_rank": 41
        },
        {
            "text": "This lagrangian has been implemented[55] into the FeynRules/Madgraph[56,57] framework for validation purposes.",
            "section": "Figure 4 .Figure 5 .",
            "paragraph_rank": 102,
            "section_rank": 41,
            "ref_spans": [
                {
                    "start": 36,
                    "end": 40,
                    "type": "bibr",
                    "ref_id": "b55",
                    "text": "[55]"
                },
                {
                    "start": 68,
                    "end": 72,
                    "type": "bibr",
                    "ref_id": "b56",
                    "text": "[56,"
                },
                {
                    "start": 72,
                    "end": 75,
                    "type": "bibr",
                    "ref_id": "b57",
                    "text": "57]"
                }
            ]
        },
        {
            "text": "Acknowledgments",
            "section_rank": 43
        },
        {
            "text": "The authors are grateful to Artur Apresyan, Michalis Bachtis, Adam   Open Access. ",
            "section": "Acknowledgments",
            "paragraph_rank": 103,
            "section_rank": 43
        },
        {
            "text": "This article is distributed under the terms of the Creative Commons Attribution License (CC-BY 4.0), which permits any use, distribution and reproduction in any medium, provided the original author(s) and source are credited.",
            "section": "Acknowledgments",
            "paragraph_rank": 103,
            "section_rank": 43
        },
        {
            "text": "JHEP01(2015)125",
            "section_rank": 45
        },
        {
            "text": "This gives finally for the normalized signal pdf,",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 104,
            "section_rank": 45
        },
        {
            "text": ". (5.8) Since each N ij nm is computed, one does not need to compute the normalization each time a new hypothesis for A is constructed. The procedure outlined here also works on more general polynomial functions of the parameters A which one finds after expanding potentially momentum-dependent form factors in powers of momenta. See [40] for this more general discussion.",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 105,
            "section_rank": 45,
            "ref_spans": [
                {
                    "start": 2,
                    "end": 7,
                    "type": "bibr",
                    "text": "(5.8)"
                },
                {
                    "start": 334,
                    "end": 338,
                    "type": "bibr",
                    "ref_id": "b40",
                    "text": "[40]"
                }
            ]
        },
        {
            "text": "Note also that if we take the Higgs mass as a fixed input and only fit for ratios of parameters and not their overall normalization, we do not need the absolute normalization of the differential cross sections. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 106,
            "section_rank": 45
        },
        {
            "text": "It thus suffices to have the relative normalization between the different components correct when performing the maximization. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 106,
            "section_rank": 45
        },
        {
            "text": "This fact greatly reduces the computational complexity. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 106,
            "section_rank": 45
        },
        {
            "text": "Instead of propagating the full normalization and aligning units correctly so that when one integrates over all 8 dimensions unity is obtained, it is sufficient to do a Monte Carlo integration using a fixed sample size in a consistent and sufficiently large range. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 106,
            "section_rank": 45
        },
        {
            "text": "The meaning of the log likelihood difference remains unchanged with this construction. ",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 106,
            "section_rank": 45
        },
        {
            "text": "Further details of the normalization procedure for both signal and background are found in [40,41].",
            "section": "JHEP01(2015)125",
            "paragraph_rank": 106,
            "section_rank": 45,
            "ref_spans": [
                {
                    "start": 91,
                    "end": 95,
                    "type": "bibr",
                    "ref_id": "b40",
                    "text": "[40,"
                },
                {
                    "start": 95,
                    "end": 98,
                    "type": "bibr",
                    "ref_id": "b41",
                    "text": "41]"
                }
            ]
        },
        {
            "text": "Signal plus background pdf and final likelihood",
            "section_rank": 46
        },
        {
            "text": "With eq. ",
            "section": "Signal plus background pdf and final likelihood",
            "paragraph_rank": 107,
            "section_rank": 46
        },
        {
            "text": "(5.3) and eq. ",
            "section": "Signal plus background pdf and final likelihood",
            "paragraph_rank": 107,
            "section_rank": 46
        },
        {
            "text": "(5.8) in hand we can now build the signal plus background pdf from which the total likelihood will be constructed. ",
            "section": "Signal plus background pdf and final likelihood",
            "paragraph_rank": 107,
            "section_rank": 46
        },
        {
            "text": "The signal plus background pdf can be written as,",
            "section": "Signal plus background pdf and final likelihood",
            "paragraph_rank": 107,
            "section_rank": 46
        },
        {
            "text": "where O \u2261 (\u015d, M 1 , M 2 , \u2126) is our final set of observables to be used in the construction of the likelihood and F i B is the background fraction for a particular component, each of which must also be extracted.",
            "section": "Signal plus background pdf and final likelihood",
            "paragraph_rank": 108,
            "section_rank": 46
        },
        {
            "text": "The sum over background components is given by,",
            "section": "Signal plus background pdf and final likelihood",
            "paragraph_rank": 109,
            "section_rank": 46
        },
        {
            "text": "where P qq B (O) is the dominant qq \u2192 4 component and is obtained via the convolution integral in eq. ",
            "section": "Signal plus background pdf and final likelihood",
            "paragraph_rank": 110,
            "section_rank": 46
        },
        {
            "text": "(2.1). ",
            "section": "Signal plus background pdf and final likelihood",
            "paragraph_rank": 110,
            "section_rank": 46
        },
        {
            "text": "The sub-dominant gg \u2192 4 and Z + X components, given by P gg B (O) and P Z+X B (O) respectively, must be obtained via the linearly interpolated 'look-up' tables from large Monte Carlo samples as discussed in section 3.6.",
            "section": "Signal plus background pdf and final likelihood",
            "paragraph_rank": 110,
            "section_rank": 46
        },
        {
            "text": "We can now write the likelihood of obtaining a particular dataset containing N events as, ",
            "section": "Signal plus background pdf and final likelihood",
            "paragraph_rank": 111,
            "section_rank": 46
        }
    ]
}