{
    "id": "dde861f54b",
    "abstract": [],
    "body_text": [
        {
            "text": "Statistical models for nucleotide or amino acid mutations and substitutions, and the algorithms for computing with them, are fundamental to the study of molecular evolution and biology. ",
            "section": "Introduction"
        },
        {
            "text": "As we widen our focus from the evolution of genes to the evolution of genomes, individuals, and populations, a whole new class of modeling challenges present themselves. ",
            "section": "Introduction"
        },
        {
            "text": "These include the development of realistic quantitative models for traits which vary over a continuous range of values (O'Meara 2012). ",
            "section": "Introduction"
        },
        {
            "text": "Of course, the usefulness of any new model is contingent on the tools available to compute with them. ",
            "section": "Introduction"
        },
        {
            "text": "The main contribution of this article is to show how, by combining ideas from statistical phylogenetics and numerical mathematics, we can compute efficiently with a far larger range of evolutionary models.",
            "section": "Introduction"
        },
        {
            "text": "The algorithms we develop are for computation of the likelihood, that is the probability of the data given the phylogeny, evolutionary model and parameters. ",
            "section": "Introduction"
        },
        {
            "text": "If we are working with an evolutionary model with only a small (finite) number of states, then likelihoods can be computed using the dynamic programming algorithm of Felsenstein (1981a). ",
            "section": "Introduction",
            "ref_spans": [
                {
                    "start": 166,
                    "end": 185,
                    "type": "bibr",
                    "ref_id": "b7",
                    "text": "Felsenstein (1981a)"
                }
            ]
        },
        {
            "text": "We will show how to extend this algorithm to also compute likelihoods for (essentially) arbitrary continuous trait models.",
            "section": "Introduction"
        },
        {
            "text": "There is already a wide range of evolutionary phenomena that are studied using continuous trait models. ",
            "section": "Introduction"
        },
        {
            "text": "Much of comparative genomics relies on implicit or explicit models for the evolution of morphology (Stevens 1991;Felsenstein 2002;Ronquist 2004;Harmon et al. 2010; O'Meara 2012), many of which make gross simplifying assumptions about how traits vary over time. ",
            "section": "Introduction",
            "ref_spans": [
                {
                    "start": 99,
                    "end": 113,
                    "type": "bibr",
                    "ref_id": "b34",
                    "text": "(Stevens 1991;"
                },
                {
                    "start": 113,
                    "end": 130,
                    "type": "bibr",
                    "ref_id": "b10",
                    "text": "Felsenstein 2002;"
                },
                {
                    "start": 130,
                    "end": 144,
                    "type": "bibr",
                    "ref_id": "b30",
                    "text": "Ronquist 2004;"
                },
                {
                    "start": 144,
                    "end": 162,
                    "type": "bibr",
                    "ref_id": "b17",
                    "text": "Harmon et al. 2010"
                }
            ]
        },
        {
            "text": "Continuous evolutionary models have been used in comparative transcriptomics to study heritable aspects of gene expression levels (Khaitovich et al. 2005(Khaitovich et al. , 2006, an area with exceptional promise given recent improvements in accuracy and the ability to sample in situ (Voelckel et al. 2002).",
            "section": "Introduction",
            "ref_spans": [
                {
                    "start": 130,
                    "end": 153,
                    "type": "bibr",
                    "ref_id": "b20",
                    "text": "(Khaitovich et al. 2005"
                },
                {
                    "start": 153,
                    "end": 178,
                    "type": "bibr",
                    "ref_id": "b19",
                    "text": "(Khaitovich et al. , 2006"
                },
                {
                    "start": 285,
                    "end": 307,
                    "type": "bibr",
                    "text": "(Voelckel et al. 2002)"
                }
            ]
        },
        {
            "text": "Continuous trait models will be of growing importance in evolutionary studies of whole-genome single nucleotide polymorphism-databases. ",
            "section": "Introduction"
        },
        {
            "text": "Inference methods based on the coalescent such as SNAPP (Bryant et al. 2012) do not scale well as the number of individuals grows, while those based on continuous models of gene frequencies (Cavalli-Sforza and Edwards 1967;Felsenstein 1981b; Sir\u00e9 n et al. 2011) depend only on proportions of populations with each allele, so scale extremely well. ",
            "section": "Introduction",
            "ref_spans": [
                {
                    "start": 56,
                    "end": 76,
                    "type": "bibr",
                    "ref_id": "b0",
                    "text": "(Bryant et al. 2012)"
                },
                {
                    "start": 190,
                    "end": 223,
                    "type": "bibr",
                    "ref_id": "b1",
                    "text": "(Cavalli-Sforza and Edwards 1967;"
                },
                {
                    "start": 223,
                    "end": 240,
                    "type": "bibr",
                    "ref_id": "b8",
                    "text": "Felsenstein 1981b"
                }
            ],
            "entity_spans": [
                {
                    "type": "software",
                    "start": 50,
                    "end": 55,
                    "rawForm": "SNAPP",
                    "resp": "whitelist",
                    "id": "dde861f54b-software-simple-w0"
                }
            ]
        },
        {
            "text": "In addition, it is often easier to model the effect of selection on continuous gene frequency models than with the coalescent. ",
            "section": "Introduction"
        },
        {
            "text": "Continuous evolutionary models have also been applied successfully to the study of ancestral geography distributions (Lemey et al. 2010).",
            "section": "Introduction",
            "ref_spans": [
                {
                    "start": 117,
                    "end": 136,
                    "type": "bibr",
                    "ref_id": "b25",
                    "text": "(Lemey et al. 2010)"
                }
            ]
        },
        {
            "text": "Our interest is in developing techniques used to compute with these models, and to expand the range of models we can work with. ",
            "section": "Introduction"
        },
        {
            "text": "Early work of Felsenstein (1968Felsenstein ( , 1973, revisited by Freckleton (2012) and FitzJohn (2012), demonstrated that if traits are evolving according to Brownian motion then we can compute likelihoods quickly and (up to numerical precision) exactly. ",
            "section": "Introduction",
            "ref_spans": [
                {
                    "start": 14,
                    "end": 31,
                    "type": "bibr",
                    "ref_id": "b5",
                    "text": "Felsenstein (1968"
                },
                {
                    "start": 31,
                    "end": 51,
                    "type": "bibr",
                    "ref_id": "b6",
                    "text": "Felsenstein ( , 1973"
                },
                {
                    "start": 66,
                    "end": 83,
                    "type": "bibr",
                    "ref_id": "b15",
                    "text": "Freckleton (2012)"
                },
                {
                    "start": 88,
                    "end": 103,
                    "type": "bibr",
                    "ref_id": "b14",
                    "text": "FitzJohn (2012)"
                }
            ]
        },
        {
            "text": "Felsenstein's approach extends to other Gaussian processes, notably the Ornstein-Uhlenbeck (OU) process (Lande 1976;Felsenstein 1988;Hansen 1997), and for several decades, Gaussian models were used almost exclusively to model the evolution of quantitative traits. ",
            "section": "Introduction",
            "ref_spans": [
                {
                    "start": 104,
                    "end": 116,
                    "type": "bibr",
                    "ref_id": "b22",
                    "text": "(Lande 1976;"
                },
                {
                    "start": 116,
                    "end": 133,
                    "type": "bibr",
                    "ref_id": "b9",
                    "text": "Felsenstein 1988;"
                },
                {
                    "start": 133,
                    "end": 145,
                    "type": "bibr",
                    "ref_id": "b16",
                    "text": "Hansen 1997)"
                }
            ]
        },
        {
            "text": "Ho and An\u00e9 (2014) used clever algebraic techniques to develop an alternative algorithm for computing the likelihood and related quantities. ",
            "section": "Introduction",
            "ref_spans": [
                {
                    "start": 0,
                    "end": 17,
                    "type": "bibr",
                    "ref_id": "b18",
                    "text": "Ho and An\u00e9 (2014)"
                }
            ]
        },
        {
            "text": "They survey several other models which can be handled using the same approach.",
            "section": "Introduction"
        },
        {
            "text": "These methods are very efficient, and when they can be used, they should be used. ",
            "section": "Introduction"
        },
        {
            "text": "The drawback of these methods is that they are fundamentally restricted to models which are Gaussian processes or transforms of Gaussian processes, where the computational bottleneck lies in the computation of a quadratic form involving the covariance matrix of Ho and An\u00e9 (2014). ",
            "section": "Introduction",
            "ref_spans": [
                {
                    "start": 262,
                    "end": 279,
                    "type": "bibr",
                    "ref_id": "b18",
                    "text": "Ho and An\u00e9 (2014)"
                }
            ]
        },
        {
            "text": "Many evolutionary models cannot be handled within this framework (e.g., Ronquist 2004;Landis et al. 2013). ",
            "section": "Introduction",
            "ref_spans": [
                {
                    "start": 72,
                    "end": 86,
                    "type": "bibr",
                    "ref_id": "b30",
                    "text": "Ronquist 2004;"
                },
                {
                    "start": 86,
                    "end": 105,
                    "type": "bibr",
                    "ref_id": "b23",
                    "text": "Landis et al. 2013)"
                }
            ]
        },
        {
            "text": "Some of the properties of Gaussian processes are quite restrictive: Gaussian processes have single modes, so can only model adaptive landscapes with single peaks; Brownian motion has independent increments, so the rate of change is independent of the value of a trait. ",
            "section": "Introduction"
        },
        {
            "text": "The standard strategy for computing with non-Gaussian models is to resort to Monte-Carlo strategies. ",
            "section": "Introduction"
        },
        {
            "text": "Even when we are working with a model satisfying the assumptions of Ho and An\u00e9 (2014), the algorithms they describe do not give an efficient method for integrating over sets of trait values at the tips, as in the threshold models we discuss below.",
            "section": "Introduction",
            "ref_spans": [
                {
                    "start": 68,
                    "end": 85,
                    "type": "bibr",
                    "ref_id": "b18",
                    "text": "Ho and An\u00e9 (2014)"
                }
            ]
        },
        {
            "text": "Computing the probability of quantitative character evolution may be framed as a numerical integration (quadrature) problem. ",
            "section": "Introduction"
        },
        {
            "text": "For most models, if we know the value of the trait at each ancestral node in the phylogeny, we can quickly compute the various transition probabilities. ",
            "section": "Introduction"
        },
        {
            "text": "Because we do not usually know these ancestral trait values we integrate them out. ",
            "section": "Introduction"
        },
        {
            "text": "This is a multidimensional integration problem with one dimension for each ancestral node (or two dimensions for each node if we are modeling covarying traits) see Felsenstein (2004).",
            "section": "Introduction",
            "ref_spans": [
                {
                    "start": 164,
                    "end": 182,
                    "type": "bibr",
                    "text": "Felsenstein (2004)"
                }
            ]
        },
        {
            "text": "Methods for estimating or approximating integrals are usually judged by their \"rate of convergence\": how quickly the error of approximation decreases as the amount of work (function evaluations) increases. ",
            "section": "Introduction"
        },
        {
            "text": "Consider the problem of computing a one-dimensional integral",
            "section": "Introduction"
        },
        {
            "text": "where f is a \"nice\" function with continuous and bounded derivatives. ",
            "section": "Introduction"
        },
        {
            "text": "Simpson's rule, a simple textbook method reviewed below, can be shown to have an O\u00f0N \u00c04 \u00de rate of convergence, meaning that, asymptotically in N, evaluating ten times more points reduces the error by a factor of 10 4 . ",
            "section": "Introduction"
        },
        {
            "text": "In contrast, a standard Monte Carlo method has a rate of convergence of O\u00f0N \u00c0 1 2 \u00de, meaning that evaluating ten times more points will only reduce the error by a factor of around 3. ",
            "section": "Introduction"
        },
        {
            "text": "For this reason, numerical analysis texts often refer to Monte Carlo approaches as \"methods of last resort.\"",
            "section": "Introduction"
        },
        {
            "text": "Despite this apparently lacklustre performance guarantee, Monte Carlo methods have revolutionized phylogenetics in general and the analysis of quantitative characters in particular. ",
            "section": "Introduction"
        },
        {
            "text": "The reason is their partial immunity to the curse of dimensionality. ",
            "section": "Introduction"
        },
        {
            "text": "Methods like Simpson's rule are not practical for a high number of dimensions as the asymptotic convergence rate, quoted above, is only achieved for an infeasibly large number of function evaluations N. The effective convergence rate for small N can be very poor, and typically worse than Monte Carlo. ",
            "section": "Introduction"
        },
        {
            "text": "In contrast, there are Monte Carlo approaches which achieve close to O\u00f0N \u00c0 1 2 \u00de convergence irrespective of dimension. ",
            "section": "Introduction"
        },
        {
            "text": "This has been critical when computing the likelihoods of complex evolutionary models with as many dimensions as there are nodes in the phylogeny.",
            "section": "Introduction"
        },
        {
            "text": "The main contribution of our article is to demonstrate how to efficiently and accurately compute likelihoods on a phylogeny using a sequence of one-dimensional integrations. ",
            "section": "Introduction"
        },
        {
            "text": "We obtain a fast algorithm with convergence guarantees that far exceed what can be obtained by Monte Carlo integration. ",
            "section": "Introduction"
        },
        {
            "text": "Our approach combines two standard tools: classical numerical integrators and Felsenstein's pruning algorithm for discrete characters (Felsenstein 1981a). ",
            "section": "Introduction",
            "ref_spans": [
                {
                    "start": 134,
                    "end": 153,
                    "type": "bibr",
                    "ref_id": "b7",
                    "text": "(Felsenstein 1981a)"
                }
            ]
        },
        {
            "text": "Indeed, the only real difference between our approach and Felsenstein's discrete character algorithm is that we use numerical integration techniques to integrate states at ancestral nodes, instead of just carrying out a summation.",
            "section": "Introduction"
        },
        {
            "text": "The running time of the algorithm is O\u00f0N 2 n\u00de, where N is the number of points used in the numerical integration at each node and n is the number of taxa (leaves) in the tree. ",
            "section": "Introduction"
        },
        {
            "text": "Using Simpson's method, we obtain a convergence rate of O\u00f0nN \u00c04 \u00de, meaning that if we increase N by a factor of 10, we will obtain an estimate which is accurate to four more decimal places.",
            "section": "Introduction"
        },
        {
            "text": "To illustrate the application of our general framework, we develop an efficient algorithm for computing the likelihood of a tree under the threshold model of Wright (1934) and Felsenstein (2005Felsenstein ( , 2012. ",
            "section": "Introduction",
            "ref_spans": [
                {
                    "start": 158,
                    "end": 171,
                    "type": "bibr",
                    "ref_id": "b37",
                    "text": "Wright (1934)"
                },
                {
                    "start": 176,
                    "end": 193,
                    "type": "bibr",
                    "ref_id": "b11",
                    "text": "Felsenstein (2005"
                },
                {
                    "start": 193,
                    "end": 213,
                    "type": "bibr",
                    "ref_id": "b12",
                    "text": "Felsenstein ( , 2012"
                }
            ]
        },
        {
            "text": "We also show how to infer marginal trait densities at ancestral nodes. ",
            "section": "Introduction"
        },
        {
            "text": "We have implemented these algorithms and used them to study evolution of extrafloral nectaries (EFN) on an 839-taxon phylogeny of Marazzi et al. (2012). ",
            "section": "Introduction",
            "ref_spans": [
                {
                    "start": 130,
                    "end": 151,
                    "type": "bibr",
                    "ref_id": "b27",
                    "text": "Marazzi et al. (2012)"
                }
            ]
        },
        {
            "text": "MATLAB code for computing the threshold likelihood has been posted on MATLAB Central and complete MATLAB code for all analyses and simulations can be found in supplementary material, Supplementary Material online.",
            "section": "Introduction",
            "entity_spans": [
                {
                    "type": "software",
                    "start": 0,
                    "end": 6,
                    "rawForm": "MATLAB",
                    "resp": "whitelist",
                    "id": "dde861f54b-software-simple-w1"
                },
                {
                    "type": "software",
                    "start": 70,
                    "end": 76,
                    "rawForm": "MATLAB",
                    "resp": "whitelist",
                    "id": "dde861f54b-software-simple-w2"
                },
                {
                    "type": "software",
                    "start": 98,
                    "end": 104,
                    "rawForm": "MATLAB",
                    "resp": "whitelist",
                    "id": "dde861f54b-software-simple-w3"
                }
            ]
        },
        {
            "text": "The combination of numerical integrators and the pruning algorithm opens up a large range of potential models and approaches which we have only just begun to explore. ",
            "section": "Introduction"
        },
        {
            "text": "It may well be that Gaussian type models provide good approximations in many contexts, however the extent to which this is true will be unknown until we have computational tools for handling richer models.",
            "section": "Introduction"
        },
        {
            "text": "Phylogenetic models for continuous trait evolution, like those for discrete traits, are specified by the density of trait values at the root and the transition densities along the branches. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "We use f \u00f0x r jy r \u00de to denote the density for the trait value at the root, where r is a set of relevant model parameters. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "We use f \u00f0x i jx j ; y i \u00de to denote the transitional density for the value at node i, conditional on the trait value at its parent node j. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "Here, i represents a bundle of parameters related to node i such as branch length, population size, and mutation rate. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "All of these parameters can vary throughout the tree.",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "To see how the model works, consider how continuous traits might be simulated. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "A state X r is sampled from the root density f \u00f0X r jy r \u00de. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "We now proceed through the phylogeny from the root to the tips, each time visiting a node only after its parent has already been visited. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "For each node i, we generate the value at that node from the density f \u00f0X i jx j ; y v \u00de, where x j is the simulated trait value at node j, the parent of node i. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "In this way, we will eventually generate trait values for the tips.",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "We use X 1 , . ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": ". ., X n to denote the random trait values at the tips and X n\u00fe1 ; . . . ; X 2n\u00c01 to denote the random trait values at the internal nodes, ordered so that children come before parents. Hence, X 2n\u00c01 is the state assigned to the root. Let E\u00f0T \u00de \u00bc f\u00f0i; j\u00de : node i is a child of node jg \u00f02\u00de denote the set of branches in the tree. The joint density for all trait values, observed and ancestral, is given by multiplying the root density with all of the transition densities",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "The probability of the observed trait values x 1 ; . . . ; x n is now determined by integrating out all of the ancestral trait values:",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "In these integrals, the bounds of integration will vary according to the model. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "The oldest, and most widely used, continuous trait models assume that traits (or transformed gene frequencies) evolve like Brownian motion (Cavalli-Sforza and Edwards 1967;Felsenstein 1973). ",
            "section": "Models for Continuous Trait Evolution",
            "ref_spans": [
                {
                    "start": 139,
                    "end": 172,
                    "type": "bibr",
                    "ref_id": "b1",
                    "text": "(Cavalli-Sforza and Edwards 1967;"
                },
                {
                    "start": 172,
                    "end": 189,
                    "type": "bibr",
                    "ref_id": "b6",
                    "text": "Felsenstein 1973)"
                }
            ]
        },
        {
            "text": "For these models, the root density f \u00f0x r jy\u00de is Gaussian (normal) with mean 0 and unknown variance s 2 r . ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "The transition densities f \u00f0x i jx j ; y v \u00de are also Gaussian, with mean x j (the trait value of the parent) and variance proportional to branch length. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "Note that there are identifiability issues which arise with the inference of the root position under this model, necessitating a few tweaks in practice (see the discussion in Chapter 23 of Felsenstein 2004).",
            "section": "Models for Continuous Trait Evolution",
            "ref_spans": [
                {
                    "start": 189,
                    "end": 206,
                    "type": "bibr",
                    "text": "Felsenstein 2004)"
                }
            ]
        },
        {
            "text": "It can be shown that when the root density and transitional densities are all Gaussian, the joint density (4) is multivariate Gaussian. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "Furthermore, the covariance matrix for this density has a special structure which methods such as the pruning techniques of Felsenstein (1968Felsenstein ( , 1973, Freckleton (2012), and FitzJohn (2012) exploit, as does the top-down approach of Ho and An\u00e9 (2014). ",
            "section": "Models for Continuous Trait Evolution",
            "ref_spans": [
                {
                    "start": 124,
                    "end": 141,
                    "type": "bibr",
                    "ref_id": "b5",
                    "text": "Felsenstein (1968"
                },
                {
                    "start": 141,
                    "end": 161,
                    "type": "bibr",
                    "ref_id": "b6",
                    "text": "Felsenstein ( , 1973"
                },
                {
                    "start": 163,
                    "end": 180,
                    "type": "bibr",
                    "ref_id": "b15",
                    "text": "Freckleton (2012)"
                },
                {
                    "start": 244,
                    "end": 261,
                    "type": "bibr",
                    "ref_id": "b18",
                    "text": "Ho and An\u00e9 (2014)"
                }
            ]
        },
        {
            "text": "This general approach continues to work when Brownian motion is replaced by an OU process (Lande 1976;Felsenstein 1988;Hansen 1997), or indeed to many linear or generalized linear models.",
            "section": "Models for Continuous Trait Evolution",
            "ref_spans": [
                {
                    "start": 90,
                    "end": 102,
                    "type": "bibr",
                    "ref_id": "b22",
                    "text": "(Lande 1976;"
                },
                {
                    "start": 102,
                    "end": 119,
                    "type": "bibr",
                    "ref_id": "b9",
                    "text": "Felsenstein 1988;"
                },
                {
                    "start": 119,
                    "end": 131,
                    "type": "bibr",
                    "ref_id": "b16",
                    "text": "Hansen 1997)"
                }
            ]
        },
        {
            "text": "Gaussian models, and their relatives, are mathematically and computationally convenient, but rely on assumptions which are unrealistic and inappropriate in many contexts. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "Numerous researchers have implemented models which do not fit into the general Gaussian framework; most have resorted to Monte Carlo computation to carry out their analyses.",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "Landis et al. (2013) discuss a class of continuous trait models which are based on L\u00e9 vy processes and include jumps. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "At particular times, as governed by a Poisson process, the trait value jumps to a value drawn from a given density. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "Examples include a compound Poisson process with Gaussian jumps and a Variance Gamma model given by Brownian motion with time varying according to a gamma process. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "Both of these processes have analytical transition probabilities in some special cases. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "Lepage et al. (2006) use the Cox-Ingersoll-Ross (CIR) process to model rate variation across a phylogeny. ",
            "section": "Models for Continuous Trait Evolution",
            "ref_spans": [
                {
                    "start": 0,
                    "end": 20,
                    "type": "bibr",
                    "ref_id": "b26",
                    "text": "Lepage et al. (2006)"
                }
            ]
        },
        {
            "text": "Like the OU process (but unlike Brownian motion), the CIR process is ergodic. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "It has a stationary Gamma density which can be used for the root density. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "The transition density is a particular noncentral chi-squared density and the process only assumes positive values.",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "Kutsukake and Innan (2013) examine a family of compound Poisson models, focusing particularly on a model where the trait values make exponentially distributed jumps upwards or downwards. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "In the case that the rates of upward and downward jumps are the same, the model has jumps that follow a double exponential distribution. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "Kutsukake and Innan (2013) use approximate Bayesian computation to carry out inference.",
            "section": "Models for Continuous Trait Evolution",
            "ref_spans": [
                {
                    "start": 0,
                    "end": 26,
                    "type": "bibr",
                    "ref_id": "b21",
                    "text": "Kutsukake and Innan (2013)"
                }
            ]
        },
        {
            "text": "Sir\u00e9 n et al. 2011propose a simple and elegant model for gene frequencies whereby the root value is drawn from a Beta distribution and each transitional density is Beta with appropriately chosen parameters.",
            "section": "Models for Continuous Trait Evolution",
            "ref_spans": [
                {
                    "start": 14,
                    "end": 18,
                    "text": "2011"
                }
            ]
        },
        {
            "text": "Trait values at the tips are not always observed directly. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "A simple, but important, example of this is the threshold model of Wright (1934), explored by Felsenstein (2005). ",
            "section": "Models for Continuous Trait Evolution",
            "ref_spans": [
                {
                    "start": 67,
                    "end": 80,
                    "type": "bibr",
                    "ref_id": "b37",
                    "text": "Wright (1934)"
                },
                {
                    "start": 94,
                    "end": 112,
                    "type": "bibr",
                    "ref_id": "b11",
                    "text": "Felsenstein (2005)"
                }
            ]
        },
        {
            "text": "Under this model, the trait value itself is censored and we only observe whether or not the value is positive or negative. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "A similar complication arises when dealing with gene frequency data as we typically do not observe the actual gene frequency but instead a binomially distributed sample based on that frequency (Sir\u00e9 n et al. 2011).",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "If the trait values at the tip are not directly observed we integrate over these values as well. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "Let p\u00f0z i jx i \u00de denote the probability of observing z i given the trait value x i . ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "The marginalized likelihood is then",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "While the level of convergence for both algorithms is correct, the accuracy of the method based on Simpson's method is far worse. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "When a branch length is short, the transition density becomes highly peaked, as does the function being integrated. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "Such functions are difficult to approximate with piecewise quadratics, and Simpson's method can fail miserably. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "Indeed, for N < 50, we would often observe estimated probabilities equal to 0, or estimates greater than 1! ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "(These were omitted from the plots). ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "Although we can always bound estimates computed by the algorithm, a sounder approach is to improve the integration technique. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "This we did using the Gaussian kernel method, and the result was far improved accuracy for little additional computation. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "For the remainder of the experiments with this model we used the Gaussian kernel method when carrying out numerical integration. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "Marazzi et al. (2012) describe AIC comparisons between their precursor model and a conventional binary trait model. ",
            "section": "Models for Continuous Trait Evolution",
            "ref_spans": [
                {
                    "start": 0,
                    "end": 21,
                    "type": "bibr",
                    "text": "Marazzi et al. (2012)"
                }
            ]
        },
        {
            "text": "We extend this comparison to include the threshold model. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "This is a one parameter model, the parameter being the value of the liability at the root. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "We used the MATLAB command fmin- search with multiple starting points to compute the maximum likelihood estimate for this value. ",
            "section": "Models for Continuous Trait Evolution",
            "entity_spans": [
                {
                    "start": 12,
                    "end": 18,
                    "type": "software",
                    "rawForm": "MATLAB",
                    "resp": "#annotator1",
                    "used": true,
                    "id": "dde861f54b-software-simple-3",
                    "cert": "1.0"
                },
                {
                    "start": 27,
                    "end": 39,
                    "type": "software",
                    "rawForm": "fmin- search",
                    "resp": "#curator",
                    "id": "dde861f54b-software-simple-4"
                },
                {
                    "type": "software",
                    "start": 12,
                    "end": 18,
                    "rawForm": "MATLAB",
                    "resp": "whitelist",
                    "id": "dde861f54b-software-simple-w4"
                }
            ]
        },
        {
            "text": "The resulting log-likelihood was log?",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "L \u00bc \u00c0240:6, giving an AIC of 483.2. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "This compares to an AIC of 507.4 for the (two parameter) binary character model and an AIC of 495.4 for the (one parameter) precursor model of Marazzi et al. (2012).",
            "section": "Models for Continuous Trait Evolution",
            "ref_spans": [
                {
                    "start": 143,
                    "end": 164,
                    "type": "bibr",
                    "text": "Marazzi et al. (2012)"
                }
            ]
        },
        {
            "text": "Analytical integration can be difficult or impossible. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "For the most part, it is unusual for an integral to have an analytical solution and there is no general method for finding it when it does exist. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "In contrast, numerical integration techniques (also known as numerical quadrature) are remarkably effective and are often easy to implement. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "A numerical integration method computes an approximation of the integral from function values at a finite number of points. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "Hence, we can obtain approximate integrals of functions even when we do not have an equation for the function itself. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "See Cheney and Kincaid (2012) for an introduction to numerical integration, and Dahlquist and Bj\u00f6 rck (2008) and Davis and Rabinowitz (1984) for more comprehensive technical surveys. ",
            "section": "Models for Continuous Trait Evolution",
            "ref_spans": [
                {
                    "start": 4,
                    "end": 29,
                    "type": "bibr",
                    "ref_id": "b2",
                    "text": "Cheney and Kincaid (2012)"
                },
                {
                    "start": 80,
                    "end": 108,
                    "type": "bibr",
                    "ref_id": "b3",
                    "text": "Dahlquist and Bj\u00f6 rck (2008)"
                },
                {
                    "start": 113,
                    "end": 140,
                    "type": "bibr",
                    "ref_id": "b4",
                    "text": "Davis and Rabinowitz (1984)"
                }
            ]
        },
        {
            "text": "The idea behind most numerical integration techniques is to approximate the target function using a function which is easy to integrate. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "In this article, we will restrict our attention to Simpson's method which approximates the original function using piecewise quadratic functions. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "To approximate an integral R b a f \u00f0x\u00dedx we first determine N + 1 equally spaced points (N even)",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "We now divide the integration into N=2 intervals",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "Within each interval \u00bdx 2'\u00c02 ; x 2' , there is a unique quadratic function which equals f(x) at each the three points x \u00bc x 2'\u00c02 ; x \u00bc x 2'\u00c01, and x \u00bc x 2' . ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "The integral of this quadratic on the interval",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "Summing over ', we obtain the approximation",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "With a little rearrangement, the approximation can be written in the form",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "where w k \u00bc 4=3 when k is odd and w k \u00bc 2=3 when k is even, with the exception of w 0 and w N which both equal 1/3. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "Simpson's method is easy to implement and has a convergence rate of O\u00f0N \u00c04 \u00de. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "Increasing the number of intervals by a factor of 10 decreases the error by a factor of 10 \u00c04 . ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "See Dahlquist and Bj\u00f6 rck (2008) and Davis and Rabinowitz (1984) for further details. ",
            "section": "Models for Continuous Trait Evolution",
            "ref_spans": [
                {
                    "start": 4,
                    "end": 32,
                    "type": "bibr",
                    "ref_id": "b3",
                    "text": "Dahlquist and Bj\u00f6 rck (2008)"
                },
                {
                    "start": 37,
                    "end": 64,
                    "type": "bibr",
                    "ref_id": "b4",
                    "text": "Davis and Rabinowitz (1984)"
                }
            ]
        },
        {
            "text": "It should be remembered, however, that the convergence rate is still only an asymptotic bound, and gives no guarantees on how well the method performs for a specific function and choice of N. Simpson's method, for example, can perform quite poorly when the function being integrated has rapid changes or sharp peaks. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "We observed this behavior when implementing threshold models, as described below. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "Our response was to better tailor the integration method for the functions appearing. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "We noted that the numerical integrations we carried out all had the form Z b a e \u00c0 \u00f0x\u00c0m\u00de 2 2s 2 f \u00f0x\u00dedx \u00f011\u00de",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "where and varied. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "Using the same general approach as Simpson's rule, we approximated f(x), rather than the whole function e \u00c0 \u00f0x\u00c0m\u00de 2 2s 2 f \u00f0x\u00de, by a piecewise quadratic function p(x). ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "We could then use standard techniques and tools to evaluate R b a e \u00c0 \u00f0x\u00c0m\u00de 2 2s 2 p\u00f0x\u00dedx numerically. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "The resulting integration formula, which we call the \"Gaussian kernel method,\" gives a significant improvement in numerical accuracy.",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "A further complication is that, in models of continuous traits, the trait value often ranges over the whole real line, or at least over the set of positive reals. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "Hence, we need to approximate integrals of the form",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "though the methods discussed above only apply to integrals on finite intervals. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "We truncate these integrals, determining values U and L such that the difference",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "between the full integral R 1 \u00c01 f \u00f0x\u00dedx and the truncated integral R U L f \u00f0x\u00dedx can be bounded analytically. ",
            "section": "Models for Continuous Trait Evolution"
        },
        {
            "text": "Other strategies are possible; see Dahlquist and Bj\u00f6 rck (2008) for a comprehensive review.",
            "section": "Models for Continuous Trait Evolution",
            "ref_spans": [
                {
                    "start": 35,
                    "end": 63,
                    "type": "bibr",
                    "ref_id": "b3",
                    "text": "Dahlquist and Bj\u00f6 rck (2008)"
                }
            ]
        },
        {
            "text": "Felsenstein has developed pruning algorithms for both continuous and discrete characters (Felsenstein 1981a,b). ",
            "section": "A Pruning Algorithm for Integrating Continuous Traits",
            "ref_spans": [
                {
                    "start": 89,
                    "end": 110,
                    "type": "bibr",
                    "text": "(Felsenstein 1981a,b)"
                }
            ]
        },
        {
            "text": "His algorithm for continuous characters works only for Gaussian processes. ",
            "section": "A Pruning Algorithm for Integrating Continuous Traits"
        },
        {
            "text": "Our approach is to take his algorithm for discrete characters and adapt it to continuous characters.",
            "section": "A Pruning Algorithm for Integrating Continuous Traits"
        },
        {
            "text": "The (discrete character) pruning algorithm is an application of dynamic programming. ",
            "section": "A Pruning Algorithm for Integrating Continuous Traits"
        },
        {
            "text": "For each node i, and each state x, we compute the probability of observing the states for all tips which are descendants of node i, conditional on node i having ancestral state x. ",
            "section": "A Pruning Algorithm for Integrating Continuous Traits"
        },
        {
            "text": "This probability is called the partial likelihood at node i given state x. ",
            "section": "A Pruning Algorithm for Integrating Continuous Traits"
        },
        {
            "text": "Our algorithm follows the same scheme, with one major difference. ",
            "section": "A Pruning Algorithm for Integrating Continuous Traits"
        },
        {
            "text": "Since traits are continuous, we cannot store all possible partial likelihoods. ",
            "section": "A Pruning Algorithm for Integrating Continuous Traits"
        },
        {
            "text": "Instead, we store likelihoods for a finite set of values and plug these values into a numerical integration routine.",
            "section": "A Pruning Algorithm for Integrating Continuous Traits"
        },
        {
            "text": "Let i be the index of a node in the tree not equal to the root, let node j be its parent node. ",
            "section": "A Pruning Algorithm for Integrating Continuous Traits"
        },
        {
            "text": "We define the partial likelihood, F i \u00f0x j \u00de; to be the likelihood for the observed trait values at the tips which are descendants of node i, conditional on the parent node j having trait value x j . ",
            "section": "A Pruning Algorithm for Integrating Continuous Traits"
        },
        {
            "text": "If node i is a tip with observed trait value x i we have",
            "section": "A Pruning Algorithm for Integrating Continuous Traits"
        },
        {
            "text": "recalling that f \u00f0x i jx j ; y i \u00de is the density for the value of the trait at node i conditional on the value of the trait for its parent. ",
            "section": "A Pruning Algorithm for Integrating Continuous Traits"
        },
        {
            "text": "More generally, we may only observe some value z i for which we have the conditional probability p\u00f0z i jx i \u00de conditional on the trait value x i . ",
            "section": "A Pruning Algorithm for Integrating Continuous Traits"
        },
        {
            "text": "In this case, the partial likelihood is given by",
            "section": "A Pruning Algorithm for Integrating Continuous Traits"
        },
        {
            "text": "Suppose node i is not the root and that it has two children u and v. Since trait evolution is conditionally independent on disjoint subtrees, we obtain the recursive formula",
            "section": "A Pruning Algorithm for Integrating Continuous Traits"
        },
        {
            "text": "Finally, suppose that node i is the root and has two children u and v. We evaluate the complete tree likelihood using the density of the trait value at the root,",
            "section": "A Pruning Algorithm for Integrating Continuous Traits"
        },
        {
            "text": "The bounds of integration in (15)-(17) will vary according to the model.",
            "section": "A Pruning Algorithm for Integrating Continuous Traits"
        },
        {
            "text": "We use numerical integration techniques to approximate (15)-(17) and dynamic programming to avoid an exponential explosion in the computation time. ",
            "section": "A Pruning Algorithm for Integrating Continuous Traits"
        },
        {
            "text": "Let N denote the number of function evaluations for each node. ",
            "section": "A Pruning Algorithm for Integrating Continuous Traits"
        },
        {
            "text": "In practice, this might vary over the tree, but for simplicity we assume that it is constant. ",
            "section": "A Pruning Algorithm for Integrating Continuous Traits"
        },
        {
            "text": "For each node i, we select N + 1 trait values",
            "section": "A Pruning Algorithm for Integrating Continuous Traits"
        },
        {
            "text": "How we do this will depend on the trait model and the numerical integration technique. ",
            "section": "A Pruning Algorithm for Integrating Continuous Traits"
        },
        {
            "text": "If, for example, the trait values vary between a and b and we are applying Simpson's method with N intervals we would use",
            "section": "A Pruning Algorithm for Integrating Continuous Traits"
        },
        {
            "text": "We traverse the tree starting at the tips and working toward the root. ",
            "section": "A Pruning Algorithm for Integrating Continuous Traits"
        },
        {
            "text": "For each nonroot node i and k \u00bc 0; 1; . . . ; N we compute and store an approximation F i \u00bdk of F i \u00f0X j \u00bdk\u00de, where node j is the parent of node i. ",
            "section": "A Pruning Algorithm for Integrating Continuous Traits"
        },
        {
            "text": "Note that this is an approximation of F i \u00f0X j \u00bdk\u00de rather than of F i \u00f0X i \u00bdk\u00de since F i \u00f0x\u00de is the partial likelihood conditional on the trait value for the parent of node i. ",
            "section": "A Pruning Algorithm for Integrating Continuous Traits"
        },
        {
            "text": "The value approximation F v \u00bdi is computed by applying the numerical integration method to the appropriate integral (15)- 17, where we replace function evaluations with approximations previously computed. ",
            "section": "A Pruning Algorithm for Integrating Continuous Traits",
            "ref_spans": [
                {
                    "start": 122,
                    "end": 124,
                    "ref_id": "formula_14",
                    "text": "17"
                }
            ]
        },
        {
            "text": "See below for a worked example of this general approach.",
            "section": "A Pruning Algorithm for Integrating Continuous Traits"
        },
        {
            "text": "The numerical integration methods we use run in time linear in the number of points being evaluated. ",
            "section": "A Pruning Algorithm for Integrating Continuous Traits"
        },
        {
            "text": "Hence, if n is the number of tips in the tree, the algorithm will run in time O\u00f0nN 2 \u00de. ",
            "section": "A Pruning Algorithm for Integrating Continuous Traits"
        },
        {
            "text": "For the integration techniques described above, the convergence rate (in N) for the likelihood on the entire tree had the same order as the convergence rate for the individual onedimensional integrations (see below for a formal proof of a specific model). ",
            "section": "A Pruning Algorithm for Integrating Continuous Traits"
        },
        {
            "text": "We have therefore avoided the computational blow-out typically associated with such high-dimensional integrations, and achieve this without sacrificing accuracy.",
            "section": "A Pruning Algorithm for Integrating Continuous Traits"
        },
        {
            "text": "The algorithms we have described compute the joint density of the states at the tips, given the tree, the branch lengths, and other parameters. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "As with discrete traits, the algorithms can be modified to infer ancestral states for internal nodes in the tree. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Here, we show how to carry out reconstruction of the marginal posterior density of a state at a particular node. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "The differences between marginal and joint reconstructions are reviewed in Yang (2006, p. 121).",
            "section": "Posterior Densities for Ancestral States",
            "ref_spans": [
                {
                    "start": 75,
                    "end": 94,
                    "type": "bibr",
                    "text": "Yang (2006, p. 121)"
                }
            ]
        },
        {
            "text": "First consider marginal reconstruction of ancestral states at the root. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Let u and v be the children of the root. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "The product F u \u00f0x\u00deF v \u00f0x\u00de equals the probability of the observed character conditional on the tree, branch lengths, parameters, and a state of x at the root. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "The marginal probability of x, ignoring the data, is given by the root density f \u00f0xjy r \u00de. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Integrating the product of F u \u00f0x\u00deF v \u00f0x\u00de and f \u00f0xjy r \u00de gives the likelihood L\u00f0T \u00de, as in (17). ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Plugging these into Bayes' rule, we obtain the posterior density of the state at the root:",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "With general time reversible models used in phylogenetics, the posterior distributions at other nodes can be found by changing the root of the tree. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Unfortunately, the same trick does not work for many quantitative trait models. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Furthermore, recomputing likelihoods for each possible root entails a large amount of unnecessary computation.",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Instead, we derive a second recursion, this one starting at the root and working toward the tips. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "A similar trick is used to compute derivatives of the likelihood function in Felsenstein and Churchill (1996). ",
            "section": "Posterior Densities for Ancestral States",
            "ref_spans": [
                {
                    "start": 77,
                    "end": 109,
                    "type": "bibr",
                    "ref_id": "b13",
                    "text": "Felsenstein and Churchill (1996)"
                }
            ]
        },
        {
            "text": "For a node i and state x we let G i \u00f0x\u00de denote the likelihood for the trait values at tips which are not descendants of node i, conditional on node i having trait value x. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "If node i is the root r, then G r \u00f0x\u00de is 1 for all x.",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Let node i be any node apart from the root, let node j be its parent and let node u be the other child of j (that is, the sibling of node i). ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "We letx denote the trait value at node j. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Then G i \u00f0x\u00de can be written",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "This integral can be evaluated using the same numerical integrators used when computing likelihoods. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Note that f \u00f0xj x; y i \u00de is the conditional density of the parent state given the child state, which is the reverse of the transition densities used to formulate the model. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "It should be noted that while Brownian motion has reversible transition probabilities, the OU process does not. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "How G i \u00f0x\u00de is computed will depend on the model and its properties; see below for an implementation of this calculation in the threshold model.",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Once G i \u00f0x\u00de has been computed for all nodes, the actual (marginal) posterior densities are computed from Bayes' rule. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Letting u, v be the children of node i,",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Case study: threshold models",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "In this section, we show how the general framework can be applied to the threshold model of Wright (1934) and Felsenstein (2005Felsenstein ( , 2012. ",
            "section": "Posterior Densities for Ancestral States",
            "ref_spans": [
                {
                    "start": 92,
                    "end": 105,
                    "type": "bibr",
                    "ref_id": "b37",
                    "text": "Wright (1934)"
                },
                {
                    "start": 110,
                    "end": 127,
                    "type": "bibr",
                    "ref_id": "b11",
                    "text": "Felsenstein (2005"
                },
                {
                    "start": 127,
                    "end": 147,
                    "type": "bibr",
                    "ref_id": "b12",
                    "text": "Felsenstein ( , 2012"
                }
            ]
        },
        {
            "text": "Each trait is modeled by a continuously varying \"liability\" which evolves along branches according to a Brownian motion process. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "While the underlying liability is continuous, the observed data are discrete: at each tip we observe only whether the liability is above or below some threshold. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "We will use standard notation for Gaussian densities. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Let \u00f0xjm; s 2 \u00de denote the density of a Gaussian random variable x with mean and variance s 2 ; let",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "denote its cumulative density function, with inverse \u00c8 \u00c01 \u00f0ajm; s 2 \u00de. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Let X 1 ; . . . ; X 2n\u00c01 denote the (unobserved) liability values at the n tips and n\u00c01 internal nodes. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "As above we assume that the i < j whenever node i is a child of node j, so that the root has index 2n \u00c0 1.",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "The liability value at the root has a Gaussian density with mean r and variance s 2",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Consider any nonroot node i and let j be the index of its parent. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Let t i denote the length of the branch connecting nodes i and j. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Then X i has a Gaussian density with mean x j and variance s 2 t v :",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Following Felsenstein (2005), we assume thresholds for the tips are all set at zero. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "We observe 1 if the liability is positive, 0 if the liability is negative, and ? ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "if data are missing. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "We can include the threshold step into our earlier framework by defining",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "The likelihood function for observed discrete values z 1 ; . . . ; z n is then given by integrating over liability values for all nodes on the tree:",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "The first step toward computing L\u00f0T jz 1 ; . . . ; z n \u00de is to bound the domain of integration so that we can apply Simpson's method. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Ideally, we would like these bounds to be as tight as possible, for improved efficiency. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "For the moment we will just outline a general procedure which can be adapted to a wide range of evolutionary models.",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "The marginal (prior) density of a single liability or trait value at a single node is the density for that liability value marginalizing over all other values and data. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "With the threshold model, the marginal density for the liability at node i is Gaussian with mean r (like the root) and variance v i equal to the sum of the variance at the root and the transition variances on the path from the root to node i. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "If P i is the set of nodes from the root to node i, then",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "The goal is to constrain the error introduced by truncating the integrals with infinite domain. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Let be the desired bound on this truncation error. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Recall that the number of internal nodes in the tree is n\u00c01. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Define",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "To illustrate the application of our general framework, we develop an efficient algorithm for computing the likelihood of a tree under the threshold model of Wright (1934) and Felsenstein (2005, 2012). ",
            "section": "Posterior Densities for Ancestral States",
            "ref_spans": [
                {
                    "start": 158,
                    "end": 171,
                    "type": "bibr",
                    "text": "Wright (1934)"
                },
                {
                    "start": 176,
                    "end": 200,
                    "type": "bibr",
                    "text": "Felsenstein (2005, 2012)"
                }
            ]
        },
        {
            "text": "We also show how to infer marginal trait densities at ancestral nodes. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "We have implemented these algorithms and used them to study evolution of extrafloral nectaries (EFN) on an 839-taxon phylogeny of Marazzi et al. (2012). ",
            "section": "Posterior Densities for Ancestral States",
            "ref_spans": [
                {
                    "start": 130,
                    "end": 151,
                    "type": "bibr",
                    "text": "Marazzi et al. (2012)"
                }
            ]
        },
        {
            "text": "MATLAB code for computing the threshold likelihood has been posted on MATLAB Central and complete MATLAB code for all analyses and simulations can be found in supplementary material, Supplementary Material online.",
            "section": "Posterior Densities for Ancestral States",
            "entity_spans": [
                {
                    "start": 0,
                    "end": 6,
                    "type": "software",
                    "rawForm": "MATLAB",
                    "resp": "#annotator1",
                    "used": true,
                    "id": "dde861f54b-software-simple-0",
                    "cert": "1.0"
                },
                {
                    "start": 70,
                    "end": 76,
                    "type": "software",
                    "rawForm": "MATLAB",
                    "resp": "#annotator1",
                    "used": true,
                    "id": "dde861f54b-software-simple-1",
                    "cert": "1.0"
                },
                {
                    "start": 98,
                    "end": 104,
                    "type": "software",
                    "rawForm": "MATLAB",
                    "resp": "#annotator1",
                    "used": true,
                    "id": "dde861f54b-software-simple-2",
                    "cert": "1.0"
                },
                {
                    "type": "software",
                    "start": 0,
                    "end": 6,
                    "rawForm": "MATLAB",
                    "resp": "whitelist",
                    "id": "dde861f54b-software-simple-w5"
                },
                {
                    "type": "software",
                    "start": 70,
                    "end": 76,
                    "rawForm": "MATLAB",
                    "resp": "whitelist",
                    "id": "dde861f54b-software-simple-w6"
                },
                {
                    "type": "software",
                    "start": 98,
                    "end": 104,
                    "rawForm": "MATLAB",
                    "resp": "whitelist",
                    "id": "dde861f54b-software-simple-w7"
                }
            ]
        },
        {
            "text": "The bounds L i and U i are chosen so that the (marginal) probability X i lies outside the interval \u00bdL i ; U i is at most =\u00f0n \u00c0 1\u00de. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "For this model, these are given by the inverse distribution function of a Gaussian; other models would involved different transition densities. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "By the inclusion-exclusion principle, the joint probability X i 2 \u00bdL i ; U i for any internal node i is at most . ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "We use this fact to bound the contribution of the regions outside these bounds.",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "We therefore compute values L i , U i for n \u00fe 1 i 2n \u00c0 1 using (28) and (29) repeatedly, and use these bounds when carrying out integration at the internal nodes. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "We define",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "for k \u00bc 0; 1; . . . ; N and each internal node i. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "The next step is to use dynamic programming and numerical integration to compute the approximate likelihood. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Let node i be a tip of the tree, let node j be its parent and let z i be the binary trait value at this tip. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "For each k \u00bc 0; 1; . . . ; N we use standard error functions to compute",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Here, \u00f0xjm; s 2 \u00de is the density of a Gaussian with mean and variance s 2 . ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Now suppose that node i is an internal node with parent node j and children u and v. Applying Simpson's rule to the bounds L i , U i to (16) we have for each k \u00bc 0; 1; . . . ; N:",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Suppose node i is the root, and u, v are its children. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Applying Simpson's rule to (17) gives an approximate likelihood of",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Pseudocode for the algorithm appears in Algorithm 1. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Let j be the index of the parent of node i",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "For all internal nodes i = n+1, ..., 2n\u22122, excluding the root Let j be the index of the parent of node i Let u, v be the indices of the children of node i",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Let u, v be indices of the the children of the root.",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Algorithm 1 Pseudo-code of the likelihood approximation algorithm for a single character, under the threshold model. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "The nodes are numbered in increasing order from tips to the root.",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Regarding efficiency and convergence we have: Theorem 1 Algorithm 1 runs in O\u00f0nN 2 \u00de time and approximates L(T) with O\u00f0nN \u00c04 \u00de error.",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Proof The running time follows from the fact that for each of the O(n) nodes in the tree we carry out O(N) applications of Simpson's method.",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Simpson's rule has O\u00f0N \u00c04 \u00de convergence on functions with bounded fourth derivatives (Dahlquist and Bj\u00f6 rck 2008). ",
            "section": "Posterior Densities for Ancestral States",
            "ref_spans": [
                {
                    "start": 85,
                    "end": 113,
                    "type": "bibr",
                    "ref_id": "b3",
                    "text": "(Dahlquist and Bj\u00f6 rck 2008)"
                }
            ]
        },
        {
            "text": "The root density and each of the transition densities are Gaussians, so individually have bounded fourth derivatives. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "For each node i, let n i denote the number of tips which are descendants of the node. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Using induction on (16), we see that for all nodes i, the fourth derivative of F i \u00f0x\u00de is O\u00f0n i \u00de.",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "If we use \u00bc nN \u00c04 in (28) and (29) then replacing the infinite domain integrals with integrals on \u00bdL i ; U i introduces at most nN \u00c04 error. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Using a second induction proof on (16) and (37) together with the bound on fourth derivatives, we have that jF i \u00f0X j \u00bdk\u00de \u00c0 F i \u00bdkj is at most O\u00f0n i N \u00c04 \u00de for all nodes i, where node j is the parent of node i. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "In this way we obtain error bound of O\u00f0n 2n\u00c01 N \u00c04 \u00de \u00bc O\u00f0nN \u00c04 \u00de on the approximation of L\u00f0T jz 1 ; . . . ; z n ; y\u00de: \u00ab We can estimate posterior densities using the recursion (20) followed by equation 21. ",
            "section": "Posterior Densities for Ancestral States",
            "ref_spans": [
                {
                    "start": 202,
                    "end": 204,
                    "ref_id": "formula_19",
                    "text": "21"
                }
            ]
        },
        {
            "text": "The conditional density",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "can be obtained by plugging the transitional density",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "and the two marginal densities (27)",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "into the identity f \u00f0xjx; y i \u00de \u00bc f \u00f0xjx; y i \u00de f \u00f0x \u00de f \u00f0x\u00de . ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "We thereby obtain the recursion",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "which we estimate using Simpson's method. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "Algorithm estimates values of the posterior densities at each node, evaluated using the same set of grid points as used in Algorithm 1. ",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "An additional round of numerical integration can be used to obtain posterior means and variances.",
            "section": "Posterior Densities for Ancestral States"
        },
        {
            "text": "To study the methods in practice, we reanalyze trait data published by Marazzi et al. (2012), using a fixed phylogeny. ",
            "section": "Evolutionary Precursors of Plant Extrafloral Nectaries",
            "ref_spans": [
                {
                    "start": 71,
                    "end": 92,
                    "type": "bibr",
                    "ref_id": "b27",
                    "text": "Marazzi et al. (2012)"
                }
            ]
        },
        {
            "text": "Marazzi et al. (2012) introduce and apply a new discrete state model for morphological traits which, in addition to states for presence and absence, incorporates an intermediate \"precursor\" state. ",
            "section": "Evolutionary Precursors of Plant Extrafloral Nectaries",
            "ref_spans": [
                {
                    "start": 0,
                    "end": 21,
                    "type": "bibr",
                    "ref_id": "b27",
                    "text": "Marazzi et al. (2012)"
                }
            ]
        },
        {
            "text": "Whenever the intermediate state is observed at the tips it is coded as \"absent.\" ",
            "section": "Evolutionary Precursors of Plant Extrafloral Nectaries"
        },
        {
            "text": "The motivation behind the model is that the intermediate state represents evolutionary precursors, changes which are necessary for the evolution of a new state but which may not be directly observed. ",
            "section": "Evolutionary Precursors of Plant Extrafloral Nectaries"
        },
        {
            "text": "These precursors could explain repeated parallel evolution of a trait in closely related traits (Marazzi et al. 2012). ",
            "section": "Evolutionary Precursors of Plant Extrafloral Nectaries",
            "ref_spans": [
                {
                    "start": 96,
                    "end": 117,
                    "type": "bibr",
                    "ref_id": "b27",
                    "text": "(Marazzi et al. 2012)"
                }
            ]
        },
        {
            "text": "They compiled a data set recording presence or absence of plant EFNs across a phylogeny of 839 species of Fabales, fitting their models to these data. ",
            "section": "Evolutionary Precursors of Plant Extrafloral Nectaries"
        },
        {
            "text": "The threshold model also involves evolutionary precursors in terms of changes in ancestral liabilities. ",
            "section": "Evolutionary Precursors of Plant Extrafloral Nectaries"
        },
        {
            "text": "We use these models, and our new algorithms to analyze the EFN data set. ",
            "section": "Evolutionary Precursors of Plant Extrafloral Nectaries"
        },
        {
            "text": "Our analysis also makes use of the time-calibrated phylogeny inferred by Simon et al. (2009), although unlike Marazzi et al. (2012) we ignore phylogenetic uncertainty.",
            "section": "Evolutionary Precursors of Plant Extrafloral Nectaries",
            "ref_spans": [
                {
                    "start": 73,
                    "end": 92,
                    "type": "bibr",
                    "ref_id": "b31",
                    "text": "Simon et al. (2009)"
                },
                {
                    "start": 110,
                    "end": 131,
                    "type": "bibr",
                    "ref_id": "b27",
                    "text": "Marazzi et al. (2012)"
                }
            ],
            "entity_spans": [
                {
                    "type": "software",
                    "start": 73,
                    "end": 78,
                    "rawForm": "Simon",
                    "resp": "whitelist",
                    "id": "dde861f54b-software-simple-w8"
                }
            ]
        },
        {
            "text": "We conduct three separate experiments. ",
            "section": "Experimental Protocol"
        },
        {
            "text": "For the first experiment, we examine the rate of convergence of the likelihood algorithm as we increase N. This is done for the \"All\" EFN character (Character 1 in Marazzi et al. [2012]) for a range of estimates for the liability variance at the root, s 2 r . ",
            "section": "Experimental Protocol",
            "ref_spans": [
                {
                    "start": 164,
                    "end": 185,
                    "type": "bibr",
                    "ref_id": "b27",
                    "text": "Marazzi et al. [2012]"
                }
            ]
        },
        {
            "text": "The interest in s 2 r stems from its use in determining bounds L i , U i for each node, with the expectation that as s 2 r increases, the convergence of the integration algorithm will slow. ",
            "section": "Experimental Protocol"
        },
        {
            "text": "The mean liability at the root, r , was determined from the data using Maximum Likelihood estimation.",
            "section": "Experimental Protocol"
        },
        {
            "text": "We also examined convergence of the algorithm on randomly generated characters. ",
            "section": "Experimental Protocol"
        },
        {
            "text": "We first evolved liabilities according to the threshold model, using the parameter settings obtained above. ",
            "section": "Experimental Protocol"
        },
        {
            "text": "To examine the difference in performance for non-phylogenetic characters, we also simulated binary characters by simulated coin flipping. ",
            "section": "Experimental Protocol"
        },
        {
            "text": "Twenty replicates were carried out for each case.",
            "section": "Experimental Protocol"
        },
        {
            "text": "The second experiment extends the model comparisons carried out in Marazzi et al. (2012) to include the threshold models. ",
            "section": "Experimental Protocol",
            "ref_spans": [
                {
                    "start": 67,
                    "end": 88,
                    "type": "bibr",
                    "ref_id": "b27",
                    "text": "Marazzi et al. (2012)"
                }
            ]
        },
        {
            "text": "For this comparison we fix the transitional variance s 2 at one, since changing this values corresponds to a rescaling of the Brownian process, with no change in likelihood. ",
            "section": "Experimental Protocol"
        },
        {
            "text": "With only one character, the maximum likelihood estimate of the root variance s 2 r is zero, irrespective of the data. ",
            "section": "Experimental Protocol"
        },
        {
            "text": "This leaves a single parameter to infer: the value of the liability at the root state. ",
            "section": "Experimental Protocol"
        },
        {
            "text": "We computed a maximum likelihood estimate for the state at the root, then applied our algorithm with a sufficiently large value of N to be sure of convergence. ",
            "section": "Experimental Protocol"
        },
        {
            "text": "The Akaike Information Criterion (AIC) was determined and compared with those obtained for the model of Marazzi et al. (2012).",
            "section": "Experimental Protocol",
            "ref_spans": [
                {
                    "start": 104,
                    "end": 125,
                    "type": "bibr",
                    "ref_id": "b27",
                    "text": "Marazzi et al. (2012)"
                }
            ]
        },
        {
            "text": "For the third experiment, we determine the marginal posterior densities for the liabilities at internal nodes, using Algorithm 2. ",
            "section": "Experimental Protocol"
        },
        {
            "text": "Let j be the index of the parent of node i. ",
            "section": "Experimental Protocol"
        },
        {
            "text": "Let v be the index of the sibling of node i.",
            "section": "Experimental Protocol"
        },
        {
            "text": "Algorithm 2 Pseudocode for the algorithm to efficiently compute ancestral posterior densities under the threshold model. ",
            "section": "Experimental Protocol"
        },
        {
            "text": "At the termination of the algorithm, H i \u00bdk is an estimate of the posterior density at internal node i, evaluated at x \u00bc X i \u00bdk.",
            "section": "Experimental Protocol"
        },
        {
            "text": "These posterior probabilities are then mapped onto the phylogeny, using shading to denote the (marginal) posterior probability that a liability is larger than zero. ",
            "section": "Experimental Protocol"
        },
        {
            "text": "We therefore obtain a figure analogous to supplementary figure S7, Supplementary Material online, of Marazzi et al. (2012).  ",
            "section": "Experimental Protocol",
            "ref_spans": [
                {
                    "start": 101,
                    "end": 122,
                    "type": "bibr",
                    "ref_id": "b27",
                    "text": "Marazzi et al. (2012)"
                }
            ]
        },
        {
            "text": "To examine convergence, we compute the absolute error of each likelihood approximation because the actual likelihood is not available we use the approximation when N = 1,000. ",
            "section": "Convergence of the Algorithm"
        },
        {
            "text": "Plots of error versus N are given in figure 1, both for Simpson's method (left) and for the modified Gaussian kernel method (right). ",
            "section": "Convergence of the Algorithm"
        },
        {
            "text": "For larger N, the error in a log-log plot decreases with slope at most \u00c04 (as indicated), corresponding to N \u00c04 convergence of the method. ",
            "section": "Convergence of the Algorithm"
        },
        {
            "text": "Log-log plots of error versus N for the simulated data are given in figure 2. ",
            "section": "Convergence of the Algorithm"
        },
        {
            "text": "In each case, the method converges for by N&30.",
            "section": "Convergence of the Algorithm"
        },
        {
            "text": "While the level of convergence for both algorithms is correct, the accuracy of the method based on Simpson's method is far worse. ",
            "section": "Convergence of the Algorithm"
        },
        {
            "text": "When a branch length is short, the transition density becomes highly peaked, as does the function being integrated. ",
            "section": "Convergence of the Algorithm"
        },
        {
            "text": "Such functions are difficult to approximate with piecewise quadratics, and Simpson's method can fail miserably. ",
            "section": "Convergence of the Algorithm"
        },
        {
            "text": "Indeed, for N < 50, we would often observe estimated probabilities equal to 0, or estimates greater than 1! ",
            "section": "Convergence of the Algorithm"
        },
        {
            "text": "(These were omitted from the plots). ",
            "section": "Convergence of the Algorithm"
        },
        {
            "text": "Although we can always bound estimates computed by the algorithm, a sounder approach is to improve the integration technique. ",
            "section": "Convergence of the Algorithm"
        },
        {
            "text": "This we did using the Gaussian kernel method, and the result was far improved accuracy for little additional computation. ",
            "section": "Convergence of the Algorithm"
        },
        {
            "text": "For the remainder of the experiments with this model we used the Gaussian kernel method when carrying out numerical integration.  ",
            "section": "Convergence of the Algorithm"
        },
        {
            "text": "Marazzi et al. (2012). ",
            "section": "Convergence of the Algorithm",
            "ref_spans": [
                {
                    "start": 0,
                    "end": 21,
                    "type": "bibr",
                    "ref_id": "b27",
                    "text": "Marazzi et al. (2012)"
                }
            ]
        },
        {
            "text": "All likelihoods and AIC values rounded to 1 d.p. Boldface indicates the best fitting model for each trait. ",
            "section": "Convergence of the Algorithm"
        },
        {
            "text": "A pre-cursor model with one parameter was used for all experiments, except for trait 6 where a two-parameter model gave a better AIC than the one-parameter model (see discussion in Marazzi et al. (2012).  ",
            "section": "Convergence of the Algorithm",
            "ref_spans": [
                {
                    "start": 181,
                    "end": 202,
                    "type": "bibr",
                    "ref_id": "b27",
                    "text": "Marazzi et al. (2012)"
                }
            ]
        },
        {
            "text": "Marazzi et al. (2012) describe AIC comparisons between their precursor model and a conventional binary trait model. ",
            "section": "Convergence of the Algorithm",
            "ref_spans": [
                {
                    "start": 0,
                    "end": 21,
                    "type": "bibr",
                    "ref_id": "b27",
                    "text": "Marazzi et al. (2012)"
                }
            ]
        },
        {
            "text": "We extend this comparison to include the threshold model. ",
            "section": "Convergence of the Algorithm"
        },
        {
            "text": "This is a one parameter model, the parameter being the value of the liability at the root. ",
            "section": "Convergence of the Algorithm"
        },
        {
            "text": "We used the MATLAB command fminsearch with multiple starting points to compute the maximum likelihood estimate for this value. ",
            "section": "Convergence of the Algorithm",
            "entity_spans": [
                {
                    "type": "software",
                    "start": 12,
                    "end": 18,
                    "rawForm": "MATLAB",
                    "resp": "whitelist",
                    "id": "dde861f54b-software-simple-w9"
                }
            ]
        },
        {
            "text": "The resulting log-likelihood was log?",
            "section": "Convergence of the Algorithm"
        },
        {
            "text": "L \u00bc \u00c0240:6, giving an AIC of 483.2. ",
            "section": "Convergence of the Algorithm"
        },
        {
            "text": "This compares to an AIC of 507.4 for the (two parameter) binary character model and an AIC of 495.4 for the (one parameter) precursor model of Marazzi et al. (2012).",
            "section": "Convergence of the Algorithm",
            "ref_spans": [
                {
                    "start": 143,
                    "end": 164,
                    "type": "bibr",
                    "ref_id": "b27",
                    "text": "Marazzi et al. (2012)"
                }
            ]
        },
        {
            "text": "We analyzed the five other EFN traits in the same way, and present the computed AIC values in table 1, together with AIC values for the two parameter binary state model and one parameter precursor model computed by Marazzi et al. (2012) (and the two parameter precursor model for trait 6). ",
            "section": "Model Comparison",
            "ref_spans": [
                {
                    "start": 215,
                    "end": 236,
                    "type": "bibr",
                    "ref_id": "b27",
                    "text": "Marazzi et al. (2012)"
                }
            ]
        },
        {
            "text": "We see that the threshold model fits better than either the binary or precursor models for all of the six traits.",
            "section": "Model Comparison"
        },
        {
            "text": "It is not clear, a priori, why the threshold model would appear to fit some data better than the precursor model because they appear to capture similar evolutionary phenomena. ",
            "section": "Model Comparison"
        },
        {
            "text": "It would be useful to explore this observation more thoroughly, given the new computational tools, perhaps incorporating phylogenetic error in a manner similar to Marazzi et al. (2012). ",
            "section": "Model Comparison",
            "ref_spans": [
                {
                    "start": 163,
                    "end": 184,
                    "type": "bibr",
                    "ref_id": "b27",
                    "text": "Marazzi et al. (2012)"
                }
            ]
        },
        {
            "text": "Figure 3 gives a representation of how the (marginal) posterior liabilities change over the tree. ",
            "section": "Model Comparison",
            "ref_spans": [
                {
                    "start": 0,
                    "end": 8,
                    "type": "figure",
                    "text": "Figure 3"
                }
            ]
        },
        {
            "text": "Branches are divided into three classes according to the posterior probability that the liability is positive, with lineages with posterior probability > 0.7 colored red, lineages with posterior probability < 0.3 colored white, and remaining lineages colored pink.  ",
            "section": "Model Comparison"
        },
        {
            "text": "Simon et al. (2009). ",
            "section": "Model Comparison",
            "ref_spans": [
                {
                    "start": 0,
                    "end": 19,
                    "type": "bibr",
                    "ref_id": "b31",
                    "text": "Simon et al. (2009)"
                }
            ],
            "entity_spans": [
                {
                    "type": "software",
                    "start": 0,
                    "end": 5,
                    "rawForm": "Simon",
                    "resp": "whitelist",
                    "id": "dde861f54b-software-simple-w10"
                }
            ]
        },
        {
            "text": "Lineages with posterior probability > 0.7 colored red, lineages with posterior probability < 0.3 colored white, and remaining lineages colored pink. ",
            "section": "Model Comparison"
        },
        {
            "text": "This diagram can be compared with Marazzi et al. (2012), figure S7. ",
            "section": "Model Comparison",
            "ref_spans": [
                {
                    "start": 34,
                    "end": 55,
                    "type": "bibr",
                    "ref_id": "b27",
                    "text": "Marazzi et al. (2012)"
                },
                {
                    "start": 57,
                    "end": 66,
                    "type": "figure",
                    "text": "figure S7"
                }
            ]
        },
        {
            "text": "The representations are, on the whole, directly comparable. ",
            "section": "Model Comparison"
        },
        {
            "text": "A positive liability corresponds, roughly, to an ancestral precursor state. ",
            "section": "Model Comparison"
        },
        {
            "text": "Both analyses suggest multiple origins of a precursor state, for example for a large clade of Mimosoidae. ",
            "section": "Model Comparison"
        },
        {
            "text": "Interestingly, there are several clades where the analysis of Marazzi et al. (2012) suggests widespread ancestral distribution of the precursor state whereas our analysis indicates a negative liability at the same nodes.",
            "section": "Model Comparison",
            "ref_spans": [
                {
                    "start": 62,
                    "end": 83,
                    "type": "bibr",
                    "ref_id": "b27",
                    "text": "Marazzi et al. (2012)"
                }
            ]
        },
        {
            "text": "Once again, our analysis is only preliminary, our goal here simply being to demonstrate what calculations can now be carried out.",
            "section": "Inferring Ancestral Liabilities"
        },
        {
            "text": "We have introduced a new framework for the computation of likelihoods from continuous characters, and illustrated the framework using an efficient algorithm for evaluating (approximate) likelihoods under Wright and Felsenstein's threshold model. ",
            "section": "Discussion",
            "ref_spans": [
                {
                    "start": 204,
                    "end": 245,
                    "type": "bibr",
                    "text": "Wright and Felsenstein's threshold model."
                }
            ]
        },
        {
            "text": "This framework opens up possibilities in several directions. ",
            "section": "Discussion"
        },
        {
            "text": "The numerical integration, or numerical quadrature, literature is vast. ",
            "section": "Discussion"
        },
        {
            "text": "In this article, we have focused in on a popular and simple numerical integration method, and our algorithm should be seen as a proof of principle rather than a definitive threshold likelihood method. ",
            "section": "Discussion"
        },
        {
            "text": "There is no question that the numerical efficiency of Algorithm 1 could be improved significantly through the use of more sophisticated techniques: better basis functions or adaptive quadrature methods for a start.",
            "section": "Discussion"
        },
        {
            "text": "The connection with Felsenstein's (discrete character) pruning algorithm also opens up opportunities for efficiency gains. ",
            "section": "Discussion"
        },
        {
            "text": "Techniques such as storing partial likelihoods, or approximating local neighborhoods, are fundamental to efficient phylogenetic computations on sequence data (Felsenstein 1981a;Larget and Simon 1998;Swofford 2002;Pond and Muse 2004;Stamatakis 2006). ",
            "section": "Discussion",
            "ref_spans": [
                {
                    "start": 158,
                    "end": 177,
                    "type": "bibr",
                    "ref_id": "b7",
                    "text": "(Felsenstein 1981a;"
                },
                {
                    "start": 177,
                    "end": 199,
                    "type": "bibr",
                    "ref_id": "b24",
                    "text": "Larget and Simon 1998;"
                },
                {
                    "start": 199,
                    "end": 213,
                    "type": "bibr",
                    "ref_id": "b35",
                    "text": "Swofford 2002;"
                },
                {
                    "start": 213,
                    "end": 232,
                    "type": "bibr",
                    "ref_id": "b29",
                    "text": "Pond and Muse 2004;"
                },
                {
                    "start": 232,
                    "end": 248,
                    "type": "bibr",
                    "ref_id": "b33",
                    "text": "Stamatakis 2006)"
                }
            ],
            "entity_spans": [
                {
                    "type": "software",
                    "start": 188,
                    "end": 193,
                    "rawForm": "Simon",
                    "resp": "whitelist",
                    "id": "dde861f54b-software-simple-w11"
                },
                {
                    "type": "software",
                    "start": 222,
                    "end": 226,
                    "rawForm": "Muse",
                    "resp": "whitelist",
                    "id": "dde861f54b-software-simple-w12"
                }
            ]
        },
        {
            "text": "These tricks could all be now applied to the calculation of likelihoods from continuous traits.",
            "section": "Discussion"
        },
        {
            "text": "Finally, we stress that the algorithm does not depend on special characteristics of the continuous trait model, beyond conditional independence of separate lineages. ",
            "section": "Discussion"
        },
        {
            "text": "Felsenstein's pruning algorithm for continuous characters is limited to Gaussian processes and breaks down if, for example, the transition probabilities are governed by Levy processes (Landis et al. 2013). ",
            "section": "Discussion",
            "ref_spans": [
                {
                    "start": 184,
                    "end": 204,
                    "type": "bibr",
                    "ref_id": "b23",
                    "text": "(Landis et al. 2013)"
                }
            ]
        },
        {
            "text": "In contrast, our approach works whenever we can numerically evaluation transition densities, an indeed only a few minor changes would transform our Algorithm 1 to one implementing on a far more complex evolutionary process.",
            "section": "Discussion"
        },
        {
            "text": "Supplementary material is available at Genome Biology and Evolution online (http://www.gbe.oxfordjournals.org/).",
            "section": "Supplementary Material",
            "entity_spans": [
                {
                    "type": "software",
                    "start": 58,
                    "end": 67,
                    "rawForm": "Evolution",
                    "resp": "whitelist",
                    "id": "dde861f54b-software-simple-w13"
                }
            ]
        },
        {
            "text": "This research was supported by an Allan Wilson Centre Doctoral Scholarship to G.H., financial support to D.B. from the Allan Wilson Centre, a Marsden grant to D.B., and financial support to all authors from the University of Otago.",
            "section": "Acknowledgments"
        }
    ]
}