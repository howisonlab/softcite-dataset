{
    "level": "paragraph",
    "abstract": [
        {
            "text": "We present an algorithm and a corresponding MATLAB numerical toolbox to solve any form of infinite-planning horizon affine linear quadratic open-loop differential games. By rewriting a specific application into the standard framework one can use the toolbox to calculate and verify the existence of both the open-loop noncooperative Nash equilibrium (equilibria) and cooperative Pareto equilibrium (equilibria). In case there is more than one equilibrium for the non-cooperative case, the toolbox determines all solutions that can be implemented as a feedback strategy. Alternatively, the toolbox can apply a number of choice methods in order to discriminate between multiple equilibria. The user can predefine a set of coalition structures for which they would like to calculate the non-cooperative Nash solution(s). It is also possible to specify the relative importance of each player in any coalition structure. Furthermore, the toolbox offers plotting facilities as well as other options to analyse the outcome of the game. For instance, it is possible to disaggregate each player's total loss into its contributing elements. The toolbox is available as a freeware from the authors of this paper."
        }
    ],
    "body_text": [
        {
            "section": "Introduction",
            "text": "Many situations in, for example, economics and management are characterised by multiple decision makers/players who can enforce decisions that have enduring consequences. This often invokes coordination problems and so a natural framework to analyze these kinds of problems involves dynamic game theoretical settings. Dynamic game theory tries to arrive at appropriate models describing a dynamic process affected by different players. Depending on the specific problem such models can sometimes be used by an individual decision maker to optimise her performance. In other cases it may serve as a starting point to introduce new communication lines which may help to improve upon the outcome of the current process. Furthermore it is possible to analyze the robustness of players' strategies w.r.t. worst-case scenarios. To this end one can introduce \"nature\" as an additional player which tries to work against the other decision makers in a process."
        },
        {
            "section": "Introduction",
            "text": "In, for example, policy coordination problems two basic questions usually arise: (i) whether policies are coordinated and, (ii) which information the participating parties have. Both these points are rather unclear and, therefore, strategies for different possible scenarios are calculated and compared with each other. Often, one of these scenarios is the so-called open-loop scenario. In this open-loop information scenario it is assumed that all players know just the initial state of the process and the model structure. More specifically, it is assumed that players simultaneously determine their actions for the whole planning horizon of the process before it starts. Next they submit their actions to some central authority who then enforces these plans as binding commitments. In other words, players cannot react on any deviations occurring during the evolution of the process. Obviously, since according to this scenario the participating parties can not react to each other's policies, its economic relevance is mostly rather limited. However, as a benchmark to see how much parties can gain by playing other strategies, its role is fundamental. Due to its analytic tractability the open-loop Nash equilibrium strategy is in particular very popular for problems where the underlying model can be described by a (set of) linear differential equation(s) and the individual objectives can be approximated by functions that quadratically penalise deviations from some (equilibrium) targets. Examples and additional references of differential games in economics and management science can be found e.g. in Dockner et al. (2000), J\u00f8rgensen and Zaccour (2003) and Plasmans et al. (2006).",
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b3",
                    "start": 1612,
                    "text": "Dockner et al. (2000)",
                    "end": 1633
                },
                {
                    "type": "bibr",
                    "ref_id": "b9",
                    "start": 1635,
                    "text": "J\u00f8rgensen and Zaccour (2003)",
                    "end": 1663
                },
                {
                    "type": "bibr",
                    "ref_id": "b16",
                    "start": 1668,
                    "text": "Plasmans et al. (2006)",
                    "end": 1690
                }
            ]
        },
        {
            "section": "Introduction",
            "text": "Under the assumption that the parties have a finite-planning horizon, the linear quadratic differential game was first modeled and solved in a mathematically rigorous way by Starr and Ho (1969a,b). A recent exposition (and additional references) on linear quadratic differential games can be found in , whereas Ba\u015far and Olsder (1999) give a good overview and introduction on dynamic games in general.",
            "ref_spans": [
                {
                    "type": "bibr",
                    "start": 174,
                    "text": "Starr and Ho (1969a,b)",
                    "end": 196
                },
                {
                    "type": "bibr",
                    "ref_id": "b2",
                    "start": 311,
                    "text": "Ba\u015far and Olsder (1999)",
                    "end": 334
                }
            ]
        },
        {
            "section": "Introduction",
            "text": "In the rest of this paper we will concentrate on the case that the players base their decisions on a performance criterion that has an infinite-planning horizon. We will present an algorithm and a corresponding MATLAB numerical toolbox which solves any form of an infinite-planning horizon affine linear quadratic open-loop differential game. The software, called LQDG Toolbox, is available as a freeware from the authors of this paper. 1 By rewriting a specific application into the standard framework, one can use the toolbox to calculate and verify the existence of both the open-loop non-cooperative Nash equilibrium (equilibria) and cooperative Pareto equilibrium (equilibria) of any infinite-planning horizon affine linear quadratic open-loop differential game. In case there is more than one equilibrium for the non-cooperative case, the toolbox determines all solutions that can be implemented as a state-feedback strategy that is a common assumption in most of the applications. 2 Alternatively, the toolbox can apply a number of choice methods in order to discriminate between multiple equilibria. For instance, one can choose to report only Pareto-undominated solutions or only those that are characterised by the lowest combined loss of all the players. In order to determine the cooperative solution, the user is asked to specify the relative importance of each player in the cooperative game. Moreover, the user can predefine a set of coalition structures for which they would like to calculate the noncooperative Nash solution(s). Conversely, a coalition structure generator is provided that automatically creates a whole space of coalition structures for a given number of players. Furthermore, the toolbox offers plotting facilities as well as other options to analyze the outcome of the game. For instance, it is possible to disaggregate each player's total loss into its contributing elements, which correspond to the quadratic expressions constituting the player's loss function."
        },
        {
            "section": "Introduction",
            "text": "The paper is organised as follows. In Sect. 2 we will outline the model considered and present both necessary and sufficient conditions under which there will exist a unique equilibrium, a number of multiple equilibria or an infinite number of these. The basic algorithm underlying the numerical toolbox that is presented in Sect. 4 is discussed in Sect. 3. In Sect. 4 we will discuss the toolbox that has been constructed to verify in typical applications whether there will be a unique equilibrium, multiple equilibria or infinite number of these and how to obtain the solution in the first two cases. In Sect. 5 we illustrate the use and capabilities of this software with a number of examples. Section 6 concludes."
        },
        {
            "section": "The Open-Loop Game",
            "text": "In this section we consider two players who control a different set of inputs v i to the single system described by the structural (simultaneous) form model:"
        },
        {
            "section": "The Open-Loop Game",
            "text": "where p is the n-dimensional state of the system; v i is an m i -dimensional (control) vector that player i, i = 1, 2, can manipulate; y is a b-dimensional vector of endogenous variables; c is a constant (that can be chosen without loss of generality equal to 1) and p 0 is the initial state of the system. We assume that all variables can be observed at any point of time and that n, m i \u2265 1 and b \u2265 0. Model (1,2) is a formulation which one frequently encounters in economic modeling. Since we like to stay close to the original equations formulated by the modeler we choose for this formulation instead of the standard state-space formulation. Notice that, by choosing P 1 = P 3 = P 6 = P 8 = 0, our formulation includes the standard state-space formulation."
        },
        {
            "section": "The Open-Loop Game",
            "text": "The performance criterion player i likes to minimise is:"
        },
        {
            "section": "The Open-Loop Game",
            "text": "where"
        },
        {
            "section": "The Open-Loop Game",
            "text": "; f and g are some constant vectors in IR 2n+b+m 1 +m 2 ; e := [1, . . . , 1] T \u2208 IR 2n+b+m 1 +m 2 and \u03b8 is a non-negative discounting factor. In this formulation the introduction of the i j matrices makes it possible to deal with several interpretations of the model. For instance by choosing in (3) i1 = i2 and f = g the vector i j w(t) can be interpreted as an output vector of the system player i likes to track towards some specific value. By choosing a specific column of the i j, j = 1, 2, matrices equal to zero, e.g., one can express the fact that some variable is not an important variable for player i. The matrices L i1 are (without loss of generality) assumed to be symmetric. Later on additional assumptions will be made w.r.t. some of the above matrices."
        },
        {
            "section": "The Open-Loop Game",
            "text": "It is assumed that the players act non-cooperatively and that their information structure about the game is of the open-loop type. More specifically, we suppose that the players choose their actions from the following set of actions:"
        },
        {
            "section": "The Open-Loop Game",
            "text": "The assumption that both players simultaneously use stabilizing controls introduces the cooperative meta-objective to stabilise the system (see e.g. , for a discussion)."
        },
        {
            "section": "The Open-Loop Game",
            "text": "We are looking for the Nash equilibria of this game. That is, for the combinations of actions of all players which are secure against any attempt by one player to unilaterally alter her strategy, or, stated differently, for such sets of actions that if one player deviates she will only lose. In the literature on dynamic games this problem is known as the open-loop Nash non-zero-sum linear quadratic differential game and has been analyzed by several authors (see e.g. Starr and Ho 1969a;Simaan and Cruz 1973;Ba\u015far and Olsder 1999;Abou-Kandil and Bertrand 1986;Feucht 1994;Kremer 2002;. To avoid cumbersome notation, we restrict the analyses in this section to the two-player case. The algorithm is, however, implemented for the general N -player case.",
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b19",
                    "start": 471,
                    "text": "Starr and Ho 1969a;",
                    "end": 490
                },
                {
                    "type": "bibr",
                    "ref_id": "b18",
                    "start": 490,
                    "text": "Simaan and Cruz 1973;",
                    "end": 511
                },
                {
                    "type": "bibr",
                    "ref_id": "b2",
                    "start": 511,
                    "text": "Ba\u015far and Olsder 1999;",
                    "end": 533
                },
                {
                    "type": "bibr",
                    "ref_id": "b0",
                    "start": 533,
                    "text": "Abou-Kandil and Bertrand 1986;",
                    "end": 563
                },
                {
                    "type": "bibr",
                    "ref_id": "b8",
                    "start": 563,
                    "text": "Feucht 1994;",
                    "end": 575
                },
                {
                    "type": "bibr",
                    "ref_id": "b10",
                    "start": 575,
                    "text": "Kremer 2002;",
                    "end": 587
                }
            ]
        },
        {
            "section": "The Open-Loop Game",
            "text": "To analyze the question under which conditions this game will have a unique equilibrium we first rewrite the model into the standard framework considered in Engwerda (2008). 3 Assuming that I \u2212 P 6 is invertible, we have from (2) tha\u1e6b",
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b6",
                    "start": 157,
                    "text": "Engwerda (2008)",
                    "end": 172
                },
                {
                    "type": "bibr",
                    "start": 174,
                    "text": "3",
                    "end": 175
                }
            ]
        },
        {
            "section": "The Open-Loop Game",
            "text": "Substitution of this into (1) and, under the assumption thatP 1 := I \u2212 P 1 (I \u2212 P 6 ) \u22121 P 8 \u2212 P 3 is invertible we can perform a number of elementary operations in order to arrive at the following reduced form of the model:"
        },
        {
            "section": "The Open-Loop Game",
            "text": "with\u0108"
        },
        {
            "section": "The Open-Loop Game",
            "text": "A :"
        },
        {
            "section": "The Open-Loop Game",
            "text": "E 1 := (I \u2212 P 6 ) \u22121 (P 8\u00ca2 + P 10 )."
        },
        {
            "section": "The Open-Loop Game",
            "text": "Next, introduce"
        },
        {
            "section": "The Open-Loop Game",
            "text": "Substituting\u1e57 and y from (5) and (6), respectively, into w yields:"
        },
        {
            "section": "The Open-Loop Game",
            "text": "Using this, J i can be rewritten as:"
        },
        {
            "section": "The Open-Loop Game",
            "text": "Finally, we introduce the extended state variable x T (t) := e \u2212 1 2 \u03b8t [ p T (t) c] and control variable u i (t) := e \u2212 1 2 \u03b8t v i (t) so that the state of the system isn = n + 1-dimensional. Now, the game can be rewritten into the standard form. Players minimise:"
        },
        {
            "section": "The Open-Loop Game",
            "text": "where x(t) is the solution to the linear differential equation:"
        },
        {
            "section": "The Open-Loop Game",
            "text": "with:"
        },
        {
            "section": "The Open-Loop Game",
            "text": "Now, factorise M i as follows:"
        },
        {
            "section": "The Open-Loop Game",
            "text": "In the rest of the paper we will assume that the matrices R ii are positive definite and matrix G (see Appendix A for some additional notation including matrix G) is invertible. In the solution of this game the next algebraic Riccati equations play an important role:"
        },
        {
            "section": "The Open-Loop Game",
            "text": "as well as the set of (coupled) algebraic Riccati equations:"
        },
        {
            "section": "The Open-Loop Game",
            "text": "or, equivalently:"
        },
        {
            "section": "The Open-Loop Game",
            "text": "In particular, the existence of a so-called strongly stabilizing solution of (21) plays an important role. A solutionP T =: (P T 1 ,P T 2 ), withP i \u2208 IRn, of (21) is called a strongly stabilizing solution if both \u03c3 \u00c3 \u2212 BG \u22121B TP and \u03c3 \u00c3 T"
        },
        {
            "section": "The Open-Loop Game",
            "text": "The next relationship between certain invariant subspaces of matrix:"
        },
        {
            "section": "The Open-Loop Game",
            "text": "and the solutions of the Riccati equations (21) are well-known (see e.g. Engwerda 2007). This property will also be used to calculate the strongly stabilizing solutions of (21).",
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b5",
                    "start": 73,
                    "text": "Engwerda 2007)",
                    "end": 87
                }
            ]
        },
        {
            "section": "The Open-Loop Game",
            "text": "Lemma 1 Let V \u2282 IR 3n be ann-dimensional invariant subspace of M, and let X i \u2208 IRn \u00d7n , i = 0, 1, 2, be three real matrices such that:"
        },
        {
            "section": "The Open-Loop Game",
            "text": "is independent of the specific choice of a basis of V ."
        },
        {
            "section": "The Open-Loop Game",
            "text": "When X 0 is invertible, then-dimensional invariant subspace V in (23) is called a graph subspace. The next lemma provides a characterisation of the strongly stabilizing solution of (21): Moreover, in case this game has a unique equilibrium, the equilibrium actions are given by:"
        },
        {
            "section": "The Open-Loop Game",
            "text": "where\u02dc (t, 0) is the solution of the transition equation:"
        },
        {
            "section": "The Open-Loop Game",
            "text": "The costs by using the actions (24) for the players are:"
        },
        {
            "section": "The Open-Loop Game",
            "text": "where, with A cl := A\u2212 BG \u22121 Z +B TP ,L i is the unique solution of the Lyapunov equation:"
        },
        {
            "section": "The Open-Loop Game",
            "text": "In case the game has more than one equilibrium, generically, there exists an infinite number of equilibria (see Kremer 2002). However, usually for a finite number of them only, the corresponding actions can be implemented as a state-feedback strategy (i.e., such strategy that can be written as a linear function of the state variables of the model like, for instance, in Theorem 3; see also footnote 1 in this paper). In economics it is often argued that actions by policymakers have a (state-)feedback structure (Taylor rule etc.). For that reason, in case there is more than one equilibrium, the algorithm will determine only those that can be implemented as a (state-)feedback rule. From  we recall the following result. Finally, if one would like to consider the game (17-18) without a constant that, in particular, allows for a zero discount rate, the state variable should not be extended, i.e., x T (t) := e \u2212 1 2 \u03b8t p T (t) is to be used instead of x T (t) := e \u2212 1 2 \u03b8t p T (t) c . The system in (18) becomes:",
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b10",
                    "start": 112,
                    "text": "Kremer 2002",
                    "end": 123
                }
            ]
        },
        {
            "section": "The Open-Loop Game",
            "text": "where:"
        },
        {
            "section": "The Open-Loop Game",
            "text": "The rest of the above analysis remains valid but withn = n."
        },
        {
            "section": "The Computational Framework",
            "text": "To verify the existence, the number and numerical values of equilibria in the game (17-18), in the numerical toolbox we use the following algorithm 5 :"
        },
        {
            "section": "Algorithm 5",
            "text": "Step A1: Verify whether R ii > 0, G is invertible and (A, B i ) are stabilizable. If this is not the case, go to Step A6."
        },
        {
            "section": "Algorithm 5",
            "text": "Step A2: Calculate the eigenstructure of:"
        },
        {
            "section": "Algorithm 5",
            "text": "If H i , i = 1, 2, has ann-dimensional stable graph subspace, then proceed. Otherwise there is not an equilibrium and go to Step A6. 6"
        },
        {
            "section": "Algorithm 5",
            "text": "Step A3:"
        },
        {
            "section": "Algorithm 5",
            "text": "If M has s \u2265n stable eigenvalues and u \u2264 2n unstable eigenvalues (counting algebraic multiplicities) then proceed to Step A4. Otherwise, i.e., if s <n, the game has no equilibrium and go to Step A6."
        },
        {
            "section": "Algorithm 5",
            "text": "Step A4: The number of equilibria equals the number of differentn-dimensional stable invariant graph subspaces of matrix M. In particular this implies that if matrix M has eigenvalues that have a geometric multiplicity that is larger than one, it may happen that there are an infinite number of equilibria (see e.g. Engwerda 2005, Example 7.11). The algorithm does not elaborate this case because (i) it is numerically more involved to decide whether an eigenvalue has a geometric multiplicity that is larger than one; (ii) the occurrence of such cases requires a more detailed inspection of how many different n-dimensional subspaces can be generated; and (iii) generically, the algebraic multiplicity of the eigenvalues is one. If s \u2265n and there is at least one eigenvalue that has an algebraic multiplicity larger than one, then the algorithm terminates and the user is informed about the possibility that in the simulation an infinite number of equilibria might occur. It is then up to the user either to choose some parameters that differ a little bit from the previous choice (yielding probably a simulation that produces no difficulties), or to take a serious look at the eigenstructure of matrix M and draw own conclusions. Therefore the algorithm proceeds as follows: A4.1: If at least one eigenvalue has an algebraic multiplicity larger than one then the game may have an infinite number of equilibria if s >n.",
            "ref_spans": [
                {
                    "type": "bibr",
                    "start": 316,
                    "text": "Engwerda 2005, Example 7.11)",
                    "end": 344
                }
            ]
        },
        {
            "section": "Algorithm 5",
            "text": "If s =n there probably exists a unique equilibrium, but this has to be verified using the generalised eigenspace(s). "
        },
        {
            "section": "Algorithm 5",
            "text": "i be the matrix constructed in a similar way as in item A4.2.1.2; (ii) go to Step A5."
        },
        {
            "section": "Algorithm 5",
            "text": "Step A5: For every matrix of eigenvectors\u1e7c s i calculate the corresponding M-invariant graph subspace P. To that end proceed as follows:"
        },
        {
            "section": "Algorithm 5",
            "text": "Verify whether matrix X 1 is invertible. If not then Im\u1e7c s i is not a graph subspace and there is no equilibrium corresponding with this set of eigenvalues. Choose another matrix\u1e7c s i from the set of potential candidates and return to the beginning of the current step (Step A5.1). If there are no other candidates left, go to Step 6."
        },
        {
            "section": "Algorithm 5",
            "text": "where"
        },
        {
            "section": "Algorithm 5",
            "text": "2 is the open-loop Nash equilibrium strategy. Here x * (t) is the solution of the differential equatio\u1e45"
        },
        {
            "section": "Algorithm 5",
            "text": "* The spectrum of the corresponding closed-loop matrix A cl equals \u03bb s i . * Players' losses can be computed from J i = p T 0L i p 0 whereL i solves the following Lyapunov equation:"
        },
        {
            "section": "Algorithm 5",
            "text": "Step A6: End of algorithm."
        },
        {
            "section": "Algorithm 5",
            "text": "Step A2 in the above algorithm verifies whether the algebraic Riccati equations (20) have a stabilizing solution. Of course one can use here MATLAB to verify this. Concerning the numerical stability of Algorithm 5 we notice that various suggestions have been made in the literature to calculate solutions of Riccati equations in a numerically reliable way (see e.g. Laub (1979Laub ( , 1991, Paige and van Loan (1981), van Dooren (1981), Mehrmann (1991) and Abou-Kandil and Bertrand (1986) for a more general survey on various types of Riccati equations). These methods can also be used to improve the numerical stability of Algorithm 5. In particular, if one considers the implementation of large scale models one should consult this literature.",
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b11",
                    "start": 366,
                    "text": "Laub (1979",
                    "end": 376
                },
                {
                    "type": "bibr",
                    "ref_id": "b12",
                    "start": 376,
                    "text": "Laub ( , 1991",
                    "end": 389
                },
                {
                    "type": "bibr",
                    "ref_id": "b15",
                    "start": 391,
                    "text": "Paige and van Loan (1981)",
                    "end": 416
                },
                {
                    "type": "bibr",
                    "ref_id": "b22",
                    "start": 422,
                    "text": "Dooren (1981)",
                    "end": 435
                },
                {
                    "type": "bibr",
                    "ref_id": "b13",
                    "start": 437,
                    "text": "Mehrmann (1991)",
                    "end": 452
                },
                {
                    "type": "bibr",
                    "ref_id": "b0",
                    "start": 457,
                    "text": "Abou-Kandil and Bertrand (1986)",
                    "end": 488
                }
            ]
        },
        {
            "section": "Algorithm 5",
            "text": "As already indicated one can also try to solve the (set of coupled) algebraic Riccati equations (20) iteratively. In particular, for large scale systems one might hope that such algorithms will be more efficient. For that reason various iteration schemes have been suggested in literature (see e.g. Abou- Kandil andBertrand 1986 or Engwerda 2007). However, since Eq. 20 may admit several solutions, convergence of any game is quite difficult to obtain under general conditions (see Azevedo-Perdico\u00falis and Jank 2005, for a result on positive solutions). An important problem with these algorithms is related to the a priori verification of the system's strong stabilizability. If one does not want to do it there is an open question how to proceed in case the algorithm terminates at a non-stabilizing solution.",
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b0",
                    "start": 305,
                    "text": "Kandil and",
                    "end": 315
                },
                {
                    "type": "bibr",
                    "start": 315,
                    "text": "Bertrand 1986 or Engwerda 2007)",
                    "end": 346
                },
                {
                    "start": 511,
                    "text": "2005",
                    "end": 515
                }
            ]
        },
        {
            "section": "LQDG Toolbox",
            "text": "Next we proceed with an outline of the numerical toolbox. The software verifies the existence of and, provided that a finite number of equilibria exists, calculates the outcome of the N -player extension of the game (1-3). The scheme presenting all the components of the toolbox software is displayed in Fig. 1. The main file, called LQDGsolver.exe, solves the LQDG which is to be defined in the input. The input file can be created by the user using an intuitive input interface provided (file TBXinput-GUI.exe). Alternatively, more proficient users might choose to create the input file directly (in MATLAB or text formats). LQDGsolver produces the following output for every coalition structure considered: The above output is saved in MATLAB and text formats in a directory that corresponds to the chosen name of the project. The following output files are created:",
            "ref_spans": [
                {
                    "type": "figure",
                    "ref_id": "fig_0",
                    "start": 304,
                    "text": "Fig. 1",
                    "end": 310
                }
            ]
        },
        {
            "section": "LQDG Toolbox",
            "text": "\u2022 PROJECT_NAME_model.txt: text file containing the structural and reduced form of the dynamic system; \u2022 inputPROJECT_NAME.m: binary MATLAB file containing (processed) input to the project; \u2022 PROJECT_NAME_validation.txt: text file containing all the information about the various stages of model validation; \u2022 PROJECT_NAME_output.txt: text file containing all the output produced; and \u2022 outputPROJECT_NAME.m: binary MATLAB file containing all the project's output."
        },
        {
            "section": "LQDG Toolbox",
            "text": "The plotting tool is provided that uses the above output to draw the dynamics of every variable in the model for a chosen coalition structure and equilibrium. Less advanced users can use a simple output interface (file TBXoutputGUI.exe) that allows both to edit the toolbox output and to plot the graphs required. Conversely, more advanced users can directly analyse output of all numerical simulations and create graphs."
        },
        {
            "section": "LQDG Toolbox",
            "text": "The input for the toolbox is the following model:"
        },
        {
            "section": "LQDG Toolbox",
            "text": "where p is the n-dimensional state of the system, v i is the m i -dimensional (control) vector player i (where i = 1, . . . , |N |) can manipulate (with m i =: m), y is the b-dimensional vector of endogenous variables and p 0 is the initial state of the system. Defining z(t) : T , the general form of the performance criterion that player i likes to minimise is:",
            "ref_spans": [
                {
                    "type": "bibr",
                    "start": 278,
                    "text": "T",
                    "end": 279
                }
            ]
        },
        {
            "section": "LQDG Toolbox",
            "text": "where:"
        },
        {
            "section": "LQDG Toolbox",
            "text": "Matrix i can be factorised as follows:"
        },
        {
            "section": "LQDG Toolbox",
            "text": "with all submatrices .,i defined in Appendix B. Furthermore, in Appendix C it is shown how, using the appropriate notation, it is possible to define any linear quadratic loss function containing the variables from vector z(t) in the input file (if the user chooses to create this file by himself not using the provided interface). Of course, the user is supposed to define only those coefficients \u03c6 (i.e., elements of matrix\u02dc i ) that are different from zero. The cost criterion (32) can be rewritten as follows:"
        },
        {
            "section": "LQDG Toolbox",
            "text": "and"
        },
        {
            "section": "LQDG Toolbox",
            "text": "The toolbox also offers the possibility to analyze equilibria for different coalition structures which are formally defined as divisions of all the players in the game into exhaustive and disjoint coalitions. That is, if, for instance, five players participate in the game and players 1, 3, 4 and players 2, 5 decide to cooperate, then the toolbox offers the possibility to calculate the open-loop Nash equilibrium for the resulting two-player game. Obviously the outcome depends on the relative weight of every players' performance criterion within the coalition. Therefore, the user is asked to specify both the coalition structure and these relative weights."
        },
        {
            "section": "LQDG Toolbox",
            "text": "The number of coalitions structures that can be created from even a small number of players is a non-trivial issue. More in detail, let denote the set of all possible coalition structures. The number of all possible coalition structures is a function of the number of players N and equals the so-called Bell number B |N | . The Bell number is the number of ways a set of |N | elements can be partitioned into non-empty subsets."
        },
        {
            "section": "LQDG Toolbox",
            "text": "The following Dobinsky's formula is one way to compute Bell numbers (Comtet 1974):",
            "ref_spans": [
                {
                    "type": "bibr",
                    "start": 68,
                    "text": "(Comtet 1974)",
                    "end": 81
                }
            ]
        },
        {
            "section": "LQDG Toolbox",
            "text": "To simplify the presentation of coalition structures we will use the following shorthand notation:"
        },
        {
            "section": "LQDG Toolbox",
            "text": "where C 1\u2264k\u2264m is represented by the sequence of players that belong to this coalition. For example: [123|4|56] stands for a coalition structure where players 1, 2, 3 and players 5, 6 cooperate, respectively and player 4 remains single. "
        },
        {
            "section": "LQDG Toolbox",
            "text": "It is clear that an examination of all possible coalition structures is not always interesting for the user. Usually, the researcher should choose and restrict her attention to a subset of coalition structures. In the sequel we will use the notation F for the full set of feasible coalition structures and R for a reduced set of relevant feasible coalition structures."
        },
        {
            "section": "LQDG Toolbox",
            "text": "We will now briefly discuss the various steps the user is confronted with while using the toolbox."
        },
        {
            "section": "LQDG Toolbox",
            "text": "Step T1: LQDG Toolbox Initialisation To define the LQDG problem the user is supposed to provide a number of compulsory components of the model. As it has been mentioned before, it is the most convenient to use the interface provided in order to create the project. The main window of the user interface is shown in Fig. 2. More proficient users also may create the input file directly in MATLAB or text formats. Compulsory components of the LQDG problem include:",
            "ref_spans": [
                {
                    "type": "figure",
                    "ref_id": "fig_1",
                    "start": 315,
                    "text": "Fig. 2",
                    "end": 321
                }
            ]
        },
        {
            "section": "LQDG Toolbox",
            "text": "\u2022 the name of the new project;"
        },
        {
            "section": "LQDG Toolbox",
            "text": "\u2022 number of players, number of state and output variables, whether the model include constant or not; \u2022 the number of control instruments per player;"
        },
        {
            "section": "LQDG Toolbox",
            "text": "\u2022 the nonzero P i and P i j matrices from the structural form model (30-31);"
        },
        {
            "section": "LQDG Toolbox",
            "text": "\u2022 the parameters from the performance criterion (32);"
        },
        {
            "section": "LQDG Toolbox",
            "text": "\u2022 the initial condition p 0 ; and \u2022 the coalition structures to be considered. 8 \u2022 If the model includes constants, i.e., at least one element of matrices P 5 and P 10 is non-zero, then it is mandatory to specify a strictly positive discount rate. Step T2: Model Validation by LQDG Toolbox Based on the input that is provided in Step A1, the toolbox verifies various regularity conditions:",
            "ref_spans": [
                {
                    "type": "bibr",
                    "start": 79,
                    "text": "8",
                    "end": 80
                }
            ]
        },
        {
            "section": "LQDG Toolbox",
            "text": "1. The invertibility of the matrices I \u2212 P 3 and I \u2212 P 7 (I \u2212 P 3 ) \u22121 P 1 \u2212 P 5 ; 2. Positive definiteness of the matrices R ii ; 3. Invertibility of G; and stabilizability of (A, B i ); and 4. The final validation step that is performed checks whether the algebraic Riccati equations (20) have a stabilizing solution."
        },
        {
            "section": "LQDG Toolbox",
            "text": "If conditions 1 or 2 fail the toolbox terminates. If conditions 3 and 4 fail then it means that no equilibrium can be found for the particular coalition structure and the toolbox considers the next coalition structure in the queue."
        },
        {
            "section": "LQDG Toolbox",
            "text": "Step T3: Calculation of Equilibria In this phase, open-loop Nash equilibria as outlined in Theorem 3 are calculated for every specified coalition structure (if such equilibria exists)."
        },
        {
            "section": "Examples",
            "text": "In this section we illustrate the various steps of the algorithm in three simple examples. Firstly, we analyze a dynamic duopoly game with sticky prices as considered by Fershtman and Kamien (1987); secondly, we present the solution of the problem used in Example 7.10 by , where a multiple finite number of equilibria emerges; thirdly, we present the solution of the problem used in Example 7.12 by  characterised by complex eigenvalues. Fershtman and Kamien (1987) The problem we address here is to find the open-loop Nash equilibria of the game defined by the revenue functions:",
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b7",
                    "start": 170,
                    "text": "Fershtman and Kamien (1987)",
                    "end": 197
                },
                {
                    "type": "bibr",
                    "ref_id": "b7",
                    "start": 439,
                    "text": "Fershtman and Kamien (1987)",
                    "end": 466
                }
            ]
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": "subject to the dynamic constraint:"
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": "Recall that, in this model, \u03b8 > 0 denotes the discount rate of future profits and s \u2208 (0, \u221e) is the adjustment speed parameter of the market price, p(t), towards the price dictated by the demand function. That is, for larger values of s the market price adjusts more quickly along the demand function. The cost functions of the companies are assumed to be C( ) is a fixed parameter. Furthermore, the inverse demand function is assumed to be given byp = a \u2212(v 1 +v 2 ).",
            "ref_spans": [
                {
                    "type": "figure",
                    "start": 359,
                    "text": ")",
                    "end": 360
                }
            ]
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": "To determine the open-loop equilibrium actions for this game (34-35) we proceed along the steps outlined in Sect. 3. To that end we first notice that the maximisation of (34) can be rewritten as the minimisation of \u2212J i ."
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": "Step T1: LQDG Toolbox Initialisation The above maximisation problems can be rewritten in terms of (32) as:"
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": "subject to the dynamics (35), where z T (t) :"
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": "The model fits into our standard model (30-31) if we specify the various parameters in the input file of the toolbox as follows: P 1 = P 2 = P 3 = P 4i = P 5 = P 6 = P 8 = 0, P 7 = \u2212s, P 9i = \u2212s and P 10 = c."
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": "Notice that in this example n = m 1 = m 2 = 1 (and therefore m = 2) and b = 0. In the performance specification all parameters are zero for both players except the next ones. For player 1 we have \u03c6 (1,3),1 = \u22122, \u03c6 (3,3),1 = 1, and \u03c6 (3,5),1 = 2c v , whereas for player 2 \u03c6 (1,4),2 = \u22122, \u03c6 (4,4),2 = 1 and \u03c6 (4,5),2 = 2c v .",
            "ref_spans": [
                {
                    "type": "figure",
                    "ref_id": "fig_0",
                    "start": 175,
                    "text": "For player 1 we have \u03c6 (1,3),1 = \u22122, \u03c6 (3,3)",
                    "end": 219
                },
                {
                    "type": "bibr",
                    "start": 233,
                    "text": "(3,",
                    "end": 236
                },
                {
                    "type": "bibr",
                    "start": 236,
                    "text": "5)",
                    "end": 238
                }
            ]
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": "There are two players in the game. Hence B 2 = 2 and F = {[1|2], [12]}. As already mentioned before, the user can either choose to compute the Nash equilibria for all coalition structures (if such equilibria exist) or only for some elements of F by creating own set of feasible coalition structures R . We choose in this example to calculate analytically the equilibrium for non-cooperative CS [1|2]."
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": "Step T2: Model Validation by LQDG Toolbox With this input the toolbox next calculates the standard form (17-18) by considering the new variables:"
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": "x 1 (t) := e \u2212 1 2 \u03b8t p(t), x 2 (t) := e \u2212 1 2 \u03b8t and u i (t) := e \u2212 1 2 \u03b8t v i (t), i = 1, 2. 36With these variables the problem (34-35) can be rewritten as finding the open-loop Nash equilibrium of",
            "ref_spans": [
                {
                    "start": 95,
                    "text": "36",
                    "end": 97
                }
            ]
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": "subject to the dynamic\u1e61"
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": "where M i = T i as in (33) with i defined by the user in Step T1. 9 Following the notation in Sect. 2 the toolbox generates the following matrices:"
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": ", and N i = 0."
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": "So, clearly R ii > 0 and (A, B i ) is stabilizable. Furthermore:"
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": "and from this:"
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": "Following Sect. 2 the game has, for all p 0 , a unique open-loop Nash equilibrium if the following sets of algebraic Riccati equations have a (strongly) stabilizing solution P i and K i , (where i = 1, 2, respectively):"
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": "1. The set of coupled Riccati differential equations:"
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": "2. The two Riccati equations:"
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": "To verify whether, e.g., the algebraic Riccati equation 40has a stabilizing solution it is sufficient to check whether the following equation satisfies this property:",
            "ref_spans": [
                {
                    "ref_id": "formula_67",
                    "start": 56,
                    "text": "40",
                    "end": 58
                }
            ]
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": "It is easily verified that the Hamiltonian matrix associated with this Riccati equation:"
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": "has a two-dimensional stable graph subspace. Thus, Eq. 40 has a stabilizing solution."
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": "In a similar way one can verify whether (41) has a strongly stabilizing solution. The procedure to verify whether (39) has a strongly stabilizing solution is presented in the next step."
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": "Step T3: Calculation of Equilibria Again, following Algorithm 5, the toolbox first computes the eigenvalues of matrix M to determine whether (42) has a strongly stabilizing solution. These eigenvalues are \u2212 1 2 \u03b8, \u2212 1 2 s \u2212 1 2 \u03bb 1 , 1 2 \u03b8, 1 2 \u03b8, 1 2 \u03b8 + 2s, \u2212 1 2 s + 1 2 \u03bb 1 , where:"
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": "Clearly, matrix M has 2 stable and 4 unstable eigenvalues. Therefore, the only open-loop Nash equilibrium candidate is obtained by considering the eigenspaces of M corresponding with the eigenvalues \u2212 1 2 \u03b8 and \u2212 1 2 s \u2212 1 2 \u03bb 1 . The eigenspaces corresponding with these eigenvalues are:"
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": "and"
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": ". In particular we see that for the values \u2212 1 2 \u03b8, \u2212 1 2 s \u2212 1 2 \u03bb 1 the corresponding eigenspace is a graph subspace (i.e., V s i = Span{T 1 , T 2 }). Since (A, B i ), where i = 1, 2, are stabilizable, R ii > 0, G is invertible, M has a 2-dimensional stable graph subspace and 4 unstable eigenvalues, and the algebraic Riccati equations (39-40) have a stabilizing solution, then all conditions are satisfied for the game to have a unique open-loop Nash equilibrium. The corresponding actions are:"
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": "Using the equilibrium actions:"
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": "the resulting closed-loop system is:"
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": "Next, we reformulate this result in terms of our original model parameters. From the above differential equation in x, one obtains the next differential equation for the equilibrium price path p(t):"
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": "The equilibrium actions are: 10 These matrices can be used to calculate players' losses for any given initial condition p 0 . 4. The optimal losses of players 11 :"
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": "The toolbox offers a possibility to plot graphs of control, state and output variables' dynamics. To plot graphs for a particular equilibrium the toolbox command plot_graph should be used. 12 Figure 3 shows the dynamics of the control variables for both players (i.e., output of both firms) for the assumed parameter values, whereas Fig. 4 shows the dynamics of the state variables (i.e., market price as well as a constant, which is added to the state variables of the system as outlined in Sect. 2).",
            "ref_spans": [
                {
                    "type": "figure",
                    "ref_id": "fig_3",
                    "start": 192,
                    "text": "Figure 3",
                    "end": 200
                },
                {
                    "type": "figure",
                    "ref_id": "fig_4",
                    "start": 333,
                    "text": "Fig. 4",
                    "end": 339
                }
            ]
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": "Furthermore, as it has been already mentioned, the toolbox offers an option to decompose the loss function of every player into its linear components showing what is each element's contribution to the total outcome. It is especially useful in both model calibration and analysis. When disaggregate losses option is chosen the toolbox creates a dummy player j for every non-zero element \u03c6 (a,b),i of matrix i in the loss function of player i. Player j s matrix j has \u03c6 (a,b), j as the only non-zero entry. Furthermore, every dummy player is assigned a control variable added to the first state equation of the system with a coefficient 0 so that it does not have any influence on the system. The weight of dummy players' control variables in their loss functions can be defined by the user using the (advanced) option dummy_control_instrument_multiplier (\u03b4) whose default value is 1."
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": "In the above example, there are 3 non-zero entries in each i matrix, namely, \u03c6 (1,3),1 , \u03c6 (3,3),1 , and \u03c6 (3,5),1 in 1 and \u03c6 (1,4),2 , \u03c6 (4,4),2 and \u03c6 (4,5),2 in 2 . Consequently, the toolbox creates 6 dummy players j = 3, 4, 5, 6, 7 and 8 with: ",
            "ref_spans": [
                {
                    "type": "figure",
                    "ref_id": "fig_0",
                    "start": 79,
                    "text": "(1,3),1 , \u03c6 (3,3)",
                    "end": 96
                },
                {
                    "type": "bibr",
                    "start": 107,
                    "text": "(3,",
                    "end": 110
                },
                {
                    "type": "bibr",
                    "start": 110,
                    "text": "5)",
                    "end": 112
                }
            ]
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": "0 0 \u22122 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \u03b4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0"
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": "and analogous 4 , 5 , 6 , 7 and 8 ."
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": "Furthermore, the toolbox adds 6 new control variables to the model and solves the following game 13 :"
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": "subject to dynamics:"
        },
        {
            "section": "A Game on Dynamic Duopolistic Competition from",
            "text": "Since dummy players have no influence on the system then their optimal strategy is to never use the control instrument as it cannot improve their loss. Consequently, all the obtained results will be the same up to additional dimensions in losses corresponding to dummy players. These losses can be always interpreted in terms of the losses of real players. In our example, since v 2 3 (t) and v 2 5 (t) are always zero, J 3 and J 5 can be interpreted as the loss from \u221e 0 e \u2212\u03b8t {\u2212 p(t)v 1 (t)}dt and \u221e 0 e \u2212\u03b8t {\u2212 p(t)v 2 (t)}dt obtained by players 1 and 2, respectively. Thus, J * 3 and J * 5 are revenues from sales, whereas J * 4 + J * 7 and J * 6 + J * 8 are costs functions of both oligopolistic firms. For the parametrisation assumed above the toolbox produces the following disaggregation of optimal losses in both regimes: which has the following interpretation: while non-cooperating the first/second company has a revenue with an equilibrium of \u2212J * 3/5 (N e ) = 39.4144 while it incurs a cost of J * 4/6 (N e ) + J * 7/8 (N e ) = 5.3650 + 21.8658 = 27.2308. Total profit for each company is \u2212J * 3/5 (N e ) \u2212 J * 4/6 (N e ) \u2212 J * 7/8 (N e ) = 12.1836 = J * 1/2 (N e ). In contrast, when companies cooperate, their production is much smaller J * 4/6 (C e ) << J * 4/6 (N e ) but due to a degree of monopolistic power they are able to obtain higher profits: J * 1/2 (C e ) = 12.8162."
        },
        {
            "section": "Example 7.10 of Engwerda (2005) With Multiple Equilibria",
            "text": "A two-player Example 7.10 from  can be rewritten using the notation outlined in Sect. 2 as follows:"
        },
        {
            "section": "Example 7.10 of Engwerda (2005) With Multiple Equilibria",
            "text": "Step T1: LQDG Toolbox Initialisation We can rewrite the above example to fit our standard model (30-31) by specifying: P 1 = P 2 = P 3 = P 4i = P 5 = P 6 = P 8 = 0, P 7 = A, P 9i = B i and P 10 = 0 0 ."
        },
        {
            "section": "Example 7.10 of Engwerda (2005) With Multiple Equilibria",
            "text": "Notice that in this example n = m 1 = 2, m 2 = 1 (and therefore m = 3) and b = 0. In the performance specification all parameters are zero for both players, except for \u03c6 (1,1),1 = 1; \u03c6 (2,2),1 = 0.1; \u03c6 (5,5),1 = 2; \u03c6 (5,6),1 = \u22121; \u03c6 (6,5),1 = \u22121; and \u03c6 (6,6),1 = 1, for the first player, and: \u03c6 (1,1),2 = 1; \u03c6 (2,1),2 = 1; \u03c6 (1,2),2 = 1; \u03c6 (2,2),2 = 2; and \u03c6 (7,7),2 = 1 for the second player. In this example, we specify the discount rate to be 0.",
            "ref_spans": [
                {
                    "type": "bibr",
                    "start": 233,
                    "text": "(6,",
                    "end": 236
                },
                {
                    "type": "bibr",
                    "start": 236,
                    "text": "5)",
                    "end": 238
                }
            ]
        },
        {
            "section": "Example 7.10 of Engwerda (2005) With Multiple Equilibria",
            "text": "Step T2: Model Validation by LQDG Toolbox With this input the toolbox next calculates the standard form (17-18). Clearly, (i) R ii > 0; (ii) (A, B i ) is stabilizable; and (iii) G is invertible (see Appendix A for a definition of G)."
        },
        {
            "section": "Example 7.10 of Engwerda (2005) With Multiple Equilibria",
            "text": "Step T3: Calculation of Equilibria Again, we will follow Algorithm 5 for the noncooperative case where matrix M is:"
        },
        {
            "section": "Example 7.10 of Engwerda (2005) With Multiple Equilibria",
            "text": "In"
        },
        {
            "section": "Example 7.10 of Engwerda (2005) With Multiple Equilibria",
            "text": "Step A4 of the algorithm, the toolbox determines the spectrum of M. Numerical calculations show that M = T J T \u22121 , where J is a diagonal matrix with entries \u03bb = {2; \u22122.2073; \u22121.0584; 2.0637; \u22120.1648; 1.4668} and "
        },
        {
            "section": "Example 7.10 of Engwerda (2005) With Multiple Equilibria",
            "text": "Matrix M has six different eigenvalues, where three of them are negative, i.e., \u03bb s = {\u22122.2073; \u22121.0584; \u22120.1648}. They correspond to eigenvectors T 2 , T 3 and T 5 . Since no eigenvalue has an algebraic multiplicity higher than one and there are no complex eigenvalues, the toolbox determines in Step A4.2.2.1 of the algorithm that there are at most 3 2 = 3 different equilibrium strategies that permit a feedback synthesis, i.e., As an example, we will calculate the equilibrium strategy that permits a feedback synthesis resulting from P 3 . To that end we factorise P 3 as follows: "
        },
        {
            "section": "Example 7.10 of Engwerda (2005) With Multiple Equilibria",
            "text": "where X, Y and Z are 2 \u00d7 2 matrices. We obtain then: The key question is whether it is possible to discriminate between multiple equilibria of a particular coalition structure. It is especially important in more complex games, where a practically intractable number of equilibria can be obtained. One of the widely accepted solution concepts to discriminate between various equilibria of a game is Pareto-domination. An equilibrium is said to be Pareto-dominated if it is possible to find another equilibrium in which all the players in the game will not be worse off and at least one of them will be better off. If option discriminate between equilibria using Pareto domination is chosen, the toolbox is going to report a list of Pareto-undominated equilibria. In the above case, it is clear that in the non-cooperative regime equilibrium N e 1 dominates the other two as J 1 (N e 1 ) < J 1 (N e 2 ) < J 1 (N e 3 ) and at the same time J 2 (N e 1 ) < J 2 (N e 2 ) < J 2 (N e 3 ). Consequently, apart from all the equilibria, the toolbox is going to report also a set of Pareto-undominated equilibria which consists of N e 1 . The particular advantage of the Pareto concept is based on the fact that it is in the interest of all the players to play only Pareto -undominated equilibria. However, the downside is that there can be a whole spectrum of them. Because of this, we propose another two ways to discriminate between multiple equilibria. The first method is based on the concept of so called social optimum, i.e., such an equilibrium is chosen that minimises the sum of all the players' losses, or, in our two-player game:"
        },
        {
            "section": "Example 7.10 of Engwerda (2005) With Multiple Equilibria",
            "text": "3 ) so the first equilibrium is chosen when this option is on. The other method we propose to discriminate between multiple equilibria refers to the adjustment speed of the equilibrium closed-loop system towards its long-term equilibrium, measured by the smallest absolute value of the eigenvalues of the A cl matrix that are located in the left half of the complex plane. In our example: Consequently, the toolbox will choose the equilibrium such that their graph subspace consists of eigenvector corresponding to \u22121.0584, \u22122.2073, i.e., N e 1 ."
        },
        {
            "section": "Example 7.12 of Engwerda (2005) With Complex Eigenvalues",
            "text": "A two-player Example 7.12 from  can be rewritten in terms of notation outlined in Sect. 2 as follows:"
        },
        {
            "section": "Example 7.12 of Engwerda (2005) With Complex Eigenvalues",
            "text": ", and N i = 0."
        },
        {
            "section": "Example 7.12 of Engwerda (2005) With Complex Eigenvalues",
            "text": "Step T1: LQDG Toolbox Initialisation We can rewrite the above example to fit our standard model (30-31) by specifying: P 1 = P 2 = P 3 = P 4i = P 5 = P 6 = P 8 = 0, P 7 = A, P 9i = B i and P 10 = 0 0 ."
        },
        {
            "section": "Example 7.12 of Engwerda (2005) With Complex Eigenvalues",
            "text": "Notice that in this example n = m 1 = m 2 = 2 (and therefore m = 4) and b = 0. In the performance specification, all parameters are zero for both players, except for \u03c6 (5,6),1 = r 12 , \u03c6 (6,5),1 = r 21 , \u03c6 (6,6),1 = r 22 , \u03c6 (1,1),2 = 1, \u03c6 (1,2),2 = \u2212 7 18 , \u03c6 (2,1),2 = \u2212 7 18 , \u03c6 (2,2),2 = 1 2 , \u03c6 (7,7),2 = s 11 , \u03c6 (7,8) for the first and second players, respectively. Also in this example, we specify the discount rate to be 0.",
            "ref_spans": [
                {
                    "type": "bibr",
                    "start": 166,
                    "text": "\u03c6 (5,6)",
                    "end": 173
                },
                {
                    "type": "bibr",
                    "start": 187,
                    "text": "(6,",
                    "end": 190
                },
                {
                    "type": "bibr",
                    "start": 190,
                    "text": "5)",
                    "end": 192
                },
                {
                    "type": "bibr",
                    "start": 206,
                    "text": "(6,",
                    "end": 209
                },
                {
                    "type": "bibr",
                    "start": 209,
                    "text": "6)",
                    "end": 211
                },
                {
                    "type": "bibr",
                    "start": 319,
                    "text": "(7,",
                    "end": 322
                },
                {
                    "type": "bibr",
                    "start": 322,
                    "text": "8)",
                    "end": 324
                }
            ]
        },
        {
            "section": "Example 7.12 of Engwerda (2005) With Complex Eigenvalues",
            "text": "Step T2: Model Validation by LQDG Toolbox With this input, the toolbox next calculates the standard form (17-18) and checks that both Q i and R i are positive definite, (A, B i ) are stabilizable and G is invertible."
        },
        {
            "section": "Example 7.12 of Engwerda (2005) With Complex Eigenvalues",
            "text": "Step T3: Calculation of Equilibria Again, we will follow Algorithm 5 for the noncooperative case. We have that:"
        },
        {
            "section": "Example 7.12 of Engwerda (2005) With Complex Eigenvalues",
            "text": "0.5000 0.0000 0.5000 \u22120.0389 0.5000 \u22120.0500 0.0000 0.2500 \u22120.0389 0.5000 \u22120.0500 0.3750 0.5000 0.5000 \u22120.5000 0.0000 0.0000 0.0000 0.5000 1.5000 0.0000 \u22120.2500 0.0000 0.0000 1.0000 \u22120.3889 0.0000 0.0000 \u22120.5000 0.0000 \u22120.3889 0.5000 0.0000 0.0000 0.0000 \u22120.2500"
        },
        {
            "section": "Example 7.12 of Engwerda (2005) With Complex Eigenvalues",
            "text": "In"
        },
        {
            "section": "Example 7.12 of Engwerda (2005) With Complex Eigenvalues",
            "text": "Step A4 of the algorithm the toolbox determines the spectrum of M. Numerical calculations show that M = T J T \u22121 , where J is a diagonal matrix with entries \u03bb = {\u22121.0004 + 0.0227i; \u22121.0004 \u2212 0.0227i; 0.2525; 0.4983; 1; 1} and Matrix M has two (complex) eigenvalues with a negative real part. Let x be the real part of the eigenvector corresponding with the eigenvalue \u22121.0004 + 0.0227i and y the imaginary part of this eigenvector"
        },
        {
            "section": "Example 7.12 of Engwerda (2005) With Complex Eigenvalues",
            "text": "x T := [0.1358, 0.4499, 0.1966, 0.5940 The with these actions corresponding closed-loop system matrix is then:",
            "ref_spans": [
                {
                    "type": "bibr",
                    "start": 2,
                    "text": "T := [0.1358, 0.4499, 0.1966, 0.5940",
                    "end": 38
                }
            ]
        },
        {
            "section": "Example 7.12 of Engwerda (2005) With Complex Eigenvalues",
            "text": "A cl := \u22121.0004 0.0222 \u22120.0231 \u22121.003 ."
        },
        {
            "section": "Example 7.12 of Engwerda (2005) With Complex Eigenvalues",
            "text": "The eigenvalues of this matrix are {\u22121.0004 + 0.0227i; \u22121.0004 \u2212 0.0227i}. The corresponding equilibrium costs are J 1 (N e ) = x T 0L 1 (N e )x 0 = 1 2 "
        },
        {
            "section": "Concluding Remarks",
            "text": "In this paper we considered a dynamic linear affine structural form model that is affected by different players who all like to minimise their own performance criterion that is a quadratic affine function of the variables occurring in the model. The costs are assumed to be discounted over time and the considered planning horizon by the players is assumed to be infinite. Under the assumption that in the minimisation of their performance the players do not cooperate, we presented both necessary and sufficient conditions under which this problem has a unique open-loop Nash equilibrium, a multiple but finite number of equilibria and or an infinite number of equilibria. A computational framework was provided for how one can numerically solve the problem. The algorithm has been implemented in a form of a numerical toolbox available on the internet. Users, starting from the structural model, can calculate for their specific application the equilibrium strategies and involved cost (if they exist). The toolbox also provides the possibility to calculate for different coalition structures whether the corresponding game will have an open-loop Nash solution. For that purpose the user has to define which coalition structures they like to analyze and what the relative importance is of each player within a certain coalition. We demonstrated both theoretically and numerically in a worked example on dynamic duopolistic competition the use of the toolbox. LQDG Toolbox is implemented in MATLAB. In particular, it uses some standard functions of MATLAB to calculate the eigenstructure of a (|N |n) \u00d7 (|N |n) matrix, where |N | is the number of involved players andn is the state dimension of the model. Since no additional efforts are taken to calculate this eigenstructure in a numerically efficient way, the practical use of the current toolbox is limited to some extent. This is because for either a large number of players and/or a large state dimension, the accuracy and efficiency is restricted by that of the implemented MATLAB functions. So for large N and/orn the user should look for an own code to implement the algorithm. Another way one might choose to calculate the equilibrium strategies is by using iterative algorithms. In the literature a number of iterative schemes have been suggested (see e.g. Engwerda 2007). A disadvantage of these schemes is that on the one hand they do not provide an answer to the question whether the game will have a unique equilibrium. On the other hand these schemes may converge without providing the appropriate equilibrium strategy. If this happens one is stuck with the question how to proceed.",
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b5",
                    "start": 2319,
                    "text": "Engwerda 2007)",
                    "end": 2333
                }
            ]
        },
        {
            "section": "Concluding Remarks",
            "text": "For the corresponding problem with a finite planning horizon, at least from a theoretical point, it is clear under which conditions there exists a unique equilibrium (see e.g. . From a computational point it is also clear how one can calculate this equilibrium. Either one can solve the involved set of nonlinear differential two-point boundary-value equations directly using standard MATLAB functions. Another possibility is to transform the involved set of Riccati differential equations (in the spirit of Reid (1972)) to a set of linear differential equations and then solve this set first (see e.g. Tabak 1975;Engwerda 2007). Since the calculations require the numerical solution of a set of (nonlinear) differential equations the dimension of the games for which one can still calculate the equilibrium actions (using standard MATLAB functions) without problems is usually smaller than in the infinite horizon case.",
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b17",
                    "start": 508,
                    "text": "Reid (1972)",
                    "end": 519
                },
                {
                    "type": "bibr",
                    "ref_id": "b21",
                    "start": 603,
                    "text": "Tabak 1975;",
                    "end": 614
                },
                {
                    "type": "bibr",
                    "ref_id": "b5",
                    "start": 614,
                    "text": "Engwerda 2007)",
                    "end": 628
                }
            ]
        },
        {
            "section": "Concluding Remarks",
            "text": "In the literature, also different equilibrium concepts have been studied for games considered above. Probably the most well-known is the feedback Nash concept. Unfortunately, for this case there are no general conditions known, except for the scalar case, i.e.,n = 1 (see e.g.  under which the game has a unique feedback Nash equilibrium."
        },
        {
            "section": "Concluding Remarks",
            "text": "Finally, we would like to mention that for discrete time systems much work has been done by Neck et al. in the development of the numerical software OPTGAME for the calculation of Nash equilibria in (non-)linear systems in case the performances of players are quadratic (see e.g. Neck et al. 2001).",
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b14",
                    "start": 280,
                    "text": "Neck et al. 2001",
                    "end": 296
                }
            ]
        },
        {
            "section": "Concluding Remarks",
            "text": "and set: \u03c6 (1,1),i = 5, \u03c6 (2,6),i = \u2212 1 2 , \u03c6 (3,n+3),i = \u03b1 1 , \u03c6 (n+2,n+3),i = \u03b1 1 , \u03c6 (3,2n+b+2),i = 1, \u03c6 (2n+b+i,2n+b+2),i = 2, \u03c6 (2n+b+i,2n+b+i),i = \u221a 3, and \u03c6 (2n+b+m+1,2n+b+m+1),i = 4.",
            "ref_spans": [
                {
                    "type": "bibr",
                    "start": 46,
                    "text": "(3,n+3)",
                    "end": 53
                },
                {
                    "type": "bibr",
                    "start": 88,
                    "text": "(3,2n+b+2)",
                    "end": 98
                }
            ]
        },
        {
            "section": "Concluding Remarks",
            "text": "Of course, instead of \u03c6 (2,6),i = \u2212 1 2 one might as well set \u03c6 (6,2),i = \u2212 1 2 or \u03c6 (2,6),i = \u2212 1 4 and \u03c6 (6,2),i = \u2212 1 4 or any other linear combination that sums up to \u2212 1 2 .",
            "ref_spans": [
                {
                    "type": "bibr",
                    "start": 107,
                    "text": "(6,",
                    "end": 110
                },
                {
                    "type": "bibr",
                    "start": 110,
                    "text": "2)",
                    "end": 112
                }
            ]
        },
        {
            "section": "Fig. 1",
            "text": "Scheme of the LQDG Toolbox software"
        },
        {
            "section": "Fig. 2",
            "text": "Main window of the User Input Interface LQDG Toolbox offers an opportunity to control and verify every important intermediate step of the solution process as well as the results obtained. The list of all the available options can be edited in the user interface."
        },
        {
            "section": "For",
            "text": "the parameters' values: a = 4, s = 0.1, c v = 1.5, \u03b8 = 0.05 and initial condition p 0 = [3] , the toolbox produces the following numerical values (N e non-cooperative and C e cooperative equilibrium between players): 1. The equilibrium actions: C L * (N e ) = 0.8042 \u22121.4385 0.8042 \u22121.4385 and C L * (C e ) = 0equations' solutions (see Eq. 29 in Step A5 of the algorithm) 10 :"
        },
        {
            "section": "Fig. 3",
            "text": "Control variables in the duopoly game (non-cooperative equilibrium)"
        },
        {
            "section": "Fig. 4",
            "text": "State variable and constant in the duopoly game (non-cooperative equilibrium)"
        },
        {
            "text": ", \u22120.0211, 0.1341] and y T := [0.4406, \u22120.1379, 0.0979, 0, 0.3279, \u22120.1964].The invariant subspace corresponding with eigenvalues {\u22121.0004 + 0.0227i; \u22121.0004 \u2212 0.0227i} is S =Im[x y]. According to Sect. 2, the unique equilibrium actions are u * i (t)"
        },
        {
            "text": "The set of coupled algebraic Riccati equations (21) has a strongly stabilizing solution, and 2. the two algebraic Riccati equations (20) have a (strongly) stabilizing solution."
        },
        {
            "text": "The set of coupled algebraic Riccati equations (21) has a stabilizing solution, and 2. the two algebraic Riccati equations (20) have a stabilizing solution. Moreover, ifP is stabilizing solution of (21), the actions (24) yield an open-loop Nash equilibrium that can be synthesised as a state feedback. The corresponding costs are given by (25)."
        },
        {
            "text": "Go to Step A5. A4.2.2: If s >n and: A4.2.2.1: If there are no complex eigenvalues then: \u2022 Calculate the set Cn \u03bb s of all stable eigenvalues that have the property where if \u03bb s i contains a complex eigenvalue it contains the complex conjugate of this eigenvalue too. \u2022 For every such combination \u03bb s"
        },
        {
            "text": "For both cases: go to Step A6. Otherwise proceed with Step A4.2. A4.2: All stable eigenvalues have an algebraic multiplicity of one. A4.2.1: Case s =n. Let \u03bb s denote the set of all stable eigenvalues and\u1e7c s denote the matrix which columns consist of the eigenvectors corresponding with these stable eigenvalues. A4.2.1.1: If \u03bb s contains no complex eigenvalues then the image of\u1e7c s represents then-dimensional sta- ble invariant subspace of M. Go to Step A5. A4.2.1.2: If \u03bb s contains complex eigenvalues then replace every pair of conjugate complex eigenvectors x + iy and x \u2212 iy in\u1e7c s by the real part of this eigenvector, x, and the imaginary part, y, respectively (see Example 6 below for further details). The image of this modified real matrix represents then then -dimensional stable invari- ant subspace of M.i ; (ii) go to Step A5. A4.2.2.2: If there are complex eigenvalues then: \u2022 Calculate the set Cn \u03bb s of alls! (s\u2212n)!n!n -element combinations from s"
        },
        {
            "text": "number of equilibria, intermediate matrices constructed during the solution process (H 1 , H 2 , H 3 and M) and eigenvalues; \u2022 output actions; \u2022 closed-loop matrices A cl ; \u2022 solution of Lyapunov equationsL i for every player; and \u2022 loss J i for every player."
        },
        {
            "text": "Example 6 Let N = {1, 2, 3, 4}. Listing all the possible partitions of the set N into coalitions, we obtain:[1234], [123|4], [124|3], [134|2], [1|234], [12|3|4], [13|2|4], [14|2|3], [23|1|4], [24|1|3], [1|2|34], [12|34], [13|24], [14|23], [1|2|3|4].Indeed, using simple recursive software to compute Dobinsky's formula we obtain: B 4 = 15. The number of possible partitions increases exponentially when n increases linearly. For |N | = 1, 2, . . . , 15, we have the following numbers of coalitions according to Dobinski's formula:"
        },
        {
            "text": "This matrix is invertible. P 1 is an element of P pos and \u03c3 (M| P 1 ) = {\u22122.2073, \u22121.0584}. In a similar way it can be verified that P 2 := Im[T 2 T 5 ] and P 3 := Im[T 3 T 5 ] are also appropriate graph subspaces. On the whole, all three M-invariant subspaces satisfy all conditions."
        },
        {
            "text": "A dedicated webpage will be available on-line soon. Mean while contact T. Michalak for obtaining the software. 2 A state-feedback strategy can be expressed as a linear function of the state variables of the model. Specifically, if we denote a vector of state variables by x, a state-feedback strategy can be written as F x, where F is a real valued function of appropriate dimension."
        },
        {
            "text": "See alsoEngwerda (2005, Chap. 7)."
        },
        {
            "text": "\u03c3 (H ) denotes the spectrum of matrix H ; C \u2212 = {\u03bb \u2208 C | Re(\u03bb) < 0}."
        },
        {
            "text": "Notice that we just present those equilibria that can be synthesized as a feedback strategy.6  With an equilibrium we mean everywhere in the algorithm an equilibrium that can be synthesized as a state feedback."
        },
        {
            "text": "See Chapter 5 ofPlasmans et al. (2006) for more details on this issue.8  For less than 6 players LQDG Toolbox has predefined sets of all coalition structures so that the user does not have to define them himself.",
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b16",
                    "start": 16,
                    "text": "Plasmans et al. (2006)",
                    "end": 38
                }
            ]
        },
        {
            "text": "Note that y(t) is not taken into account in vector z(t) in the cost criteria in Step T1 as y(t) := 0. Toolbox automatically extends matrices 1 and 2 by two appropriate zero vectors."
        },
        {
            "text": "Note that it is not possible to calculate the analytic solution of the corresponding Lyapunov equations, so it is not possible to calculate the analytic formulas for players' losses.12 See the toolbox manual for more details."
        },
        {
            "text": "Note that dummy players which corresponds to elements that involve a constant are always positioned last."
        },
        {
            "text": "Acknowledgments Tomasz Michalak acknowledges support from (a) the EPSRC under the project ALADDIN (Autonomous Learning Agents for Decentralised Data and Information Systems) project and is jointly funded by a BAE Systems and EPSRC strategic partnership; and (b) the FWO (Fonds voor Wetenschappelijk Onderzoek Vlaanderen, Belgium)."
        },
        {
            "section": "Appendix A: Notation",
            "text": "The following shorthand notation is used:"
        },
        {
            "section": "Appendix A: Notation",
            "text": "where we assume throughout that this matrix G is invertible. Furthermore:"
        },
        {
            "section": "Appendix A: Notation",
            "text": "Notice that:"
        },
        {
            "section": "Appendix A: Notation",
            "text": "where:"
        },
        {
            "section": "Appendix A: Notation",
            "text": "Matrices H 1 , H 2 , H 3 and G to construct the M are stored in the LQDG Toolbox output file. . . . . . . . . . . . \u03c6 (2n+b+m,2n+b+1)",
            "ref_spans": [
                {
                    "type": "bibr",
                    "start": 94,
                    "text": ". . . . . . . . . . . \u03c6 (2n+b+m,2n+b+1)",
                    "end": 133
                }
            ]
        },
        {
            "section": "Appendix C: Defining Linear Quadratic Loss Function in the Input File",
            "text": "If the user chooses to create by themselves the input file, the linear-quadratic loss of every player in the game should be defined as follows. According to the definition of vector z(t), i.e., z(t) := [ p(t)\u1e57(t) y(t) v(t) c] T , coefficient \u03c6 (in the loss of player i) that regards: (i) variable p 1\u2264k\u2264n has an index (k, .), i, i.e. , \u03c6 (k,.),i ; (ii) variable\u1e57 1\u2264k\u2264n has an index (n + k, .), i, i.e., \u03c6 (n+k,.),i ; (iii) variable y 1\u2264k\u2264b has an index (2n + k, .), i, i.e., \u03c6 (2n+k,.),i ; (iv) variable v 1\u2264k\u2264m has an index (2n + b + k, .), i, i.e., \u03c6 (2n+b+k,.),i ; and (v) variable c has an index (2n + b + m + 1, .), i, i.e., \u03c6 (2n+b+m+1,.),i ."
        },
        {
            "section": "Appendix C: Defining Linear Quadratic Loss Function in the Input File",
            "text": "For example, to define in the toolbox the following loss function of player i:"
        },
        {
            "section": "Appendix C: Defining Linear Quadratic Loss Function in the Input File",
            "text": "where \u03b1 1 is some parameter, we need to simplify it first into linear quadratic form:"
        },
        {
            "section": "Appendix C: Defining Linear Quadratic Loss Function in the Input File",
            "text": "i + 4 e \u2212\u03b8 t dt,"
        }
    ]
}