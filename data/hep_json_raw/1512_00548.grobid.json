{
    "level": "paragraph",
    "abstract": [
        {
            "text": "Asymmetry measurements are common in collider experiments and can sensitively probe particle properties.",
            "paragraph_rank": 2,
            "section_rank": 1
        },
        {
            "text": "Typically, data can only be measured in a finite region covered by the detector, so an extrapolation from the visible asymmetry to the inclusive asymmetry is necessary. Often a constant multiplicative factor is advantageous for the extrapolation and this factor can be readily determined using simulation methods. However, there is a potential, avoidable pitfall involved in the determination of this factor when the asymmetry in the simulated data sample is small. We find that to obtain a reliable estimate of the extrapolation factor, the number of simulated events required rises as the inverse square of the simulated asymmetry; this can mean that an unexpectedly large sample size is required when determining the extrapolation factor.",
            "paragraph_rank": 3,
            "section_rank": 1
        }
    ],
    "body_text": [
        {
            "text": "Introduction",
            "section_rank": 2
        },
        {
            "section": "Introduction",
            "text": "Measurements of production asymmetries have a long history at colliders , so examination of the experimental techniques used to make them is important. Most measurements are performed by first measuring the asymmetry within a restricted geometric region -the region covered by the detector -and then extrapolating to the inclusive region. In some cases an extrapolation based on a constant multiplicative factor is advantageous, but a potential pitfall exists in estimating the multiplicative factor via simulations.",
            "paragraph_rank": 4,
            "section_rank": 2
        },
        {
            "section": "Introduction",
            "text": "Because this sort of technique is widely applicable to experimental measurements, we explore it in detail here and identify where and why this potential pitfall arises.",
            "paragraph_rank": 5,
            "section_rank": 2
        },
        {
            "section": "Introduction",
            "text": "In general an asymmetry is defined with the partial cross sections, \u03c3 1 and \u03c3 2 , over two complementary kinematic or geometric regions,",
            "paragraph_rank": 6,
            "section_rank": 2
        },
        {
            "section": "Introduction",
            "text": "We can simplify our discussion by considering the regions defined by a single variable, x, while integrating over all other variables. In the case where x represents the pseudorapidity of a particle, which is directly related to the angle \u03b8 between an outgoing particle and the beam line, this produces a forward-backward asymmetry, for example for use in top-quark-pair production at the Fermilab Tevatron [1][2][3][4][5][6]. We define ",
            "paragraph_rank": 7,
            "section_rank": 2,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b0",
                    "start": 407,
                    "text": "[1]",
                    "end": 410
                },
                {
                    "type": "bibr",
                    "ref_id": "b1",
                    "start": 410,
                    "text": "[2]",
                    "end": 413
                },
                {
                    "type": "bibr",
                    "ref_id": "b2",
                    "start": 413,
                    "text": "[3]",
                    "end": 416
                },
                {
                    "type": "bibr",
                    "ref_id": "b3",
                    "start": 416,
                    "text": "[4]",
                    "end": 419
                },
                {
                    "type": "bibr",
                    "ref_id": "b4",
                    "start": 419,
                    "text": "[5]",
                    "end": 422
                },
                {
                    "type": "bibr",
                    "ref_id": "b5",
                    "start": 422,
                    "text": "[6]",
                    "end": 425
                }
            ]
        },
        {
            "section": "Introduction",
            "text": "However, when the entire range of x is not accessible due to kinematic constraints and/or the geometry of the detector, we can only measure",
            "paragraph_rank": 8,
            "section_rank": 2
        },
        {
            "section": "Introduction",
            "text": "x visible 0 dx d\u03c3 dx , and",
            "paragraph_rank": 9,
            "section_rank": 2
        },
        {
            "section": "Introduction",
            "text": "which define the visible asymmetry, A visible .",
            "paragraph_rank": 10,
            "section_rank": 2
        },
        {
            "section": "Introduction",
            "text": "There are multiple ways to extrapolate from A visible to A inclusive . The two simplest methods for doing this are employing an additive correction factor (C = A inclusive \u2212 A visible ) [22,23] or, a method that is commonly used, employing a multiplicative correction factor",
            "paragraph_rank": 11,
            "section_rank": 2,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b21",
                    "start": 186,
                    "text": "[22,",
                    "end": 190
                },
                {
                    "type": "bibr",
                    "ref_id": "b22",
                    "start": 190,
                    "text": "23]",
                    "end": 193
                }
            ]
        },
        {
            "section": "Introduction",
            "text": "where each are typically estimated using Monte Carlo (MC) simulations [1,2,24]. Each is applicable in different physical scenarios. While more sophisticated correction methods can be, and in some cases must be, employed [4][5][6][7][8][9][10][11][12][13][14][15][16][17][18][19][20][21]25], the multiplicative correction method has been very successful for tt leptonic asymmetry measurements, as the correction factor appears not to vary significantly with the inclusive asymmetry [24].",
            "paragraph_rank": 12,
            "section_rank": 2,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b0",
                    "start": 70,
                    "text": "[1,",
                    "end": 73
                },
                {
                    "type": "bibr",
                    "ref_id": "b1",
                    "start": 73,
                    "text": "2,",
                    "end": 75
                },
                {
                    "type": "bibr",
                    "ref_id": "b23",
                    "start": 75,
                    "text": "24]",
                    "end": 78
                },
                {
                    "type": "bibr",
                    "ref_id": "b3",
                    "start": 220,
                    "text": "[4]",
                    "end": 223
                },
                {
                    "type": "bibr",
                    "ref_id": "b4",
                    "start": 223,
                    "text": "[5]",
                    "end": 226
                },
                {
                    "type": "bibr",
                    "ref_id": "b5",
                    "start": 226,
                    "text": "[6]",
                    "end": 229
                },
                {
                    "type": "bibr",
                    "ref_id": "b6",
                    "start": 229,
                    "text": "[7]",
                    "end": 232
                },
                {
                    "type": "bibr",
                    "ref_id": "b7",
                    "start": 232,
                    "text": "[8]",
                    "end": 235
                },
                {
                    "type": "bibr",
                    "ref_id": "b8",
                    "start": 235,
                    "text": "[9]",
                    "end": 238
                },
                {
                    "type": "bibr",
                    "ref_id": "b9",
                    "start": 238,
                    "text": "[10]",
                    "end": 242
                },
                {
                    "type": "bibr",
                    "ref_id": "b10",
                    "start": 242,
                    "text": "[11]",
                    "end": 246
                },
                {
                    "type": "bibr",
                    "ref_id": "b11",
                    "start": 246,
                    "text": "[12]",
                    "end": 250
                },
                {
                    "type": "bibr",
                    "ref_id": "b12",
                    "start": 250,
                    "text": "[13]",
                    "end": 254
                },
                {
                    "type": "bibr",
                    "ref_id": "b13",
                    "start": 254,
                    "text": "[14]",
                    "end": 258
                },
                {
                    "type": "bibr",
                    "ref_id": "b14",
                    "start": 258,
                    "text": "[15]",
                    "end": 262
                },
                {
                    "type": "bibr",
                    "ref_id": "b15",
                    "start": 262,
                    "text": "[16]",
                    "end": 266
                },
                {
                    "type": "bibr",
                    "ref_id": "b16",
                    "start": 266,
                    "text": "[17]",
                    "end": 270
                },
                {
                    "type": "bibr",
                    "ref_id": "b17",
                    "start": 270,
                    "text": "[18]",
                    "end": 274
                },
                {
                    "type": "bibr",
                    "ref_id": "b18",
                    "start": 274,
                    "text": "[19]",
                    "end": 278
                },
                {
                    "type": "bibr",
                    "ref_id": "b19",
                    "start": 278,
                    "text": "[20]",
                    "end": 282
                },
                {
                    "type": "bibr",
                    "ref_id": "b20",
                    "start": 282,
                    "text": "[21]",
                    "end": 286
                },
                {
                    "type": "bibr",
                    "ref_id": "b24",
                    "start": 286,
                    "text": "25]",
                    "end": 289
                },
                {
                    "type": "bibr",
                    "ref_id": "b23",
                    "start": 481,
                    "text": "[24]",
                    "end": 485
                }
            ]
        },
        {
            "section": "Introduction",
            "text": "In this Article, we explore a simple example in which this condition holds, but use it to identify a pitfall in the estimation of the correction factor and explore ways in which this pitfall may be avoided by future analyses.",
            "paragraph_rank": 13,
            "section_rank": 2
        },
        {
            "section": "Introduction",
            "text": "For illustrative purposes, we consider a simplified model based on the measurement of the top leptonic forward-backward asymmetry at the Fermilab Tevatron [1][2][3][4][5][6]. It has been shown both that the differential cross section of leptons as a function of pseudorapidity can be well approximated as the sum of two Gaussian distributions with a common mean, and that the simple multiplicative extrapolation technique works in this case [24]. For the purposes of this study, we take the differential cross section d\u03c3/dx to be the simpler single-Gaussian distribution with unit width and a non-zero mean, \u00b5. As shown in Appendix A there is an approximately linear relationship between the asymmetry and \u00b5 for small values of \u00b5; we can refer to the behavior of \u00b5 and the asymmetry interchangeably. This simple model provides a foundation to understand the general behavior of multiplicative asymmetry extrapolation methods.",
            "paragraph_rank": 14,
            "section_rank": 2,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b0",
                    "start": 155,
                    "text": "[1]",
                    "end": 158
                },
                {
                    "type": "bibr",
                    "ref_id": "b1",
                    "start": 158,
                    "text": "[2]",
                    "end": 161
                },
                {
                    "type": "bibr",
                    "ref_id": "b2",
                    "start": 161,
                    "text": "[3]",
                    "end": 164
                },
                {
                    "type": "bibr",
                    "ref_id": "b3",
                    "start": 164,
                    "text": "[4]",
                    "end": 167
                },
                {
                    "type": "bibr",
                    "ref_id": "b4",
                    "start": 167,
                    "text": "[5]",
                    "end": 170
                },
                {
                    "type": "bibr",
                    "ref_id": "b5",
                    "start": 170,
                    "text": "[6]",
                    "end": 173
                },
                {
                    "type": "bibr",
                    "ref_id": "b23",
                    "start": 441,
                    "text": "[24]",
                    "end": 445
                }
            ]
        },
        {
            "section": "Introduction",
            "text": "A potential pitfall occurs when estimating the correction factor in Eq. (4) using MC samples with small asymmetries. Under certain quantifiable conditions, simulations can produce values of R that are misleading and far from the correct value. To make the discussion concrete, we pick a visible region for our single Gaussian distribution of \u22121.5 < x < 1.5, which gives the visible and inclusive regions as shown in Fig. 1, with the dashed lines indicating the boundaries. Given this particular description, to an excellent degree of approximation we find R = 0.7795 \u00b1 0.0005, as shown in Appendix A. Since analyses typically have more complicated distributions and use MC methods to estimate R, we begin this study by using MC samples to determine the distribution of the multiplicative factor, and illustrate the pitfalls when the simulated A inclusive goes to zero. We then compare this result with a closed form statistical solution to gain a better understanding of why this pitfall arises.",
            "paragraph_rank": 15,
            "section_rank": 2,
            "ref_spans": [
                {
                    "type": "figure",
                    "ref_id": "fig_1",
                    "start": 416,
                    "text": "Fig. 1",
                    "end": 422
                }
            ]
        },
        {
            "section": "Introduction",
            "text": "(arbitrary units) ",
            "paragraph_rank": 16,
            "section_rank": 2
        },
        {
            "text": "Monte Carlo Study",
            "section_rank": 3
        },
        {
            "section": "Monte Carlo Study",
            "text": "The most common method to determine the multiplicative correction factor is to simulate events according to a calculated differential cross section d\u03c3 dx , and calculate the correction factor R from the simulated events. We mimic this procedure by generating sets of random numbers according to a simplified differential cross section that takes the form of a Gaussian function with unit width and a mean \u00b5. Each random number represents an event, each set of random numbers is a pseudo-experiment (PE), and the number of events in each PE is denoted by N . From each PE, we can measure both A visible and A inclusive , and therefore R. Distributions of these three values can then be generated with an ensemble of PEs; the number of PEs used to generate these distributions is denoted by N PE . For example, in Fig. 1, we show two examples of differential cross sections (a single PE) with N = 10 6 and both \u00b5 = 0.0 and \u00b5 = 0.5. In Fig. 2, we show the distributions of A visible , A inclusive , and R for N PE = 10 6 , each with N = 10 6 and \u00b5 = 0.1. This value of \u00b5 is chosen as it corresponds to A inclusive \u2248 8%, which is a value we typically see in tt asymmetry measurements at the Tevatron [1][2][3][4][5][6].",
            "paragraph_rank": 17,
            "section_rank": 3,
            "ref_spans": [
                {
                    "type": "figure",
                    "ref_id": "fig_1",
                    "start": 812,
                    "text": "Fig. 1",
                    "end": 818
                },
                {
                    "type": "figure",
                    "ref_id": "fig_2",
                    "start": 933,
                    "text": "Fig. 2",
                    "end": 939
                },
                {
                    "type": "bibr",
                    "ref_id": "b0",
                    "start": 1196,
                    "text": "[1]",
                    "end": 1199
                },
                {
                    "type": "bibr",
                    "ref_id": "b1",
                    "start": 1199,
                    "text": "[2]",
                    "end": 1202
                },
                {
                    "type": "bibr",
                    "ref_id": "b2",
                    "start": 1202,
                    "text": "[3]",
                    "end": 1205
                },
                {
                    "type": "bibr",
                    "ref_id": "b3",
                    "start": 1205,
                    "text": "[4]",
                    "end": 1208
                },
                {
                    "type": "bibr",
                    "ref_id": "b4",
                    "start": 1208,
                    "text": "[5]",
                    "end": 1211
                },
                {
                    "type": "bibr",
                    "ref_id": "b5",
                    "start": 1211,
                    "text": "[6]",
                    "end": 1214
                }
            ]
        },
        {
            "section": "Monte Carlo Study",
            "text": "Since the simulation of a practical differential cross section is usually computationally expensive, the common practice is to simulate one PE with a modest N , usually on the order of 10 6 , and calculate R from it. In this analysis, the distribution of R from an ensemble of PEs reveals the quality of the estimation of R from a single PE. We note that in Fig. 2(c) the variation in R is small, with a width less than 1% of its mean value. With the simplified single-Gaussian differential cross section and the visible region specified above, R = 0.7798 which is consistent with the calculation in Appendix A.",
            "paragraph_rank": 18,
            "section_rank": 3,
            "ref_spans": [
                {
                    "type": "figure",
                    "ref_id": "fig_2",
                    "start": 358,
                    "text": "Fig. 2",
                    "end": 364
                }
            ]
        },
        {
            "section": "Monte Carlo Study",
            "text": "We next study the quality of the estimation of R as we vary the two factors, \u00b5 and N , which have significant impact on potential measurements: we examine what happens both in the limit of small simulation sample size and as \u00b5 \u2192 0 (or equivalently, as the asymmetry approaches zero). Specifically, we aim to understand whether the estimation of R is correct and what the uncertainty on that estimation is, the sample size needed to obtain a small uncertainty, and whether the value of R is constant for all values of \u00b5 when it is measured with a large sample size.",
            "paragraph_rank": 19,
            "section_rank": 3
        },
        {
            "section": "Monte Carlo Study",
            "text": "For \u00b5 = 0.1, R is well determined even with a fairly small value of N . much less Gaussian, and the peak of the distribution shifts. Thus, estimating the value of R from a single PE (as is typically done in realistic scenarios with more complicated differential cross sections) quickly leads to incorrect results. That is, there is a minimum allowable N , above which we can be confident in the estimation of R, and below which the estimation of R is no longer reliable, hence introducing a significant and asymmetric systematic uncertainty to the inclusive asymmetry measurement. This issue becomes even more pronounced as \u00b5, and thus the asymmetry, approaches 0.",
            "paragraph_rank": 20,
            "section_rank": 3
        },
        {
            "section": "Monte Carlo Study",
            "text": "Pseudo-Experiments / 0.01 As we note in the next section, the statistics behind this effect has been studied in great detail in the literature, and we see that the R distribution begins to approximate a Cauchy distribution [26]. To explain this, we note that the Cauchy distribution is the distribution of the ratio of two Gaussian random variables when the mean of the denominator is zero. When the mean of the Gaussian in the denominator is far enough away from zero, the distribution is Gaussian, and in the limit that it approaches zero, the distribution approaches the Cauchy distribution. The usual measurements of mean and standard deviation are not expected to give accurate and reliable results; indeed, for a true Cauchy distribution these two values are not defined.",
            "paragraph_rank": 21,
            "section_rank": 3,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b25",
                    "start": 223,
                    "text": "[26]",
                    "end": 227
                }
            ]
        },
        {
            "section": "Monte Carlo Study",
            "text": "To determine how many events we need to be able to make a reliable estimation of R, we define the fraction of PEs with R < 0.5:",
            "paragraph_rank": 22,
            "section_rank": 3
        },
        {
            "section": "Monte Carlo Study",
            "text": "The results here do not depend qualitatively on the choice of R < 0.5. This inequality is simply chosen to capture information on the lower tail of the R distribution; since R = 0.5 is many standard deviations below the mean from the large N answer, we can require f \u2248 0 for a reliable measurement of R. In Fig. 4 we show f varying with N for various values of \u00b5. For each value of \u00b5, we see the same basic structure. For low statistics (small N ) we see large values of f (typically above 20%). However, at some threshold, f drops quickly to zero. A qualitative definition of \"proper statistics\" is requiring N to be in the region where f \u223c 0, which we refer to as the \"high-statistics regime\"; otherwise we are in the \"low-statistics regime\". For \u00b5 = 0.1, f approaches zero at N \u223c 10 3 . This is consistent with what we see in Fig. 3; it is Gaussian for N = 10 , but begins approximating a Cauchy distribution at N \u223c 10 3 . And we can see that as \u00b5 approaches zero, the number of events that are needed to reliably estimate R increases. We quantify a measure of this \"threshold\" by defining f thresh = 0.13 and then measuring the corresponding N , which we denote as N thresh . This choice of f thresh is also somewhat arbitrary, as any value between 0% and \u2248 20% would capture the relationship between N thresh and \u00b5 that we seek, and thus the results do not depend on this choice. We examine how this value varies as \u00b5 \u2192 0. The result is shown in Fig. 5. As we can read off from the graph (and will show analytically in Sec. 3), \u00b5 is roughly proportional to 1/ \u221a N thresh . We note that A second conclusion is shown in Fig. 6, which shows distributions of R measured in the high-statistics regime for various values of \u00b5. We see that R converges to a constant number for small \u00b5, i.e. for this particular differential cross section model and visible x-range it is R = 0.7795. ",
            "paragraph_rank": 23,
            "section_rank": 3,
            "ref_spans": [
                {
                    "type": "figure",
                    "ref_id": "fig_4",
                    "start": 307,
                    "text": "Fig. 4",
                    "end": 313
                },
                {
                    "type": "figure",
                    "ref_id": "fig_3",
                    "start": 829,
                    "text": "Fig. 3",
                    "end": 835
                },
                {
                    "type": "figure",
                    "ref_id": "fig_5",
                    "start": 1451,
                    "text": "Fig. 5",
                    "end": 1457
                },
                {
                    "type": "figure",
                    "ref_id": "fig_6",
                    "start": 1623,
                    "text": "Fig. 6",
                    "end": 1629
                }
            ]
        },
        {
            "text": "Closed Form Statistical Study",
            "section_rank": 4
        },
        {
            "section": "Closed Form Statistical Study",
            "text": "In this section we use a closed form calculation to study the simulation size needed to get reliable estimates of the constant multiplicative term. As previously noted, as N decreases, the R distribution transitions from being Gaussian to approximating a Cauchy distribution. Since both A visible and A inclusive have approximately Gaussian distributions, the distribution of R begins to approximate a Cauchy distribution as \u00b5 approaches zero. Cauchy distributions have a peak and a width, but the mean and standard deviation are undefined [26], and, without special considerations, determining these values using numerical methods is precarious and can give wrong values.",
            "paragraph_rank": 24,
            "section_rank": 4,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b25",
                    "start": 540,
                    "text": "[26]",
                    "end": 544
                }
            ]
        },
        {
            "section": "Closed Form Statistical Study",
            "text": "In Fig. 7 we show contour plots of A visible vs. A inclusive in both the low-statistics and high-statistics regimes, where we have taken \u00b5 = 10 \u22123 and N PE = 10 6 , with N = 10 7 and N = 10 9 . We can think of our measurement of R as R = A visible /A inclusive = tan(\u03b8), where \u03b8 is the angle from the x-axis to the point on the plot measured from the origin. We can see that in the high-statistics regime, \u03b8 doesn't vary much and is measuring the true slope of A visible vs. MC methods will not reliably estimate R if the measurement of A inclusive (the denominator of R) from a single PE has a reasonable probability of being close to zero. Therefore, we need the simulation sample to be large enough such that A inclusive is well separated from zero. We require A inclusive to be at least k standard deviations away from zero, where k is typically a few, and calculate the minimum value of N that satisfies this constraint.",
            "paragraph_rank": 25,
            "section_rank": 4,
            "ref_spans": [
                {
                    "type": "figure",
                    "ref_id": "fig_7",
                    "start": 3,
                    "text": "Fig. 7",
                    "end": 9
                }
            ]
        },
        {
            "section": "Closed Form Statistical Study",
            "text": "To do this we start with the inequality",
            "paragraph_rank": 26,
            "section_rank": 4
        },
        {
            "section": "Closed Form Statistical Study",
            "text": "where \u03c3 A inclusive is the uncertainty of the measured value of A inclusive . Using standard error propagation, we calculate \u03c3 A inclusive to be",
            "paragraph_rank": 27,
            "section_rank": 4
        },
        {
            "section": "Closed Form Statistical Study",
            "text": "By plugging Eq. 7into Eq. (6) and solving for N , we obtain a lower bound on N given A inclusive that defines the high-statistics regime:",
            "paragraph_rank": 28,
            "section_rank": 4,
            "ref_spans": [
                {
                    "ref_id": "formula_11",
                    "start": 16,
                    "text": "7",
                    "end": 17
                }
            ]
        },
        {
            "section": "Closed Form Statistical Study",
            "text": "In the limit where A \u2192 0, we find N \u221d 1/(A inclusive ) 2 , which is consistent with what others have observed [27].",
            "paragraph_rank": 29,
            "section_rank": 4,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b26",
                    "start": 110,
                    "text": "[27]",
                    "end": 114
                }
            ]
        },
        {
            "section": "Closed Form Statistical Study",
            "text": "Since A inclusive \u221d \u00b5, this is equivalent to N \u221d 1/\u00b5 2 , and when k \u2248 2 we get a line that is consistent with the line shown in Fig. 5; any larger value of k will also give a good description of the high-statistics regime. While it is well known from similar calculations that a measurement of the uncertainty requires more statistics as A gets smaller, it is not as readily known just how important this is for use in MC correction techniques.",
            "paragraph_rank": 30,
            "section_rank": 4,
            "ref_spans": [
                {
                    "type": "figure",
                    "ref_id": "fig_5",
                    "start": 128,
                    "text": "Fig. 5",
                    "end": 134
                }
            ]
        },
        {
            "text": "Conclusions",
            "section_rank": 5
        },
        {
            "section": "Conclusions",
            "text": "We have studied the use of a simple multiplicative extrapolation method in asymmetry measurements.",
            "paragraph_rank": 31,
            "section_rank": 5
        },
        {
            "section": "Conclusions",
            "text": "This method has already been used for measurements made at the Fermilab Tevatron of the tt forwardbackward asymmetry, and has potential for wide use. Perhaps most important for future experiments is that, if the correction factor and its uncertainty are to be estimated from a simulated sample, more statistics than expected may be needed, especially when the simulation yields small asymmetry values. We find that the number of simulated events needed for reliable measurements rises as 1/(A inclusive ) 2 .",
            "paragraph_rank": 32,
            "section_rank": 5
        },
        {
            "text": "Appendix A Closed Form Numerical Validation",
            "section_rank": 6
        },
        {
            "section": "Appendix A Closed Form Numerical Validation",
            "text": "In this appendix we show both that the value of R is approximately constant for small values of \u00b5 and that A inclusive is linearly proportional to \u00b5 for our single-Gaussian model [24] using a closed form numerical solution. Specifically, we use the following equations, , and (10)",
            "paragraph_rank": 33,
            "section_rank": 6,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b23",
                    "start": 179,
                    "text": "[24]",
                    "end": 183
                }
            ]
        },
        {
            "section": "Appendix A Closed Form Numerical Validation",
            "text": "with \u03c3 = 1.0, to plot R as a function of \u00b5, as \u00b5 goes to 0. The result is shown in Fig. 8. While R is not exactly constant for all values of \u00b5, it does not vary significantly from its value of 0.7795 at \u00b5 = 0 in the regions that are typically relevant to experiments. For example, R only rises by 0.04% to 0.7798 at \u00b5 = 0.1 (corresponding to A inclusive = 7.97%). Similarly, R only rises by 1.10% at \u00b5 = 0.5 (corresponding to A inclusive = 22.2%). Thus, while assuming a constant multiplicative factor for the extrapolation is not perfect, the systematic uncertainty introduced from taking it to be constant is minimal for the region we are considering, and should be good for all but the highest precision measurements.",
            "paragraph_rank": 34,
            "section_rank": 6,
            "ref_spans": [
                {
                    "type": "figure",
                    "ref_id": "fig_9",
                    "start": 83,
                    "text": "Fig. 8",
                    "end": 89
                }
            ]
        },
        {
            "section": "Appendix A Closed Form Numerical Validation",
            "text": "From Eq. 9, we can see that this is the error function, thus we write that",
            "paragraph_rank": 35,
            "section_rank": 6,
            "ref_spans": [
                {
                    "ref_id": "formula_13",
                    "start": 9,
                    "text": "9",
                    "end": 10
                }
            ]
        },
        {
            "section": "Appendix A Closed Form Numerical Validation",
            "text": "where in the limit \u00b5 1, erf( \u00b5 \u221a 2 ) \u2248 2 \u03c0 \u00b5, and so we can see that A inclusive \u221d \u00b5. ",
            "paragraph_rank": 36,
            "section_rank": 6
        },
        {
            "text": "Figure 1 :",
            "section_rank": 7
        },
        {
            "section": "Figure 1 :",
            "text": "Figure 1: Two Gaussian distributions with unit width, with \u00b5 = 0.0 and \u00b5 = 0.5. The dashed lines at -1.5 and 1.5 indicate the boundaries for the visible region we consider here.",
            "paragraph_rank": 37,
            "section_rank": 7
        },
        {
            "text": "Figure 2 :",
            "section_rank": 8
        },
        {
            "section": "Figure 2 :",
            "text": "Figure 2: Distributions of A inclusive , A visible , and R in (a), (b), and (c) respectively. Each distribution has N PE = 10 6 with N = 10 6 and \u00b5 = 0.1.",
            "paragraph_rank": 38,
            "section_rank": 8
        },
        {
            "text": "Figure 3 :",
            "section_rank": 9
        },
        {
            "section": "Figure 3 :",
            "text": "Figure 3: Distributions of R with N PE = 10 6 and \u00b5 = 0.1, for N = 10 5 and N = 10 3 . As N decreases, the estimation of R becomes worse; therefore, obtaining the correct result with a single PE becomes statistically unreliable, and the systematic uncertainty becomes asymmetric and grows without bound.",
            "paragraph_rank": 39,
            "section_rank": 9
        },
        {
            "text": "Figure 4 :",
            "section_rank": 10
        },
        {
            "section": "Figure 4 :",
            "text": "Figure 4: A plot showing f , the fraction of PEs with R < 0.5, versus N . Each line represents a different choice of \u00b5 varying from \u00b5 = 0.1 to \u00b5 = 10 \u22129 . We highlight f thresh = 0.13, and note that as \u00b5 gets smaller, the value of N where the line crosses f thresh gets significantly larger.",
            "paragraph_rank": 40,
            "section_rank": 10
        },
        {
            "text": "Figure 5 :",
            "section_rank": 11
        },
        {
            "section": "Figure 5 :",
            "text": "Figure 5: A plot of N thresh versus \u00b5. Note that as \u00b5 \u2192 0, N thresh \u2192 \u221e.",
            "paragraph_rank": 41,
            "section_rank": 11
        },
        {
            "text": "Figure 6 :",
            "section_rank": 12
        },
        {
            "section": "Figure 6 :",
            "text": "Figure 6: Distributions of R with N PE = 10 6 , for various small values of \u00b5. In each case we have selected N large enough such that we are in the high-statistics regime to ensure a reliable estimation of R, and we see that R converges to 0.7795 in all cases, with small uncertainty.",
            "paragraph_rank": 42,
            "section_rank": 12
        },
        {
            "text": "Figure 7 :",
            "section_rank": 13
        },
        {
            "section": "Figure 7 :",
            "text": "Figure 7: Contour plots of A visible vs. A inclusive for N PE = 10 6 and \u00b5 = 10 \u22123 . We have set N = 10 7 and N = 10 9 in (a) and (b) respectively.",
            "paragraph_rank": 43,
            "section_rank": 13
        },
        {
            "text": "2 ) 1 . 5 0 2 2\u03c3 2 )",
            "section_rank": 14
        },
        {
            "section": "2 ) 1 . 5 0 2 2\u03c3 2 )",
            "text": "dx exp(\u2212 (x\u2212\u00b5) 2 2\u03c3 2 ) + exp(\u2212 (\u2212x\u2212\u00b5)",
            "paragraph_rank": 44,
            "section_rank": 14
        },
        {
            "text": "Figure 8 :",
            "section_rank": 15
        },
        {
            "section": "Figure 8 :",
            "text": "Figure 8: A plot of R determined analytically as a function of \u00b5. We can see here how in the limit of small \u00b5, R = 0.7795 and only rises by 0.04% when \u00b5 = 0.1.",
            "paragraph_rank": 45,
            "section_rank": 15
        },
        {
            "text": "Acknowledgements",
            "section_rank": 17
        },
        {
            "section": "Acknowledgements",
            "text": "The authors would like to thank the Mitchell Institute for Fundamental Physics and Astronomy and the Department of Physics and Astronomy at Texas A&M University, the DOE, and the Texas A&M Office of Graduate and Professional Studies for their support. We would also like to thank Matteo Cremonesi, Ricardo Eusebi, Ulrich Husemann, Doug Orbaker, Jonathan Rosner, and Willis Sakumoto for their useful feedback.",
            "paragraph_rank": 46,
            "section_rank": 17
        }
    ]
}