{
    "level": "paragraph",
    "abstract": [],
    "body_text": [
        {
            "text": "In this paper we present the results of the first low frequency all-sky search of continuous gravitational wave signals conducted on Virgo VSR2 and VSR4 data. The search covered the full sky, a frequency range between 20 Hz and 128 Hz with a range of spin-down between \u22121.0 \u00d7 10 \u221210 Hz/s and +1.5 \u00d7 10 \u221211 Hz/s, and was based on a hierarchical approach. The starting point was a set of short Fast Fourier Transforms (FFT), of length 8192 seconds, built from the calibrated strain data. Aggressive data cleaning, both in the time and frequency domains, has been done in order to remove, as much as possible, the effect of disturbances of instrumental origin. On each dataset a number of candidates has been selected, using the FrequencyHough transform in an incoherent step. Only coincident candidates among VSR2 and VSR4 have been examined in order to strongly reduce the false alarm probability, and the most significant candidates have been selected. The criteria we have used for candidate selection and for the coincidence step greatly reduce the harmful effect of large instrumental artifacts. Selected candidates have been subject to a follow-up by constructing a new set of longer FFTs followed by a further incoherent analysis, still based on the FrequencyHough transform. No evidence for continuous gravitational wave signals was found, therefore we have set a population-based joint VSR2-VSR4 90% confidence level upper limit on the dimensionless gravitational wave strain in the frequency range between 20 Hz and 128 Hz. This is the first all-sky search for continuous gravitational waves conducted, on data of ground-based interferometric detectors, at frequencies below 50 Hz. We set upper limits in the range between about 10 \u221224 and 2 \u00d7 10 \u221223 at most frequencies. Our upper limits on signal strain show an improvement of up to a factor of \u223c2 with respect to the results of previous all-sky searches at frequencies below 80 Hz. PACS numbers: 04.80Nn,95.55Ym,97.60Gb,07.05Kf ",
            "paragraph_rank": 1,
            "section_rank": 1,
            "ref_spans": [
                {
                    "type": "bibr",
                    "start": 1943,
                    "text": "PACS numbers: 04.80Nn,",
                    "end": 1965
                },
                {
                    "type": "bibr",
                    "start": 1965,
                    "text": "95.55Ym,",
                    "end": 1973
                },
                {
                    "type": "bibr",
                    "start": 1973,
                    "text": "97.60Gb,",
                    "end": 1981
                },
                {
                    "type": "bibr",
                    "start": 1981,
                    "text": "07.05Kf",
                    "end": 1988
                }
            ]
        },
        {
            "text": "I. INTRODUCTION",
            "section_rank": 2
        },
        {
            "section": "I. INTRODUCTION",
            "text": "Continuous gravitational wave signals (CW) emitted by asymmetric spinning neutron stars are among the sources currently sought in the data of interferometric gravitational wave detectors. The search for signals emit-ted by spinning neutron stars with no electromagnetic counterpart requires the exploration of a large portion of the source parameter space, consisting of the source position, signal frequency and signal frequency timederivative (spin-down). This kind of search, called allsky, cannot be based on fully coherent methods, as in targeted searches for known pulsars, see e.g. [1,2], because of the huge computational resources that would be required.",
            "paragraph_rank": 2,
            "section_rank": 2,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b59",
                    "start": 589,
                    "text": "[1,",
                    "end": 592
                },
                {
                    "type": "bibr",
                    "ref_id": "b60",
                    "start": 592,
                    "text": "2]",
                    "end": 594
                }
            ]
        },
        {
            "section": "I. INTRODUCTION",
            "text": "For this reason various hierachical analysis pipelines, based on the alternation of coherent and incoherent steps, have been developed [3], [4], [5], [6], [7]. They allow us to dramatically reduce the computational burden of the analysis, at the cost of a small sensitivity loss. In this paper we present the results of the first all-sky search for CW signals using the data of Virgo science runs VSR2 and VSR4 (discussed in Sec. III). The analysis has been carried out on the frequency band 20-128 Hz, using an efficient hierarchical analysis pipeline, based on the Fre-quencyHough transform [7]. No detection was made, so we established upper limits on signal strain amplitude as a function of the frequency. Frequencies below 50 Hz have never been considered in all-sky searches for CW signals, and the estimated joint sensitivity of Virgo VSR2 and VSR4 data is better than that of data from LIGO science runs S5 and S6 below about 60-70 Hz. Moreover, lower frequencies could potentially offer promising sources. Higher frequency signals would be in principle easier to detect because of their high signal amplitudes at fixed distance and ellipticity (see Eq. 5). On the other hand, neutron stars with no electromagnetic counterpart, which are the main target of an all-sky search, could have a spin rate distribution significantly different with respect to standard pulsars. Then, we cannot exclude that a substantial fraction of neutron stars emits gravitational waves with frequency in the range between 20 Hz and about 100 Hz. This is particularly true when considering young, unrecycled, neutron stars, which could be more distorted than older objects. Below about 20 Hz the detector sensitivity significantly worsens and the noise is highly non-stationary making the analysis pointless. A search at low frequency, as described below, could detect signals from a potentially significant population of nearby neutron stars.",
            "paragraph_rank": 3,
            "section_rank": 2,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b61",
                    "start": 135,
                    "text": "[3]",
                    "end": 138
                },
                {
                    "type": "bibr",
                    "start": 140,
                    "text": "[4]",
                    "end": 143
                },
                {
                    "type": "bibr",
                    "ref_id": "b63",
                    "start": 145,
                    "text": "[5]",
                    "end": 148
                },
                {
                    "type": "bibr",
                    "ref_id": "b64",
                    "start": 150,
                    "text": "[6]",
                    "end": 153
                },
                {
                    "type": "bibr",
                    "ref_id": "b65",
                    "start": 155,
                    "text": "[7]",
                    "end": 158
                },
                {
                    "type": "bibr",
                    "ref_id": "b65",
                    "start": 593,
                    "text": "[7]",
                    "end": 596
                }
            ]
        },
        {
            "section": "I. INTRODUCTION",
            "text": "The plan of the paper is as follows. In Sec. II we describe the kind of gravitational wave (GW) signal we are searching for. In Sec. III we discuss the Virgo detector performance during VSR2 and VSR4 runs. In Sec. IV we briefly recap the analysis procedure, referring the reader to [7] for more details. Section V is focused on the cleaning steps applied at different stages of the analysis. Section VI is dedicated to candidate selection, and Sec. VII to their clustering and coincidences. Section VIII deals with the follow-up of candidates surviving the coincidence step. Section IX is dedicated to validation tests of the analysis pipeline, by using hardware-injected signals in VSR2 and VSR4 data. In Sec. X a joint upper limit on signal strain amplitude is derived as a function of the search frequency. Conclusions and future prospects are presented in Sec. XI. Appendix A contains a list of the 108 candidates for which the follow-up has been done, along with their main parameters. Appendix B is devoted to a deeper analysis of the three outliers found. Appendix C contains the list of frequency intervals ex-cluded from the computation of the upper limits.",
            "paragraph_rank": 4,
            "section_rank": 2,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b65",
                    "start": 282,
                    "text": "[7]",
                    "end": 285
                }
            ]
        },
        {
            "text": "II. THE SIGNAL",
            "section_rank": 3
        },
        {
            "section": "II. THE SIGNAL",
            "text": "The expected quadrupolar GW signal from a nonaxisymmetric neutron star steadily spinning around one of its principal axes has a frequency f 0 twice the rotation frequency f rot , with a strain at the detector of [7,8] ",
            "paragraph_rank": 5,
            "section_rank": 3,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b65",
                    "start": 212,
                    "text": "[7,",
                    "end": 215
                },
                {
                    "type": "bibr",
                    "ref_id": "b66",
                    "start": 215,
                    "text": "8]",
                    "end": 217
                }
            ]
        },
        {
            "section": "II. THE SIGNAL",
            "text": "where taking the real part is understood and where \u03a6 0 is an initial phase. The signal's time-dependent angular frequency \u03c9(t) will be discussed below. The two complex amplitudes H + and H \u00d7 are given respectively by",
            "paragraph_rank": 6,
            "section_rank": 3
        },
        {
            "section": "II. THE SIGNAL",
            "text": "in which \u03b7 is the ratio of the polarization ellipse semiminor to semi-major axis, and the polarization angle \u03c8 defines the direction of the major axis with respect to the celestial parallel of the source (counterclockwise). The parameter \u03b7 varies in the range [\u22121, 1], where \u03b7 = 0 for a linearly polarized wave, while \u03b7 = \u00b11 for a circularly polarized wave (\u03b7 = 1 if the circular rotation is counterclockwise). The functions A +,\u00d7 describe the detector response as a function of time, with a periodicity of one and two sidereal periods, and depend on the source position, detector position and orientation on the Earth [8]. As discussed in [1], the strain described by Eq.(1) is equivalent to the standard expression (see e.g. [9])",
            "paragraph_rank": 7,
            "section_rank": 3,
            "ref_spans": [
                {
                    "type": "bibr",
                    "start": 260,
                    "text": "[\u22121, 1]",
                    "end": 267
                },
                {
                    "type": "bibr",
                    "ref_id": "b66",
                    "start": 619,
                    "text": "[8]",
                    "end": 622
                },
                {
                    "type": "bibr",
                    "ref_id": "b59",
                    "start": 640,
                    "text": "[1]",
                    "end": 643
                },
                {
                    "type": "bibr",
                    "ref_id": "b67",
                    "start": 727,
                    "text": "[9]",
                    "end": 730
                }
            ]
        },
        {
            "section": "II. THE SIGNAL",
            "text": "Here F + , F \u00d7 are the standard beam-pattern functions and \u03b9 is the angle between the star's rotation axis and the line of sight. The amplitude parameter",
            "paragraph_rank": 8,
            "section_rank": 3
        },
        {
            "section": "II. THE SIGNAL",
            "text": "depends on the signal frequency f 0 and on the source distance d; on I zz , the star's moment of inertia with respect to the principal axis aligned with the rotation axis; and on \u03b5, which is the fiducial equatorial ellipticity expressed in terms of principal moments of inertia as",
            "paragraph_rank": 9,
            "section_rank": 3
        },
        {
            "section": "II. THE SIGNAL",
            "text": "It must be stressed that it is not the fiducial ellipticity but the quadrupole moment Q 22 \u221d I zz \u03b5 that, in case of detection, can be measured independently of any assumption about the star's equation of state and moment of inertia (assuming the source distance can be also estimated). There exist estimates of the maximum ellipticity a neutron star can sustain from both elastic and magnetic deformations. In the elastic case, these maxima depend strongly on the breaking strain of the solid portion sustaining the deformation (see, e.g., [10], [11] for calculations for the crust) as well as on the star's structure and equation of state, and the possible presence of exotic phases in the stars interior (like in hybrid or strange quark stars, see, e.g., [12]). In the magnetic case, the deformation depends on the strength and configuration of the star's internal magnetic field (see, e.g., [13]). However, the actual ellipticity of a given neutron star is unknown-the best we have are observational upper limits. The relations between H 0 , \u03b7 and h 0 , \u03b9 are given, e.g., in [8]. In Eq. 1 the signal angular frequency \u03c9(t) is a function of time, therefore the signal phase",
            "paragraph_rank": 10,
            "section_rank": 3,
            "ref_spans": [
                {
                    "type": "bibr",
                    "start": 541,
                    "text": "[10]",
                    "end": 545
                },
                {
                    "type": "bibr",
                    "ref_id": "b69",
                    "start": 547,
                    "text": "[11]",
                    "end": 551
                },
                {
                    "type": "bibr",
                    "ref_id": "b70",
                    "start": 758,
                    "text": "[12]",
                    "end": 762
                },
                {
                    "type": "bibr",
                    "ref_id": "b71",
                    "start": 895,
                    "text": "[13]",
                    "end": 899
                },
                {
                    "type": "bibr",
                    "ref_id": "b66",
                    "start": 1080,
                    "text": "[8]",
                    "end": 1083
                }
            ]
        },
        {
            "section": "II. THE SIGNAL",
            "text": "is not that of a simple monochromatic signal. It depends on the rotational frequency and frequency derivatives of the neutron star, as well as on Doppler and propagation effects. In particular, the received Doppler-shifted frequency f (t) is related to the emitted frequency f 0 (t) by the well-known relation (valid in the non-relativistic approximation)",
            "paragraph_rank": 11,
            "section_rank": 3
        },
        {
            "section": "II. THE SIGNAL",
            "text": "where v is the detector velocity with respect to the Solar System barycenter (SSB),n is the unit vector in the direction to the source from the SSB and c is the light speed. A smaller relativistic effect, namely the Einstein delay, is not relevant for the incoherent step of the search described in Sec. IV, due to the use of short length FFTs, and has been therfore neglected. On the contrary, it has been taken into account in the candidate follow-up, described in Sec. VIII, specifically when a coherent analysis using candidate parameters is done. The intrinsic signal frequency f 0 (t) slowly decreases in time due to the source's spin-down, associated with the rotational energy loss following emission of electromagnetic and/or gravitational radiation. The spin-down can be described through a series expansion",
            "paragraph_rank": 12,
            "section_rank": 3
        },
        {
            "section": "II. THE SIGNAL",
            "text": "In general, the frequency evolution of a CW depends on 3+s parameters: position, frequency and s spin-down parameters. In the all-sky search described in this paper we need to take into account only the first spin-down (s = 1) parameter (see Sec. IV).",
            "paragraph_rank": 13,
            "section_rank": 3
        },
        {
            "text": "III. INSTRUMENTAL PERFORMANCE DURING VSR2 AND VSR4 RUNS",
            "section_rank": 4
        },
        {
            "section": "III. INSTRUMENTAL PERFORMANCE DURING VSR2 AND VSR4 RUNS",
            "text": "Interferometric GW detectors, such as LIGO [14], Virgo [15], and GEO [16], have collected years of data, from 2002 to 2011. For the analysis described in this paper we have used calibrated data from the Virgo VSR2 and VSR4 science runs. The VSR3 run was characterized by a diminished sensitivity level and poor data quality (highly non-stationary data, large glitch rate), and so was not included in this analysis. The VSR2 run began on July 7th, 2009 (21:00 UTC) and ended on January 8th, 2010 (22:00 UTC). The duty cycle was 80.4%, resulting in a total of \u223c 149 days of science mode data, divided among 361 segments. The data used in the analysis have been produced using the most up-to-date calibration parameters and reconstruction procedure. The associated systematic error amounts to 5.5% in amplitude and \u223c 50 mrad in phase [17].",
            "paragraph_rank": 14,
            "section_rank": 4,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b72",
                    "start": 43,
                    "text": "[14]",
                    "end": 47
                },
                {
                    "type": "bibr",
                    "ref_id": "b73",
                    "start": 55,
                    "text": "[15]",
                    "end": 59
                },
                {
                    "type": "bibr",
                    "ref_id": "b74",
                    "start": 69,
                    "text": "[16]",
                    "end": 73
                },
                {
                    "type": "bibr",
                    "ref_id": "b75",
                    "start": 831,
                    "text": "[17]",
                    "end": 835
                }
            ]
        },
        {
            "section": "III. INSTRUMENTAL PERFORMANCE DURING VSR2 AND VSR4 RUNS",
            "text": "The VSR4 run extended from June 3rd, 2011 (10:27 UTC) to September 5th, 2011 (13:26 UTC), with a duty factor of about 81%, corresponding to an effective duration of 76 days. Calibration uncertainties amounted to 7.5% in amplitude and (40 + 50f kHz ) mrad in phase up to 500 Hz, where f kHz is the frequency in kilohertz [18]. The uncertainty on the amplitude contributes to the uncertainty on the upper limit on signal amplitude, together with that coming from the finite size of the Monte Carlo simulation used to compute it (see Sec. X). A calibration error on the phase of this size can be shown to have a negligible impact on the analysis [1]. The low-frequency sensitivity of VSR4 was significantly better, up to a factor of 2, than that of previous Virgo runs, primarily due to the use of monolithic mirror suspensions, and nearly in agreement with the design sensitivity of the initial Virgo interferometer [15]. This represents a remarkable improvement considering that, being the gravitational wave strain proportional to the inverse of the distance to the source, a factor of 2 in sensitivity corresponds to an increase of a factor of 8 in the accessible volume of space (assuming a homogeneous source distribution). We show in Fig. 1 the average experimental strain amplitude spectral density for VSR2 and VSR4, in the frequency range 20-128 Hz, obtained by making an average of the periodograms (squared modulus of the FFTs) stored in the short FFT database (see next section).",
            "paragraph_rank": 15,
            "section_rank": 4,
            "ref_spans": [
                {
                    "type": "bibr",
                    "start": 42,
                    "text": "(10:27 UTC)",
                    "end": 53
                },
                {
                    "type": "bibr",
                    "start": 77,
                    "text": "(13:26 UTC)",
                    "end": 88
                },
                {
                    "type": "bibr",
                    "ref_id": "b76",
                    "start": 320,
                    "text": "[18]",
                    "end": 324
                },
                {
                    "type": "bibr",
                    "ref_id": "b59",
                    "start": 643,
                    "text": "[1]",
                    "end": 646
                },
                {
                    "type": "bibr",
                    "ref_id": "b73",
                    "start": 914,
                    "text": "[15]",
                    "end": 918
                },
                {
                    "type": "figure",
                    "start": 1238,
                    "text": "Fig. 1",
                    "end": 1244
                }
            ]
        },
        {
            "text": "IV. THE ANALYSIS PROCEDURE",
            "section_rank": 5
        },
        {
            "section": "IV. THE ANALYSIS PROCEDURE",
            "text": "All-sky searches are intractable using completely coherent methods because of the huge size of the parameter space, which poses challenging computational problems [19], [20]. Moreover, a completely coherent search would not be robust against unpredictable phase variations of the signal during the observation time.",
            "paragraph_rank": 16,
            "section_rank": 5,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b77",
                    "start": 163,
                    "text": "[19]",
                    "end": 167
                },
                {
                    "type": "bibr",
                    "ref_id": "b78",
                    "start": 169,
                    "text": "[20]",
                    "end": 173
                }
            ]
        },
        {
            "section": "IV. THE ANALYSIS PROCEDURE",
            "text": "For these reasons hierarchical schemes have been developed. The hierarchical scheme we have used for this anal- ysis has been described in detail in [7]. In this section we briefly recall the main steps. The analysis starts from the detector calibrated data, sampled at 4096 Hz. The first step consists of constructing a database of short Discrete Fourier Transforms (SFDB) [21], computed through the FFT algorithm (the FFT is just an efficient algorithm to compute Discrete Fourier Transforms (DFT), but for historical reasons and for consistency with previous papers we will use the term FFT instead of DFT). Each FFT covers the frequency range from 20 to 128Hz and is built from a data chunk of duration (coherence time) short enough such that if a signal is present, its frequency (modified by Doppler and spin-down) does not shift more than a frequency bin. The FFT duration for this search is 8192 seconds. This corresponds to a natural frequency resolution \u03b4f = 1.22 \u00d7 10 \u22124 Hz. The FFTs are interlaced by half and windowed with a Tukey window with a width parameter \u03b1 = 0.5 [22]. Before constructing the SFDB, short strong time domain disturbances are removed from the data. This is the first of several cleaning steps applied to the data (see Sec. V). The total number of FFTs for VSR2 run is 3896 and for VSR4 run is 1978.",
            "paragraph_rank": 17,
            "section_rank": 5,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b65",
                    "start": 149,
                    "text": "[7]",
                    "end": 152
                },
                {
                    "type": "bibr",
                    "ref_id": "b79",
                    "start": 374,
                    "text": "[21]",
                    "end": 378
                },
                {
                    "type": "bibr",
                    "ref_id": "b80",
                    "start": 1082,
                    "text": "[22]",
                    "end": 1086
                }
            ]
        },
        {
            "section": "IV. THE ANALYSIS PROCEDURE",
            "text": "From the SFDB we create a time-frequency map, called the peakmap [23]. This is obtained by selecting the most significant local maxima (which we call peaks) of the square root of equalized periodograms, obtained by dividing the periodogram by an auto-regressive average spectrum estimation. The threshold for peak selection has been chosen equal to \u221a 2.5 = 1.58 [7] which, in the ideal case of Gaussian noise, would correspond to a probability of selecting a peak of 0.0755. The peakmap is cleaned by removing peaks clearly due to disturbances, as explained in Sec. V. The peakmap is then corrected for the Doppler shift for the different sky directions, by shifting the frequency of the peaks by an amount corresponding to the variation the frequency of a signal coming from a given direction would be subject to at a given time. A coarse grid in the sky is used in this stage of the analysis. The grid is built using ecliptic coordinates, as described in [7]. Figure 2 shows the number of sky points (\"patches\") as a function of the frequency (in steps of 1 Hz), for both VSR2 and VSR4 analyses. The number of patches increases with the square of the frequency, and ranges from 2492 at 20 Hz to 81244 at 128 Hz. The total number of sky patches is N sky \u2248 3.5 \u00d7 10 6 .",
            "paragraph_rank": 18,
            "section_rank": 5,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b81",
                    "start": 65,
                    "text": "[23]",
                    "end": 69
                },
                {
                    "type": "bibr",
                    "ref_id": "b65",
                    "start": 362,
                    "text": "[7]",
                    "end": 365
                },
                {
                    "type": "bibr",
                    "ref_id": "b65",
                    "start": 957,
                    "text": "[7]",
                    "end": 960
                },
                {
                    "type": "figure",
                    "ref_id": "fig_1",
                    "start": 962,
                    "text": "Figure 2",
                    "end": 970
                }
            ]
        },
        {
            "section": "IV. THE ANALYSIS PROCEDURE",
            "text": "Each corrected peakmap is the input of the incoherent step, based on the FrequencyHough transform [7,24]. This is a very efficient implementation of the Hough transform (see [24] for efficiency tests and comparison with a different implementation) which, for every sky position, maps the points of the peakmap into the signal frequency/spin-down plane. In the Frequen-cyHough transform we take into account slowly varying non-stationarity in the noise and the varying detector sensitivity caused by the time-dependent radiation pattern [25], [26]. Furthermore, the frequency/spin-down plane is discretized by building a suitable grid [7]. As the transformation from the peakmap to the Hough plane is not computationally bounded by the size of the frequency bin (which only affects the size of the Hough map) we have increased the frequency resolution by a factor of 10, with respect to the natural step size \u03b4f , in order to reduce the digitalization loss, so that the actual resolution is \u03b4f H = \u03b4f /10 = 1.22 \u00d7 10 \u22125 Hz.",
            "paragraph_rank": 19,
            "section_rank": 5,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b65",
                    "start": 98,
                    "text": "[7,",
                    "end": 101
                },
                {
                    "type": "bibr",
                    "ref_id": "b82",
                    "start": 101,
                    "text": "24]",
                    "end": 104
                },
                {
                    "type": "bibr",
                    "ref_id": "b82",
                    "start": 174,
                    "text": "[24]",
                    "end": 178
                },
                {
                    "type": "bibr",
                    "ref_id": "b83",
                    "start": 536,
                    "text": "[25]",
                    "end": 540
                },
                {
                    "type": "bibr",
                    "start": 542,
                    "text": "[26]",
                    "end": 546
                },
                {
                    "type": "bibr",
                    "ref_id": "b65",
                    "start": 634,
                    "text": "[7]",
                    "end": 637
                }
            ]
        },
        {
            "section": "IV. THE ANALYSIS PROCEDURE",
            "text": "We have searched approximately over the spin-down range [\u22121.0 \u00d7 10 \u221210 , +1.5 \u00d7 10 \u221211 ] Hz/s. This choice has been dictated by the need to not increase too much the computational load of the analysis while, at the same time, covering a range of spin-down values including the values measured for most known pulsars. Given the spin-down bin width scales as T \u22121 obs (\u03b4\u1e1f = \u03b4f /T obs ), this implies a different number of spin-down values for the two data sets: N sd =16 for VSR2 with a resolution of \u03b4\u1e1f = 7.63 \u00d7 10 \u221212 Hz/s, and N sd =9 for VSR4 with a resolution of \u03b4\u1e1f = 1.5 \u00d7 10 \u221211 Hz/s. The corresponding minimum gravitational-wave spin-down age, defined as \u03c4 min (f ) = f /4N sd \u03b4\u1e1f (where 4N sd \u03b4\u1e1f is the absolute value of the maximum spin-down we have searched over), is a function of the frequency, going from \u223c1600 yr to \u223c10200 yr for VSR2 and from \u223c1500 yr to \u223c9700 yr for VSR4. These values are large enough that only the first order spin-down is needed in the analysis [7]. In Tab. I some quantities referring to the FFTs and peakmaps of VSR2 and VSR4 data sets are given. Tab. II contains a summary of the main parameters of the coarse step, among which the exact spin-down range considered for VSR2 and VSR4 analyses. For each run T obs is the run duration, Tstart is the run start epoch, TFFT is the FFT time length, and N peaks is the number of peaks in the peakmap, after applying all the vetoing procedures.",
            "paragraph_rank": 20,
            "section_rank": 5,
            "ref_spans": [
                {
                    "type": "bibr",
                    "start": 359,
                    "text": "\u22121",
                    "end": 361
                },
                {
                    "type": "bibr",
                    "ref_id": "b65",
                    "start": 979,
                    "text": "[7]",
                    "end": 982
                }
            ]
        },
        {
            "section": "IV. THE ANALYSIS PROCEDURE",
            "text": "For a given sky position, the result of the Fre-quencyHough transform is a histogram in the signal frequency/spin-down plane, called the Hough map. The most significant candidates, i.e. the bins of the Hough map with the highest amplitude, are then selected using an effective way to avoid being blinded by particularly disturbed frequency bands (see Sec. VI and [7]). For each coarse (or raw) candidate a refined search, still based on the FrequencyHough, is run again on the neighborhood of the candidate parameters and the final first-level refined candidates are selected. The refinement results in a reduction of the digitalization effects, that is the sensitivity loss due to the use of a discrete grid in the parameter space. With regard to the frequency, which was already refined at the coarse step, no further over-resolution occurs. For the spin-down we have used an over-resolution factor K\u1e1f =6, i.e., the coarse interval between the spindown of each candidate and the next value (on both sides) is divided in 6 pieces. The refined search range includes 2 K\u1e1f =12 bins on the left of the coarse original value, and (2 K\u1e1f \u2212 1)=11 bins on the right, so that two coarse bins are covered on both sides. This choice is dictated by the fact that the refinement is also done in parallel for the position of the source and, because of parameter correlation, a coarse candidate could be found with a refined spin-down value outside the original coarse bin. Using an over-resolution factor K\u1e1f =6 is a compromise between the reduction of digitization effects and the increase of computational load.",
            "paragraph_rank": 21,
            "section_rank": 5,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b65",
                    "start": 363,
                    "text": "[7]",
                    "end": 366
                }
            ]
        },
        {
            "section": "IV. THE ANALYSIS PROCEDURE",
            "text": "The refinement in the sky position for every candidate is performed by using a rectangular region centered at the candidate coordinates. The distance between the estimated latitude (longitude) and the next latitude (longitude) point in the coarse grid is divided into K sky = 5 points, so that 25 sky points are considered in total, see discussion in Sec. IX-C of [7].",
            "paragraph_rank": 22,
            "section_rank": 5,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b65",
                    "start": 364,
                    "text": "[7]",
                    "end": 367
                }
            ]
        },
        {
            "section": "IV. THE ANALYSIS PROCEDURE",
            "text": "From a practical point of view, the incoherent step of the analysis has been done by splitting the full parameter space to be explored in several independent jobs. Each job covered a frequency band of 5 Hz, the full spin-down range, and a portion of the sky (the extent of which depended on the frequency band and was chosen to maintain balanced job durations). The full set of jobs was run on the European Grid Infrastructure  II. Summary of the main parameters for the coarse step of the analysis. \u03b4fH is the frequency bin, N f is the number of frequency bins in the analyzed band, \u03b4\u1e1f is the spin-down bin, N sd is the number of spin-down steps, \u2206\u1e1f is the range of spin-down covered in the analysis, \u03c4min is the corresponding minimum spin-down age, N sky is the total number of sky patches.",
            "paragraph_rank": 23,
            "section_rank": 5
        },
        {
            "section": "IV. THE ANALYSIS PROCEDURE",
            "text": "(http://www.egi.eu/). Overall, about 7000 jobs were run, with a total computational load of about 22,000 CPU\u2022hours.",
            "paragraph_rank": 24,
            "section_rank": 5
        },
        {
            "section": "IV. THE ANALYSIS PROCEDURE",
            "text": "Candidates found in the analysis of VSR2 and VSR4 data are then clustered, grouping together those occupying nearby points in the parameter space. This is done to improve the computational efficiency of the next steps of the analysis. In order to significantly reduce the false alarm probability, coincidences are required among clusters of candidates obtained from the the two data sets. The most significant coincident candidates are subject to a follow-up with greater coherence time, in order to confirm or discard them. Candidate selection and analysis are described in some detail in Sec. VI-VIII.",
            "paragraph_rank": 25,
            "section_rank": 5
        },
        {
            "text": "V. DATA CLEANING",
            "section_rank": 6
        },
        {
            "section": "V. DATA CLEANING",
            "text": "Time and frequency domain disturbances in detector data affect the search and, if not properly removed, can significantly degrade the search sensitivity, in the worst case blinding the search at certain times or in certain frequency bands. The effects can vary depending on the nature and amplitude of the disturbance. As described in [7], we apply cleaning procedures to safely remove such disturbances or reduce their effect, without contaminating a possible CW signal. The disturbances can be catalogued as \"time domain glitches\", which enhance the noise level of the detector in a wide frequency band; \"spectral lines of constant frequency\", in most cases of known origin, like calibration lines or lines whose origin has been discovered by studying the behaviour of the detector and the surrounding environment, or \"spectral wandering lines\", where the frequency of the disturbance changes in time (often of unknown origin and present only for a few days or even hours). Time-domain glitches are removed during the construction of the SFDB.",
            "paragraph_rank": 26,
            "section_rank": 6,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b65",
                    "start": 335,
                    "text": "[7]",
                    "end": 338
                }
            ]
        },
        {
            "section": "V. DATA CLEANING",
            "text": "Spectral wandering lines and spectral lines of constant frequency are removed from the peakmaps [7]. Removal of spectral wandering lines (composed by peaks occurring at varying frequencies) is based on the construction of a histogram of low resolution (both in time and in frequency) peakmap entries, which we call the \"gross histogram\". Based on a study on VSR2 and VSR4 data, we have chosen a time resolution of 12 hours and a frequency resolution of 0.01 Hz. In this way any true CW signal of plausible strength would be completely confined within one bin, but would not significantly contribute to the histogram, avoiding veto. As an example, Fig. 3 shows the time-frequency plot of the peaks removed by the \"gross histogram\" cleaning procedure on VSR2 and VSR4 data and Fig. 4 shows the histogram of the removed peaks, using a 10 mHz bin width, again both for VSR2 and VSR4 data.",
            "paragraph_rank": 27,
            "section_rank": 6,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b65",
                    "start": 96,
                    "text": "[7]",
                    "end": 99
                },
                {
                    "type": "figure",
                    "start": 647,
                    "text": "Fig. 3",
                    "end": 653
                },
                {
                    "type": "figure",
                    "start": 775,
                    "text": "Fig. 4",
                    "end": 781
                }
            ]
        },
        {
            "section": "V. DATA CLEANING",
            "text": "A second veto, aimed at removing lines of constant frequency, is based on the \"persistency\" analysis of the peakmaps, defined as the ratio between the number of FFTs in which a given line was present and the total number of analyzed FFTs. The vetoing procedure consisted of histogramming the frequency bins and setting a reasonable threshold to select lines to be removed. To evaluate the veto threshold, we have used a \"robust\" statistic, described in Appendix D of [7], which is based on the median rather than the mean, which is much less affected by tails in the distribution. The resulting threshold on the persistency is of the order of 10%. Figure 5 shows the lines of constant frequency vetoed on the basis of the persistency, given on the ordinate axis. In this way we have vetoed 710 lines for VSR2 and 1947 lines for VSR4, which we know to be more disturbed than VSR2. The \"gross\" histogram veto reduced the total number of peaks by 11.3% and 13.1% for VSR2 and VSR4 respectively. The persistency veto brings the fraction of removed peaks to 11.5 % and 13.5 % for VSR2 and VSR4 respectively. We end up with a total number of peaks which is 191,771,835 for VSR2 and 93,896,752 for VSR4. The use of the adaptivity in the FrequencyHough transform acts to reduce the effect of some of the remaining peaks, those corresponding to an average level of the noise higher than usual or to times when the detectorsource relative position is unfavourable.",
            "paragraph_rank": 28,
            "section_rank": 6,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b65",
                    "start": 467,
                    "text": "[7]",
                    "end": 470
                },
                {
                    "type": "figure",
                    "ref_id": "fig_3",
                    "start": 648,
                    "text": "Figure 5",
                    "end": 656
                }
            ]
        },
        {
            "section": "V. DATA CLEANING",
            "text": "For testing purposes, ten simulated CW signals, called hardware injections, have been injected during VSR2 and VSR4 runs, by properly acting on the mirrors control system (see Sec. IX for more details). While we have developed a method to effectively remove HIs from the peakmap, it has not been applied for the present analysis as their presence allowed testing the whole analysis chain. We will show results from HIs analysis in Sec. IX.",
            "paragraph_rank": 29,
            "section_rank": 6
        },
        {
            "text": "VI. CANDIDATE SELECTION",
            "section_rank": 7
        },
        {
            "section": "VI. CANDIDATE SELECTION",
            "text": "As outlined in Sec. IV, after the FrequencyHough transform has been computed for a given dataset, the first level of refined candidates is selected. Their number  is chosen as a compromise between a manageable size and an acceptable sensitivity loss, as explained in Sect. IX of [7]. Moreover, candidates are selected in a way to reduce as much as possible the effect of disturbances. Let us describe the selection procedure. The full frequency range is split into 1 Hz sub-bands, each of which is analyzed separately and independently. Following the reasoning in Sec. VIII of [7], we fixed the total number of candidates to be selected in each run to N cand = 10 8 . We distribute them in frequency by fixing their number in each 1 Hz band, N cand, i , where i = 20, . . . , 127, in such a way to have the same expected number of coincidences in all the bands. Moreover, for each given frequency band we have decided to have the same expected number of coincidences for each sky cell. Then, the number of candidates to be selected for each 1 Hz band and for each sky cell is given by N sky cand, i = N cand, i /N sky, i , where N sky, i is the number of sky patches in the ith frequency band. Since N cand, i linearly increases with the frequency (see Eq. 48 in [7]) and, for a given frequency band, the number of points in the sky increases with the square of the band maximum frequency, we have that the number of candidates selected per sky patch decreases with frequency.",
            "paragraph_rank": 30,
            "section_rank": 7,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b65",
                    "start": 279,
                    "text": "[7]",
                    "end": 282
                },
                {
                    "type": "bibr",
                    "ref_id": "b65",
                    "start": 577,
                    "text": "[7]",
                    "end": 580
                },
                {
                    "type": "bibr",
                    "ref_id": "b65",
                    "start": 1263,
                    "text": "[7]",
                    "end": 1266
                }
            ]
        },
        {
            "section": "VI. CANDIDATE SELECTION",
            "text": "We now focus on some practical aspects of the procedure. As previously explained, we have fixed the size of the frequency bands to 1 Hz, the total number of candidates to be selected in each of them (N cand, i ) and the number of candidates in each cell of the sky (N sky cand, i ). We have now the problem of being affected by the presence of disturbances of unknown origin. They could still pollute sub-bands in the ith band, even after performing all the cleaning steps described in Sec.V. We have designed a procedure for candidate selection for this purpose [7]. For each sky cell, we divide the ith band into n sb = N sky cand, i sub-bands, and select the most significant candidate in each of them, i.e. the bin in the Hough map with the highest amplitude. In this way a uniform selection of candidates is done in every band and the contribution of possible large disturbances is strongly reduced. A further step consists of selecting the \"second order\" candidates. Once the most significant candidate in each sub-band has been selected, an empirically established exclusion region of \u00b14 frequency bins around it is imposed. This means we do not select any further candidate which is within that range from the loudest candidate in the sub-band. In this way we reduce the probability to select more candidates which could be due to the same disturbance. We now look for the second loudest candidate in that sub-band and select it only if it is well separated in frequency from the first one, by at least \u00b18 frequency bins. In this way, we expect to select two candidates per sub-band in most cases and to have one candidate only when the loudest candidate is due to a big disturbance, or a particularly strong hardware injection. Results are shown in Fig. 6  (left), which gives the number of candidates selected in every 1 Hz band and in Fig. 6 (right), which gives the number of candidates selected in every 1 Hz band and for each sky patch. In the end we have 194,457,048 candidates for VSR2 and 193,855,645 for VSR4, which means that we have selected also the \"second order\" candidates in \u223c 96% of the cases.",
            "paragraph_rank": 31,
            "section_rank": 7,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b65",
                    "start": 563,
                    "text": "[7]",
                    "end": 566
                },
                {
                    "type": "figure",
                    "ref_id": "fig_4",
                    "start": 1758,
                    "text": "Fig. 6  (left)",
                    "end": 1772
                },
                {
                    "type": "figure",
                    "ref_id": "fig_4",
                    "start": 1846,
                    "text": "Fig. 6 (right)",
                    "end": 1860
                }
            ]
        },
        {
            "text": "VII. CANDIDATE CLUSTERING AND COINCIDENCE",
            "section_rank": 8
        },
        {
            "section": "VII. CANDIDATE CLUSTERING AND COINCIDENCE",
            "text": "We expect that nearly all the candidates selected in the analysis of a dataset will be false, arising from noise. In order to reduce the false alarm probability, coincidences among the two sets of candidates, found in VSR2 and VSR4 analysis, have been required. Indeed, given the persistent nature of CWs, a candidate in a dataset due to a real signal will (approximately) have the same parameters in another dataset, even if this covers a different time span. If a candidate is found to be coincident among the two datasets, it will be further analyzed as described in Sec. VIII.",
            "paragraph_rank": 32,
            "section_rank": 8
        },
        {
            "section": "VII. CANDIDATE CLUSTERING AND COINCIDENCE",
            "text": "In fact, due to computational reasons, candidates from each dataset are clustered before making coincidences. A cluster is a collection of candidates such that the distance d in the parameter space among any two is smaller than a threshold d clust . We have used an empirically chosen value d clust = 2. Each candidate is defined by a set of 4 parameters: position in ecliptic coordinates (\u03bb, \u03b2), frequency f and spin-down\u1e1f . Therefore, for two given candidates with",
            "paragraph_rank": 33,
            "section_rank": 8
        },
        {
            "section": "VII. CANDIDATE CLUSTERING AND COINCIDENCE",
            "text": "respectively, we define their distance as",
            "paragraph_rank": 34,
            "section_rank": 8
        },
        {
            "section": "VII. CANDIDATE CLUSTERING AND COINCIDENCE",
            "text": "Here k \u03bb = |\u03bb 2 \u2212\u03bb 1 |/\u03b4\u03bb is the difference in number of bins between the ecliptic longitudes of the two candidates, and \u03b4\u03bb = (\u03b4\u03bb 1 + \u03b4\u03bb 2 )/2 is the mean value of the width of the coarse bins in the ecliptic longitude for the two candidates (which can vary, as the resolution in longitude depends on the longitude itself), and similarly for the other terms. We find 94,153,784 clusters for VSR2 and 38,953,404 for VSR4. Once candidates of both datasets have been clustered, candidate frequencies are referred to the same epoch, which is the beginning of VSR4 run. This means that the frequency of VSR2 candidate are shifted according to the corresponding spin-down value. Then coincidence requirements among clusters are imposed as follows. For each cluster of the first set, a check is performed on clusters in the second set. First, a cluster of the second set is discarded if its parameters are not compatible with the trial cluster in the first set. As an example, if the maximum frequency found in a cluster is smaller than the minimum frequency found in the other one, they cannot be coincident.",
            "paragraph_rank": 35,
            "section_rank": 8
        },
        {
            "section": "VII. CANDIDATE CLUSTERING AND COINCIDENCE",
            "text": "For each candidate of the first cluster of a potentially coincident pair, the distance from the candidates of the second cluster is computed. If a distance smaller than d coin = 2 is found, then the two clusters are considered coincident: the distance between all the pairs of candidates of the two clusters is computed and the pair with the smallest distance constitutes a pair of coincident candidates. This means that each pair of coincident clusters produces just one pair of coincident candidates. The choice d coin = 2, based on a study of software-injected signals, allows us to reduce the false alarm probability and is robust enough against the fact that true signals can be found with slightly different parameters in the two datasets. The total number of coincidences we found is 3,608,192. At this point, coincident candidates are divided into bands of 0.1 Hz and subject to a ranking procedure in order to select the most significant ones. Let N be the number of coincident candidates in a given 0.1 Hz band. Let us order them in descending order of Hough map amplitude (i.e. from the highest to the smallest), separately for VSR2 and VSR4. We assign a rank to each of them, which is 1/N to the highest and 1 to the smallest. We have then two sets of ranks, one for VSR2 candidates and one for VSR4 candidates. Now we make the product of the ranks of coincident candidates. The smallest possible value is 1/N 2 , if a pair of coincident candidates has the highest Hough amplitude in both VSR2 and VSR4, while the largest possible value is 1, if a pair of coincident candidates has the smallest amplitude in both VSR2 and VSR4. For each 0.1 Hz band we select the candidates having the smallest rank product. We chose 0.1 Hz wide bands as a good compromise between having a statistic large enough in every band and reducing the effect of (strong) noise outliers in wider bands, as will be clear in the following. With this choice we have 1080 coincident candidates over the band  At this point, among the ten candidates in ten consecutive 0.1 Hz bands we chose the most significant one, i.e. that having the smallest rank product, ending up with 108 candidates, one per 1 Hz band, which will be subject to a follow-up procedure, as described in the next section. Note that due to the cleaning steps we apply, especially those on the peakmaps, more disturbed 0.1 Hz bands tend to have a smaller number of candidates and then a smaller number of coincidences N . This reduces the chance that the most significant candidate in a 1 Hz band comes from a particularly noisy 0.1 Hz interval. The number of candidates selected at this stage depends on the amount of available computing resources and is constrained by the amount of time the analysis will take. Figure 7 shows the rank product for the final 108 candidates as a function of their frequency. The two smallest values corresponds to the hardware-injected signals at 52.8 Hz and 108.3 Hz. In Tab. V the main parameters of the 108 selected candidates are given. They have been ordered as a function of the value of the ranking parameter, starting from the most significant one.",
            "paragraph_rank": 36,
            "section_rank": 8,
            "ref_spans": [
                {
                    "type": "figure",
                    "start": 2764,
                    "text": "Figure 7",
                    "end": 2772
                }
            ]
        },
        {
            "text": "VIII. CANDIDATE FOLLOW-UP",
            "section_rank": 9
        },
        {
            "section": "VIII. CANDIDATE FOLLOW-UP",
            "text": "The follow-up procedure consists of several steps applied to each of the 108 selected candidates. The basic idea is that of repeating the previous incoherent analysis with an improved sensitivity, which can be obtained by increasing the time baseline of the FFTs. In order to do this a coherent step, using the candidate parameters, is done separately for the two runs at first. This is based on the same analysis pipeline used for targeted searches [1], [2], [27], [28] and the output is a down-sampled (at 1 Hz) time series where the Doppler effect, the spin-down and the Einstein delay for a source, having the same parameters as the candidate, have been corrected. A final cleaning stage is also applied, by removing the non-Gaussian tail of the data distribution.",
            "paragraph_rank": 37,
            "section_rank": 9,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b59",
                    "start": 450,
                    "text": "[1]",
                    "end": 453
                },
                {
                    "type": "bibr",
                    "ref_id": "b60",
                    "start": 455,
                    "text": "[2]",
                    "end": 458
                },
                {
                    "type": "bibr",
                    "ref_id": "b85",
                    "start": 460,
                    "text": "[27]",
                    "end": 464
                },
                {
                    "type": "bibr",
                    "ref_id": "b86",
                    "start": 466,
                    "text": "[28]",
                    "end": 470
                }
            ]
        },
        {
            "section": "VIII. CANDIDATE FOLLOW-UP",
            "text": "From these data, a new set of longer FFTs is computed, from chunks of data of duration 81,920 seconds, which is ten times longer than in the initial step of the analysis. This procedure preserves true signals with parameters slightly different from those of the candidate, but within the uncertainty window because of the partial Doppler and spin-down correction just applied. If we assume that the true signal has a frequency different from that of the candidate by a coarse bin 1/T FFT , and a sky position also shifted by a coarse sky bin, the maximum allowed FFT duration can be numerically evaluated using Eq. 36 in [7], and is of about 290,000 seconds, significantly larger than our choice.",
            "paragraph_rank": 38,
            "section_rank": 9,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b65",
                    "start": 621,
                    "text": "[7]",
                    "end": 624
                }
            ]
        },
        {
            "section": "VIII. CANDIDATE FOLLOW-UP",
            "text": "From the set of FFTs a new peakmap is also computed, selecting peaks above a threshold of \u221a 5.5 \u2243 2.34 on the square root of the equalized spectra, significantly higher than that (1.58) initially used (see Sec. IV). This Rank product for the final 108 candidates, which will be subject to the follow-up procedure. The two candidates with smallest rank product, indicated by filled circles, correspond to two hardware-injected signals.",
            "paragraph_rank": 39,
            "section_rank": 9
        },
        {
            "section": "VIII. CANDIDATE FOLLOW-UP",
            "text": "is justified by the fact that a signal present in the data, and strong enough to produce a candidate, would contribute similarly when lengthening the FFT (by a factor of 10) while the noise in a frequency bin decreases by a factor of 10 (in energy). In fact, a threshold of 2.34 is a very conservative choice which, nevertheless, reduces the expected number of noise peaks by a factor of 20 with respect to the initial threshold.",
            "paragraph_rank": 40,
            "section_rank": 9
        },
        {
            "section": "VIII. CANDIDATE FOLLOW-UP",
            "text": "At this point the peakmaps computed for the two runs are combined, so that their peaks cover a total observation time of 788.67 days, from the beginning of VSR2 to the end of VSR4 run. Before applying the incoherent step, a grid is built around the current candidate. The frequency grid is built with an over-resolution factor of 10, as initially done, so that \u03b4f = 1/81920 \u00d7 10 = 1.22 \u00d7 10 \u22126 Hz, and covers 0.1 Hz around the candidate frequency. The grid on the spin-down is computed with a step 10 times smaller than the coarse step of the shorter run (VSR4), and covering \u00b11 coarse step, so that 21 spin-down bins are considered. Finally, a grid of 41 by 41 sky points (1681 in total) is built around the candidate position, covering \u00b10.75 times the dimension of the coarse patch (whose extension actually depends on the position in the sky and on the candidate frequency). For every sky point the peakmap is Doppler corrected by shifting each peak by an amount corresponding to the Doppler shift, and a FrequencyHough transform is computed. This means that for each candidate 41\u00d741=1681 FrequencyHough transforms are computed. The loudest candidate, among the full set of FrequencyHough maps, is then selected.",
            "paragraph_rank": 41,
            "section_rank": 9
        },
        {
            "section": "VIII. CANDIDATE FOLLOW-UP",
            "text": "The starting peakmap is now corrected using the parameters of the loudest candidate and projected on the frequency axis. On the resulting histogram we search for significant peaks. This is done by taking the maximum of the histogram over a search band covering a range of \u00b12 coarse bins around the candidate frequency. The rest of the 0.1 Hz band is used to estimate the background noise: it is similarly divided in sub-intervals covering 4 coarse bins and the loudest candidate is taken in each of them. In total we have 408 sub-intervals. In the frequentist approach the significance of a candidate is measured by the p-value, that is the probability that a candidate as significant as that, or more, is due to noise. The smaller is the computed p-value and less consistent is the candidate with noise. We estimate a p-value associated to the candidate by computing the fraction of sub-bands in which the loudest peak is larger than that in the search band. The smaller is the p-value, the higher is the candidate significance. If the p-value is smaller than 1% the candidate can be considered as \"interesting\", namely it is not fully compatible with noise, and will be subject to a deeper scrutiny, looking at the consistency of the candidate between the two runs and, possibly, extending the analysis to other data sets or applying a further step of follow-up with a longer coherence time.",
            "paragraph_rank": 42,
            "section_rank": 9
        },
        {
            "section": "VIII. CANDIDATE FOLLOW-UP",
            "text": "As an example, Fig. 8 shows the peakmap histogram for the candidate at frequency 121.81 Hz, in which no significant peak is found around the candidate frequency (identified by the vertical dashed line). The corresponding p-value is \u223c0.44.",
            "paragraph_rank": 43,
            "section_rank": 9,
            "ref_spans": [
                {
                    "type": "figure",
                    "ref_id": "fig_6",
                    "start": 15,
                    "text": "Fig. 8",
                    "end": 21
                }
            ]
        },
        {
            "section": "VIII. CANDIDATE FOLLOW-UP",
            "text": "In contrast, Fig. 10 shows the peakmap histograms for the candidates at 52.80 Hz (left), corresponding to hardware injection pulsar 5, and the candidate at 108.85 Hz (right), corresponding to hardware injection pulsar 3. In each case a highly significant peak is visible at the frequency of the candidate (in fact it is the largest peak in the whole 0.1 Hz band around it), as detailed in Sec.",
            "paragraph_rank": 44,
            "section_rank": 9,
            "ref_spans": [
                {
                    "type": "figure",
                    "start": 13,
                    "text": "Fig. 10",
                    "end": 20
                }
            ]
        },
        {
            "text": "IX.",
            "section_rank": 10
        },
        {
            "section": "IX.",
            "text": "The p-value for the 108 candidates is given in the last column of Tab. V. In Fig. 9 the p-value for the 108 candidates is shown as a function of candidate frequency. Both the hardware injections have the lowest possible pvalue (equal to 1/408=2.45\u00d710 \u22123 ), that is the highest possible significance, providing a good check that the full analysis pipeline works correctly.",
            "paragraph_rank": 45,
            "section_rank": 10,
            "ref_spans": [
                {
                    "type": "figure",
                    "ref_id": "fig_7",
                    "start": 77,
                    "text": "Fig. 9",
                    "end": 83
                }
            ]
        },
        {
            "section": "IX.",
            "text": "Moreover, there are three outliers, which are candidates not associated to injected signals, having a p-value very close or below the 1% threshold we have established. These three candidates have undergone further analysis in order to increase their significance or to discard them as possible GW signals. In fact, as described in Appendix B, all of them appear to be incompatible with GW signals.",
            "paragraph_rank": 46,
            "section_rank": 10
        },
        {
            "text": "IX. HARDWARE INJECTION RECOVERY",
            "section_rank": 11
        },
        {
            "section": "IX. HARDWARE INJECTION RECOVERY",
            "text": "Ten simulated CW signals have been continuously injected in the Virgo detector during VSR2 and VSR4 runs, by actuating on the mirror control system with the aim of testing analysis pipelines. Two of these hardware injections have frequency below 128 Hz and have been considered in this work: pulsar 5, with a frequency of about 52.8 Hz, and pulsar 3, at about 108.85 Hz. In Tab. III parameters relevant for the current analysis are given. These signals are strong enough to appear as the most significant candidates in the final list (Tab. V). As such they have been also subject to the follow-up procedure. In Fig. 10 we show the final peakmap histograms for the candidate corresponding to pulsar 5 (left) and pulsar 3 (right), where in both cases a very high peak is clearly visible in correspondence of the signal frequency. This is reflected in the high significance level shown in Tab. V. Tab. IV contains the estimated parameters for the hardware injections, together with the associated error, which is the difference with respect to the injected values. For both signals the parameters are well recovered with an improved accuracy thanks to the followup.",
            "paragraph_rank": 47,
            "section_rank": 11,
            "ref_spans": [
                {
                    "type": "figure",
                    "start": 611,
                    "text": "Fig. 10",
                    "end": 618
                }
            ]
        },
        {
            "text": "X. RESULTS",
            "section_rank": 12
        },
        {
            "section": "X. RESULTS",
            "text": "As all the 106 non-injection candidates appear to be consistent with what we would expect from noise only, we proceed to compute an upper limit on the signal amplitude in each 1-Hz band between 20 Hz and 128 Hz, with the exception of the band 52-53 Hz and 108-109 Hz, which correspond to the two hardware injections (in fact, see point 2. in this section, there are also several noisy sub-bands which have been excluded a posteriori from the computation of the upper limit). We follow a standard approach adopted for all-sky CW searches [4], [6] and detailed in the following. Many (of the order of 200,000 in our case) simulated signals are injected into the data, and the signal strain amplitude is determined such that 90 % of the signals (or the desired confidence level) are detected, and are more significant than the original candidate found in the actual analysis of the same  frequency band.",
            "paragraph_rank": 48,
            "section_rank": 12,
            "ref_spans": [
                {
                    "type": "bibr",
                    "start": 537,
                    "text": "[4]",
                    "end": 540
                },
                {
                    "type": "bibr",
                    "ref_id": "b64",
                    "start": 542,
                    "text": "[6]",
                    "end": 545
                }
            ]
        },
        {
            "section": "X. RESULTS",
            "text": "In other words, for each 1-Hz band we generate 100 simulated signals in the time domain, with unitary amplitude and having frequency and the other parameters drawn from a uniform distribution: the spin-down within the search range, position over the whole sky, polarization angle \u03c8 between \u2212 \u03c0 2 and \u03c0 2 , and inclination of the rotation axis with respect to the line of observation, cos \u03b9, between \u22121 and 1. The time series containing the signals are then converted in a set of FFTs, with duration 8192 seconds, the same used for the analysis, and covering the band of 1 Hz. These \"fake signal FFTs\" are multiplied by an amplitude factor and summed to the original data FFTs. This is repeated using of the order of 10-15 different amplitudes, chosen in order to be around the expected 90% confidence level upper limit.",
            "paragraph_rank": 49,
            "section_rank": 12
        },
        {
            "section": "X. RESULTS",
            "text": "For each set of 100 injections an analysis is done using the all-sky search code over a reduced parameter space around each injection, consisting of a frequency band of \u00b10.2 Hz around the injection frequency, the same spindown range used in the production analysis, and 9 sky points around the coarse grid point nearest to the injection position. We have verified, by injecting software simulated signals into Virgo VSR2 and VSR4 data, that for signal amplitudes around the approximately expected upper limit values this volume is sufficiently large to contain all the candidates produced by a given signal, and at the same time is small enough to make the procedure reasonably fast. In fact, the frequency and position of the injections are chosen in such a way that any two signals are separated by at least 0.005 Hz and their sky search regions do not overlap. The output of this stage is, for each injected signal, a set of candidates from VSR2 data and another set of candidates from VSR4. In the production analysis, candidates of each run are clustered before making coincidences. For the computation of the upper limit the clustering cannot be applied because of the density of signals which would strongly affect the cluster composition introducing a mixing of candidates belonging to different injections. We recall that the candidate clustering has been introduced in the production analysis with the main purpose to reduce the computational cost of the coincidence step. However, for the upper limit computation, a direct coincidence step among candidates is still affordable. Hence, for every candidate found in VSR2 we determine, if it exists, the nearest coincident candidate found in VSR4 with a distance smaller than 2. The coincident candidates are then ranked using the same procedure described in Sec.VII, and the most significant one is selected. Then, for each injected signal amplitude we have at most 100 coincident candidates. They are compared to the candidate found in the actual analysis in the same 1-Hz band, in order to count the fraction \"louder\" than that. Two issues arise here and must be properly addressed.",
            "paragraph_rank": 50,
            "section_rank": 12
        },
        {
            "section": "X. RESULTS",
            "text": "1. In principle, the comparison between the candidates found after injections and the actual analysis candidate should be done on the basis of their ranking. In fact this cannot be done because the numerical values of the ranking depend on the number of candidates present in the 1-Hz band, and this number is very different in the two cases, as the injection analysis is performed over a smaller portion of the parameter space. We have then decided to make the comparison using the Hough amplitudes of the candidates: a candidate found in the injection analysis is considered \"louder\" if the amplitudes of its parent candidates, found in VSR2 and VSR4 data, are both larger than the corresponding amplitudes of the parents of the actual analysis candidate. This will tend to slightly overestimate the upper limit.",
            "paragraph_rank": 51,
            "section_rank": 12
        },
        {
            "section": "X. RESULTS",
            "text": "2. We have verified that in some bands the upper limit can be heavily affected by the presence of gaps in the starting peakmap, namely frequency bands in which the number of peaks is significantly smaller than in the rest of the band. As an example, in Fig. 11 the peakmap peak distribution is shown for a \"bad\" frequency band between 35 and 36 Hz in VSR2 data, containing gaps, and for a good one, between 126 and 127 Hz. The gaps are the result of the various cleaning steps applied to the data, and the injections that, for a given amplitude, have frequency overlapping with a gap will not able, in most cases, to produce detectable candidates because the amplitude in the Hough map near the signal frequency is reduced by the smaller data contribution. As a consequence, the upper limit tends to be significantly worse with respect to the case in which the gaps are not relevant. To cope with this issue we opted to exclude from the computation of the upper limit the parts of a 1-Hz band that correspond to gaps. This procedure excludes the injections that happen to lie within the excluded region. In this way we obtain better results, which are valid only in a sub-interval of the 1-Hz band.",
            "paragraph_rank": 52,
            "section_rank": 12,
            "ref_spans": [
                {
                    "type": "figure",
                    "ref_id": "fig_8",
                    "start": 253,
                    "text": "Fig. 11",
                    "end": 260
                }
            ]
        },
        {
            "section": "X. RESULTS",
            "text": "In Appendix C we report all the intervals excluded from the upper limit computations. In total they cover about 8.6 Hz (out of the 108 Hz analyzed).",
            "paragraph_rank": 53,
            "section_rank": 12
        },
        {
            "section": "X. RESULTS",
            "text": "For each 1-Hz band, and for each injected signal amplitude, once we have computed the fraction of candidates louder than the actual analysis candidate, the pair of amplitudes that are nearest, respectively from above and from below, to the 90% confidence level are used as starting point of a new round, in which a new set of signals with amplitudes between those values are injected until the final confidence level of 90% is reached. Overall, of the order of 2 \u00d7 10 5 signals have been injected in both VSR2 and VSR4 data. The final accuracy of the upper limit depends on the number of injections actually used and on the quality of the data in the considered 1-Hz band. By repeating of the order of 10 times the upper limit computation in a few selected bands, we have verified that the upper limits have an accuracy better than \u223c5% for \"bad\" bands and better than about 1% for \"good\" bands, in any case smaller than the amplitude uncertainty due to the data calibration error (Sec. III). In Fig. 12 the upper limits on signal strain as a function of the frequency are plotted. The values that are valid on just a portion of the corresponding 1-Hz band are labeled by a filled circle. A rough comparison with other all-sky searches result shows that our upper limits are better than those established, for instance, by the Einstein@Home pipeline on LIGO S5 data [4] for frequencies below \u223c80 Hz (however, in [4] upper limits are computed every 0.5 Hz, instead of 1 Hz). A useful plot to understand the astrophysical reach of the search is shown in Fig. 13. The various sets of points give the relation between the signal frequency derivative and the signal frequency for sources detectable at various distances, assuming their spin-down to be due solely to the emission of gravitational radiation (these types of sources are also referred to as gravitars [29]). For instance, considering a source at a distance of 100 parsecs and emitting a CW signal with a frequency of 80Hz, it would be detectable if its frequency derivative was larger, in modulus, than about 2.8 \u00d7 10 \u221212 Hz/s. On the same plot curves of constant ellipticity are also shown. The above source example would have an ellipticity larger than about 2 \u00d7 10 \u22125 . From this plot we can conclude that our search would have been sensitive enough to detect all the gravitars within about 400 parsecs, emitting a signal with frequency above about 60 Hz and with spin-down age larger than about 4500 years. Also, all the gravitars within about 50 parsecs, emitting a signal with frequency above 20 Hz and with spin-down age larger than about 1500 years would have been detected.",
            "paragraph_rank": 54,
            "section_rank": 12,
            "ref_spans": [
                {
                    "type": "figure",
                    "ref_id": "fig_1",
                    "start": 995,
                    "text": "Fig. 12",
                    "end": 1002
                },
                {
                    "type": "bibr",
                    "start": 1365,
                    "text": "[4]",
                    "end": 1368
                },
                {
                    "type": "bibr",
                    "start": 1411,
                    "text": "[4]",
                    "end": 1414
                },
                {
                    "type": "figure",
                    "ref_id": "fig_9",
                    "start": 1551,
                    "text": "Fig. 13",
                    "end": 1558
                },
                {
                    "type": "bibr",
                    "ref_id": "b87",
                    "start": 1858,
                    "text": "[29]",
                    "end": 1862
                }
            ]
        },
        {
            "text": "XI. CONCLUSIONS",
            "section_rank": 13
        },
        {
            "section": "XI. CONCLUSIONS",
            "text": "In this paper we have described a low-frequency allsky search for CW signals, performed using data from the Virgo VSR2 and VSR4 runs. This is the first allsky search for isolated stars with GW frequencies below 50 Hz. We have applied a hierarchical procedure, in which the incoherent step is based on the Frequen-cyHough transform. Particular care has been placed on cleaning the data of known and unknown instrumental disturbances, before selecting potentially interesting CW candidates. The criteria used to select candidates have been designed in such a way to avoid sensitivity to any single noise disturbance. For each candidate surviving a coincidence step, a follow-up procedure has been applied in order to reject or confirm it. Three candidates have been found to be most significant, but their potential GW origin has been ruled out after a deeper analysis. Having found no evidence for CW signals, a 90% confidence level upper limit on signal strain has been computed over the full frequency band. Our upper limit improves upon prior results below \u223c80 Hz and the astrophysical reach of the search is interesting. Our search would have been able to detect all the gravitars within about 400 parsecs from the Earth, spinning at frequencies above 30 Hz and with spin-down age larger than about 4500 years. It would have been also able to detect all the gravitars within about 50 parsecs from the Earth, spinning at frequencies above 10 Hz and with spin-down age larger than about 1500 years. This analysis pipeline will be applied to data of Advanced LIGO and Virgo detectors. Given their improved sensitivities, the chance to detect CW signals by spinning neutron stars will be significantly better. Detection of such signals would provide insights into the internal structure, history formation and demography of neutron stars.",
            "paragraph_rank": 55,
            "section_rank": 13
        },
        {
            "text": "Appendix A: Candidate list",
            "section_rank": 14
        },
        {
            "section": "Appendix A: Candidate list",
            "text": "In the following table the main parameters of the final 108 candidates are given. They are ordered according to decreasing rank values. histograms are plotted both for the two runs separately and for the joint analysis. We clearly see that the outlier is strong in VSR4 data but not in VSR2 data. Given the characteristics of the two runs this is not what we expect for a real GW signal. The expected ratio between the peakmap histogram heights for the two data runs can be estimated for nominal signal strengths [7] and is about 1.5. This is much lower than the observed ratio, which is about 13. The inconsistency of the apparent signals in VSR2 and VSR4 is also indicated by the lower height of the joint-run peak map histogram in Fig. 14 with respect to that of VSR4 alone. This is confirmed by the Hough map, shown in Fig. 15 (left), where a single and wide stripe is clearly visible, suggesting that the outlier is produced by a rather short duration disturbance present in VSR4 data only (for comparison, Fig. 3 in [7] shows the Hough map for an HI in VSR2 data). This seems to be confirmed looking at the peakmap around the candidate [see Fig. 15 (right)], where a high concentration of peaks, of unidentified origin, is present at the beginning of VSR4, lasting for about 10 days. From this analysis we think the outlier can be safely ruled out as being inconsistent with a real GW signal.",
            "paragraph_rank": 56,
            "section_rank": 14,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b65",
                    "start": 513,
                    "text": "[7]",
                    "end": 516
                },
                {
                    "type": "figure",
                    "start": 734,
                    "text": "Fig. 14",
                    "end": 741
                },
                {
                    "type": "figure",
                    "ref_id": "fig_3",
                    "start": 823,
                    "text": "Fig. 15 (left)",
                    "end": 837
                },
                {
                    "type": "figure",
                    "start": 1012,
                    "text": "Fig. 3",
                    "end": 1018
                },
                {
                    "type": "bibr",
                    "ref_id": "b65",
                    "start": 1022,
                    "text": "[7]",
                    "end": 1025
                },
                {
                    "type": "figure",
                    "ref_id": "fig_3",
                    "start": 1147,
                    "text": "Fig. 15 (right)",
                    "end": 1162
                }
            ]
        },
        {
            "text": "Outlier at 43.30 Hz",
            "section_rank": 15
        },
        {
            "section": "Outlier at 43.30 Hz",
            "text": "This candidate has a very high significance (corresponding to the smallest possible p-value). In Fig. 16 the peakmap histogram for the full analysis, together to those for the single runs are shown. We see that basically the \"signal\" is present mainly in one of the two runs. This is also what we conclude looking at the Hough map and the peakmap in Fig. 17, where the main contribution coming from VSR2 is clearly visible. From the previous considerations it seems that also this outlier is associated to some disturbance in the data. In particular it happens in a frequency region (between 40 and 45 Hz) which is heavily polluted by noise produced by rack cooling fans. It must be noticed that outliers clearly associated to a disturbed region found at this step of the procedure should not be surprising. In fact, despite all the cleaning procedures and criteria used to select candidates, some instrumental disturbance can be still present in the data. This is the reason why the most interesting candidates must be subject to a close scrutiny.",
            "paragraph_rank": 57,
            "section_rank": 15,
            "ref_spans": [
                {
                    "type": "figure",
                    "ref_id": "fig_4",
                    "start": 97,
                    "text": "Fig. 16",
                    "end": 104
                },
                {
                    "type": "figure",
                    "start": 350,
                    "text": "Fig. 17",
                    "end": 357
                }
            ]
        },
        {
            "text": "Outlier at 71.20 Hz",
            "section_rank": 16
        },
        {
            "section": "Outlier at 71.20 Hz",
            "text": "This third outlier has many characteristics in common with that at 30.88 Hz. Comparing the peakmap histograms of Figs. 14 and 18, we see again that it is mainly present in VSR4 data. In this case the expected ratio between the peakmap histogram heights, in presence of a signal, is about 0.7 while we observe a ratio of about 3. Moreover, as for the outlier at 30.88 Hz, the height of the joint-run peak map histogram is smaller than for VSR4 alone, which is also inconsistent with the signal hypothesis. This is confirmed by the Hough map shown in Fig. 19 (left), where basically only a wide stripe in the frequency/spin-down plane is visibile, indicating that the outlier comes mainly from only one of the two runs. A further confirmation comes from the peakmap in Fig. 19 (right), in which a high concentration of peaks is visible at the right frequencies just at the beginning of VSR4, similarly to what happens for the first outlier. We conclude that this outlier is not due to a real GW signal. 30.885 30.8851 30.8852 30.8853 30.8854 30.8855 30.8856 30.8857 30.8858   30.88 Hz. The right plot shows the combination of the peakmaps from VSR2 and VSR4 data. The empty region in the middle corresponds to the time separation between the end of VSR2 and the beginning of VSR4. The outlier at 30.88 Hz is due to the concentration of peaks clearly visibile at the beginning of VSR4. FIG. 16. Final peakmap histograms for the outliers at 43.30 Hz. The dark thick curve corresponds to the full VSR2/VSR4 analysis; the light continuous (red in color version) curve corresponds to VSR4 analysis while the light dashed (blue in color version) curve corresponds to the analysis of VSR2 alone.  2 71.2001 71.2002 71.2003 71.2004 71.2005 71.2006 71.2007 71.2008  Final peakmap histograms for the outlier at 71.20 Hz. The dark thick curve corresponds to the full VSR2/VSR4 analysis; the light dashed (blue in color version) curve corresponds to VSR2 analysis while the light continuous (red in color version) curve corresponds to the analysis of VSR4 alone. ",
            "paragraph_rank": 58,
            "section_rank": 16,
            "ref_spans": [
                {
                    "type": "figure",
                    "ref_id": "fig_6",
                    "start": 113,
                    "text": "Figs. 14 and 18",
                    "end": 128
                },
                {
                    "type": "figure",
                    "ref_id": "fig_7",
                    "start": 549,
                    "text": "Fig. 19 (left)",
                    "end": 563
                },
                {
                    "type": "figure",
                    "ref_id": "fig_7",
                    "start": 767,
                    "text": "Fig. 19",
                    "end": 774
                },
                {
                    "type": "bibr",
                    "start": 1001,
                    "text": "30.885 30.8851 30.8852 30.8853 30.8854 30.8855 30.8856 30.8857 30.8858",
                    "end": 1071
                },
                {
                    "type": "bibr",
                    "start": 1074,
                    "text": "30.88",
                    "end": 1079
                },
                {
                    "type": "bibr",
                    "start": 1688,
                    "text": "2 71.2001 71.2002 71.2003 71.2004 71.2005 71.2006 71.2007 71.2008",
                    "end": 1753
                }
            ]
        },
        {
            "text": "]",
            "section_rank": 17
        },
        {
            "section": "]",
            "text": "FIG. 1. VSR2 (darker, black in the color version) and VSR4 (lighter, red in the color version) average strain amplitude spectral density in the frequency range from 20 Hz up to 128 Hz.",
            "paragraph_rank": 59,
            "section_rank": 17
        },
        {
            "text": "FIG. 2 .",
            "section_rank": 18
        },
        {
            "section": "FIG. 2 .",
            "text": "FIG. 2. Number of sky patches in every 1 Hz band, from 20 Hz up to 128 Hz. The frequency on abscissa axis indicates the beginning frequency of each band. The number of patches increases with the square of the frequency, and is fixed by the highest frequency of each 1 Hz band.",
            "paragraph_rank": 60,
            "section_rank": 18
        },
        {
            "text": "FIG. 3 .FIG. 4 .",
            "section_rank": 19
        },
        {
            "section": "FIG. 3 .FIG. 4 .",
            "text": "FIG. 3. Time-frequency plot of the peaks removed by the \"gross histogram\" cleaning procedure for VSR2 (left) and VSR4 (right).",
            "paragraph_rank": 61,
            "section_rank": 19
        },
        {
            "text": "FIG. 5 .",
            "section_rank": 20
        },
        {
            "section": "FIG. 5 .",
            "text": "FIG. 5. Lines of constant frequency vetoed on the basis of the persistency, shown in the ordinate axis, for VSR2 (left) and VSR4 (right). We have removed 710 lines for VSR2 and 1947 lines for VSR4.)",
            "paragraph_rank": 62,
            "section_rank": 20
        },
        {
            "text": "FIG. 6 .",
            "section_rank": 21
        },
        {
            "section": "FIG. 6 .",
            "text": "FIG. 6. Number of candidates selected in every 1 Hz band (left) and in every 1 Hz band and in every sky patch (right). Asterisks (red in the online version) corresponds to VSR2, black circles to VSR4.",
            "paragraph_rank": 63,
            "section_rank": 21
        },
        {
            "text": "FIG. 7.Rank product for the final 108 candidates, which will be subject to the follow-up procedure. The two candidates with smallest rank product, indicated by filled circles, correspond to two hardware-injected signals.",
            "paragraph_rank": 64,
            "section_rank": 22
        },
        {
            "text": "FIG. 8 .",
            "section_rank": 23
        },
        {
            "section": "FIG. 8 .",
            "text": "FIG. 8. Peakmap histogram around the candidate at frequency 121.81 Hz. The vertical line identifies the candidate frequency.",
            "paragraph_rank": 65,
            "section_rank": 23
        },
        {
            "text": "FIG. 9 .",
            "section_rank": 24
        },
        {
            "section": "FIG. 9 .",
            "text": "FIG. 9.Final p-values for the 108 candidates as a function of candidate frequency after performing the follow-up step. The minimum value is 1/408=0.00245. The two filled circles identify hardware-injected signals.",
            "paragraph_rank": 66,
            "section_rank": 24
        },
        {
            "text": "FIG. 11 .",
            "section_rank": 25
        },
        {
            "section": "FIG. 11 .",
            "text": "FIG. 11. Peakmap peak distribution for two bands in VSR2 data. The left plot refers to the band 35-36 Hz, with gaps clearly visible. The right plot refers to a much cleaner band, ranging from 126 Hz to 127 Hz.",
            "paragraph_rank": 67,
            "section_rank": 25
        },
        {
            "text": "FIG. 13 .",
            "section_rank": 26
        },
        {
            "section": "FIG. 13 .",
            "text": "FIG. 13. Astrophysical reach of the search. The sets of points gives the relation between the frequency derivative and the frequency of a signal emitted by a detectable source placed at various distances. The triangles correspond to a distance of 500 pc; the circles to a distance of 100 pc; the stars to a distance of 10 pc and the squares to a distance of 1 pc. The dashed lines represents lines of constant ellipticity. The horizontal dot-dashed line indicates the maximum spin-down values searched in the analysis.",
            "paragraph_rank": 68,
            "section_rank": 26
        },
        {
            "text": "43.2995 43.2996 43.2996 43.2997 43.2997 43.2998 43.2998 43.",
            "paragraph_rank": 69,
            "section_rank": 27
        },
        {
            "text": "FIG. 18.Final peakmap histograms for the outlier at 71.20 Hz. The dark thick curve corresponds to the full VSR2/VSR4 analysis; the light dashed (blue in color version) curve corresponds to VSR2 analysis while the light continuous (red in color version) curve corresponds to the analysis of VSR4 alone.",
            "paragraph_rank": 70,
            "section_rank": 28
        },
        {
            "text": "FrequencyFIG. 19 .",
            "section_rank": 29
        },
        {
            "section": "FrequencyFIG. 19 .",
            "text": "FIG. 19. Hough map (left)  and peakmap (right) for the outlier at 71.20 Hz. As for the outlier at 30.88 Hz, this outlier is due to a concentration of peaks at the beginning of VSR4, barely visible in the right plot.",
            "paragraph_rank": 71,
            "section_rank": 29
        },
        {
            "text": ".22 \u2022 10 \u22125 8,847,360 7.63 \u2022 10 \u221212 16 [-9.91, 1.52]\u202210 \u221211 1600-10200 3,528,767 VSR4 1.22 \u2022 10 \u22125 8,847,360 1.50 \u2022 10 \u221211 9 [-10.5 , 1.50]\u202210 \u221211 1500-9700 3,528,767",
            "paragraph_rank": 72,
            "section_rank": 30
        },
        {
            "text": "TABLE",
            "section_rank": 31
        },
        {
            "text": "\u00d710 \u221224 pulsar 5 52.80832 \u22124.03 \u00d7 10 \u221218 276.8964 -61.1909 3.703 pulsar 3 108.85716 \u22121.46 \u00d7 10 \u221217 193.3162 -30.9956 8.296 TABLE III. Main parameters of the hardware injections in the band of the present analysis. The reference epoch for the frequency is MJD 52944.",
            "paragraph_rank": 74,
            "section_rank": 32
        },
        {
            "text": "FIG. 10. Peakmap histogram around the hardware injections pulsar 5 (left) and pulsar 3 (right). In both cases the highest peak corresponds to the signal frequency, with high accuracy.\u00d7 10 \u22126 276.93 0.12 \u221261.19 0.007 pulsar 3 108.85714 \u22121.2 1.18 \u00d7 10 \u221212 1.05 193.36 \u22120.05 -31.00 0.66 TABLE IV. Estimated parameters, and corresponding errors, for candidates corresponding to hardware injections present in the band bewteen 20 Hz and 128 Hz. The parametersf ,f,\u03bb,\u03b2 are the estimated frequency, spin-down, ecliptic coordinates; \u2206f, \u2206\u1e1f , \u2206\u03bb, \u2206\u03b2 are the differences with respect to the injected parameter values in units of the corresponding bins.",
            "paragraph_rank": 75,
            "section_rank": 33
        },
        {
            "text": "TABLE V :",
            "section_rank": 34
        },
        {
            "section": "TABLE V :",
            "text": "Main parameters of the 108 selected candidates: frequency, spin-down, sky position (in ecliptic coordinates), rank value and the final significance, after doing the follow-up. The candidates are ordered according to their rank value, starting from the most significant.",
            "paragraph_rank": 76,
            "section_rank": 34
        },
        {
            "text": "FIG. 14.Final peakmap histograms for the outliers at 30.88 Hz. The dark thick curve corresponds to the full VSR2/VSR4 analysis; the thin dashed (blue in color version) curve corresponds to VSR2 analysis while the thin continuous (red in color version) curve corresponds to the analysis of VSR4 alone.FIG. 15. Hough map (left)  and peakmap (right) for the outlier at",
            "paragraph_rank": 77,
            "section_rank": 35
        },
        {
            "text": "FIG. 17. Hough map (left)  and peakmap (right) for the outlier at 43.30 Hz.71.",
            "paragraph_rank": 78,
            "section_rank": 36
        },
        {
            "text": "Appendix B: Outliers analysis",
            "section_rank": 38
        },
        {
            "section": "Appendix B: Outliers analysis",
            "text": "In this section we describe the further analysis steps applied to the three outliers found in the follow-up step (see Sec. VIII). The goal here is to reject or confirm each of them as potential gravitational wave signal candidates. The main parameters of the three outliers are listed in Tab. VI.",
            "paragraph_rank": 79,
            "section_rank": 38
        },
        {
            "text": "Outlier at 30.88 Hz",
            "section_rank": 39
        },
        {
            "section": "Outlier at 30.88 Hz",
            "text": "This candidate has a significance just above the 1% threshold. An important verification step consists in checking if the \"signal characteristics\" are consistent among the two detectors. For this purpose we have repeated the last part of the follow-up procedure (from the FrequencyHough stage on) separately for the two runs. The result is shown in Fig. 14, where the final peakmap In the following table the noisy frequency intervals excluded from the computation of the upper limits are given. The two intervals 52-53 Hz and 108-109 Hz have been excluded because their most significant candidate is an hardware injected signal.",
            "paragraph_rank": 80,
            "section_rank": 39,
            "ref_spans": [
                {
                    "type": "figure",
                    "start": 349,
                    "text": "Fig. 14",
                    "end": 356
                }
            ]
        },
        {
            "text": "ACKNOWLEDGEMENT",
            "section_rank": 40
        },
        {
            "section": "ACKNOWLEDGEMENT",
            "text": "The authors gratefully acknowledge the support of the United States National Science Foundation (NSF) for the construction and operation of the LIGO Laboratory, the Science and Technology Facilities Council (STFC) of the United Kingdom, the Max-Planck-Society (MPS), and the State of Niedersachsen/Germany for support of the construction and operation of the GEO600 detector, the Italian Istituto Nazionale di Fisica Nucleare (INFN) and the French Centre National de la Recherche Scientifique (CNRS) for the construction and operation of the Virgo detector and the creation and support of the EGO consortium. The authors also gratefully acknowledge research support from these agencies as well as by the Australian Research Council, the International Science Linkages program of the Commonwealth of Australia, the Council of Scientific and Industrial Research of India, Department of Science and Technology, India, Science & Engineering Research Board (SERB), India, Ministry of Human Resource Development, India, the Spanish Ministerio de Econom\u00eda y Competitividad, the Conselleria d'Economia i Competitivitat and Conselleria d'Educaci\u00f3, Cultura i Universitats of the Govern de les Illes Balears, the Foundation for Fundamental Research on Matter supported by the Netherlands Organisation for Scientific Research, the National Science Centre of Poland, the European Union, the Royal Society, the Scottish Funding Council, the Scottish Universities Physics Alliance, the National Aeronautics and Space Administration, the Hungarian Scientific Research Fund (OTKA), the Lyon Institute of Origins (LIO), the National Research Foundation of Korea, Industry Canada and the Province of Ontario through the Ministry of Economic Development and Innovation, the National Science and Engineering Research Council Canada, the Brazilian Ministry of Science, Technology, and Innovation, the Carnegie Trust, the Leverhulme Trust, the David and Lucile Packard Foundation, the Research Corporation, and the Alfred P. Sloan Foundation. The authors gratefully acknowledge the support of the NSF, STFC, MPS, INFN, CNRS and the State of Niedersachsen/Germany for provision of computational resources. The authors are also grateful to the anonymous referees for their comments, which helped to improve the clarity of the paper.",
            "paragraph_rank": 81,
            "section_rank": 40
        }
    ]
}