{
    "level": "paragraph",
    "abstract": [
        {
            "text": "The Bayesian discovery probability of future experiments searching for neutrinoless double-\u03b2 decay is evaluated under the popular assumption that neutrinos are their own antiparticles. A Bayesian global fit is performed to construct a probability distribution for the effective Majorana mass, the observable of interest for these experiments. This probability distribution is then combined with the sensitivity of each experiment derived from a heuristic counting analysis. The discovery probability is found to be higher than previously considered, but strongly depends on whether the neutrino mass ordering is normal or inverted. For the inverted ordering, next-generation experiments are likely to observe a signal already during their first operational stages. Even for the normal ordering, in the absence of neutrino mass mechanisms that drive the lightest state or the effective Majorana mass to zero, the probability of discovering neutrinoless double-\u03b2 decay can reach \u223c50% or more in the most promising experiments.",
            "paragraph_rank": 1,
            "section_rank": 1
        }
    ],
    "body_text": [
        {
            "text": "I. INTRODUCTION",
            "section_rank": 2
        },
        {
            "section": "I. INTRODUCTION",
            "text": "Definitive evidence for non-zero neutrino masses from oscillation experiments has been available for nearly two decades [1][2][3][4]. However, the incorporation of neutrino masses into the Standard Model (SM) of particle physics remains an open issue. Because it is electrically neutral, the neutrino is the only known fundamental fermion that could be its own anti-particle, and obtain its mass through a Majorana mass term [5]. Such a Majorana mass term would violate total lepton number conservation, and naturally emerges in many beyond-the-SM theories [6]. It also emerges in leading theories that explain the dominance of matter over antimatter in the universe [7], to which we owe our very existence. The motivation to test the Majorana nature of the neutrino has never been higher.",
            "paragraph_rank": 2,
            "section_rank": 2,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b0",
                    "start": 120,
                    "text": "[1]",
                    "end": 123
                },
                {
                    "type": "bibr",
                    "ref_id": "b1",
                    "start": 123,
                    "text": "[2]",
                    "end": 126
                },
                {
                    "type": "bibr",
                    "ref_id": "b2",
                    "start": 126,
                    "text": "[3]",
                    "end": 129
                },
                {
                    "type": "bibr",
                    "ref_id": "b3",
                    "start": 129,
                    "text": "[4]",
                    "end": 132
                },
                {
                    "type": "bibr",
                    "ref_id": "b4",
                    "start": 425,
                    "text": "[5]",
                    "end": 428
                },
                {
                    "type": "bibr",
                    "ref_id": "b5",
                    "start": 557,
                    "text": "[6]",
                    "end": 560
                },
                {
                    "type": "bibr",
                    "ref_id": "b6",
                    "start": 667,
                    "text": "[7]",
                    "end": 670
                }
            ]
        },
        {
            "section": "I. INTRODUCTION",
            "text": "At present, the only feasible method for testing a pure-Majorana SM neutrino without requiring new fields or symmetries is to search for neutrinoless double-\u03b2 (0\u03bd\u03b2\u03b2) decay [8]. In this hypothetical nuclear transition a nucleus of mass number A and charge Z decays as (A, Z) \u2192 (A, Z+2)+2e \u2212 [9]. A positive detection would signify the first observation of a matter-creating process (without the balancing emission of antimatter), and would unambiguously establish that neutrinos have a Majorana mass component, independent of the channels involved in the transition or the isotope under study [10,11]. An experimental campaign to search for this process has been underway for decades, and its continuation requires intense effort and significant resources. We set out to explore the justification for such an expenditure, a task for which Bayesian methods are particularly well suited. In this work we present our evaluation, using all available information about neutrino phenomenology, of the Bayesian probability that future 0\u03bd\u03b2\u03b2 decay searches will prove that neutrinos are Majorana particles.",
            "paragraph_rank": 3,
            "section_rank": 2,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b7",
                    "start": 172,
                    "text": "[8]",
                    "end": 175
                },
                {
                    "type": "bibr",
                    "ref_id": "b8",
                    "start": 290,
                    "text": "[9]",
                    "end": 293
                },
                {
                    "type": "bibr",
                    "ref_id": "b9",
                    "start": 592,
                    "text": "[10,",
                    "end": 596
                },
                {
                    "type": "bibr",
                    "ref_id": "b10",
                    "start": 596,
                    "text": "11]",
                    "end": 599
                }
            ]
        },
        {
            "section": "I. INTRODUCTION",
            "text": "Neutrino phenomenology is described by an extension of the SM in which three quantum flavor states \u03bd e , \u03bd \u00b5 , and \u03bd \u03c4 couple to charged leptons via the weak interaction [4]. Such flavor states do not have a fixed mass but are rather a quantum-mechanical superposition of three mass eigenstates \u03bd 1 , \u03bd 2 , \u03bd 3 , with masses m 1 , m 2 , m 3 . The transformation between the mass and flavor bases is described by the unitary PMNS matrix, which is parametrized by three mixing angles (\u03b8 12 , \u03b8 13 , \u03b8 23 ), the CP-violating phase \u03b4, and two Majorana phases (\u03b1 21 , \u03b1 31 ). Consequently, neutrinos can transform from one flavor state to another during propagation, giving rise to neutrino oscillation, which remains to date the only observed phenomenon requiring non-zero neutrino masses. The transformation probability is a function of the two squared mass differences \u2206m 2 31 and \u2206m 2 21 (where \u2206m 2 ij \u2261 m 2 i \u2212m 2 j ), the three mixing angles, and \u03b4. All oscillation parameters have been measured with the exception of \u03b4 and the sign of \u2206m 2 31 [4,12]. These parameters should be accessible in the near future by experiments exploiting vacuum oscillations or matter-induced flavor transformations [13][14][15][16].",
            "paragraph_rank": 4,
            "section_rank": 2,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b3",
                    "start": 170,
                    "text": "[4]",
                    "end": 173
                },
                {
                    "type": "bibr",
                    "ref_id": "b1",
                    "start": 870,
                    "text": "2",
                    "end": 871
                },
                {
                    "type": "bibr",
                    "ref_id": "b1",
                    "start": 897,
                    "text": "2",
                    "end": 898
                },
                {
                    "type": "bibr",
                    "ref_id": "b1",
                    "start": 1041,
                    "text": "2",
                    "end": 1042
                },
                {
                    "type": "bibr",
                    "ref_id": "b3",
                    "start": 1046,
                    "text": "[4,",
                    "end": 1049
                },
                {
                    "type": "bibr",
                    "ref_id": "b11",
                    "start": 1049,
                    "text": "12]",
                    "end": 1052
                },
                {
                    "type": "bibr",
                    "ref_id": "b12",
                    "start": 1198,
                    "text": "[13]",
                    "end": 1202
                },
                {
                    "type": "bibr",
                    "ref_id": "b13",
                    "start": 1202,
                    "text": "[14]",
                    "end": 1206
                },
                {
                    "type": "bibr",
                    "ref_id": "b14",
                    "start": 1206,
                    "text": "[15]",
                    "end": 1210
                },
                {
                    "type": "bibr",
                    "ref_id": "b15",
                    "start": 1210,
                    "text": "[16]",
                    "end": 1214
                }
            ]
        },
        {
            "section": "I. INTRODUCTION",
            "text": "Complementary constraints on neutrino phenomenology are provided by cosmological observations, precision measurements of \u03b2-decay kinematics, and 0\u03bd\u03b2\u03b2 decay searches [17,18]. Lepton number violation searches at accelerators and other experimental probes can provide additional information on neutrinos (see, for example, [19,20]) but will not be discussed here.",
            "paragraph_rank": 5,
            "section_rank": 2,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b16",
                    "start": 165,
                    "text": "[17,",
                    "end": 169
                },
                {
                    "type": "bibr",
                    "ref_id": "b17",
                    "start": 169,
                    "text": "18]",
                    "end": 172
                },
                {
                    "type": "bibr",
                    "ref_id": "b18",
                    "start": 320,
                    "text": "[19,",
                    "end": 324
                },
                {
                    "type": "bibr",
                    "ref_id": "b19",
                    "start": 324,
                    "text": "20]",
                    "end": 327
                }
            ]
        },
        {
            "section": "I. INTRODUCTION",
            "text": "Cosmology is sensitive to the sum of neutrino masses: \u03a3 = m 1 + m 2 + m 3 . The value of \u03a3 is constrained by Planck and other observations [21] which set upper limits on the order of tens to hundreds of meV, depending on the model and data-sets used for analysis [22]. A lower limit for \u03a3 is imposed by the measurements of the mass splittings.",
            "paragraph_rank": 6,
            "section_rank": 2,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b20",
                    "start": 139,
                    "text": "[21]",
                    "end": 143
                },
                {
                    "type": "bibr",
                    "ref_id": "b21",
                    "start": 263,
                    "text": "[22]",
                    "end": 267
                }
            ]
        },
        {
            "section": "I. INTRODUCTION",
            "text": "The energy spectrum end-point of electrons emitted in nuclear \u03b2-decay is sensitive to the rest mass of the electron antineutrino [23,24]. Since the neutrino mass splittings are smaller than can be resolved with available electron spectroscopic techniques, the end point defect is characterized by the effective neutrino mass: (1)",
            "paragraph_rank": 7,
            "section_rank": 2,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b22",
                    "start": 129,
                    "text": "[23,",
                    "end": 133
                },
                {
                    "type": "bibr",
                    "ref_id": "b23",
                    "start": 133,
                    "text": "24]",
                    "end": 136
                }
            ]
        },
        {
            "section": "I. INTRODUCTION",
            "text": "where s ij = sin \u03b8 ij and c ij = cos \u03b8 ij . A non-zero m \u03b2 has not yet been observed and the best upper limits are set by the Troitsk [25] and Mainz [26] experiments, giving m \u03b2 < 2.12 eV at 95% credible interval (CI) and m \u03b2 < 2.3 eV at 95% confidence level (CL), respectively. The strongest limits on the half life of 0\u03bd\u03b2\u03b2 decay are from the KamLAND-Zen [27] and GERDA [28] experiments, giving T 1/2 ( 136 Xe) > 10.7 \u00d7 10 25 yr (sensitivity: 5.6 \u00d7 10 25 yr) and T 1/2 ( 76 Ge) > 5.3 \u00d7 10 25 yr (sensitivity: 4.0 \u00d7 10 25 yr) at 90% CL, respectively. In a minimal SM extension that incorporates neutrino masses by only adding Majorana neutrino mass terms for the three known mass eigenstates to the SM Lagrangian, 0\u03bd\u03b2\u03b2 decay is mediated by the exchange of neutrinos. In this case, the half life of the process is given by [29]:",
            "paragraph_rank": 8,
            "section_rank": 2,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b24",
                    "start": 134,
                    "text": "[25]",
                    "end": 138
                },
                {
                    "type": "bibr",
                    "ref_id": "b25",
                    "start": 149,
                    "text": "[26]",
                    "end": 153
                },
                {
                    "type": "bibr",
                    "ref_id": "b26",
                    "start": 356,
                    "text": "[27]",
                    "end": 360
                },
                {
                    "type": "bibr",
                    "ref_id": "b28",
                    "start": 371,
                    "text": "[28]",
                    "end": 375
                },
                {
                    "type": "bibr",
                    "ref_id": "b29",
                    "start": 822,
                    "text": "[29]",
                    "end": 826
                }
            ]
        },
        {
            "section": "I. INTRODUCTION",
            "text": "where G 0\u03bd is a phase-space factor and M 0\u03bd is the dimensionless nuclear matrix element (NME) encompassing the nuclear physics. The observable m \u03b2\u03b2 , the effective Majorana mass, is given by",
            "paragraph_rank": 9,
            "section_rank": 2
        },
        {
            "section": "I. INTRODUCTION",
            "text": "The aforementioned limits on T 1/2 translate to m \u03b2\u03b2 < 61 \u2212 165 eV and m \u03b2\u03b2 < 150 \u2212 330 eV (90% CL) [27,28]. The ranges account for different theoretical calculations of the NME [29].",
            "paragraph_rank": 10,
            "section_rank": 2,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b26",
                    "start": 100,
                    "text": "[27,",
                    "end": 104
                },
                {
                    "type": "bibr",
                    "ref_id": "b28",
                    "start": 104,
                    "text": "28]",
                    "end": 107
                },
                {
                    "type": "bibr",
                    "ref_id": "b29",
                    "start": 178,
                    "text": "[29]",
                    "end": 182
                }
            ]
        },
        {
            "section": "I. INTRODUCTION",
            "text": "For light Majorana neutrino exchange, the allowed parameter space for 0\u03bd\u03b2\u03b2 decay is considerably constrained. In the case \u2206m 2 31 < 0, referred to as the inverted neutrino mass ordering (IO), the oscillation parameters dictate that m \u03b2\u03b2 cannot be much lower than \u223c18 meV [16]. A broad international experimental program requiring considerable resources is being mounted to search for 0\u03bd\u03b2\u03b2 decay in this range. These experiments will also be sensitive to part of the parameter space for the normal ordering (NO, corresponding to \u2206m 2 31 > 0), although if m \u03b2\u03b2 is exceedingly small even larger experiments will be required.",
            "paragraph_rank": 11,
            "section_rank": 2,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b1",
                    "start": 125,
                    "text": "2",
                    "end": 126
                },
                {
                    "type": "bibr",
                    "ref_id": "b15",
                    "start": 271,
                    "text": "[16]",
                    "end": 275
                },
                {
                    "type": "bibr",
                    "ref_id": "b1",
                    "start": 531,
                    "text": "2",
                    "end": 532
                }
            ]
        },
        {
            "section": "I. INTRODUCTION",
            "text": "To maximize the return on this investment, it is the opinion of the authors that the design of these future experiments should be driven by the likelihood of discovering 0\u03bd\u03b2\u03b2 decay, rather than limit-setting capability as is usually done. With the aim of furthering progress in this direction, this article presents a global Bayesian analysis to extract the present-day probability distribution of m \u03b2\u03b2 using all relevant experimental information available to date. The probability distribution is folded with the discovery sensitivity of future 0\u03bd\u03b2\u03b2 decay experiments, computed here with a heuristic counting analysis. As will be seen, the resulting discovery probabilities indicate that next-generation experiments have a high likelihood of observing a signal if neutrinos are indeed Majorana particles.",
            "paragraph_rank": 12,
            "section_rank": 2
        },
        {
            "section": "I. INTRODUCTION",
            "text": "Our analysis focuses on scenarios in which the lightest neutrino mass eigenstate m l and m \u03b2\u03b2 are not fixed by mass mechanisms or flavour symmetries that would significantly alter the parameter space of interest [30][31][32]. To explore the discovery probability of models yielding hierarchical mass spectra (i.e. with m l m 2 [33]), we analyze the extreme case in which m l is zero. Projections for models predicting intermediate values of m l can be obtained by interpolating between our results. We do not consider explicitly scenarios in which m \u03b2\u03b2 has a fixed value since the posterior distribution would be a trivial delta function and the discovery probability can be directly extracted from the sensitivity of the experiments.",
            "paragraph_rank": 13,
            "section_rank": 2,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b30",
                    "start": 212,
                    "text": "[30]",
                    "end": 216
                },
                {
                    "type": "bibr",
                    "ref_id": "b31",
                    "start": 216,
                    "text": "[31]",
                    "end": 220
                },
                {
                    "type": "bibr",
                    "ref_id": "b32",
                    "start": 220,
                    "text": "[32]",
                    "end": 224
                },
                {
                    "type": "bibr",
                    "ref_id": "b33",
                    "start": 327,
                    "text": "[33]",
                    "end": 331
                }
            ]
        },
        {
            "text": "II. GLOBAL FIT",
            "section_rank": 3
        },
        {
            "section": "II. GLOBAL FIT",
            "text": "The parameter basis selected for our global fit is {\u03a3, \u2206m 2 21 , \u2206m 2 31 or \u2206m 2 23 , \u03b8 12 , \u03b8 13 , \u03b1 21 , (\u03b1 31 \u2212 \u03b4)}, where \u2206m 2 31 is used for NO and \u2206m 2 23 for IO. The notation is taken from Ref [4]. The remaining degrees of freedom of the model do not affect the analysis and are neglected. Statistical correlations of the parameters in the basis are also negligible [12]. The ignorance on the scale of the parameters is introduced through scale invariant priors: the priors of the mass observables are logarithmic whereas the priors of angles and phases -whose values are restricted to the range [0, 2\u03c0] -are flat.",
            "paragraph_rank": 14,
            "section_rank": 3,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b1",
                    "start": 58,
                    "text": "2",
                    "end": 59
                },
                {
                    "type": "bibr",
                    "start": 79,
                    "text": "2 23",
                    "end": 83
                },
                {
                    "type": "bibr",
                    "ref_id": "b1",
                    "start": 129,
                    "text": "2",
                    "end": 130
                },
                {
                    "type": "bibr",
                    "ref_id": "b3",
                    "start": 200,
                    "text": "[4]",
                    "end": 203
                },
                {
                    "type": "bibr",
                    "ref_id": "b11",
                    "start": 373,
                    "text": "[12]",
                    "end": 377
                }
            ]
        },
        {
            "section": "II. GLOBAL FIT",
            "text": "The choice of the basis affects our results only slightly as long as the basis covers all degrees of freedom of the problem and its parameters are constrained by the data (see discussion in Appendix A). Our usage of \u03a3 and the mass splittings to cover the three degrees of freedom related to the neutrino masses is motivated both by physical and statistical arguments. The \u2206m 2 parameters are direct observables of oscillation experiments and \u03a3 can be physically interpreted as the neutrino mass scale. In addition, \u03a3 is constrained by the data to a finite range and cannot vanish. This is critical for having a normalizable posterior distribution when a scale-invariant prior is employed.",
            "paragraph_rank": 15,
            "section_rank": 3
        },
        {
            "section": "II. GLOBAL FIT",
            "text": "This basis does not accommodate scenarios with extreme hierarchical mass spectra in which m l is driven to zero. The discovery probability for such hierarchical scenarios can however be easily studied by fixing \u03a3 to its lower limit. It might seem appropriate to to use a basis in which \u03a3 is substituted by m l . This apparently natural choice poses serious difficulties, as the data are not directly sensitive to m l except in the case of quasidegenerate masses. If used as an element of the basis, its posterior would be strongly influenced by whatever prior is chosen in the low-mass range. The use of scaleinvariant priors would then make the m \u03b2\u03b2 probability distribution non-normalizable without the imposition of an ad-hoc cutoff on m l , whose value affects directly the posteriors. The choice of a cutoff could be motivated by theoretical reasons (see e.g. Ref. [34]), but it would still insert into the analysis an arbitrary assumption which affects the results of the fit.",
            "paragraph_rank": 16,
            "section_rank": 3,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b34",
                    "start": 870,
                    "text": "[34]",
                    "end": 874
                }
            ]
        },
        {
            "section": "II. GLOBAL FIT",
            "text": "The likelihood function of the available data is constructed as the product of normalized factors, each expressing the conditional probability of a sub-set of data given the value of an observable:",
            "paragraph_rank": 17,
            "section_rank": 3
        },
        {
            "section": "II. GLOBAL FIT",
            "text": "where: D osc are the oscillation data, whose likelihoods are computed using the nu-fit analysis (v3.0, Nov. 2016) [12]; D Troitsk refers to the limit from Troitsk [25] (including also the limit from Mainz [26] yields no perceptible change in the m \u03b2\u03b2 distribution); and D 0\u03bd\u03b2\u03b2 is the combined results from GERDA and KamLAND-Zen. The latter is built using the sensitivity of the experiments rather then their actual limits, which are strengthened by background under-fluctuations (that is, we consider power-constrained limits [35]). This results in a normalized exponentially-decreasing likelihood with 90% quantile at m \u03b2\u03b2 = 71 \u2212 161 meV, depending on the choice of NME.",
            "paragraph_rank": 18,
            "section_rank": 3,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b11",
                    "start": 114,
                    "text": "[12]",
                    "end": 118
                },
                {
                    "type": "bibr",
                    "ref_id": "b24",
                    "start": 163,
                    "text": "[25]",
                    "end": 167
                },
                {
                    "type": "bibr",
                    "ref_id": "b25",
                    "start": 205,
                    "text": "[26]",
                    "end": 209
                },
                {
                    "type": "bibr",
                    "ref_id": "b35",
                    "start": 526,
                    "text": "[35]",
                    "end": 530
                }
            ]
        },
        {
            "section": "II. GLOBAL FIT",
            "text": "The NME values are fixed parameters in this analysis and the impact of their variation is evaluated by performing the calculations multiple times assuming different nuclear models. We consider the quasi-particle random phase approximation (QRPA [36][37][38]), the interacting shell model (ISM [39,40]), the interacting boson model (IBM-2 [41]), and energy density functional theory (EDF [42,43]). Within each model we use the average of the computations performed by different groups, taking the spread as an indication of systematic uncertainty as discussed in Ref. [29]. We perform the primary analysis without considering quenching of the axial vector coupling constant g A . The effect of variation of g A is discussed below. For recent insight into the status of the quenching issue we refer the reader to Ref. [29].",
            "paragraph_rank": 19,
            "section_rank": 3,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b36",
                    "start": 245,
                    "text": "[36]",
                    "end": 249
                },
                {
                    "type": "bibr",
                    "ref_id": "b37",
                    "start": 249,
                    "text": "[37]",
                    "end": 253
                },
                {
                    "type": "bibr",
                    "ref_id": "b38",
                    "start": 253,
                    "text": "[38]",
                    "end": 257
                },
                {
                    "type": "bibr",
                    "ref_id": "b39",
                    "start": 293,
                    "text": "[39,",
                    "end": 297
                },
                {
                    "type": "bibr",
                    "ref_id": "b40",
                    "start": 297,
                    "text": "40]",
                    "end": 300
                },
                {
                    "type": "bibr",
                    "ref_id": "b41",
                    "start": 338,
                    "text": "[41]",
                    "end": 342
                },
                {
                    "type": "bibr",
                    "ref_id": "b42",
                    "start": 387,
                    "text": "[42,",
                    "end": 391
                },
                {
                    "type": "bibr",
                    "ref_id": "b43",
                    "start": 391,
                    "text": "43]",
                    "end": 394
                },
                {
                    "type": "bibr",
                    "ref_id": "b29",
                    "start": 567,
                    "text": "[29]",
                    "end": 571
                },
                {
                    "type": "bibr",
                    "ref_id": "b29",
                    "start": 816,
                    "text": "[29]",
                    "end": 820
                }
            ]
        },
        {
            "section": "II. GLOBAL FIT",
            "text": "The marginalized posterior distributions for all parameters of the basis and observables of interest are computed via Markov-chain Monte-Carlo numerical integrations with the BAT toolkit [44]. All marginalized distributions are included in Appendix A. The posterior distributions for m \u03b2\u03b2 as a function of m l are shown in FIG. 1, separately for the NO and IO scenarios. The color map indicates the probability density and the solid lines show the maximally allowed parameter space given the constraints on the oscillation parameters from nu-fit. The volume of the allowed parameter space is dominated by the freedom of the Majorana phase values, on which no direct measurement is available. The probability density is clearly nonuniform: high m \u03b2\u03b2 values are disfavored by the experimental limits on m \u03b2\u03b2 and m \u03b2 ; low m \u03b2\u03b2 values are unlikely because a fine tuning of the Majorana phases is needed for the right-hand-side of equation 3to vanish [45]. m l is unlikely to assume low values because oscillation experiments constrain \u03a3 to be larger than |\u2206m 2 31 |, and its scale invariant prior leaves a small volume of probable parameter space near that lower bound over which m l can become small. Our results are consistent with previous work [45][46][47] and the differences can be attributed to the different data sets considered.",
            "paragraph_rank": 20,
            "section_rank": 3,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b44",
                    "start": 187,
                    "text": "[44]",
                    "end": 191
                },
                {
                    "type": "figure",
                    "start": 320,
                    "text": "in FIG. 1",
                    "end": 329
                },
                {
                    "ref_id": "formula_1",
                    "start": 936,
                    "text": "3",
                    "end": 937
                },
                {
                    "type": "bibr",
                    "ref_id": "b45",
                    "start": 947,
                    "text": "[45]",
                    "end": 951
                },
                {
                    "type": "bibr",
                    "ref_id": "b1",
                    "start": 1056,
                    "text": "2",
                    "end": 1057
                },
                {
                    "type": "bibr",
                    "ref_id": "b45",
                    "start": 1245,
                    "text": "[45]",
                    "end": 1249
                },
                {
                    "type": "bibr",
                    "ref_id": "b46",
                    "start": 1249,
                    "text": "[46]",
                    "end": 1253
                },
                {
                    "type": "bibr",
                    "ref_id": "b47",
                    "start": 1253,
                    "text": "[47]",
                    "end": 1257
                }
            ]
        },
        {
            "section": "II. GLOBAL FIT",
            "text": "FIG. 2 shows the marginalized posterior distributions for m \u03b2\u03b2 and the corresponding cumulative distributions. The deformation of the posterior distributions due to the NME is visualized by the band. The 90% probability central interval for m \u03b2\u03b2 is 20-119 meV assuming IO and 3-104 meV assuming NO, where we have allowed for the maximum variation among the various NME considered. Consequently, the next-generation experiments that aim for a discovery sensitivity of 10 \u2212 20 meV will cover the true value of m \u03b2\u03b2 with > 95% probability assuming IO and with \u223c50% probability assuming NO. To cover the true value of m \u03b2\u03b2 in the case of NO with about 90% probability, an experiment should reach a discovery sensitivity of about 5 meV.",
            "paragraph_rank": 21,
            "section_rank": 3
        },
        {
            "section": "II. GLOBAL FIT",
            "text": "FIG. 2 shows also the distributions constructed when the data from Planck and other cosmological observations are added to the fit as an additional normalized factor of the likelihood L(D cosm |\u03a3), where D cosm represents the observational constraints on \u03a3 from the combination of data labeled as \"TT+lowP+lensing+ext\" in Ref. [21]. These new data disfavor the quasi-degenerate region at high values of m l and compress the distributions of m \u03b2\u03b2 to lower values. In this work, we use as reference results those obtained without imposing cosmological constraints. This choice is motivated by the fact that cosmological constraints are model-dependent, not only on the \u039bCDM model used to interpret the data, but also on a host of astrophysical models required to extract limits on \u03a3 from disparate datasets with complex and interrelated systematic uncertainties [22,48]. In any case, at present the impact of cosmological data is still limited: the cumulative distributions of m \u03b2\u03b2 -and ultimately also the experimental discovery probabilities - change by only tens of percent.",
            "paragraph_rank": 22,
            "section_rank": 3,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b20",
                    "start": 327,
                    "text": "[21]",
                    "end": 331
                },
                {
                    "type": "bibr",
                    "ref_id": "b21",
                    "start": 860,
                    "text": "[22,",
                    "end": 864
                },
                {
                    "type": "bibr",
                    "ref_id": "b48",
                    "start": 864,
                    "text": "48]",
                    "end": 867
                }
            ]
        },
        {
            "section": "II. GLOBAL FIT",
            "text": "When the fit is performed with \u03a3 fixed to its minimum allowed value (corresponding to m l = 0), the m \u03b2\u03b2 posterior distribution is constrained to lie within the horizontal bands that extend to m l \u2192 0 in FIG. 1. The m \u03b2\u03b2 posterior distribution is slightly shifted to smaller values for IO, and the discovery probability of future experiments remains very high. In NO, m \u03b2\u03b2 is pushed below the reach of future experiments, and the discovery probabilities are driven to be very small as shown in FIG. 2. Using m l in the fit basis with a log-flat scale invariant prior would provide the same results as long as the cutoff on m l , required to have normalizable posterior distributions, is set low enough to make the result independent of the choice of cutoff.",
            "paragraph_rank": 23,
            "section_rank": 3
        },
        {
            "text": "III. EXPERIMENTAL SENSITIVITY",
            "section_rank": 4
        },
        {
            "section": "III. EXPERIMENTAL SENSITIVITY",
            "text": "The experimental search for 0\u03bd\u03b2\u03b2 decay is a very active field. There is a number of isotopes that can undergo 0\u03bd\u03b2\u03b2 decay and many detection techniques have been developed and tested in recent years [49,50]. Examples are: high-purity Ge detectors [51,52], cryogenic bolometers [53,54], loaded organic liquid scintillators [27], timeprojection chambers [55,56], and tracking chambers [57]. Various larger-scale experiments with the sensitivity to probe the full IO parameter space are being mounted or proposed for the near or far future. This work focuses on those projects considered recently by the U.S. DOE/NSF Nuclear Science Advisory Committee's Subcommittee on Neutrinoless Double Beta Decay [58]: CU-PID [59,60], KamLAND-Zen [61], LEGEND [62,63], nEXO [64], NEXT [65], PandaX-III [66], SNO+ [67,68], and SuperNEMO [69,70]. Most of these projects follow a staged-approach in which the target mass will be progressively increased. The various phases and parameters of each project are summarized in TABLE I and discussed in Appendix C. We would like to caution the reader, however, that many of these experiments are under rapid development, and the parameters publicly available during the snapshot of time in which this manuscript was pre-pared will often poorly characterize their ultimate reach. Our conclusions should therefore be taken with a heavy grain of salt, and we implore the reader to resist the urge to use our results to make comparisons between experiments, and instead to focus on their combined promise as a global, multi-isotope endeavor. We hope that our methods are also useful as a figure-of-merit by which individual experiments can evaluate their own implementations. This analysis will be updated when new information becomes available.",
            "paragraph_rank": 24,
            "section_rank": 4,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b49",
                    "start": 198,
                    "text": "[49,",
                    "end": 202
                },
                {
                    "type": "bibr",
                    "ref_id": "b50",
                    "start": 202,
                    "text": "50]",
                    "end": 205
                },
                {
                    "type": "bibr",
                    "ref_id": "b51",
                    "start": 246,
                    "text": "[51,",
                    "end": 250
                },
                {
                    "type": "bibr",
                    "ref_id": "b52",
                    "start": 250,
                    "text": "52]",
                    "end": 253
                },
                {
                    "type": "bibr",
                    "ref_id": "b53",
                    "start": 276,
                    "text": "[53,",
                    "end": 280
                },
                {
                    "type": "bibr",
                    "ref_id": "b54",
                    "start": 280,
                    "text": "54]",
                    "end": 283
                },
                {
                    "type": "bibr",
                    "ref_id": "b26",
                    "start": 321,
                    "text": "[27]",
                    "end": 325
                },
                {
                    "type": "bibr",
                    "ref_id": "b55",
                    "start": 351,
                    "text": "[55,",
                    "end": 355
                },
                {
                    "type": "bibr",
                    "ref_id": "b56",
                    "start": 355,
                    "text": "56]",
                    "end": 358
                },
                {
                    "type": "bibr",
                    "ref_id": "b57",
                    "start": 382,
                    "text": "[57]",
                    "end": 386
                },
                {
                    "type": "bibr",
                    "ref_id": "b58",
                    "start": 697,
                    "text": "[58]",
                    "end": 701
                },
                {
                    "type": "bibr",
                    "ref_id": "b59",
                    "start": 710,
                    "text": "[59,",
                    "end": 714
                },
                {
                    "type": "bibr",
                    "ref_id": "b60",
                    "start": 714,
                    "text": "60]",
                    "end": 717
                },
                {
                    "type": "bibr",
                    "ref_id": "b61",
                    "start": 731,
                    "text": "[61]",
                    "end": 735
                },
                {
                    "type": "bibr",
                    "ref_id": "b62",
                    "start": 744,
                    "text": "[62,",
                    "end": 748
                },
                {
                    "type": "bibr",
                    "ref_id": "b63",
                    "start": 748,
                    "text": "63]",
                    "end": 751
                },
                {
                    "type": "bibr",
                    "ref_id": "b64",
                    "start": 758,
                    "text": "[64]",
                    "end": 762
                },
                {
                    "type": "bibr",
                    "ref_id": "b65",
                    "start": 769,
                    "text": "[65]",
                    "end": 773
                },
                {
                    "type": "bibr",
                    "ref_id": "b66",
                    "start": 786,
                    "text": "[66]",
                    "end": 790
                },
                {
                    "type": "bibr",
                    "ref_id": "b67",
                    "start": 797,
                    "text": "[67,",
                    "end": 801
                },
                {
                    "type": "bibr",
                    "ref_id": "b68",
                    "start": 801,
                    "text": "68]",
                    "end": 804
                },
                {
                    "type": "bibr",
                    "ref_id": "b69",
                    "start": 820,
                    "text": "[69,",
                    "end": 824
                },
                {
                    "type": "bibr",
                    "ref_id": "b70",
                    "start": 824,
                    "text": "70]",
                    "end": 827
                }
            ]
        },
        {
            "section": "III. EXPERIMENTAL SENSITIVITY",
            "text": "A primary experimental signature for 0\u03bd\u03b2\u03b2 decay is a mono-energetic peak in the measured energy spectrum at the Q-value of the decay, produced when the two electrons emitted in the process are fully absorbed in the detector's active volume. While in many detectors additional analysis handles are available to distinguish signal from background, energy is the one observable that is both necessary and sufficient for discovery, and so the sensitivity of a 0\u03bd\u03b2\u03b2 decay experiment is driven by Poisson statistics for events near the Q-value. It can thus be approximated with a heuristic counting analysis, where there are just two parameters of interest: the \"sensitive exposure\" (E) and the \"sensitive background\" (B). E is given by the product of active isotope mass and live time, corrected by the active fiducial volume, the signal detection efficiency, and the probability for a 0\u03bd\u03b2\u03b2 decay event to fall in the energy region of interest (ROI) in which the experiment is sensitive to the signal. B is the number of background events in the ROI after all analysis cuts divided by E. The number of signal and background counts in the final spectrum is then given by:",
            "paragraph_rank": 25,
            "section_rank": 4
        },
        {
            "section": "III. EXPERIMENTAL SENSITIVITY",
            "text": "where N A is Avogadro's number, m a is the molar mass of the target isotope, and T 1/2 is the half-life of the decay. The experimental efficiencies can be separated into: the actual fraction of mass used for analysis F V (accounting for dead volumes in solid detectors and fiducial volume cuts in liquid and gaseous detectors), the signal efficiency sig (which is the product of the analysis cut efficiency and the 0\u03bd\u03b2\u03b2 containment efficiency), and the fraction of fully-contained 0\u03bd\u03b2\u03b2 decay events with energy reconstructed in the ROI. The choice of optimal ROI depends on the background rate, its energy distribution, and the energy resolution (\u03c3) of the Gaussian peak expected from the signal. Experiments with an excellent energy resolution (\u03c3 < 1%) have a ROI centered at the Q-value with a width depending on the background rate. For experiments with poorer energy resolution, the background due to two-neutrino double-\u03b2 decay is significant up to the Q-value. These experiments have an asymmetric optimal ROI covering primarily the upper half of the Gaussian signal. Our method to compute the optimal ROI is discussed in Appendix B.",
            "paragraph_rank": 26,
            "section_rank": 4
        },
        {
            "section": "III. EXPERIMENTAL SENSITIVITY",
            "text": "With these considerations, the discovery sensitivity for each next-generation experiment is computed using a heuristic counting analysis. In cases where energy spec-tral fits and position non-uniformity enter non-trivially into the sensitivity (as e.g. in SuperNEMO and nEXO), we tuned our parameters to match the collaboration's stated sensitivity until agreement at the 10-20% level was achieved. Again, our goal is not to directly compare one experiment to another, but to interpolate the sensitivity curves as a function of live time to allow a study of the discovery probability of the ensemble of proposed experiments. Further details of these computations and the input parameters are discussed in Appendix B and C.",
            "paragraph_rank": 27,
            "section_rank": 4
        },
        {
            "section": "III. EXPERIMENTAL SENSITIVITY",
            "text": "The sensitivity of an experiment to discover a signal is here defined as the value of T 1/2 or m \u03b2\u03b2 for which the experiment has a 50% chance to measure a signal with a significance of at least 3\u03c3 [76]. FIG. 3 plots the m \u03b2\u03b2 discovery sensitivity as a function of E and B for three isotopes. Contours in m \u03b2\u03b2 are drawn as bands representing the spread in NME for the given isotope. The expected discovery sensitivity of each experiment after 5 years of live time is marked in the plot and also included in TA-BLE I. The T 1/2 sensitivity after 10 years of live time is about a factor \u221a 2 higher for all experiments considered, although for the lowest background experiments the improvement is as high as a factor of 1.6. For each isotope, next-generation experiments are expected to reach discovery sensitivity over the entire IO parameter space for at least some NME.",
            "paragraph_rank": 28,
            "section_rank": 4,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b77",
                    "start": 197,
                    "text": "[76]",
                    "end": 201
                },
                {
                    "type": "figure",
                    "ref_id": "fig_2",
                    "start": 203,
                    "text": "FIG. 3",
                    "end": 209
                }
            ]
        },
        {
            "text": "IV. DISCOVERY PROBABILITY",
            "section_rank": 5
        },
        {
            "section": "IV. DISCOVERY PROBABILITY",
            "text": "The ultimate question that we want to address in this work is: what is the probability of detecting a 0\u03bd\u03b2\u03b2 decay signal assuming that neutrinos are truly Majorana particles? We define this Bayesian discovery probability as the odds of measuring a 0\u03bd\u03b2\u03b2 decay signal with a significance of at least 3\u03c3. This is computed by folding the discovery sensitivity with the probability distribution of m \u03b2\u03b2 output by the global fit. FIG. 4 shows the evolution of the discovery probability as a function of live time for a selection of next-generation experiments, assuming the absence of mechanisms driving m \u03b2\u03b2 and m l to zero. NME variations are visualized as bands. The discovery probability for the most massive experiments exhibit a steep rise already in the first year or two of data taking. And while they begin to flatten after 5 years, each experiment continues to gain discovery probability out to 10 years.",
            "paragraph_rank": 29,
            "section_rank": 5,
            "ref_spans": [
                {
                    "type": "figure",
                    "ref_id": "fig_3",
                    "start": 423,
                    "text": "FIG. 4",
                    "end": 429
                }
            ]
        },
        {
            "section": "IV. DISCOVERY PROBABILITY",
            "text": "For the case of Majorana neutrinos with an inverted mass ordering, next-generation experiments in each isotope are almost certain to observe a signal in just 5 years of live time. Even several near-term experiments -SNO+ Phase I, KamLAND-Zen 800, and LEGEND 200 -will have significant chances of discovery before the larger experiments come online. Remarkably, several experiments also reach a discovery probability of over 50% in the case of NO. This strong possibility for discovery arises from the fact that even though the NO parameter space extends down to exceedingly small m \u03b2\u03b2 , the TABLE I. Experimental parameters of next-generation experiments. The quoted mass refers to the 0\u03bd\u03b2\u03b2 decaying isotope and the energy resolution to the standard deviation (\u03c3). The ROI edges are given in units of \u03c3 from the Q-value of the decay.",
            "paragraph_rank": 30,
            "section_rank": 5
        },
        {
            "section": "IV. DISCOVERY PROBABILITY",
            "text": "F V is the fraction of mass used for analysis and sig is the signal detection efficiency. For SuperNEMO only, the reported sig encompasses also the fraction of 0\u03bd\u03b2\u03b2 decay events in the ROI. The sensitive exposure (E) and background (B) are normalized to 1 yr of live time.T 1/2 andm \u03b2\u03b2 are the median 3\u03c3 discovery sensitivities assuming 5 years of live time. Them \u03b2\u03b2 ranges account for the different NME calculations considered in the analysis. The last columns show the envisioned reduction of background level and \u03c3, as well as the expected increase of isotope mass, with respect to predecessor experiments which have released data at the time of manuscript preparation; \"n/a\" indicates that no published experimental data are available yet.",
            "paragraph_rank": 31,
            "section_rank": 5
        },
        {
            "text": "Experiment",
            "section_rank": 6
        },
        {
            "section": "Experiment",
            "text": "Iso. Iso.  amount of parameter space left at high m \u03b2\u03b2 comprises a significant fraction. One subtlety to note about the bands is that, while their width is driven by the NME variation, the relationship between the discovery probability curves and the NME values is not monotonic. A change in NME model shifts the discovery sensitivity to higher or lower m \u03b2\u03b2 for all isotopes. But the KamLAND-Zen and GERDA constraints result in parameter space opening up or being excluded at high m \u03b2\u03b2 depending on just the changes in the 136 Xe and 76 Ge NME values. This leads to both a shift and a subtle distortion of the m \u03b2\u03b2 probability distribution. The ultimate change in the discovery probability is a non-trivial combination of these shifts and ",
            "paragraph_rank": 32,
            "section_rank": 6,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b77",
                    "start": 535,
                    "text": "76",
                    "end": 537
                }
            ]
        },
        {
            "text": "distortions.",
            "section_rank": 7
        },
        {
            "section": "distortions.",
            "text": "We explored the impact on the discovery probabilities of adding also cosmological constraints to our global fit. As expected based on the small deviations that these constraints generate in the m \u03b2\u03b2 distribution, we find that the discovery probability only degrades by \u223c30% for NO. In the case of IO, the discovery probability of future experiments is so strong that cosmological constraints are almost irrelevant.",
            "paragraph_rank": 33,
            "section_rank": 7
        },
        {
            "section": "distortions.",
            "text": "We also explored the impact of g A quenching on the discovery probabilities. Quenching degrades the sensitivity of future 0\u03bd\u03b2\u03b2 experiments, making parameter space at low m \u03b2\u03b2 inaccessible. For a given half-life, the corresponding value of m \u03b2\u03b2 scales roughly like g \u22122 A , so that even just \u223c30% quenching can degrade an experiment's discovery sensitivity by a factor-of-two. However, quenching also relaxes the constraints imposed on m \u03b2\u03b2 by existing experiments, opening up additional parameters space at high m \u03b2\u03b2 . As a result, the impact on discovery potential isn't nearly as large as on the sensitivity. We find that a reduction of g A by 30% reduces the discovery power by \u223c15% (\u223c25%) for the most promising future experiments in our reference analysis for IO (NO).",
            "paragraph_rank": 34,
            "section_rank": 7
        },
        {
            "section": "distortions.",
            "text": "When we include both 30% quenching as well as cos-mological constraints, the region at high m \u03b2\u03b2 stays disfavored and the future experiments simply lose reach. In this case we see this biggest suppression in discovery power. However, even in this most pessimistic case the most promising experiments still have discovery power well above 50% in the IO, and in the tens-of-percent range for NO. The preceding discussion refers to our reference analysis. To explore the case of extreme hierarchical neutrino masses, we repeat the analysis by fixing \u03a3 to its minimum allowed value. We find that for the IO the discovery probability is only marginally impacted for the most promising next-generation experiments, decreasing by at most 10%. For the NO, as expected, the discovery probability drops to 2% or lower for all experiments and for all NME considered.",
            "paragraph_rank": 35,
            "section_rank": 7
        },
        {
            "section": "distortions.",
            "text": "As a final note, we consider the impact of KA-TRIN [77], which will perform a tritium-endpointdefect-based kinematic measurement of the effective neutrino mass m \u03b2 with 90% CL limit-setting sensitivity of 200 meV, and 5\u03c3 discovery level of 350 meV [78]. An upper limit by KATRIN would have a marginal impact: including an m \u03b2 90% upper limit at 200 meV reduces discovery probabilities negligibly for the IO, and by less than 10% for the NO. A discovery by KATRIN, on the other hand, would be game-changing. Including a KA-TRIN signal consistent with m \u03b2 = 350 meV in our global analysis results in discovery probabilities in excess of 99% for both IO and NO, for all NME. In this case neutrino masses would be in the degenerate region, and 0\u03bd\u03b2\u03b2 decay experiments could not distinguish between NO and IO (cf . FIG. 6). Conversely, a non-observation of neutrinoless double-beta decay in that scenario would reject the standard light, left-handed Majorana neutrino exchange mechanism at high confidence level.",
            "paragraph_rank": 36,
            "section_rank": 7,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b78",
                    "start": 51,
                    "text": "[77]",
                    "end": 55
                },
                {
                    "type": "bibr",
                    "ref_id": "b79",
                    "start": 248,
                    "text": "[78]",
                    "end": 252
                },
                {
                    "type": "figure",
                    "start": 807,
                    "text": ". FIG. 6",
                    "end": 815
                }
            ]
        },
        {
            "text": "V. CONCLUSIONS",
            "section_rank": 8
        },
        {
            "section": "V. CONCLUSIONS",
            "text": "The probability distribution for the effective Majorana mass has been extracted with a Bayesian global fit using all experimental information available to-date and exploring various assumptions. If the Majorana phases are not fixed by a flavor symmetry and the lightest mass eigenvalue is not driven to zero, this distribution is found to peak at high values of m \u03b2\u03b2 not far from existing limits. This puts much of the remaining parameter space within the reach of next-generation experiments; it arises from the freedom of the Majorana phases and our requirement that the basis choice yields a normalizable posterior distribution when scale-invariant priors are used.",
            "paragraph_rank": 37,
            "section_rank": 8
        },
        {
            "section": "V. CONCLUSIONS",
            "text": "The sensitivity of a suite of next-generation 0\u03bd\u03b2\u03b2 decay experiments was estimated with a heuristic counting analysis based on two parameters which fully determine the performance of an experiment: the sensitive background and the sensitive exposure. The sensitivity is finally combined with the probability distribution of the effective Majorana mass to derive the discovery probability.",
            "paragraph_rank": 38,
            "section_rank": 8
        },
        {
            "section": "V. CONCLUSIONS",
            "text": "The discovery probability is found in general to be higher than previously considered for both mass orderings. For the inverted ordering, next-generation experiments will likely observe a signal already during their first operational stages independently of the considered assumptions. Even for the normal ordering, in the absence of neutrino mass mechanisms that drive the lightest state or the effective Majorana mass to zero, the probability of discovering 0\u03bd\u03b2\u03b2 reaches \u223c50% or higher in the most promising experiments. These conclusions do not change qualitatively when cosmological constraints are imposed, or when we allow for g A quenching.",
            "paragraph_rank": 39,
            "section_rank": 8
        },
        {
            "section": "V. CONCLUSIONS",
            "text": "Our results indicate that even if oscillation experiments or cosmological observations begin to strongly indicate a normal ordering (as e.g. in Ref. [79]), next-generation 0\u03bd\u03b2\u03b2 decay experiments will still probe a relevant region of the parameter space and give a valuable return on investment.",
            "paragraph_rank": 40,
            "section_rank": 8,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b80",
                    "start": 149,
                    "text": "[79]",
                    "end": 153
                }
            ]
        },
        {
            "section": "V. CONCLUSIONS",
            "text": "Note added.",
            "paragraph_rank": 41,
            "section_rank": 8
        },
        {
            "section": "V. CONCLUSIONS",
            "text": "On the date of submission of our manuscript, a work by A. Caldwell and others [80] became public on the arXiv. They also perform a Bayesian global analysis of all data to extract a probability dis-tribution for m \u03b2\u03b2 . Although their work has some similarities with ours, the most important difference is their use of the lightest mass eigenvalue (m l ) in the fit basis instead of \u03a3. When they use a flat prior for m l , their results are in qualitative agreement with ours, including both discovery probabilities of future experiments as well as the relative impact of cosmological constraints. However, when they use a log-flat prior (with cutoff set to 10 \u22127 eV), they find a degraded discovery probability, precisely as we discuss in Section II. There are a few other key differences worth highlighting. Caldwell et al. extend their Bayesian analysis to include also priors on NME (primarily variations of QRPA) as well as the mass orderings, which we treat independently. They do not consider quenching of the NME. They also use a posterior odds threshold of 99% as the criterion for discovery, as opposed to our choice of a 3\u03c3. There are three arbitrary elements in our analysis: the sets of data included in the analysis, the priors, and the parametrization of the model (i.e. the fit basis). The impact of the data set has been already discussed in the extreme case in which Planck results are added to the analysis. This changes the posterior distributions by about 10-20%.",
            "paragraph_rank": 42,
            "section_rank": 8,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b81",
                    "start": 78,
                    "text": "[80]",
                    "end": 82
                }
            ]
        },
        {
            "section": "V. CONCLUSIONS",
            "text": "The impact of the priors is in general weak as the data are strongly informative for most of the parameters in the basis, with the exception of the Majorana phases and \u03a3. Using a flat prior for Majorana phases seems the only reasonable choice: the parameter ranges are well defined and no information is available on them. The prior used for \u03a3 is logarithmic to preserve scale invariance. An alternative choice would be a flat prior: this would favor larger values of \u03a3 and inflate the discovery probabilities.",
            "paragraph_rank": 43,
            "section_rank": 8
        },
        {
            "section": "V. CONCLUSIONS",
            "text": "The parametrization of the model has potentially a huge impact on the results. For this reason different parameterizations have been tested and the impact on the posterior for m \u03b2\u03b2 was found to be in general marginal as long as the basis covers all the degrees of freedom of the model and its parameters are constrained by the data. Conversely, if a parameter of the basis is not sensitive to the data (e.g. m l ) its posterior probability coincides with the prior and the resulting distribution cannot be normalized. When \u03a3 is fixed to its minimum allowed value to study extreme hierarchical models in which m l = 0, the posteriors become trivial: all mass eigenvalues, \u03a3, and m \u03b2 are sharply peaked at their minimum allowed values, while posteriors for square mass differences and angles are nearly indistinguishable from the results of the quasi-degenerate scenarios. Meanwhile, m \u03b2\u03b2 is pushed to lower values as shown in FIG. 2.",
            "paragraph_rank": 44,
            "section_rank": 8,
            "ref_spans": [
                {
                    "type": "figure",
                    "start": 922,
                    "text": "in FIG. 2",
                    "end": 931
                }
            ]
        },
        {
            "section": "V. CONCLUSIONS",
            "text": "Although there is no deep physical motivation to treat m \u03b2\u03b2 itself as a fundamental parameter, for completeness we also performed the analysis substituting \u03a3 with m \u03b2\u03b2 in the parameter basis. For the IO, all posterior distribu- tions except those of the Majorana phases coincide with the posteriors obtained with m \u03b2 in the basis. For the NO, m \u03b2\u03b2 could be vanishingly small, so the results depend in principle on the choice of the cutoff as for the case of the basis with m l . However, with our flat priors for the Majorana phases, values of m \u03b2\u03b2 below \u223c10 \u22123 eV are strongly suppressed and the posterior of m \u03b2\u03b2 is not affected by the cutoff choice as long as it is 10 \u22125 eV. The posterior for m \u03b2\u03b2 shows a preference for lower values with respect to what is obtained with our reference fit, which can be interpreted as a volume effect coming from the assignment of a log-flat prior on m \u03b2\u03b2 instead of on \u03a3. Additionally, the posteriors for the Majorana phases show different features with respect to what is obtained with the other bases. Again, these are the results of volume effects and indicate that the current knowledge does not allow us to make any clear statement on the Majorana phases.",
            "paragraph_rank": 45,
            "section_rank": 8
        },
        {
            "text": "Appendix B: Heuristic counting analysis",
            "section_rank": 9
        },
        {
            "section": "Appendix B: Heuristic counting analysis",
            "text": "In this work, the discovery sensitivity is defined to be the value of T 1/2 or m \u03b2\u03b2 for which an experiment has a 50% chance to measure a signal above background with a significance of at least 3\u03c3. The computation is performed for T 1/2 and the result converted to a range of m \u03b2\u03b2 values by using equation 2with different NME values. Given an expectation for the background counts in the ROI of B = BE, the sensitivity for T 1/2 is given by:",
            "paragraph_rank": 46,
            "section_rank": 9,
            "ref_spans": [
                {
                    "ref_id": "formula_6",
                    "start": 306,
                    "text": "2",
                    "end": 307
                }
            ]
        },
        {
            "section": "Appendix B: Heuristic counting analysis",
            "text": "where S 3\u03c3 (B) denotes the Poisson signal expectation at which 50% of the measurements in an ensemble of identical experiments would report a 3\u03c3 positive fluctuation above B. If B is large then S 3\u03c3 (B) \u221d \u221a B, while if B(t)",
            "paragraph_rank": 47,
            "section_rank": 9
        },
        {
            "section": "Appendix B: Heuristic counting analysis",
            "text": "1 then S 3\u03c3 (B) is a constant. To transition smoothly between these two regimes, we find the number of counts C 3\u03c3 such that the cumulative Poisson distribution with mean B satisfies CDF P oisson (C 3\u03c3 |B) = 3\u03c3, and then obtain S 3\u03c3 by solving CDF P oisson (C 3\u03c3 |S 3\u03c3 + B) = 50%, as suggested in [81] (where CDF refers to the complementary CDF). While C 3\u03c3 should strictly be integervalued, restricting it as such would result in discrete jumps in the discovery sensitivity as B increases. To smooth over these jumps we extend CDF P oisson to a continuous distribution in C using its definition via the normalized upper incomplete gamma function:",
            "paragraph_rank": 48,
            "section_rank": 9,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b82",
                    "start": 297,
                    "text": "[81]",
                    "end": 301
                }
            ]
        },
        {
            "section": "Appendix B: Heuristic counting analysis",
            "text": "Using equation (B2), S 3\u03c3 varies smoothly and monotonically with B for values greater than \u2212 ln erf (3/ \u221a 2) = 0.0027 counts. Below this value of B, the observation of a single count represents a 3\u03c3 discovery, marking this as the level at which an experiment becomes effectively \"background-free\" under this metric. In this regime, S 3\u03c3 takes the constant value ln 2. Using equations (B1) and (B2), the T 1/2 sensitivity for 76 Ge as a function of E and B is shown in FIG. 7. Values for other isotopes can be obtained by dividing by the ratio of their molar mass to that of 76 Ge. Discovery sensitivity increases linearly with exposure until the experiment exceeds the background-free threshold of 0.0027 counts. For a given exposure, the sensitivity degrades rapidly with background level.",
            "paragraph_rank": 49,
            "section_rank": 9,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b77",
                    "start": 425,
                    "text": "76",
                    "end": 427
                },
                {
                    "type": "figure",
                    "start": 465,
                    "text": "in FIG. 7",
                    "end": 474
                },
                {
                    "type": "bibr",
                    "ref_id": "b77",
                    "start": 574,
                    "text": "76",
                    "end": 576
                }
            ]
        },
        {
            "section": "Appendix B: Heuristic counting analysis",
            "text": "In a similar manner, the discovery probability is defined to be the probability that an experiment will measure a 3\u03c3 positive fluctuation above B, given the probability distribution function dP/dm \u03b2\u03b2 for m \u03b2\u03b2 (i.e . FIG. 2). Explicitly, the discovery probability (DP) is computed as",
            "paragraph_rank": 50,
            "section_rank": 9,
            "ref_spans": [
                {
                    "type": "figure",
                    "start": 214,
                    "text": ". FIG. 2)",
                    "end": 223
                }
            ]
        },
        {
            "section": "Appendix B: Heuristic counting analysis",
            "text": "where S(m \u03b2\u03b2 ) is the expected signal counts in the experiment for a given value of m \u03b2\u03b2 .",
            "paragraph_rank": 51,
            "section_rank": 9
        },
        {
            "section": "Appendix B: Heuristic counting analysis",
            "text": "For high resolution experiments with flat background spectra in the vicinity of the Q value, we performed an optimization of the ROI width by maximizing the figureof-merit",
            "paragraph_rank": 52,
            "section_rank": 9
        },
        {
            "section": "Appendix B: Heuristic counting analysis",
            "text": "where n is the ROI half-width in units of the energy resolution (\u03c3), and b is the background counts per unit \u03c3 at 5 years of live time. Since S 3\u03c3 (bn) \u221d \u221a bn for large values of b, in this regime the F.O.M. is maximal for the value of n that solves the transcendental equation ne \u2212n 2 /2 = erf n/ \u221a 2 \u221a \u03c0/4. This gives an optimal ROI width of 2.8\u03c3 for background-dominated experiments, with a corresponding signal efficiency of 84%. At lower background the sensitivity improves with a wider ROI. In the background-free regime, the F.O.M. is optimized when the ROI width is expanded until the region contains 0.0027 count. Above this region, the F.O.M. was maximized numerically, making use of equation (B2). The deviations from the asymptotic value of 2.8 were plotted on a log-log scale and were found to be well-approximated by a 2 nd -order polynomial. This gives the following expression for the optimum ROI accurate to <1%:",
            "paragraph_rank": 53,
            "section_rank": 9
        },
        {
            "section": "Appendix B: Heuristic counting analysis",
            "text": "ROI opt = 2.8 + 10 a0+a1 log 10 b+a2 log 10 2b",
            "paragraph_rank": 54,
            "section_rank": 9
        },
        {
            "section": "Appendix B: Heuristic counting analysis",
            "text": "(B5)",
            "paragraph_rank": 55,
            "section_rank": 9
        },
        {
            "section": "Appendix B: Heuristic counting analysis",
            "text": "where the parameter values are a 0 = \u22120.40, a 1 = \u22120.29, and a 2 = \u22120.039. Our treatment ignores uncertainty in the background rate as well as systematic uncertainties. Backgrounds are typically well-constrained in 0\u03bd\u03b2\u03b2 experiments using sidebands in energy and, for some detectors, position. Similarly, systematic uncertainties are typically well below 10%. This makes these sources of uncertainty subdominant to the large fluctuations that drive low-countrate Poisson statistics.",
            "paragraph_rank": 56,
            "section_rank": 9
        },
        {
            "text": "Appendix C: Experimental parameters",
            "section_rank": 10
        },
        {
            "section": "Appendix C: Experimental parameters",
            "text": "This appendix discusses the experiments and parameters listed in TABLE I. The parameter values are taken from official publications and presentations of each collaboration. If not available, the values are assumed to be the same of predecessor or similar experiments (e.g. the instrumental efficiency is usually not given prior to the construction and operation of an experiment). Our heuristic counting analysis is used to derive the sensitivity of each experiment for both a limit setting and a signal discovery analysis [35]. The collaborations typically quote only the former, but this is enough to cross-check -and possibly tune -the sensitive background and exposure used for this work. Given the values in TABLE I, our calculation reproduces the official sensitivities quoted by each experiment with 10-20% accuracy.",
            "paragraph_rank": 57,
            "section_rank": 10,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b35",
                    "start": 523,
                    "text": "[35]",
                    "end": 527
                }
            ]
        },
        {
            "section": "Appendix C: Experimental parameters",
            "text": "LEGEND [62,63] is the successor of GERDA and Majorana [51,52].",
            "paragraph_rank": 58,
            "section_rank": 10,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b62",
                    "start": 7,
                    "text": "[62,",
                    "end": 11
                },
                {
                    "type": "bibr",
                    "ref_id": "b63",
                    "start": 11,
                    "text": "63]",
                    "end": 14
                },
                {
                    "type": "bibr",
                    "ref_id": "b51",
                    "start": 54,
                    "text": "[51,",
                    "end": 58
                },
                {
                    "type": "bibr",
                    "ref_id": "b52",
                    "start": 58,
                    "text": "52]",
                    "end": 61
                }
            ]
        },
        {
            "section": "Appendix C: Experimental parameters",
            "text": "The project consists of two stages: LEGEND 200 and LEGEND 1k. In the first phase, 200 kg of germanium detectors enriched at 87% in 76 Ge will be operated in the existing GERDA infrastructure. The background level measured in GERDA Phase II is B=1.2\u202210 \u22122 cts/(kg iso ROI yr) in average and 5.1\u202210 \u22123 cts/(kg iso ROI yr) when only the new generation BEGe-type detectors are considered [63]. Compared to the results obtained with BEGe detectors, a further reduction of a factor \u223c3 is expected in LEGEND 200. For LEGEND 1k, a new infrastructure able to host 1 ton of target mass and a further 6-fold background reduction are conceived. We assume the same resolution achieved by the running experiments (\u223c3 keV full width at half maximum, FWHM), and use a ROI of (Q-value \u00b12\u03c3). Enrichment, active volume, containment and instrumental efficiency are taken from Ref. [28]. Our calculation agrees with the sensitivity projections of the collaboration [62,63] when the same ROI is used.",
            "paragraph_rank": 59,
            "section_rank": 10,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b77",
                    "start": 131,
                    "text": "76",
                    "end": 133
                },
                {
                    "type": "bibr",
                    "ref_id": "b63",
                    "start": 384,
                    "text": "[63]",
                    "end": 388
                },
                {
                    "type": "bibr",
                    "ref_id": "b28",
                    "start": 861,
                    "text": "[28]",
                    "end": 865
                },
                {
                    "type": "bibr",
                    "ref_id": "b62",
                    "start": 944,
                    "text": "[62,",
                    "end": 948
                },
                {
                    "type": "bibr",
                    "ref_id": "b63",
                    "start": 948,
                    "text": "63]",
                    "end": 951
                }
            ]
        },
        {
            "section": "Appendix C: Experimental parameters",
            "text": "SuperNEMO [69,70] is an upgrade of the NEMO-3 experiment. This is the only experiment considered here in which the 0\u03bd\u03b2\u03b2 decay isotope is separate from the detector. SuperNEMO will consist of 20 identical tracking chambers, each containing \u223c5 kg of 82 Se embedded in Mylar foils. SuperNEMO can measure independently the energy and direction of the two electrons emitted by 0\u03bd\u03b2\u03b2 decays, and distinguish different decay channels [70]. The electrons do not release all their energy in the chamber: the expected 0\u03bd\u03b2\u03b2 decay signature for 82 Se is thus a Gaussian peak at \u223c2830 keV, about 170 keV below the 82 Se Q-value [70]. The product of containment and instrumental efficiency for 82 Se 0\u03bd\u03b2\u03b2 decay events is quoted to be 28.2% in Ref. [70]. However, the 0\u03bd\u03b2\u03b2 decay peak will be on the tail of the 2\u03bd\u03b2\u03b2 decay spectrum (see FIG. 5 of Ref. [70]). We therefore extracted the expected total efficiency and total number of background counts for different energy ranges, and use the ones providing the best sensitivity, i.e. [2800, 3100] keV. The corresponding total efficiency, which also includes the fraction of 0\u03bd\u03b2\u03b2 decay events falling within the ROI, is taken to be 16.5%. With such parameters, we accurately reproduce the official sensitivity [70]. SuperNEMO expects to improve their energy resolution by a factor of 2 and the background level by a factor of \u223c50 with respect to NEMO-3 [69,70].",
            "paragraph_rank": 60,
            "section_rank": 10,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b69",
                    "start": 10,
                    "text": "[69,",
                    "end": 14
                },
                {
                    "type": "bibr",
                    "ref_id": "b70",
                    "start": 14,
                    "text": "70]",
                    "end": 17
                },
                {
                    "type": "bibr",
                    "ref_id": "b83",
                    "start": 248,
                    "text": "82",
                    "end": 250
                },
                {
                    "type": "bibr",
                    "ref_id": "b70",
                    "start": 426,
                    "text": "[70]",
                    "end": 430
                },
                {
                    "type": "bibr",
                    "ref_id": "b70",
                    "start": 614,
                    "text": "[70]",
                    "end": 618
                },
                {
                    "type": "bibr",
                    "ref_id": "b70",
                    "start": 733,
                    "text": "[70]",
                    "end": 737
                },
                {
                    "type": "bibr",
                    "ref_id": "b70",
                    "start": 835,
                    "text": "[70]",
                    "end": 839
                },
                {
                    "type": "bibr",
                    "ref_id": "b70",
                    "start": 1241,
                    "text": "[70]",
                    "end": 1245
                },
                {
                    "type": "bibr",
                    "ref_id": "b69",
                    "start": 1384,
                    "text": "[69,",
                    "end": 1388
                },
                {
                    "type": "bibr",
                    "ref_id": "b70",
                    "start": 1388,
                    "text": "70]",
                    "end": 1391
                }
            ]
        },
        {
            "section": "Appendix C: Experimental parameters",
            "text": "CUPID [59,60,71] is an upgrade of the CUORE experiment [53,54]. In CUORE, \u223c1000 TeO 2 crystals with natural isotopic composition are operated as calorimeters (bolometers) at a base temperature of \u223c10 mK. CU-PID plans to exploit the CUORE cryogenic infrastructure, and increase the sensitivity to 0\u03bd\u03b2\u03b2 decay using enriched crystals with \u03b1/\u03b2 discrimination capabilities. Several crystals with different double-\u03b2 decaying isotopes are under investigation, including TeO 2 , ZnMoO 4 , ZnSe and CdWO 4 . We quote results only for TeO 2 and ZnSe, which we found to yield the lowest background and the highest sensitivity. Both CUORE and CUPID aim at an energy resolution of \u223c0.2% (FWHM), which has been proven on a large array of TeO 2 crystals in CUORE-0 [82]. In CUORE, a background level reduction of a factor \u223c6 with respect to CUORE-0 is expected thanks to improved shielding and a careful selection of all materials [83]. A further reduction in background level by a factor \u223c500 is conceived for CUPID with TeO 2 : this can be achieved thanks to the readout of Cherenkov light induced by electrons in TeO 2 , or of the scintillation light in the other crystals mentioned above. The optimal ROI's for CUORE and CUPID are (Q-value\u00b11.4\u03c3) and (Q-value\u00b12\u03c3), respectively. For both experiments we used an instrumental efficiency of 92% as in its predecessor CUORE-0 [82]. The exclusion sensitivity we obtained differs by 10% from the official values [59,84]. SNO+ is an ongoing upgrade of SNO. It is a multipurpose neutrino experiment, with 0\u03bd\u03b2\u03b2 decay search as one of its main physics goals [67,72]. An acrylic sphere with about 800 tons of liquid scintillator, loaded with tellurium, will be inserted in water. A multi-staged approach is foreseen. In SNO+ Phase I, \u223c1.3 tons of 130 Te are used and an energy resolution of 7.5% FWHM is expected. The goal of SNO+ Phase II [68] is to increase the 130 Te mass to \u223c8 tons and improve the energy resolution to 5.3%. This is achievable thanks to an improvement of the light yield to 800 pe/MEV [85]. We assumed a containment efficiency of 100% and an instrumental efficiency of \u223c97% as for KamLAND-Zen. Using an asymmetric ROI of (Q-value +1. 5 \u22120.5 \u03c3) [67,68,72], we reproduce the official limit-setting sensitivity [72] with a few percent accuracy.",
            "paragraph_rank": 61,
            "section_rank": 10,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b59",
                    "start": 6,
                    "text": "[59,",
                    "end": 10
                },
                {
                    "type": "bibr",
                    "ref_id": "b60",
                    "start": 10,
                    "text": "60,",
                    "end": 13
                },
                {
                    "type": "bibr",
                    "ref_id": "b71",
                    "start": 13,
                    "text": "71]",
                    "end": 16
                },
                {
                    "type": "bibr",
                    "ref_id": "b53",
                    "start": 55,
                    "text": "[53,",
                    "end": 59
                },
                {
                    "type": "bibr",
                    "ref_id": "b54",
                    "start": 59,
                    "text": "54]",
                    "end": 62
                },
                {
                    "type": "bibr",
                    "ref_id": "b83",
                    "start": 750,
                    "text": "[82]",
                    "end": 754
                },
                {
                    "type": "bibr",
                    "ref_id": "b84",
                    "start": 916,
                    "text": "[83]",
                    "end": 920
                },
                {
                    "type": "bibr",
                    "ref_id": "b83",
                    "start": 1360,
                    "text": "[82]",
                    "end": 1364
                },
                {
                    "type": "bibr",
                    "ref_id": "b59",
                    "start": 1444,
                    "text": "[59,",
                    "end": 1448
                },
                {
                    "type": "bibr",
                    "ref_id": "b85",
                    "start": 1448,
                    "text": "84]",
                    "end": 1451
                },
                {
                    "type": "bibr",
                    "ref_id": "b67",
                    "start": 1586,
                    "text": "[67,",
                    "end": 1590
                },
                {
                    "type": "bibr",
                    "ref_id": "b72",
                    "start": 1590,
                    "text": "72]",
                    "end": 1593
                },
                {
                    "type": "bibr",
                    "ref_id": "b68",
                    "start": 1867,
                    "text": "[68]",
                    "end": 1871
                },
                {
                    "type": "bibr",
                    "ref_id": "b86",
                    "start": 2034,
                    "text": "[85]",
                    "end": 2038
                },
                {
                    "type": "bibr",
                    "ref_id": "b4",
                    "start": 2183,
                    "text": "5",
                    "end": 2184
                },
                {
                    "type": "bibr",
                    "ref_id": "b67",
                    "start": 2193,
                    "text": "[67,",
                    "end": 2197
                },
                {
                    "type": "bibr",
                    "ref_id": "b68",
                    "start": 2197,
                    "text": "68,",
                    "end": 2200
                },
                {
                    "type": "bibr",
                    "ref_id": "b72",
                    "start": 2200,
                    "text": "72]",
                    "end": 2203
                },
                {
                    "type": "bibr",
                    "ref_id": "b72",
                    "start": 2257,
                    "text": "[72]",
                    "end": 2261
                }
            ]
        },
        {
            "section": "Appendix C: Experimental parameters",
            "text": "KamLAND-Zen is a KamLAND upgrade tailored to the search of 0\u03bd\u03b2\u03b2 decay: a nylon balloon is inserted in the active detector volume and filled with liquid scintillator loaded with enriched xenon. After two successful data taking phases [27,86], the KamLAND-Zen collaboration is currently preparing two additional phases called KamLAND-Zen 800 and KamLAND2-Zen in which 750 kg and 1 ton of 136 Xe will be deployed, respectively. A major upgrade of the experiment is conceived for KamLAND2-Zen to improve the energy resolution at the 136 Xe Q-values from 4.6% to 2% (\u03c3) and to reduce the background by an order of magnitude. The upgrade includes the installation of new light concentrators and PMTs with higher quantum efficiency [61] as well as purer liquid scintillator. In our study we used the same instrumental efficiency as reported in Ref. [27]. The optimal ROI is asymmetric covering only the upper half of the expected 0\u03bd\u03b2\u03b2 decay peak to avoid the background due to the 2\u03bd\u03b2\u03b2 decay spectrum tail. Our calculations reproduce the sensitivities presented in [27,61,86] within 20%. The background measured in KamLAND-Zen phase 2 is B=1.1\u202210 \u22121 cts/(kg iso ROI yr) in average, and 5.9\u202210 \u22122 cts/(kg iso ROI yr) when only the second part of the data taking is considered (period 2). Compared to this last result, a further reduction of a factor 1.5 (\u223c15) is expected for KamLAND-Zen 800 (KamLAND2-Zen).",
            "paragraph_rank": 62,
            "section_rank": 10,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b26",
                    "start": 233,
                    "text": "[27,",
                    "end": 237
                },
                {
                    "type": "bibr",
                    "ref_id": "b87",
                    "start": 237,
                    "text": "86]",
                    "end": 240
                },
                {
                    "type": "bibr",
                    "ref_id": "b61",
                    "start": 725,
                    "text": "[61]",
                    "end": 729
                },
                {
                    "type": "bibr",
                    "ref_id": "b26",
                    "start": 842,
                    "text": "[27]",
                    "end": 846
                },
                {
                    "type": "bibr",
                    "ref_id": "b26",
                    "start": 1058,
                    "text": "[27,",
                    "end": 1062
                },
                {
                    "type": "bibr",
                    "ref_id": "b61",
                    "start": 1062,
                    "text": "61,",
                    "end": 1065
                },
                {
                    "type": "bibr",
                    "ref_id": "b87",
                    "start": 1065,
                    "text": "86]",
                    "end": 1068
                }
            ]
        },
        {
            "section": "Appendix C: Experimental parameters",
            "text": "nEXO [87] is an upgrade of the EXO-200 [55] experiment. The detector is a liquid Time Projection Chamber (TPC) filled with 5 tons of xenon enriched at 90% in 136 Xe. One of the main background contributions expected in nEXO is due to radioactive isotopes in the TPC materials. Because of the self-shielding of the Xe material, the rate of background events decreases exponentially moving toward the center. The collaboration plans to perform an analysis of the full detector volume, using the outer part to constrain the external background contribution. Our counting analysis cannot take care of this and we are forced to tune the sensitive background and exposure. Given a fiducial volume of 3 tons of Xe, a ROI of (Q-value\u00b11.2\u03c3) and an average background level of \u223c4\u202210 \u22126 cts/keV/kg iso /yr (that is \u223c20% of the reference value [64,88]) we obtain a discovery sensitivity 15-20% lower than the collaboration's estimate. This is however sufficient for our analysis. The instrumental efficiency is taken for EXO-200 [55]. In nEXO, the energy resolution is expected to be improved by a factor of 1.2, and the background level reduced by about a factor 400 with respect to EXO-200, due primarily to better self-shielding and more efficient background identification in the larger experiment.",
            "paragraph_rank": 63,
            "section_rank": 10,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b88",
                    "start": 5,
                    "text": "[87]",
                    "end": 9
                },
                {
                    "type": "bibr",
                    "ref_id": "b55",
                    "start": 39,
                    "text": "[55]",
                    "end": 43
                },
                {
                    "type": "bibr",
                    "ref_id": "b64",
                    "start": 832,
                    "text": "[64,",
                    "end": 836
                },
                {
                    "type": "bibr",
                    "ref_id": "b89",
                    "start": 836,
                    "text": "88]",
                    "end": 839
                },
                {
                    "type": "bibr",
                    "ref_id": "b55",
                    "start": 1017,
                    "text": "[55]",
                    "end": 1021
                }
            ]
        },
        {
            "section": "Appendix C: Experimental parameters",
            "text": "NEXT [65] aims at searching for 0\u03bd\u03b2\u03b2 decay using a high-pressure Xe-gas TPC, which combines tracking capabilities with a low background typical of experiments with a single element in the active volume. The expected presence of the 214 Bi gamma line at 2447 keV in vicinity of the 0\u03bd\u03b2\u03b2 decay Q-value at 2458 keV, requires the use of an asymmetric ROI [74]. A single TPC with 100 kg of Xe (90% 136 Xe) and a resolution of 0.75% FWHM [74] will be used in the next phase of the project (NEXT 100). In a later stage, the collaboration plans to operate an array of 3 TPCs, each with a total Xe mass of 500 kg, a background level lower by a factor \u223c10 with respect to NEXT 100 and an improved energy resolution of 0.5% FWHM [75] (NEXT 1.5k) [75]. The total effi-ciency is taken from [74]: the value reported in TABLE I does not contain the fiducial volume fraction (88%) and the fraction of events in the ROI (90%). We compared the NEXT 100 exclusion sensitivity obtained with our approach with that given in [74], and find that the two values agree within \u223c10%.",
            "paragraph_rank": 64,
            "section_rank": 10,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b65",
                    "start": 5,
                    "text": "[65]",
                    "end": 9
                },
                {
                    "type": "bibr",
                    "ref_id": "b75",
                    "start": 351,
                    "text": "[74]",
                    "end": 355
                },
                {
                    "type": "bibr",
                    "ref_id": "b75",
                    "start": 432,
                    "text": "[74]",
                    "end": 436
                },
                {
                    "type": "bibr",
                    "ref_id": "b76",
                    "start": 718,
                    "text": "[75]",
                    "end": 722
                },
                {
                    "type": "bibr",
                    "ref_id": "b76",
                    "start": 735,
                    "text": "[75]",
                    "end": 739
                },
                {
                    "type": "bibr",
                    "ref_id": "b75",
                    "start": 777,
                    "text": "[74]",
                    "end": 781
                },
                {
                    "type": "bibr",
                    "ref_id": "b75",
                    "start": 1003,
                    "text": "[74]",
                    "end": 1007
                }
            ]
        },
        {
            "section": "Appendix C: Experimental parameters",
            "text": "Another experiment using the same technique of NEXT is PandaX. After two phases dedicated to dark matter searches, a 0\u03bd\u03b2\u03b2 decay search program -denoted PandaX-III -is planned [66]. The TPC of PandaX-III will be about twice as big as that of NEXT, but will have an energy resolution of about 3% FWHM [66]. As for NEXT, one of the major expected backgrounds is 214 Bi. Consequently, an asymmetric ROI would yield a higher sensitivity, but for consistency with Ref. [66] we used an ROI of (Q-value\u00b12\u03c3). We could not find information regarding the size of the fiducial volume, and we assume it to be 100%. The total efficiency is about 35% [66]. In a second stage, the PandaX-III collaboration plans to construct four additional TPCs with energy resolution improved to 1% FWHM and a background level reduced by one order of magnitude. Our evaluation of the exclusion sensitivity agrees at the \u223c10% level with the official value [66].",
            "paragraph_rank": 65,
            "section_rank": 10,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b66",
                    "start": 175,
                    "text": "[66]",
                    "end": 179
                },
                {
                    "type": "bibr",
                    "ref_id": "b66",
                    "start": 299,
                    "text": "[66]",
                    "end": 303
                },
                {
                    "type": "bibr",
                    "ref_id": "b66",
                    "start": 463,
                    "text": "[66]",
                    "end": 467
                },
                {
                    "type": "bibr",
                    "ref_id": "b66",
                    "start": 636,
                    "text": "[66]",
                    "end": 640
                },
                {
                    "type": "bibr",
                    "ref_id": "b66",
                    "start": 924,
                    "text": "[66]",
                    "end": 928
                }
            ]
        },
        {
            "text": "FIG. 1 . 1 FIG. 2 .",
            "section_rank": 11
        },
        {
            "section": "FIG. 1 . 1 FIG. 2 .",
            "text": "FIG. 1. Marginalized posterior distributions for m \u03b2\u03b2 and m l for NO (a) and IO (b). The solid lines show the allowed parameter space assuming 3\u03c3 intervals of the neutrino oscillation observables from nu-fit [12]. The plot is produced assuming QRPA NMEs and the absence of mechanisms that drive m l or m \u03b2\u03b2 to zero. The probability density is normalized by the logarithm of m \u03b2\u03b2 and of m l .",
            "paragraph_rank": 66,
            "section_rank": 11
        },
        {
            "text": "FIG. 3 .",
            "section_rank": 12
        },
        {
            "section": "FIG. 3 .",
            "text": "FIG. 3. Discovery sensitivity for 76 Ge, 130 Te, and 136 Xe as a function of sensitive exposure and sensitive background. Contours in m \u03b2\u03b2 are represented as bands spanning the range of considered NME values. The experimental sensitivities of future or running experiments are marked after 5 years of live time. Past or current experiments with published background level and energy resolution (red marks) are shown according to the average performance in their latest data taking phase.",
            "paragraph_rank": 67,
            "section_rank": 12
        },
        {
            "text": "FIG. 4 .",
            "section_rank": 13
        },
        {
            "section": "FIG. 4 .",
            "text": "FIG.4. Discovery probability as a function of live time for a selection of next-generation experiments grouped according to the target isotope (from left to right:76 Ge, 130 Te, 136 Xe), assuming the absence of mechanisms that drive m l or m \u03b2\u03b2 to zero. The top panels show the discovery probability for NO, the bottom panels for IO. The variation of the NME among models is represented by the shaded regions.",
            "paragraph_rank": 68,
            "section_rank": 13,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b3",
                    "start": 4,
                    "text": "4",
                    "end": 5
                },
                {
                    "type": "bibr",
                    "ref_id": "b77",
                    "start": 163,
                    "text": "76",
                    "end": 165
                }
            ]
        },
        {
            "text": "FIG. 5 .",
            "section_rank": 14
        },
        {
            "section": "FIG. 5 .",
            "text": "FIG. 5. Marginalized posterior distributions for NO and IO. The band shows the deformation of the posterior distributions due to different assumptions on the NME. For each parameter three bands are displayed, corresponding to different parametrization of the basis in the fit. The lighter bands are obtained with the reference basis, the darker band are obtained for a basis in which \u03a3 is replaced by m \u03b2 , and the red and blue bands are obtained by replacing \u03a3 with m \u03b2\u03b2 .",
            "paragraph_rank": 69,
            "section_rank": 14
        },
        {
            "text": "For instance, FIG. 5 shows the posterior distributions obtained when \u03a3 is replaced by m \u03b2 in the fit basis (maintaining the logarithmic prior). As occurs for \u03a3, lower m \u03b2 values are prohibited by oscillation experiments and the parameter cannot vanish. The posteriors are basically unchanged with the understandable exception of \u03a3 and m \u03b2 .",
            "paragraph_rank": 70,
            "section_rank": 15
        },
        {
            "text": "1 FIG. 6 .",
            "section_rank": 16
        },
        {
            "section": "1 FIG. 6 .",
            "text": "FIG. 6.Marginalized posterior distributions for the mass observables assuming NO (left) and IO (right).The computation is performed assuming QRPA NMEs and the absence of mechanisms that drive m l or m \u03b2\u03b2 to zero. The solid lines show the allowed parameter space assuming 3\u03c3 intervals of the neutrino oscillation observables from nu-fit[12]. The probability density is normalized by the logarithms of the mass observables.",
            "paragraph_rank": 71,
            "section_rank": 16,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b11",
                    "start": 335,
                    "text": "[12]",
                    "end": 339
                }
            ]
        },
        {
            "text": "10 FIG. 7 .",
            "section_rank": 17
        },
        {
            "section": "10 FIG. 7 .",
            "text": "FIG. 7. 76Ge T 1/2 discovery sensitivity as a function of sensitive exposure for a selection of sensitive background levels.",
            "paragraph_rank": 72,
            "section_rank": 17
        },
        {
            "text": "ACKNOWLEDGMENTS",
            "section_rank": 19
        },
        {
            "section": "ACKNOWLEDGMENTS",
            "text": "The authors would like to thank A. Caldwell ",
            "paragraph_rank": 73,
            "section_rank": 19
        },
        {
            "text": "The posterior distributions of the angles and mass splittings are Gaussian and well defined. The shifts between IO and NO probability distributions come from the results of oscillation experiments [12]. The posterior distributions of the Majorana phases contain some information as the current limits on 0\u03bd\u03b2\u03b2 decay force a partial cancellation between the three terms on the RHS of equation (3). The posterior distribution for \u03b1 21 is more informative than for (\u03b4 \u2212 \u03b1 31 ) as the absolute value of the second term is larger than the third one. The distributions of the parameters related to the mass eigenvalues are considerably different for NO and IO as one would expect. The posteriors of the mass eigenvalues and mass observables are constrained to a finite range because of the relative volumes in the likelihood space. For completeness , FIG. 6 shows the correlations between the",
            "paragraph_rank": 74,
            "section_rank": 21,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b11",
                    "start": 197,
                    "text": "[12]",
                    "end": 201
                },
                {
                    "type": "bibr",
                    "ref_id": "b2",
                    "start": 391,
                    "text": "(3)",
                    "end": 394
                },
                {
                    "type": "figure",
                    "start": 842,
                    "text": ", FIG. 6",
                    "end": 850
                }
            ]
        }
    ]
}