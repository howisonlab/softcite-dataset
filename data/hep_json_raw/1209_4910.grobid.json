{
    "level": "paragraph",
    "abstract": [
        {
            "text": "Prompt photons are a powerful tool to study heavy ion collisions. Their production rates provide access to the initial state parton distribution functions and also provide a means to calibrate the expected energy of jets that are produced in the medium. The ATLAS detector measures photons with its hermetic, longitudinally segmented calorimeter, which gives excellent spatial and energy resolutions, and detailed information about the shower shape of each measured photon. This provides significant rejection against the expected background from the decays of neutral pions in jets. Rejection against jet fragmentation products is further enhanced by requiring candidate photons to be isolated. First results on the spectra of isolated prompt photons from a dataset with an integrated luminosity of approximately 0.13 nb \u22121 of lead-lead collisions at \u221a s NN = 2.76 TeV are shown as a function of transverse momentum and centrality.",
            "paragraph_rank": 0,
            "section_rank": 1
        },
        {
            "text": "The measured spectra are compared to expectations from perturbative QCD calculations.",
            "paragraph_rank": 1,
            "section_rank": 1
        }
    ],
    "body_text": [
        {
            "text": "Introduction",
            "section_rank": 2
        },
        {
            "section": "Introduction",
            "text": "While di-jet asymmetry distributions at the Large Hadron Collider (LHC) [1] are consistent with energy loss in the hot, dense medium, the detailed physical mechanism of \"jet quenching\" is still not understood. One of the limiting factors in understanding jet quenching is having a proper calibration of the initial jet energy. Replacing one of the jets with a penetrating probe, such as a photon or electroweak boson (W or Z), offers the possibility of calibrating the energy of the initial jet. This was first proposed by Wang and collaborators in Ref. [2].",
            "paragraph_rank": 2,
            "section_rank": 2,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b0",
                    "start": 72,
                    "text": "[1]",
                    "end": 75
                },
                {
                    "type": "bibr",
                    "ref_id": "b1",
                    "start": 554,
                    "text": "[2]",
                    "end": 557
                }
            ]
        },
        {
            "section": "Introduction",
            "text": "Prompt photons are themselves expected to arise via direct emission and fragmentation from jets. In order to remove background events from di-jet processes, as well as the fragmentation photons, an \"isolation\" criterion is typically applied within a cone of a well-defined radius relative to the photon direction. In lower-energy heavy ion collisions, the PHENIX experiment performed measurements of direct photon rates in gold-gold collisions at \u221a s NN = 200 GeV [3]. The CMS experiment performed the first measurement of isolated prompt photon rates in both proton-proton as well as lead-lead collisions, at the nucleon-nucleon center-of-mass energy of \u221a s NN = 2.76 TeV [4].",
            "paragraph_rank": 3,
            "section_rank": 2,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b2",
                    "start": 464,
                    "text": "[3]",
                    "end": 467
                },
                {
                    "type": "bibr",
                    "ref_id": "b3",
                    "start": 673,
                    "text": "[4]",
                    "end": 676
                }
            ]
        },
        {
            "section": "Introduction",
            "text": "They found rates consistent with a scaling with the number of binary collisions. This work presents the measurement of the yield of prompt isolated photons in the transverse momentum range p T = 45 \u2212 200 GeV as a function of collision centrality from the ATLAS experiment. The results are described in more detail in Ref.",
            "paragraph_rank": 4,
            "section_rank": 2
        },
        {
            "section": "Introduction",
            "text": "[5].",
            "paragraph_rank": 5,
            "section_rank": 2
        },
        {
            "text": "Experimental setup and photon reconstruction",
            "section_rank": 3
        },
        {
            "section": "Experimental setup and photon reconstruction",
            "text": "The ATLAS detector is described in detail in Ref. [6]. The ATLAS inner detector is comprised of three major subsystems: the pixel detector, the semiconductor detector (SCT) and the transition radiation tracker (TRT), which cover full azimuth and pseudorapidity out to |\u03b7| = 2.5. The ATLAS calorimeter is a large-acceptance, longitudinallysegmented sampling calorimeter covering |\u03b7| < 4.9 with electromagnetic and hadronic sections. In test beam environments and in typical proton-proton collisions, the calorimeter is found to have a sampling term for electromagnetic arXiv:1209.4910v1 [hep-ex] 21 Sep 2012",
            "paragraph_rank": 6,
            "section_rank": 3,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b4",
                    "start": 50,
                    "text": "[6]",
                    "end": 53
                }
            ]
        },
        {
            "section": "Experimental setup and photon reconstruction",
            "text": ". The total material in front of the electromagnetic calorimeter ranges from 2.5 to 6 radiation lengths as a function of pseudorapidity, except the transition region between the barrel and endcap regions, in which the material is up to 11.5 radiation lengths. The hadronic calorimeter section is located radially just after the electromagnetic calorimeter. Within |\u03b7| < 1.7, it is a sampling calorimeter of steel and scintillator tiles, with a depth of 7.4 hadronic interaction lengths. In the endcap region it is copper and liquid argon with a depth of 9 interaction lengths.",
            "paragraph_rank": 7,
            "section_rank": 3
        },
        {
            "section": "Experimental setup and photon reconstruction",
            "text": "To reconstruct photons in the context of a heavy ion collision, the large background from the underlying event (UE) is subtracted from each event. This is performed during the heavy ion jet reconstruction, which precedes the photon reconstruction, as explained in detail in Ref. [7]. This procedure provides a new set of \"subtracted\" cells, from which the mean underlying event, as well as the large-scale modulation from elliptic flow, has been removed. Acting upon the subtracted cells, the ATLAS photon reconstruction [8] is seeded by clusters of at least 2.5 GeV found using a sliding window algorithm applied to the second sampling layer of the electromagnetic calorimeter, which typically absorbs over 50% of the deposited photon energy. The energy measurement is made using all three layers of the electromagnetic calorimeter and the presampler, with a size in the barrel region of \u2206\u03b7 \u00d7 \u2206\u03c6 = 0.075 \u00d7 0.0125. In the dense environment of the heavy ion collision, the photon conversion recovery procedure is not performed, due to the overwhelming number of combinatoric pairs in more central collisions.",
            "paragraph_rank": 8,
            "section_rank": 3,
            "ref_spans": [
                {
                    "type": "bibr",
                    "start": 279,
                    "text": "[7]",
                    "end": 282
                }
            ]
        },
        {
            "section": "Experimental setup and photon reconstruction",
            "text": "To reject clusters arising from hadronic fragments of jets, particularly neutral mesons, the calorimeter is also used to measure an isolation energy for each photon candidate, E T (R iso ). The isolation energy is the sum of transverse energies in calorimeter cells (including hadronic and electromagnetic sections) in a cone defined by R = \u2206\u03b7 2 + \u2206\u03c6 2 < R iso around the photon axis, excluding central core of cells in a region with a size corresponding to 5\u00d77 second layer cells.",
            "paragraph_rank": 9,
            "section_rank": 3
        },
        {
            "text": "Data and simulation samples",
            "section_rank": 4
        },
        {
            "section": "Data and simulation samples",
            "text": "The data sample analyzed here is from the 2011 LHC heavy ion run, colliding lead nuclei at",
            "paragraph_rank": 10,
            "section_rank": 4
        },
        {
            "section": "Data and simulation samples",
            "text": "TeV. After a trigger requiring a 16 GeV energy deposition in the electromagnetic calorimeter, which is sensitive in particular to both electrons and photons, events were selected which contained a reconstructed photon or electron candidate with a cluster transverse energy of at least 40 GeV. Events were then further analyzed if they satisfied a set of quality cuts: the event had to be taken during a period when the detector was found to be working properly, leaving an integrated luminoisty of approximately L int = 0.13 nb \u22121 for this analysis, after the exclusion of several runs. Two sets of Minimum Bias Trigger Scintillators covering 2.09 < |\u03b7| < 3.84 are required to have a well reconstructed time signal, and a relative time between the two counters of less than 5 ns. Finally, a good vertex is required to be reconstructed in the ATLAS detector, to reject background events from e.g. cosmic rays. In this measurement, yields are presented per minimum bias collision, which are estimated using the total integrated luminosity, measured using the ATLAS luminosity detectors [9]. The centrality of each heavy ion collision is determined using the sum of the transverse energy in all cells in the forward calorimeter (3.1 < |\u03b7| < 4.9), at the electromagnetic scale. The minimum bias trigger and event selection criteria were studied in detail in the 2010 data sample [13] and it was found that 98 \u00b1 2% of the total inelastic cross section is sampled by the trigger and event selection requirements. For this analysis, the data have been divided into four centrality intervals, covering the 0-10%, 10-20%, 20-40% and 40-80% most central events. In this convention, the 0-10% interval has the highest multiplicities, and the 40-80% the lowest.",
            "paragraph_rank": 11,
            "section_rank": 4,
            "ref_spans": [
                {
                    "type": "bibr",
                    "start": 1084,
                    "text": "[9]",
                    "end": 1087
                },
                {
                    "type": "bibr",
                    "ref_id": "b8",
                    "start": 1375,
                    "text": "[13]",
                    "end": 1379
                }
            ]
        },
        {
            "section": "Data and simulation samples",
            "text": "For the extraction of photon performance parameters (efficiencies, photon energy scale, isolation properties), a set of 450,000 photon+jet events generated using the ATLAS MC11 tune of PYTHIA 6.4 [10] at \u221a s = 2.76 TeV, is overlaid on minimum-bias HIJING [11] events, which are referred-to as the \"PYTHIA+HIJING\" sample. The generated events are fully simulated using GEANT4 [12] and digitized to produce simulated raw data files, that are reconstructed and analyzed exactly as is done for experimental data.",
            "paragraph_rank": 12,
            "section_rank": 4,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b5",
                    "start": 196,
                    "text": "[10]",
                    "end": 200
                },
                {
                    "type": "bibr",
                    "ref_id": "b6",
                    "start": 255,
                    "text": "[11]",
                    "end": 259
                },
                {
                    "type": "bibr",
                    "ref_id": "b7",
                    "start": 375,
                    "text": "[12]",
                    "end": 379
                }
            ]
        },
        {
            "text": "Photon selection and reconstruction performance",
            "section_rank": 5
        },
        {
            "section": "Photon selection and reconstruction performance",
            "text": "The fine-grained, longitudinally segmented calorimeter utilized in ATLAS allows detailed characterization of the shape of each photon shower, providing tools to reject jets and hadrons, while maintaining high efficiency for the photons themselves. In this analysis, nine shower-shape variables are used, all of which have been used extensively in previous ATLAS measurements, particularly the measurement of prompt photon spectra as a function of pseudorapidity [14,15]. The cuts used in this analysis are \"HI tight\" cuts, defined in Ref.",
            "paragraph_rank": 13,
            "section_rank": 5,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b9",
                    "start": 462,
                    "text": "[14,",
                    "end": 466
                },
                {
                    "type": "bibr",
                    "ref_id": "b10",
                    "start": 466,
                    "text": "15]",
                    "end": 469
                }
            ]
        },
        {
            "section": "Photon selection and reconstruction performance",
            "text": "[5] as a minimal set of changes to the standard set of tight cuts used for unconverted photons in the proton-proton analysis. Photons are also restricted to be in the pseudorapidity interval |\u03b7| < 1.3.",
            "paragraph_rank": 14,
            "section_rank": 5
        },
        {
            "section": "Photon selection and reconstruction performance",
            "text": "Relative to the energy calibration determined in pp collisions [8], the residual correction needed to compensate for the mixture of converted and unconverted photons is found to be generally less than a percent for much of the measured p T range. It was found in the PYTHIA+HIJING sample, that there are no significant differences in the residual corrections between peripheral and central events. Figure 1 shows the distributions of the isolation energy E T (R iso = 0.3) for two centrality bins, compared with simulated distributions, normalized in the region E T (R iso = 0.3) < 0. Both data and MC distributions grow noticeably wider with increasing centrality, and agree well in the region of negative isolation energy. The observed enhancement on the E T (R iso = 0.3) > 0 side of these distributions is expected from di-jet background events.",
            "paragraph_rank": 15,
            "section_rank": 5,
            "ref_spans": [
                {
                    "type": "figure",
                    "ref_id": "fig_0",
                    "start": 398,
                    "text": "Figure 1",
                    "end": 406
                }
            ]
        },
        {
            "text": "Measurement of photon yields",
            "section_rank": 6
        },
        {
            "section": "Measurement of photon yields",
            "text": "Di-jet backgrounds are subtracted using the so-called \"double sideband method\" [14,15]) where photons are binned along two axes: the isolation energy within a chosen isolation cone size, and the photon selection criterion (\"tight\" or \"non tight\"). Non-tight photons fail at least one of the more stringent cuts, and have an enhanced di-jet contribution. The double sideband approach uses the ratio of counts for non-tight photons which satisfy or fail the isolation requirement to extrapolate the measured number of tight non-isolated photons into the signal region. The purity extracted using this technique is shown in the left panel of Figure 2 (as 1\u2212Purity) for four centrality intervals.",
            "paragraph_rank": 16,
            "section_rank": 6,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b9",
                    "start": 79,
                    "text": "[14,",
                    "end": 83
                },
                {
                    "type": "bibr",
                    "ref_id": "b10",
                    "start": 83,
                    "text": "15]",
                    "end": 86
                },
                {
                    "type": "figure",
                    "ref_id": "fig_1",
                    "start": 639,
                    "text": "Figure 2",
                    "end": 647
                }
            ]
        },
        {
            "section": "Measurement of photon yields",
            "text": "The final conversion of the measured yield into a yield per event requires two more factors: the total number of events in each centrality sample, and a reconstruction efficiency including all known effects. The efficiencies are defined for \"HI tight\", isolated photons relative to all PYTHIA photons with an isolation energy in a cone of R iso = 0.3 around the photon direction of less than 6 GeV. The needed efficiency corrections are categorized into three broad classes: reconstruction efficiency, identification efficiency, and isolation efficiency. These are defined in such a way that the \"total efficiency\" tot is simply the product of these three factors. The right panel of Figure 2 shows the product of the reconstruction and identification efficiency (points) and the total efficiency (solid lines).",
            "paragraph_rank": 17,
            "section_rank": 6,
            "ref_spans": [
                {
                    "type": "figure",
                    "ref_id": "fig_1",
                    "start": 684,
                    "text": "Figure 2",
                    "end": 692
                }
            ]
        },
        {
            "section": "Measurement of photon yields",
            "text": "Several sources of systematic uncertainty have been estimated by varying the assumptions applied to the analysis: the definition of tight and non-tight cuts, the event counting procedure, the photon energy scale, and the photon energy resolution. The uncertainties are dominated by the variations in the choice of the photon identification cuts and the precise choice of isolation cone properties, and a p T -and centrality-independent uncertainty of 31% is applied.",
            "paragraph_rank": 18,
            "section_rank": 6
        },
        {
            "section": "Measurement of photon yields",
            "text": "The photon yield is defined as 1",
            "paragraph_rank": 19,
            "section_rank": 6
        },
        {
            "section": "Measurement of photon yields",
            "text": "A is the background-subtracted yield in region A, tot is the abovementioned total efficiency, N evt is the number of events in the centrality bin c, \u2206p T is the width of the transverse momentum interval. The final yields are shown divided by the mean nuclear thickness T AA (which scales as the number of binary collisions) as a function of photon p T in Figure 3. While the most peripheral interval (40-80%) is unscaled, each subsequent centrality interval is scaled up by a factor of 10 for visibility. Also included are CMS data [4] for 0-10% central heavy ion collisions, |\u03b7| < 1.44 (a 10% larger interval in \u03b7), and an isolation condition of at most 5 GeV transverse energy in a cone of radius R iso = 0.4, superimposed on the most central bin, as well as CMS pp data [4] from \u221a s = 2.76 TeV, superimposed on the most peripheral bin. The systematic uncertainties on the yield are indicated by yellow bands, and the uncertainties on the mean nuclear thickness are tabulated in Ref. [5]. The ratio of the data to JETPHOX 1.3.0 [16, 17] is shown in the right panel of Figure 3. It is observed that, within the statistical and systematic uncertainties, the data are consistent with the predictions in all centrality intervals.",
            "paragraph_rank": 20,
            "section_rank": 6,
            "ref_spans": [
                {
                    "type": "figure",
                    "ref_id": "fig_2",
                    "start": 355,
                    "text": "Figure 3",
                    "end": 363
                },
                {
                    "type": "bibr",
                    "ref_id": "b3",
                    "start": 532,
                    "text": "[4]",
                    "end": 535
                },
                {
                    "type": "bibr",
                    "ref_id": "b3",
                    "start": 773,
                    "text": "[4]",
                    "end": 776
                },
                {
                    "type": "bibr",
                    "start": 986,
                    "text": "[5]",
                    "end": 989
                },
                {
                    "type": "figure",
                    "ref_id": "fig_2",
                    "start": 1070,
                    "text": "Figure 3",
                    "end": 1078
                }
            ]
        },
        {
            "text": "Conclusion",
            "section_rank": 7
        },
        {
            "section": "Conclusion",
            "text": "Yields of isolated prompt photons in lead-lead collisions have been measured as a function of collision centrality in a kinematic range of photon p T = 45 \u2212 200 GeV and for |\u03b7| < 1.3. Photons have been reconstructed using the large-acceptance, longitudinally segmented ATLAS electromagnetic calorimeter, after subtraction of the average background, event-by-event. After scaling the yields by the mean nuclear thickness T AA , they are observed to be constant as a function of centrality within experimental uncertainties, implying a linear scaling with the number of binary collisions. The scaled yields, as a function of p T , are found to be in good agreement with next-to-leading order pQCD calculations, as implemented in JETPHOX 1.3.0. ",
            "paragraph_rank": 21,
            "section_rank": 7
        },
        {
            "text": "Figure 1 :",
            "section_rank": 8
        },
        {
            "section": "Figure 1 :",
            "text": "Figure 1: Distributions of photon isolation energy in a R iso = 0.3 cone for the most peripheral and central centrality bins in data (black points) and for MC (yellow histogram), normalized for negative E T (R iso = 0.3) values [5]. The differences at large values of E T (R iso = 0.3) can be attributed to the presence of jet contamination in the data, which is not present in the MC sample.",
            "paragraph_rank": 22,
            "section_rank": 8
        },
        {
            "text": "Figure 2 :",
            "section_rank": 9
        },
        {
            "section": "Figure 2 :",
            "text": "photon p 0 100 200 300",
            "paragraph_rank": 23,
            "section_rank": 9
        },
        {
            "text": "Figure 3 :",
            "section_rank": 10
        },
        {
            "section": "Figure 3 :",
            "text": "photon p 0 100 200",
            "paragraph_rank": 24,
            "section_rank": 10
        }
    ]
}