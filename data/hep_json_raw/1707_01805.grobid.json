{
    "level": "paragraph",
    "abstract": [
        {
            "text": "The search for the lepton flavor violating decay \u03bc + \u2192 e + \u03b3 will reach an unprecedented level of sensitivity within the next five years thanks to the MEG-II experiment. This experiment will take data at the Paul Scherrer Institut where continuous muon beams are delivered at a rate of about 10 8 muons per second. On the same time scale, accelerator upgrades are expected in various facilities, making it feasible to have continuous beams with an intensity of 10 9 or even 10 10 muons per second. We investigate the experimental limiting factors that will define the ultimate performances, and hence the sensitivity, in the search for \u03bc + \u2192 e + \u03b3 with a continuous beam at these extremely high rates. We then consider some conceptual detector designs and evaluate the corresponding sensitivity as a function of the beam intensity.",
            "paragraph_rank": 2,
            "section_rank": 1
        }
    ],
    "body_text": [
        {
            "text": "Introduction",
            "section_rank": 2
        },
        {
            "section": "Introduction",
            "text": "The search for lepton flavor violation in charged lepton decays like \u03bc + \u2192 e + \u03b3 plays a crucial role in the search for physics beyond the Standard Model (SM). The conservation of the lepton flavor is an accidental symmetry in the SM and is generally broken in new physics (NP) models, which are already strongly constrained by the present limits. The discovery of neutrino oscillations already demonstrated that this symmetry is not exact, although the impact on the charged lepton sector is negligible, predicting for the \u03bc + \u2192 e + \u03b3 decay a branching ratio (BR) of about 10 \u221254 , far away from the present experimental limit, BR(\u03bc + \u2192 e + \u03b3 ) < 4.2 \u00d7 10 \u221213 [1], obtained by the MEG collaboration at the Paul Scherrer Institut (PSI, Switzerland).",
            "paragraph_rank": 3,
            "section_rank": 2,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b0",
                    "start": 661,
                    "text": "[1]",
                    "end": 664
                }
            ]
        },
        {
            "section": "Introduction",
            "text": "a e-mail: angela.papa@psi.ch b e-mail: francesco.renga@roma1.infn.it These features make the search for charged lepton flavor violation (cLFV) very attractive: on one side, limits on BR(\u03bc + \u2192 e + \u03b3 ) hugely impact the development of NP models; on the other side, an observation of this or any other cLFV decay would be an unambiguous evidence of NP [2], without any theoretical uncertainty.",
            "paragraph_rank": 4,
            "section_rank": 2,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b1",
                    "start": 349,
                    "text": "[2]",
                    "end": 352
                }
            ]
        },
        {
            "section": "Introduction",
            "text": "In the search for cLFV in muon decays, a central role is played by the availability of high intensity continuous muon beams, 1 and there are activities around the world [3][4][5][6][7] to increase the beam rates to eventually reach 10 10 muons per second. In this context, it is crucial to understand which factors will limit the sensitivity of experiments to be run at these facilities in the future. In this paper we concentrate on the \u03bc + \u2192 e + \u03b3 searches. After briefly reviewing the current experimental status and the ongoing efforts to build high intensity continuous muon beam lines, we will investigate the ultimate experimental resolutions and efficiencies which cannot be realistically surpassed with the current experimental concepts, even considering some incremental improvement in the detection techniques. Moreover, we will shortly discuss how these ultimate performances could be technically reached. Finally, we determine the sensitivity which could be obtained if the proposed strategies will be found to be technically feasible.",
            "paragraph_rank": 5,
            "section_rank": 2,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b0",
                    "start": 125,
                    "text": "1",
                    "end": 126
                },
                {
                    "type": "bibr",
                    "ref_id": "b2",
                    "start": 169,
                    "text": "[3]",
                    "end": 172
                },
                {
                    "type": "bibr",
                    "ref_id": "b3",
                    "start": 172,
                    "text": "[4]",
                    "end": 175
                },
                {
                    "type": "bibr",
                    "ref_id": "b4",
                    "start": 175,
                    "text": "[5]",
                    "end": 178
                },
                {
                    "type": "bibr",
                    "ref_id": "b5",
                    "start": 178,
                    "text": "[6]",
                    "end": 181
                },
                {
                    "type": "bibr",
                    "ref_id": "b6",
                    "start": 181,
                    "text": "[7]",
                    "end": 184
                }
            ]
        },
        {
            "text": "Basics of \u03bc \u2192 e\u03b3 searches",
            "section_rank": 3
        },
        {
            "section": "Basics of \u03bc \u2192 e\u03b3 searches",
            "text": "The largest step in \u03bc \u2192 e\u03b3 sensitivity was due to the transition from the search in cosmic muon decays (rate of the order of Hz) to muons from stopped pion beams (four orders of magnitude higher rate) and eventually to muon beams (two further orders of magnitude). Within each beam configuration the improvements of the detector resolutions, which determine the background rejection capability, were fundamental.",
            "paragraph_rank": 6,
            "section_rank": 3
        },
        {
            "section": "Basics of \u03bc \u2192 e\u03b3 searches",
            "text": "Muons are usually stopped in a target, in order to exploit the very clear signature of a decay at rest: an e + and a \u03b3 in coincidence, moving collinearly back-to-back with their energies equal to half of the muon mass (m \u03bc /2 = 52.8 MeV). The searches are carried out by using positive muons: negative muons cannot be used, since they are captured by nuclei while being stopped in the target.",
            "paragraph_rank": 7,
            "section_rank": 3
        },
        {
            "section": "Basics of \u03bc \u2192 e\u03b3 searches",
            "text": "There are two major sources of background events. One is the radiative muon decay (RMD), \u03bc + \u2192 e\u03b3 \u03bd e\u03bd\u03bc , when the positron and the photon are emitted almost back-toback while the two neutrinos carry off little energy. The other is due to the accidental coincidence of a positron from a Michel muon decay, \u03bc + \u2192 e + \u03bd e\u03bd\u03bc , with a high energy photon, whose source might be either a RMD, the annihilation-in-flight (AIF) of a positron in a Michel decay or the bremsstrahlung from a positron.",
            "paragraph_rank": 8,
            "section_rank": 3
        },
        {
            "section": "Basics of \u03bc \u2192 e\u03b3 searches",
            "text": "To separate the signal from the various background events, four discriminating variables are commonly used. The positron energy E e , the photon energy E \u03b3 and the relative angle \u0398 e\u03b3 allow to reject both accidental and RMD events, while the further request of a tight time coincidence between the positron and the photon (relative time T e\u03b3 = 0) helps by reducing the accidental background. It is also important to notice that these variables are not correlated for accidental background events, and poorly correlated for RMDs on the scale of the detector resolutions, while in signal events there is a precise expectation value for each of them. This makes it advantageous to use them separately in a statistical analysis, instead of combining them into an invariant mass.",
            "paragraph_rank": 9,
            "section_rank": 3
        },
        {
            "section": "Basics of \u03bc \u2192 e\u03b3 searches",
            "text": "In the four-dimensional space of these discriminating variables a signal region can be defined around their expectation values for the signal events, with widths \u03b4 E e , \u03b4 E \u03b3 , \u03b4T e\u03b3 and \u03b4\u0398 e\u03b3 which can be taken proportional to the corresponding resolutions. Hence, the impact of the resolution on each variable can be quantified, considering the rate of accidental events falling in this signal region. According to [8,9], this rate satisfies:",
            "paragraph_rank": 10,
            "section_rank": 3,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b7",
                    "start": 418,
                    "text": "[8,",
                    "end": 421
                },
                {
                    "type": "bibr",
                    "ref_id": "b8",
                    "start": 421,
                    "text": "9]",
                    "end": 423
                }
            ]
        },
        {
            "section": "Basics of \u03bc \u2192 e\u03b3 searches",
            "text": "where \u0393 \u03bc is the muon stopping rate. This expression is derived considering the photons from RMD, whose rate can be precisely predicted based on the RMD theoretical BR and the detector acceptance, with only minor corrections [10]. For AIF photons, the absolute rate depends on the material crossed by the positrons along their trajectory, and hence on the details of the detector layout.",
            "paragraph_rank": 11,
            "section_rank": 3,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b9",
                    "start": 225,
                    "text": "[10]",
                    "end": 229
                }
            ]
        },
        {
            "section": "Basics of \u03bc \u2192 e\u03b3 searches",
            "text": "A crucial element of Eq. 1 is the dependence on the square of \u0393 \u03bc . Given the current detector resolutions, and with the large values of \u0393 \u03bc available at the present facilities, the accidental background is largely dominant over the prompt RMD contribution. Even imagining a sensible improvement of the resolutions, this is likely to be the case also for the future facilities, when \u0393 \u03bc is increased by one or two orders of magnitude. Under these conditions, there are two regimes for the expected experimental sensitivity. If one indicates with B acc T the background yield in the signal region over the data-taking period of the experiment (T ), the sensitivity improves linearly with the beam rate, as far as B acc T 1 (efficiency-dominated regime). On the other hand, as soon as B acc T 1, there is no advantage from a further increase of the \u0393 \u03bc , since the ratio of the signal yield over the square root of the background yield remains constant (backgrounddominated regime). Indeed, the increased pile-up of several muon decays in the same event would even deteriorate the detector performances. Hence, for a given detector, the optimal \u0393 \u03bc is the one for which no more than a few background events are expected over T . From another point of view, for a given \u0393 \u03bc , the best compromise between resolutions and efficiency is the one giving a few expected background events, because it implies an optimal use of the available beam.",
            "paragraph_rank": 12,
            "section_rank": 3
        },
        {
            "section": "Basics of \u03bc \u2192 e\u03b3 searches",
            "text": "Some further considerations must be added to the discussion above.",
            "paragraph_rank": 13,
            "section_rank": 3
        },
        {
            "section": "Basics of \u03bc \u2192 e\u03b3 searches",
            "text": "1. Tracking detectors can be used to determine precisely the positron direction, but photon detectors cannot provide by themselves a precise determination of the photon direction, to be used in the determination of the \u0398 e\u03b3 angle. Hence, the following procedure is used: muons are stopped in a planar target, the intersection of the positron track with the target plane (positron vertex) is taken as the muon decay point and the photon direction is taken as the vector going from the muon decay point to the photon detection point. Hence, the \u0398 e\u03b3 resolution is determined by the positron vertex resolution and the photon detection point resolution. 2. B acc depends on the square of both the E \u03b3 and \u0398 e\u03b3 resolution. In the first case this dependence arises from the quick drop of the RMD and AIF photon spectra at the kinematic end point. In the second case this can be understood by decomposing \u0398 e\u03b3 in its two independent projections, an azimuth angle \u03c6 e\u03b3 and a polar angle \u03b8 e\u03b3 . This dependence implies that even a small improvement in the resolution of these variables can have a significant impact on the sensitivity. 3. The rate of AIF photons, which tends to be dominant at the kinematical end point [8], depends on the material crossed by the positrons on their trajectories (including positrons out of the detector acceptance and/or produced off-target). Hence, it is crucial to design the detector in order to have the lowest possible material budget, not only in the tracking volume (as needed for good positron resolutions), but in any region around the beam line, in particular near the target. The target itself has to be considered as the main source of AIF photons. 4. Depending on the reconstruction techniques, further discriminating variables can be introduced to suppress the accidental background. If the photon detector allows an even rough reconstruction of the photon trajectory, the likelihood of the photon and positron to come from the same vertex can be evaluated. It would help to further discriminate between signal and accidental background events. In this case, Eq. 1 becomes [11]:",
            "paragraph_rank": 14,
            "section_rank": 3,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b7",
                    "start": 1211,
                    "text": "[8]",
                    "end": 1214
                },
                {
                    "type": "bibr",
                    "ref_id": "b10",
                    "start": 2112,
                    "text": "[11]",
                    "end": 2116
                }
            ]
        },
        {
            "section": "Basics of \u03bc \u2192 e\u03b3 searches",
            "text": "where \u03b4\u0398 \u03b3 is the angular resolution of the photon detector.",
            "paragraph_rank": 15,
            "section_rank": 3
        },
        {
            "section": "Basics of \u03bc \u2192 e\u03b3 searches",
            "text": "The last point above brings us to the discussion of the reconstruction techniques. Concerning the positron, the choice is between charged particle tracking in a magnetic spectrometer and calorimetry, and it is exclusively driven by the achievable resolutions: efficiencies are in fact comparable and potentially close to 100% in both cases. Conversely, for the photon the interplay between efficiency and resolution has to be carefully considered. A calorimetric technique was adopted in most of the past experiments, including MEG [12] with its Liquid Xenon (LXe) detector. This approach provides a large efficiency, only limited by the amount of material in front of the detector (\u223c 1 X 0 in MEG). However, a dif-ferent technique was used in MEGA [13], a previous experiment performed at the Los Alamos National Laboratory: thin layers (\u223c 0.1 X 0 ) of high-Z material were used to make the photon convert, and the resulting e + e \u2212 pair was tracked in a magnetic field. The conversion efficiency is very low (few %), but this technique provides a very precise energy measurement, an extremely precise conversion point measurement and some information about the direction of the photon. Depending on the sensitivity regimes described above, these very good resolutions can compensate the loss in efficiency. Therefore, if \u0393 \u03bc is so low that the B acc can be reduced to a negligible level with a calorimetric technique, there is no real advantage from a large improvement of the resolutions, when it comes at the price of a large efficiency loss. But in a high \u0393 \u03bc regime, when the calorimetric measurement would give too many background events, a strong improvement of the resolutions is the only way to really exploit the highest \u0393 \u03bc , because in this scenario it can compensate the concurrent efficiency loss. Figure 1 shows how a typical detector can be designed to exploit either the calorimetric or conversion technique. In both cases, in order to measure precisely the time of the positron, fast detectors need to be placed at the end of the positron trajectory (not shown in the picture). If the photon is reconstructed in a calorimeter, a fast scintillator needs to be used in order to extract a good measurement of the photon time. Options for timing with the conversion technique will be discussed in detail in Sect. 4.",
            "paragraph_rank": 16,
            "section_rank": 3,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b11",
                    "start": 532,
                    "text": "[12]",
                    "end": 536
                },
                {
                    "type": "bibr",
                    "ref_id": "b12",
                    "start": 749,
                    "text": "[13]",
                    "end": 753
                },
                {
                    "type": "figure",
                    "ref_id": "fig_0",
                    "start": 1813,
                    "text": "Figure 1",
                    "end": 1821
                },
                {
                    "type": "bibr",
                    "ref_id": "b3",
                    "start": 2328,
                    "text": "4",
                    "end": 2329
                }
            ]
        },
        {
            "section": "Basics of \u03bc \u2192 e\u03b3 searches",
            "text": "A real-life example is the MEG experiment: positrons were tracked by a set of 16 planar drift chambers, in order to reconstruct their momentum and direction, and they finally   Sensitivity trends as a function of the beam intensity, for a calorimetry-based design (black), a photon-conversion-based design with unchanged positron resolutions (blue) and a calorimetry-based design with a factor two improvement in resolutions (red). See the text for a detailed description reached a set of scintillating bars for timing purposes, while photons were detected inside a LXe calorimeter instrumented with PMTs, allowing to measure their energy, time and conversion position.",
            "paragraph_rank": 17,
            "section_rank": 3
        },
        {
            "section": "Basics of \u03bc \u2192 e\u03b3 searches",
            "text": "Some concepts presented above are illustrated in Fig. 2. The sensitivity is the smallest BR that can be excluded at some confidence level. The black line shows it for a hypothetical experiment based on the calorimetric technique against the \u0393 \u03bc , for a fixed T . As discussed above, the sensitivity saturates at large \u0393 \u03bc . The blue line shows instead the sensitivity of an experiment having 1/20 photon efficiency but 10 times better E \u03b3 and \u0398 e\u03b3 resolutions, like in a photon conversion approach. For low \u0393 \u03bc the calorimetric approach overcomes the photon conversion, but for very high \u0393 \u03bc the latter is advantageous. Notice that there is also an intermediate range (green-hatched area) where a moderate improvement in calorimetry (a factor 2 in resolutions for this example, red line) can bring this solution back to be preferable. This is exactly what happened with the introduction of LXe calorimetry in MEG after the use of photon conversion in MEGA.",
            "paragraph_rank": 18,
            "section_rank": 3,
            "ref_spans": [
                {
                    "type": "figure",
                    "ref_id": "fig_2",
                    "start": 49,
                    "text": "Fig. 2",
                    "end": 55
                }
            ]
        },
        {
            "section": "Basics of \u03bc \u2192 e\u03b3 searches",
            "text": "The MEG experiment is currently being upgraded (MEG-II, [14]) with the same detector concept but several improvements which will push the sensitivity down of about one order of magnitude in three years of data taking. The main improvements with respect to MEG are: a 2 m-long single-volume cylindrical drift chamber, to improve the tracking resolutions and the positron efficiency; a finer photon detector granularity at the inner face of the calorimeter, to improve the position and energy resolution and the pile-up rejection capabilities of the detector; a highly segmented positron timing counter, to improve the positron time resolution with multiple measurements along the particle's trajectory.",
            "paragraph_rank": 19,
            "section_rank": 3,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b13",
                    "start": 56,
                    "text": "[14]",
                    "end": 60
                }
            ]
        },
        {
            "text": "The next generation of high intensity muon beams",
            "section_rank": 4
        },
        {
            "section": "The next generation of high intensity muon beams",
            "text": "The current best limit on the \u03bc + \u2192 e + \u03b3 BR comes from the MEG experiment, operated at the \u03c0 E5 beam line at PSI. Muons originate from the decay of pions produced by a proton beam impinging on a graphite target. The \u03c0 E5 channel is tuned to select positive muons with an average momentum of 28 MeV/c and a momentum bite of 5-7% FWHM. This setup allows the selection of muons produced by pions decaying right at the surface of the graphite target, providing high beam intensity and optimal rejection of other particles. A rate of 10 8 muons/s can be obtained, but is was limited to 3 \u00d7 10 7 muon/s in MEG, as this gave the best sensitivity, according to the discussion in Sect. 2. In MEG-II \u0393 \u03bc will be increased to 7 \u00d7 10 7 muons/s, thanks to the improved resolutions of the upgraded detectors. Another beam line (\u03bcE4) is also operated at PSI, with the capability of delivering up to 5 \u00d7 10 8 muons/s.",
            "paragraph_rank": 20,
            "section_rank": 4
        },
        {
            "section": "The next generation of high intensity muon beams",
            "text": "In the meanwhile, an intense activity is ongoing at PSI and elsewhere to design channels for continuous muon beams with \u0393 \u03bc exceeding 10 10 muons/s and possibly reaching O(10 11 ) muons/s. At PSI, the high-intensity muon beam (HiMB) project [3][4][5] intends to exploit:",
            "paragraph_rank": 21,
            "section_rank": 4,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b2",
                    "start": 241,
                    "text": "[3]",
                    "end": 244
                },
                {
                    "type": "bibr",
                    "ref_id": "b3",
                    "start": 244,
                    "text": "[4]",
                    "end": 247
                },
                {
                    "type": "bibr",
                    "ref_id": "b4",
                    "start": 247,
                    "text": "[5]",
                    "end": 250
                }
            ]
        },
        {
            "section": "The next generation of high intensity muon beams",
            "text": "1. an optimized muon production target; 2. a higher muon capture efficiency at the production target (26% versus 6% in the existing \u03bcE4 channel), thanks to a new system of normal conducting capture solenoids; 3. a higher transmission efficiency (40% versus 7% in \u03bcE4), thanks to an improved design of the beam optics.",
            "paragraph_rank": 22,
            "section_rank": 4
        },
        {
            "section": "The next generation of high intensity muon beams",
            "text": "Given the present \u0393 \u03bc in \u03bcE4, 5 \u00d7 10 8 muons/s in the experimental area, the goal of O(10 10 ) muons/s seems to be within reach. At PSI, muons are produced on a relatively thin target (20 mm), since the beam has to be preserved for the subsequent spallation neutron source, SINQ. At RCNP in Osaka (Japan), the MuSIC project [6] makes use of a thicker target (200 mm), exploiting maximally the much lower proton beam intensity. The target is surrounded by a high-strength solenoidal magnetic field in order to capture pions and muons with a large solid angle acceptance. Moreover, the field is reduced adiabatically from 3.5 T at the center of the target to 2 T at the exit of the capture solenoid in order to reduce the angular divergence of the beam and hence increase the acceptance of the solenoidal muon transport beam line. Tests have been performed, showing that \u223c 10 6 muons per Watt of beam power can be obtained. At the full beam power which is available at RCNP, a rate of \u223c 4\u00d710 8 muons per second is expected at the production target, in the full momentum spectrum. The transport of the muons to the experimental areas and the selection of surface muons will reduce significantly this rate. Nonetheless, it is a good example of the alternative approach for the production of intense continuous muon beams, with lower power of the primary proton beam (400 W at MuSIC, to be compared with the 1400 kW power of the PSI proton accelerator) but a much higher muon yield per unit of power, thanks to the thicker muon production target. A compromise between the two approaches could open interesting future perspectives for a further increase of the beam rates.",
            "paragraph_rank": 23,
            "section_rank": 4,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b5",
                    "start": 324,
                    "text": "[6]",
                    "end": 327
                }
            ]
        },
        {
            "section": "The next generation of high intensity muon beams",
            "text": "Ideas to perform searches for \u03bc + \u2192 e + \u03b3 and \u03bc + \u2192 e + e + e \u2212 have been also proposed in the framework of the PIP-II project at FNAL [7,15]. To the best of our knowledge, a realistic design of a continuous muon beam line at this facility and a reliable estimate of the achievable muon beam rates are not yet available in the literature. Nonetheless, there are indications that this facility could be competitive with the PSI HiMB project.",
            "paragraph_rank": 24,
            "section_rank": 4,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b6",
                    "start": 135,
                    "text": "[7,",
                    "end": 138
                },
                {
                    "type": "bibr",
                    "ref_id": "b14",
                    "start": 138,
                    "text": "15]",
                    "end": 141
                }
            ]
        },
        {
            "section": "The next generation of high intensity muon beams",
            "text": "These recent developments will give the possibility of running \u03bc + \u2192 e + \u03b3 searches with muon beams one or two orders of magnitude more intense than what is presently available.",
            "paragraph_rank": 25,
            "section_rank": 4
        },
        {
            "text": "Experimental limiting factors",
            "section_rank": 5
        },
        {
            "section": "Experimental limiting factors",
            "text": "In this section we try to identify the factors which will ultimately limit the \u03bc + \u2192 e + \u03b3 sensitivity of the next generation experiments. In this respect, we will only marginally consider the intrinsic performances of the specific detection techniques (single hit resolutions, etc.), which will be better discussed in the next sections. Conversely, our goals are to find the experimental factors (interaction with materials, etc.) which will not improve automatically with the technological evolution of the detectors, and to identify the experimental issues which will require a technological breakthrough in order to be addressed. Besides providing the basic information to estimate the potential sensitivity of the next generations of \u03bc + \u2192 e + \u03b3 searches, this discussion will give some directions towards a more radical step forward.",
            "paragraph_rank": 26,
            "section_rank": 5
        },
        {
            "text": "Efficiency",
            "section_rank": 6
        },
        {
            "section": "Efficiency",
            "text": "The discrimination between signal and background events can be made through a maximum likelihood fit, as shown in MEG [1], with only a small loss of signal. The signal efficiency is therefore dominated by the positron and photon reconstruction efficiencies, e and \u03b3 .",
            "paragraph_rank": 27,
            "section_rank": 6,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b0",
                    "start": 118,
                    "text": "[1]",
                    "end": 121
                }
            ]
        },
        {
            "section": "Efficiency",
            "text": "The first element affecting e and \u03b3 is the geometrical acceptance of the detector. Due to the back-to-back signature of the signal, the detector can be designed in such a way that, for signal events, positrons never escape the detection if the photon is within the detector acceptance, or vice versa. So, one of the two sub-detectors unequivocally defines the detector acceptance. While in principle there is nothing preventing to have an almost full angular coverage, apart from a small region around the beam axis, costs can provide a strong limit. The MEG experiment, for instance, only had a 10% acceptance, limited by the angular coverage of the (very expensive) LXe calorimeter. Though mitigated, this point could be relevant also for the innovative crystals we will discuss in Sect. 5.1.",
            "paragraph_rank": 28,
            "section_rank": 6
        },
        {
            "section": "Efficiency",
            "text": "When photons are within the acceptance, a fraction of them generate a shower before entering the detector. This is mainly due to the material in front of the detector (photon detectors and the magnet coil of a positron spectrometer are typically placed in front of the active volume of the calorimeter). A reconstruction efficiency of \u223c 60% was obtained in MEG, but different detector designs with lighter photon detectors could significantly improve this figure in the future.",
            "paragraph_rank": 29,
            "section_rank": 6
        },
        {
            "section": "Efficiency",
            "text": "Moreover, at larger \u0393 \u03bc , the necessity of rejecting pile-up events implies some signal inefficiency. At \u0393 \u03bc \u223c 10 9 muons per second, B acc could be dominated by the superposition of two RMD photons, with a total energy above 50 MeV, impinging on the photon detector, and the signal efficiency of the necessary pile-up rejection algorithms could be relevant. An estimate of these effects largely depends on the specific detector design.",
            "paragraph_rank": 30,
            "section_rank": 6
        },
        {
            "section": "Efficiency",
            "text": "The situation is completely different if the photon conversion technique is adopted. Thin converters are needed in order to preserve very good resolutions. It implies in turn a few percent \u03b3 . In Fig. 3 the conversion probability for 52.8 MeV photons in lead and tungsten for different thicknesses are shown. It must be noticed that, due to the relatively low energy of the photons, this probability is lower than the high-energy asymptotic value (7/9 times the thickness in units of radiation lengths). Moreover, both the electron and  the positron produced in the photon conversion have to be sufficiently energetic to be efficiently tracked. Considering that a typical tracking detector will have a few mm granularity along the track direction, only tracks with at least a few MeV can be reconstructed in a magnetic field of 1 T. Although the magnetic field can be optimized, a low momentum cutoff is unavoidable and, for instance, the requirement that the electron and the positron energies are both larger than 5 MeV further reduces \u03b3 by a factor \u223c 20%. Concerning the positron from the muon decay, both tracking and calorimetry usually provide very large e . Inefficiencies, however, can arise when the track is propagated from the last measurement point in the tracking detector to the positron timing detector. Multiple Coulomb scattering (MS) or energy loss (\u0394E) might be dramatic and introduce large inefficiencies in the matching between the spectrometer and the timing detector. In MEG this effect was particularly important and reduced e by a factor of two.",
            "paragraph_rank": 31,
            "section_rank": 6,
            "ref_spans": [
                {
                    "type": "figure",
                    "ref_id": "fig_3",
                    "start": 196,
                    "text": "Fig. 3",
                    "end": 202
                }
            ]
        },
        {
            "text": "Photon energy",
            "section_rank": 7
        },
        {
            "section": "Photon energy",
            "text": "Calorimetry The E \u03b3 resolution is dominated by the photon statistics. Hence, the light yield determines the choice of the scintillator to be used, along with the fast response that is needed in order to reach a very good time resolution. Table 1 summarizes the relevant properties of some state-of-the-art scintillating materials.",
            "paragraph_rank": 32,
            "section_rank": 7,
            "ref_spans": [
                {
                    "type": "table",
                    "ref_id": "tab_0",
                    "start": 238,
                    "text": "Table 1",
                    "end": 245
                }
            ]
        },
        {
            "section": "Photon energy",
            "text": "A degradation of the resolution due to the stability of the energy scale can be avoided with an accurate and frequent multi-channel calibration. In MEG this enabled the E \u03b3 scale to be kept stable to within 0.2%.",
            "paragraph_rank": 33,
            "section_rank": 7
        },
        {
            "section": "Photon energy",
            "text": "Pair conversion The limiting factor of the E \u03b3 resolution is the interaction of the e + e \u2212 pair within the material of the photon converter itself. Indeed, just after the conversion, the electron and the positron lose energy before exiting the converter. The \u0394E fluctuation predominantly contributes to the resolution, since E \u03b3 is estimated as the sum of the e + and e \u2212 energies (in some previous studies like [16] this contribution was disregarded [17]). According to our GEANT4 [18] simulations, a 280 \u00b5m Pb layer (\u223c 5% X 0 ), with photon conversions happening uniformly along the thickness of the converter, would give a resolution of \u223c 240 keV in the limit of perfect tracking of the e + e \u2212 pair. In Fig. 3 the contribution of the material effects to the resolution is also shown versus the layer thickness for lead and tungsten, along with the total conversion probability. The resolution is evaluated as a truncated RMS of the reconstructed energy distribution, after discarding 20% of the events in the low energy tail.",
            "paragraph_rank": 34,
            "section_rank": 7,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b15",
                    "start": 413,
                    "text": "[16]",
                    "end": 417
                },
                {
                    "type": "bibr",
                    "ref_id": "b16",
                    "start": 452,
                    "text": "[17]",
                    "end": 456
                },
                {
                    "type": "bibr",
                    "ref_id": "b17",
                    "start": 483,
                    "text": "[18]",
                    "end": 487
                },
                {
                    "type": "figure",
                    "ref_id": "fig_3",
                    "start": 708,
                    "text": "Fig. 3",
                    "end": 714
                }
            ]
        },
        {
            "section": "Photon energy",
            "text": "Considering that a lower thickness improves the E \u03b3 resolution but also lowers \u03b3 , an optimization is necessary. As pointed out in [11], the background rate is expected to scale with the third power of the converter thickness t, while \u03b3 scales linearly. So, one can try to maximize a Punzi figure of merit [19]:",
            "paragraph_rank": 35,
            "section_rank": 7,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b10",
                    "start": 131,
                    "text": "[11]",
                    "end": 135
                },
                {
                    "type": "bibr",
                    "ref_id": "b18",
                    "start": 306,
                    "text": "[19]",
                    "end": 310
                }
            ]
        },
        {
            "section": "Photon energy",
            "text": "where B 0 is the background yield expected with t = t 0 at given \u0393 \u03bc and T . Typical choices of n \u03c3 are 2 or 3. This function has a maximum for a t such that the number of expected background events is B 0 (t/t 0 ) 3 = n 2 \u03c3 = 4 \u223c 9. It indicates that, if allowed by the available beam intensity, the converter should be designed to yield from a few to \u223c 10 accidental background events. If the background yield is much higher, it is convenient to reduce t, in order to improve the resolutions. If it is significantly lower, it is worth increasing t to get a higher \u03b3 , to the detriment of the resolution. If it is much lower, a calorimetric approach is likely to perform better with that beam intensity.",
            "paragraph_rank": 36,
            "section_rank": 7
        },
        {
            "section": "Photon energy",
            "text": "The choice of the material of the converter has to be considered too. The \u0394E fluctuations are \u221d Z\u03c1/A, while the resolution on the photon angle for vertexing is determined by the MS on the converter, which depends upon the square root of the number of radiation lengths ( \u221a x/ X 0 \u221d Z 2 \u03c1/A). From Eq. 2 we get B acc \u221d Z 4 \u03c1 3 /A 3 . Given that the conversion efficiency is proportional to the number of the radiation lengths ( \u221d Z 2 \u03c1/A), we conclude that in the background-dominated regime (where the Punzi f.o.m. can be approximated with / \u221a B acc ) the sensitivity improves with increasing \u221a \u03c1 A, while it obviously goes with Z 2 \u03c1/A in the efficiency-dominated regime. Hence, dense, large-Z materials are favored as converters, and Lead or Tungsten are typical choices.",
            "paragraph_rank": 37,
            "section_rank": 7
        },
        {
            "text": "Positron energy",
            "section_rank": 8
        },
        {
            "section": "Positron energy",
            "text": "The material in front of the positron detector ultimately limits the E e and positron angular resolutions by MS and \u0394E fluctuations.",
            "paragraph_rank": 38,
            "section_rank": 8
        },
        {
            "section": "Positron energy",
            "text": "The detector technology adopted for a tracking approach is therefore relevant: while gaseous detectors have been the choice for both MEGA and MEG, a silicon vertex tracker is used for the search of \u03bc + \u2192 e + e + e \u2212 by the Mu3e Col- laboration [20], and a similar design has been suggested for future \u03bc + \u2192 e + \u03b3 searches [16]. State-of-the-art silicon pixel detectors can reach very good position resolutions (\u223c 3 \u00b5m), with a thickness of 50 \u00b5m Si + 25 \u00b5m Kapton per layer [21], corresponding to \u223c 10 \u22123 radiation lengths per layer. On the other hand, the complete drift-chamber spectrometers of MEG or MEG-II amount to less than 3 \u00d7 10 \u22123 radiation lengths over the whole track length within the tracking volume, nonetheless material effects gave a significant contribution in MEG and will almost be dominant in MEG-II. It clearly indicates that more than a few silicon layers cannot be used: indeed, simulations [16] point toward E e resolutions of \u223c 200 keV, which are not competitive with what can be obtained with gaseous detectors [14]. We then believe that the positron spectrometer of a next-generation \u03bc + \u2192 e + \u03b3 experiment has to incorporate an extended tracking region (dozens of cm of track length for a magnetic field of \u223c 1 T) with dozens of measurement points and a few 10 \u22123 radiation lengths material budget, providing a single hit resolution of \u223c 100 \u03bcm and hence a momentum resolution of \u223c 100 keV [14,22].",
            "paragraph_rank": 39,
            "section_rank": 8,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b19",
                    "start": 244,
                    "text": "[20]",
                    "end": 248
                },
                {
                    "type": "bibr",
                    "ref_id": "b15",
                    "start": 322,
                    "text": "[16]",
                    "end": 326
                },
                {
                    "type": "bibr",
                    "ref_id": "b20",
                    "start": 474,
                    "text": "[21]",
                    "end": 478
                },
                {
                    "type": "bibr",
                    "ref_id": "b15",
                    "start": 915,
                    "text": "[16]",
                    "end": 919
                },
                {
                    "type": "bibr",
                    "ref_id": "b13",
                    "start": 1038,
                    "text": "[14]",
                    "end": 1042
                },
                {
                    "type": "bibr",
                    "ref_id": "b13",
                    "start": 1419,
                    "text": "[14,",
                    "end": 1423
                },
                {
                    "type": "bibr",
                    "ref_id": "b21",
                    "start": 1423,
                    "text": "22]",
                    "end": 1426
                }
            ]
        },
        {
            "text": "Relative angle \u0398 e\u03b3",
            "section_rank": 9
        },
        {
            "section": "Relative angle \u0398 e\u03b3",
            "text": "The relative angle \u0398 e\u03b3 is measured by combining the positron angle, the photon conversion point and the positron vertex on the target. The MS and \u0394E in the target and the material in front of the spectrometer (e.g. the inner wall of a gas chamber) limit the measurement of the positron track direction. The target material is also a relevant source of AIF photons pointing towards the photon detector. However, the target has to be thick enough to provide a good stopping power for muons. A good compromise has been obtained by slanting the target with respect to the beam axis (in MEG the target normal vector makes an angle \u03b1 \u223c 70 \u2022 with the beam axis, which will be increased to 76 \u2022 in MEG-II). In this configuration, the effective thickness seen by muons is magnified by a factor 1/ cos(\u03b1) \u223c 3, while positrons emitted at the center of the detector acceptance (90 \u2022 with respect to the beam axis) see a thickness magnified only by a factor 1/ sin(\u03b1) \u223c 1.06. In Table 2 we show the angular uncertainties induced by targets of different materials. GEANT4 simulations have been used to determine, for each material, the target thickness providing 90% stopping power and the distribution of the stopping depth, used then in the simulation of the positron energy loss. In the best case, a contribution to the angular resolutions of about 3 mrad is found. It should be noticed that, due to the target geometry, this contribution depends on the angular acceptance of the detector. We assume here a full acceptance in \u03c6 e and \u00b1\u03c0/4 acceptance in \u03c0/2 \u2212 \u03b8 e . Some strategies to reduce this contribution are discussed in Sect. 7.",
            "paragraph_rank": 40,
            "section_rank": 9,
            "ref_spans": [
                {
                    "type": "table",
                    "ref_id": "tab_1",
                    "start": 967,
                    "text": "Table 2",
                    "end": 974
                }
            ]
        },
        {
            "section": "Relative angle \u0398 e\u03b3",
            "text": "Due to the back-propagation of the track from the measured points to the target, E e and positron angular uncertainties at the inner layer of the spectrometer also translate into vertex position uncertainties at the target, which increase with the radius R e of the inner tracking layer. In this respect, it is crucial to have this first layer as close as possible to the target. These effects are illustrated in Table 3, where different scenarios are considered for R e = 20 cm, and in Fig. 4, Table 3 Relative \u03b8 e\u03b3 and \u03c6 e\u03b3 angles and energy E e uncertainties introduced by tracking (first figure) and material effects between the target and the tracking detector (second figure), under different scenarios. In the second and third scenario, the gas in the tracking volume extends to the region around the target to avoid a separation wall. The first tracking layer is placed at R e = 20 cm. The photon detector is placed at R \u03b3 = 30 cm. The tracking resolutions of MEG-II are assumed. Notice that, due to the correlations among variables, tracking and material contributions do not decouple completely -increasing the material effects also increases the impact of the tracking resolutions where the dependence on R e is shown, as an example, for the vertex resolution in the Z coordinate. We assumed here the tracking resolutions expected for the MEG-II drift chamber, the MS due to Helium and a 25 \u03bcm Kapton foil just in front of the inner tracking layer, a magnetic field of 1 T, tracks emitted in the acceptance and target configuration of MEG-II and a photon detector placed at R \u03b3 = 30 cm. With the photon conversion technique, the photon conversion point can be measured very precisely, essentially with the single hit resolution of the e + e \u2212 tracker (\u223c 100 \u00b5m for a gaseous detector), with a first layer placed just behind the converter. As a consequence, the photon angle resolution is completely dominated by the positron vertex resolution. With calorimetry, the detector and readout granularity of the entrance surface determines the resolution, but we can generally say that a sub-mm level can be reasonably reached, giving \u223c 1 mrad contributions to \u03c6 e\u03b3 and \u03b8 e\u03b3 when the detector is placed at a few dozens of cm from the target (60 cm in MEG and MEG-II).",
            "paragraph_rank": 41,
            "section_rank": 9,
            "ref_spans": [
                {
                    "type": "table",
                    "start": 413,
                    "text": "Table 3",
                    "end": 420
                },
                {
                    "type": "figure",
                    "start": 487,
                    "text": "Fig. 4",
                    "end": 493
                },
                {
                    "type": "table",
                    "start": 495,
                    "text": "Table 3",
                    "end": 502
                }
            ]
        },
        {
            "section": "Relative angle \u0398 e\u03b3",
            "text": "It must be noticed that an absolute calibration of \u0398 e\u03b3 is very difficult to be obtained, resulting in a systematic uncertainty of a few mrad. As an example, in the MEG configuration, the 500 \u00b5m accuracy obtained for the target position along its normal direction translates into an uncertainty > 3.5 mrad on \u03c6 e\u03b3 . Hence, quoting angular resolutions at the mrad level is subject to the non-trivial ability of aligning the target with \u223c 100 \u00b5m accuracy.",
            "paragraph_rank": 42,
            "section_rank": 9
        },
        {
            "text": "Relative time T e\u03b3",
            "section_rank": 10
        },
        {
            "section": "Relative time T e\u03b3",
            "text": "A T e\u03b3 resolution of 120 ps was obtained in MEG with scintillation detectors, and a 80 ps resolution is expected for MEG-II.",
            "paragraph_rank": 43,
            "section_rank": 10
        },
        {
            "section": "Relative time T e\u03b3",
            "text": "The positron time resolution of \u223c 35 ps foreseen for MEG-II might be probably improved with the incremental progress of the technologies. It is important to stress here that the positron time is usually measured at the end of the spectrometer, and the time of flight from the target to the timing detector needs to be subtracted. If there are long segments of the positron path which are untracked, the extrapolated track length can fluctuate significantly due to MS and \u0394E in the crossed materials. In MEG, the track length uncertainty (\u223c 90 ps) turned out to be the largest contribution to the T e\u03b3 resolution, due to the long untracked path (\u223c 1 m) from the last reconstructed hit to the positron timing detector. In MEG-II this issue will be solved, thanks to the 2 m-long drift chamber, which largely reduces the untracked segments of the positron trajectory with respect to MEG. Future designs should keep in mind this lesson, and this aspect could be critical for silicon detectors, which would track only a small portion of the positron trajectory.",
            "paragraph_rank": 44,
            "section_rank": 10
        },
        {
            "section": "Relative time T e\u03b3",
            "text": "For photons, if the conversion technique is adopted, a further complication arises. As far as only one conversion layer is foreseen, one can place thick scintillators at some distance from the converter, in such a way that either the electron or the positron reaches this detector. On the other hand, in order to stack multiple layers, a layer of active material just behind the converter should provide the required timing resolution. A thick layer (few mm) of plastic scintillators would deteriorate unacceptably the E \u03b3 resolution, and thin scintillating fibers (few 100 \u00b5m) cannot provide a resolution below a few 100 ps and efficiencies above 90% [23]. Hence, a technological breakthrough is needed here, and a novel idea will be proposed in Sect. 5. For calorimetry, performances comparable or better than the MEG-II ones could be easily reached, considering the light yield and decay time of the state-of-theart scintillators. Table 4 shows a summary of the limiting factors for the efficiency and resolutions of future \u03bc + \u2192 e + \u03b3 searches. We stress again that, with the only exception of the tracking resolutions, these factors come from experimental conditions which are quite independent of the specific detector design, and only marginally dependent on the intrinsic resolutions of the detectors. It means that, even if the detector performances could be arbitrarily improved, most of these factors would remain unchanged. Hence, a radically new experimental approach would be needed to bring the resolutions on the \u03bc + \u2192 e + \u03b3 discriminating variables significantly below these limits.",
            "paragraph_rank": 45,
            "section_rank": 10,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b22",
                    "start": 652,
                    "text": "[23]",
                    "end": 656
                },
                {
                    "type": "table",
                    "ref_id": "tab_2",
                    "start": 934,
                    "text": "Table 4",
                    "end": 941
                }
            ]
        },
        {
            "text": "Summary",
            "section_rank": 11
        },
        {
            "text": "Photon reconstruction perspectives",
            "section_rank": 12
        },
        {
            "section": "Photon reconstruction perspectives",
            "text": "In this section we discuss two possible realistic photon detectors for \u03bc + \u2192 e + \u03b3 searches. We will consider a calorimetric approach with LaBr 3 (Ce) crystals and a pair production approach with one or more layers of conversion material.",
            "paragraph_rank": 46,
            "section_rank": 12
        },
        {
            "text": "Calorimetry",
            "section_rank": 13
        },
        {
            "section": "Calorimetry",
            "text": "A homogeneous scintillation detector is placed out of the positron tracking volume and the magnetic field, and provides the E \u03b3 , the photon conversion point, and the photon time measurements. With their high light yield and fast response, LaBr 3 (Ce) crystals are a good candidates. Thanks to its high density (5.08 g/cm 3 ), a 20 cm long crystal with 13 cm diameter would contain the electromagnetic shower up to 100 MeV. Silicon photon detectors like MPPCs could be coupled to the crystal, in such a way that a good coverage is guaranteed (\u223c 50% of the crystal surface considering the inactive areas of the single detector).",
            "paragraph_rank": 47,
            "section_rank": 13
        },
        {
            "section": "Calorimetry",
            "text": "We performed a set of GEANT4 simulations, which were validated against data obtained with a 3 inch (diameter) \u00d7 3 inch (length) LaBr 3 (Ce) crystal, irradiated with different sources, and in particular 9 MeV \u03b3 rays from neutrons captured on Nickel, and instrumented with PMTs and MPPCs in order to characterize both the crystal and photon detector response [24][25][26]. The simulation includes the MPPC response, a full electronics chain and the reconstruction algorithms. Different geometries, sensors and analysis algorithms have been investigated. In the end, a \u03c3 \u03b3 /E \u03b3 \u223c 1.6% and a time resolution \u03c3 t \u223c 30 ps are predicted at the \u03bc + \u2192 e + \u03b3 decay energy. Table 5 summarizes the performance of this solution.",
            "paragraph_rank": 48,
            "section_rank": 13,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b23",
                    "start": 357,
                    "text": "[24]",
                    "end": 361
                },
                {
                    "type": "bibr",
                    "ref_id": "b24",
                    "start": 361,
                    "text": "[25]",
                    "end": 365
                },
                {
                    "type": "bibr",
                    "ref_id": "b25",
                    "start": 365,
                    "text": "[26]",
                    "end": 369
                },
                {
                    "type": "table",
                    "ref_id": "tab_3",
                    "start": 663,
                    "text": "Table 5",
                    "end": 670
                }
            ]
        },
        {
            "text": "Pair production",
            "section_rank": 14
        },
        {
            "section": "Pair production",
            "text": "A basic design for a \u03bc + \u2192 e + \u03b3 experiment adopting the photon conversion technique would consist of tracking detectors interleaved with one or more thin conversion layers. The design of the detector is also constrained by the requirement that an extended tracker for 52.8 MeV positron and tracking devices for the low-momentum photon-conversion products should coexist in the same magnetic field. According to our results (see Sect. 4.2), the E \u03b3 resolution is expected to be dominated by the fluctuations of the energy loss in the converter, when its thickness is greater than 0.1 X 0 . For smaller values, the tracking of the e + e \u2212 pair can be relevant, considering that previous studies [15,16] point toward a 200-300 keV contribution.",
            "paragraph_rank": 49,
            "section_rank": 14,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b14",
                    "start": 694,
                    "text": "[15,",
                    "end": 698
                },
                {
                    "type": "bibr",
                    "ref_id": "b15",
                    "start": 698,
                    "text": "16]",
                    "end": 701
                }
            ]
        },
        {
            "section": "Pair production",
            "text": "Moreover, it should be noticed that, if a single layer is used, its size and the magnetic field can be optimized in such a way that the positron from the muon decay and at least one of the tracks in the e + e \u2212 pair reach the outer radius of the detector, where fast detectors for timing could be placed. If multiple layers are foreseen, the conversion layer itself should include an active component, able to measure the e + e \u2212 timing with the required resolution (but scintillating fibers cannot provide the required performances).",
            "paragraph_rank": 50,
            "section_rank": 14
        },
        {
            "section": "Pair production",
            "text": "A possible solution is given by a new generation of silicon detectors, with extremely good time resolution. An R&D activity is ongoing (TT-PET project [27,28]) to realize a thin monolithic detector (100-300 \u00b5m) in a Si-Ge Bi-CMOS process, that contains both the silicon sensor and the frontend electronics, featuring less than 100 ps time resolution for minimum ionizing particles. A dedicated design could be adopted in the \u03bc + \u2192 e + \u03b3 application, by stacking multiple detector layers in order to improve the resolution accordingly.",
            "paragraph_rank": 51,
            "section_rank": 14,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b26",
                    "start": 151,
                    "text": "[27,",
                    "end": 155
                },
                {
                    "type": "bibr",
                    "ref_id": "b27",
                    "start": 155,
                    "text": "28]",
                    "end": 158
                }
            ]
        },
        {
            "section": "Pair production",
            "text": "The additional low-Z material of the detector behind the converter is expected to deteriorate the E \u03b3 resolution without contributing significantly to the conversion efficiency. According to our simulations, a single layer with the specifications in [28] (100 \u00b5m silicon on top of 50 \u00b5m Kapton) would give a negligible contribution to the E \u03b3 resolution. For a 4-layer system, which would give a 50 ps resolution, comparable with the timing performances of the MEG-II LXe calorimeter, this contribution would be \u223c 300 keV, i.e. of the same order of the energy loss fluctuations for a 0.05 X 0 Lead converter.",
            "paragraph_rank": 52,
            "section_rank": 14,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b27",
                    "start": 250,
                    "text": "[28]",
                    "end": 254
                }
            ]
        },
        {
            "section": "Pair production",
            "text": "It is also worth mentioning that, if the converter layer itself would be active and could provide some information about the energy deposit, it could be used to improve the E \u03b3 resolution.",
            "paragraph_rank": 53,
            "section_rank": 14
        },
        {
            "section": "Pair production",
            "text": "Based on the results of Sect. 4, Table 6 shows the expected photon reconstruction performances for this design. We assume: -one passive conversion layer, 0.05 X 0 Lead, covering 135 \u2022 in \u03c6 and 60 cm in Z , and placed at R \u03b3 = 30 cm; -scintillating tiles at the end of the trajectory of conversion pairs and positrons from muons, providing a time resolution of \u223c 50 ps; -a tracking system providing an e + e \u2212 vertex resolution which contributes negligibly to the photon angle uncertainty (with respect to the contribution of the positron vertex reconstruction) and to the E \u03b3 resolution (with respect to the fluctuations of the energy loss in the converter).",
            "paragraph_rank": 54,
            "section_rank": 14,
            "ref_spans": [
                {
                    "type": "table",
                    "start": 33,
                    "text": "Table 6",
                    "end": 40
                }
            ]
        },
        {
            "section": "Pair production",
            "text": "If multiple conversion layers are present and timing is provided by the TT-PET detectors, the 50 ps resolution can be preserved but the photon energy resolution deteriorates as estimated above.",
            "paragraph_rank": 55,
            "section_rank": 14
        },
        {
            "section": "Pair production",
            "text": "Beside providing better resolutions with respect to calorimetry, the photon conversion technique also provides a measurement of the photon direction, from the combination of the reconstructed directions of the e + e \u2212 pair, independently of the positron reconstruction. The resulting angular resolution, deteriorated by the MS in the converter, is \u223c 80 mrad with 0.1X 0 Lead, and hence cannot compete with the one obtained from the combination of the positron vertex and photon conversion point. Nonetheless, this additional information can be used to reduce the accidental background. In Fig. 5 we show the distribution of the normalized distance defined as:",
            "paragraph_rank": 56,
            "section_rank": 14,
            "ref_spans": [
                {
                    "type": "figure",
                    "start": 589,
                    "text": "Fig. 5",
                    "end": 595
                }
            ]
        },
        {
            "section": "Pair production",
            "text": "where (X e , Y e ) and (X \u03b3 , Y \u03b3 ) are the coordinates on the target of the vertex obtained in two ways, one by propagating the positron track back to the target and the other by using the direction of the e + e \u2212 pair. The uncertainties (\u03c3 X and \u03c3 Y ) of the e + e \u2212 back-propagation are used, since they largely dominate over the positron vertex resolutions. The expected distributions for signal and accidental background events with the photon coming from the target (assuming the same beam profile used in MEG) are shown in Fig. 5, for a 0.05 X 0 Lead converted at R \u03b3 = 30 cm, a 76 \u2022 slanted target and the acceptance defined in Sect. 4.4. In this scenario, the optimal ratio of signal to square root of background is obtained for d vt x e\u03b3 < 1.25, which removes 91% of background events with 52% signal efficiency. Similarly, background produced by positron AIF occurring far from the target would be easily removed without any significant loss of signal efficiency. However the average background rejection capability is lower if multiple conversion layers are used, because the layers after the first one have a larger R \u03b3 and hence the resolution of the back-projection to the target is worse for photons converting there.",
            "paragraph_rank": 57,
            "section_rank": 14,
            "ref_spans": [
                {
                    "type": "figure",
                    "start": 530,
                    "text": "Fig. 5",
                    "end": 536
                }
            ]
        },
        {
            "text": "Positron reconstruction perspectives",
            "section_rank": 15
        },
        {
            "section": "Positron reconstruction perspectives",
            "text": "We consider a positron detector, composed of two sectors: a vertex detector for a precise determination of the muon decay point and the positron angles, and an extended tracker for the measurement of the positron momentum.",
            "paragraph_rank": 58,
            "section_rank": 15
        },
        {
            "text": "Vertex detector",
            "section_rank": 16
        },
        {
            "section": "Vertex detector",
            "text": "As already discussed, a silicon detector would not be competitive with a gaseous detector as an extended tracker. Nonetheless, we can still consider the possibility of having two layers of silicon detectors for vertexing. Silicon pixels would give a very good vertex resolution, thanks to the very precise deter-  Fig. 5 Distribution of the normalized distance between the positron and photon vertices, for signal (blue) and accidental background (black) events, with a 0.1X 0 Lead converter mination of both the azimuthal and the longitudinal coordinate (\u223c 10 \u00b5m). In practice, the vertex and angle resolution would be completely dominated by the MS in this detector. As a consequence, the extended tracker would be only useful for the determination of E e .",
            "paragraph_rank": 59,
            "section_rank": 16,
            "ref_spans": [
                {
                    "type": "figure",
                    "start": 314,
                    "text": "Fig. 5",
                    "end": 320
                }
            ]
        },
        {
            "text": "Signal Background",
            "section_rank": 17
        },
        {
            "section": "Signal Background",
            "text": "As an alternative, one could consider a time projection chamber (TPC) with a very light (helium-based) gas mixture. The single hit resolution of such a device would be limited by the diffusion of the drifting electrons, but a large number of hits would be available. Gaseous electron multiplier (GEM) foils or Micromegas could be used to generate the electron avalanche, inducing signals on readout pads and allowing the TPC to be operated in continuous mode (no gating) even in presence of a very high track rate [29].",
            "paragraph_rank": 60,
            "section_rank": 17,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b28",
                    "start": 514,
                    "text": "[29]",
                    "end": 518
                }
            ]
        },
        {
            "section": "Signal Background",
            "text": "We performed simulations with the GARFIELD software [30], assuming a He:CO 2 (90:10) gas mixture, a 0.5 T magnetic field and a 1 kV/cm electric field. We assume the readout to be performed with very high granularity, as in the GEMPIX [31] and InGrid [32] projects, so that the single ionization clusters are detected and the space resolution is dominated by the diffusion of the drifting electrons. For a given drift distance d drift , a resolution of \u223c 180(150) \u00b5m \u2022 \u221a d drift (cm) is found in the azimuthal (longitudinal) coordinate, with \u223c 100 hits per track. On the other hand, at a very high rate, the use of such a device would be limited by both the rate capability of the multiplication stage and the space charge accumulated in the drift region due to the primary ionization itself.",
            "paragraph_rank": 61,
            "section_rank": 17,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b29",
                    "start": 52,
                    "text": "[30]",
                    "end": 56
                },
                {
                    "type": "bibr",
                    "ref_id": "b30",
                    "start": 234,
                    "text": "[31]",
                    "end": 238
                },
                {
                    "type": "bibr",
                    "ref_id": "b31",
                    "start": 250,
                    "text": "[32]",
                    "end": 254
                }
            ]
        },
        {
            "text": "Extended tracker",
            "section_rank": 18
        },
        {
            "section": "Extended tracker",
            "text": "The basic option for the extended tracker is a drift chamber, with stereo wires for the measurement of the longitudinal position. The MEG-II drift chamber can be used as a benchmark for the material budget and the single hit resolution.",
            "paragraph_rank": 62,
            "section_rank": 18
        },
        {
            "section": "Extended tracker",
            "text": "On the other hand, the high track rate in the inner layers is expected to produce visible aging effects at the beam rate expected in MEG-II [14]. It could make a TPC the only choice for a gaseous extended tracker at higher beam rates. The detector geometry would be strongly constrained, because a very long TPC (\u223c 1 m drift distance) could not provide acceptable resolutions due to the electron diffusion. As an alternative, in the early stages of the MEG upgrade project, a 2 m long radial TPC was proposed, with a He:CO 2 :C 2 H 6 (70:10:20) gas mixture. The radial design implies some technical difficulties connected to the drift of the electrons orthogonally to the magnetic field. First, their diffusion is not suppressed by the magnetic field as in a longitudinal TPC. Second, the curved trajectory of the drifting positrons need to be accounted in the reconstruction stages. If these problems can be overcome with a proper tuning of the gas mixture composition, an accurate knowledge of the magnetic field and a detailed calibration of the drift trajectories, a resolution of \u223c 130 \u00b5m \u2022 \u221a d drift (cm) in the radial and azimuthal coordinates could be achieved [14], with drift distances not exceeding 10 cm.",
            "paragraph_rank": 63,
            "section_rank": 18,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b13",
                    "start": 140,
                    "text": "[14]",
                    "end": 144
                },
                {
                    "type": "bibr",
                    "ref_id": "b13",
                    "start": 1169,
                    "text": "[14]",
                    "end": 1173
                }
            ]
        },
        {
            "text": "Target optimization",
            "section_rank": 19
        },
        {
            "section": "Target optimization",
            "text": "The target thickness represents one of the most stringent limitations to the achievable angular resolution. In order to use thinner targets, two options can be investigated.",
            "paragraph_rank": 64,
            "section_rank": 19
        },
        {
            "section": "Target optimization",
            "text": "1. If the muon momentum can be significantly reduced, without reducing the beam intensity and preserving a good momentum bite, the distribution of the muon decay depth in the target (i.e. the width of the Bragg peak) is reduced accordingly. A thinner target could be used, improving the angular resolution without affecting \u0393 \u00b5 , e and \u03b3 . 2. The target could be replaced by multiple thinner targets.",
            "paragraph_rank": 65,
            "section_rank": 19
        },
        {
            "section": "Target optimization",
            "text": "A tentative design consists of a V-shaped target, made of two planes forming a 152 \u2022 angle. The problem with such an approach is that a relevant fraction of muons would decay in the gas within the two targets: signal events from such muons could not be identified, contributing only to the accidental background. As an example, two Beryllium targets of 40 \u00b5m thickness each would provide 80% stopping efficiency on target, while 13% of muons would decay in the gas between the two target sections. The advantage in terms of angular resolutions would be far too small to compensate this inefficiency. The use of multiple targets can nonetheless help to reduce the background, when the photon conversion approach is used to reconstruct the photon direction. If, for instance, the single target foil is replaced by two staggered foils, each illuminated by half the beam spot, and with sufficient sep- aration in space, the back-propagation of the e + e \u2212 pair can be used to identify the foil where the photon has been produced, and check if it is the same of the positron. In this case, the accidental background is effectively reduced by a factor of two. More generally, spreading the beam over a larger surface makes more effective the background rejection based on the goodness of the electron-photon vertex.",
            "paragraph_rank": 66,
            "section_rank": 19
        },
        {
            "text": "Sensitivity reach",
            "section_rank": 20
        },
        {
            "section": "Sensitivity reach",
            "text": "In this section we give an estimate of the sensitivity reach of a \u03bc + \u2192 e + \u03b3 search based on the technologies described above. At first, we consider a basic design based on the photon conversion technique, with a single conversion layer, an inner vertex detector (silicon pixels or a TPC) and a 200 cm long extended tracker (a drift chamber or a TPC) which would serve as a positron and a positron-electron pair spectrometer. The inclusion of multiple conversion layers would be an interesting improvement to this design. It can be made without any loss in the timing performances only if timing is provided by fast silicon detectors at the conversion layer.",
            "paragraph_rank": 67,
            "section_rank": 20
        },
        {
            "section": "Sensitivity reach",
            "text": "We finally consider a calorimetric approach for the photon reconstruction, while leaving the positron reconstruction unchanged.",
            "paragraph_rank": 68,
            "section_rank": 20
        },
        {
            "section": "Sensitivity reach",
            "text": "In both cases, we neglect the difficulties connected to the reconstruction of signal events in a crowded environment with positron tracks from multiple Michel muon decays.",
            "paragraph_rank": 69,
            "section_rank": 20
        },
        {
            "text": "A design with photon conversion",
            "section_rank": 21
        },
        {
            "section": "A design with photon conversion",
            "text": "In Fig. 6 we show a sketch of a \u03bc + \u2192 e + \u03b3 detector based on the photon conversion technique, with two different options for the inner vertex detector and a typical signal event. A similar design was recently proposed in [15].",
            "paragraph_rank": 70,
            "section_rank": 21,
            "ref_spans": [
                {
                    "type": "figure",
                    "ref_id": "fig_6",
                    "start": 3,
                    "text": "Fig. 6",
                    "end": 9
                },
                {
                    "type": "bibr",
                    "ref_id": "b14",
                    "start": 222,
                    "text": "[15]",
                    "end": 226
                }
            ]
        },
        {
            "section": "A design with photon conversion",
            "text": "In this design, a target identical to the one of MEG-II is surrounded by a positron tracker extending from R = 20 to R = 30 cm. with a length of 200 cm. It can be a drift chamber or a radial TPC. As in MEG and MEG-II, plastic scintillators (positron timing counters) are placed behind it, in order to measure the positron track timing.",
            "paragraph_rank": 71,
            "section_rank": 21
        },
        {
            "section": "A design with photon conversion",
            "text": "At R = 30 cm, a 60 cm long Lead conversion layer is placed, with a 0.1 X 0 thickness. The longitudinal extent of the conversion layer defines the acceptance of the detector, \u223c 70%.",
            "paragraph_rank": 72,
            "section_rank": 21
        },
        {
            "section": "A design with photon conversion",
            "text": "Externally, a 84 cm long drift chamber or radial TPC is used as an electron-positron pair spectrometer. This chamber extends up to R = 42 cm, where plastic scintillators (photon timing counters) are placed.",
            "paragraph_rank": 73,
            "section_rank": 21
        },
        {
            "section": "A design with photon conversion",
            "text": "Optionally, a small TPC or a two-layer silicon vertex detector can be considered. Both detectors are 40 cm long. The TPC has an inner radius of 10 cm and an outer radius of 20 cm. The first silicon layer is placed at a radius of 10 cm.",
            "paragraph_rank": 74,
            "section_rank": 21
        },
        {
            "section": "A design with photon conversion",
            "text": "Everything is immersed in a graded magnetic field similar to the MEG one, such that, for events within the acceptance defined above, the signal positron curls before reaching the converter layer and finally reaches the positron timing counters, while at least one of the tracks from the photon conversion goes through the whole e + e \u2212 pair spectrometer and reaches the photon timing counters.",
            "paragraph_rank": 75,
            "section_rank": 21
        },
        {
            "section": "A design with photon conversion",
            "text": "We estimated the expected performances of such a detector. For simplicity, we rely on the results shown in Table 6 for the photon reconstruction, although they are obtained for a uniform magnetic field. For the positron angle and momentum reconstruction in the tracker we assume the performances of the MEG-II drift chamber, with a 90% reconstruction efficiency, while for the vertex resolution with an inner tracker we assume two different scenarios. In the first, conservative one, the only improvement comes from having the first measured point which is closer to the target, while the momentum and angular resolutions are still dominated by the extended tracker, and the angular resolution is deteriorated by the presence of the inner wall of the TPC or the inner layer of the silicon vertex tracker. In the second, optimistic one, the vertex detector makes the tracking contribution to the angu- lar resolution negligible. This resolution is then completely determined by material effects before and inside the first layer of the inner vertex detector. A summary of the expected performances can be found in Tables 7 and 8. It is evident that a silicon vertex detector cannot help, because the MS in the first layer of such a detector negates the advantage of having a very good determination of the track angle between the first and the subsequent layers. We also considered a simpler design, with similar radial dimensions, where the magnetic field is reduced to 0.5 T and the conversion layer covers only a portion (\u223c 18%) of the azimuthal angular range. In this design, signal positrons reach the e + e \u2212 pair spectrometer, which also acts as an extended tracker, without hitting the conversion layer if the corresponding photon does. Finally, the positron reaches the same counters used for photon timing. Simulations show that such a design, similar to the one proposed in [16], implies a large degradation of the momentum resolution. While it could be still suitable for a beam rate \u223c 10 9 \u00b5/s, this design would not fit a larger rate and, as acknowledged in [16], the optimal working point would be even lower in a scenario where multiple conversion layers are used.",
            "paragraph_rank": 76,
            "section_rank": 21,
            "ref_spans": [
                {
                    "type": "table",
                    "start": 107,
                    "text": "Table 6",
                    "end": 114
                },
                {
                    "type": "table",
                    "ref_id": "tab_4",
                    "start": 1113,
                    "text": "Tables 7 and 8",
                    "end": 1127
                },
                {
                    "type": "bibr",
                    "ref_id": "b15",
                    "start": 1884,
                    "text": "[16]",
                    "end": 1888
                },
                {
                    "type": "bibr",
                    "ref_id": "b15",
                    "start": 2071,
                    "text": "[16]",
                    "end": 2075
                }
            ]
        },
        {
            "text": "A design with calorimetry",
            "section_rank": 22
        },
        {
            "section": "A design with calorimetry",
            "text": "A \u03bc + \u2192 e + \u03b3 experiment based on calorimetry could have a design very similar to the one above for the central part of the detector, but the external e + e \u2212 pair tracker would be replaced by a scintillation detector placed outside of the magnet. With LaBr 3 (Ce) crystals, the calorimeter could be about 20 cm deep and the performance summarized in Tables 7 and  8 could be reached. Here we assume that the photon conversion point can be still determined with a negligible resolution compared to the positron vertex resolution.",
            "paragraph_rank": 77,
            "section_rank": 22,
            "ref_spans": [
                {
                    "type": "table",
                    "ref_id": "tab_4",
                    "start": 351,
                    "text": "Tables 7 and  8",
                    "end": 366
                }
            ]
        },
        {
            "text": "Sensitivity estimates",
            "section_rank": 23
        },
        {
            "section": "Sensitivity estimates",
            "text": "We consider here 100 weeks of data taking (3-4 years at PSI), with muon rates from 10 8 to 10 10 muons per second. We define a different signal region for each scenario, in such a way that, according to the resolutions estimated above, the efficiency for the signal to be inside that region is always 70%. We then assume that a counting analysis is performed on the events falling within this region.",
            "paragraph_rank": 78,
            "section_rank": 23
        },
        {
            "section": "Sensitivity estimates",
            "text": "Formulas in [8] allow to estimate the background rate, by using as an input the measured photon rate in the MEG calorimeter, linearly scaled with the beam rate. Considering that the geometry in the central region of the detector is very similar to the MEG one, this approach takes into account reliably the rate of AIF photons, which would be otherwise very difficult to extract from simulations, given the extremely low probability of this process per single muon decay.",
            "paragraph_rank": 79,
            "section_rank": 23,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b7",
                    "start": 12,
                    "text": "[8]",
                    "end": 15
                }
            ]
        },
        {
            "section": "Sensitivity estimates",
            "text": "When the photon conversion technique is adopted, we also assume a background rejection performed by requiring a good electron-photon vertex as explained in Sect. 5. The efficiency and background rejection capabilities of this approach are determined in each scenario according to the expected resolutions.",
            "paragraph_rank": 80,
            "section_rank": 23
        },
        {
            "section": "Sensitivity estimates",
            "text": "Finally, we extract the expected sensitivity of the experiment according to a frequentistic approach [33]. Figures 7 and 8 show the expected sensitivity to the \u03bc + \u2192 e + \u03b3 decay as a function of the beam intensity in different scenarios.",
            "paragraph_rank": 81,
            "section_rank": 23,
            "ref_spans": [
                {
                    "type": "bibr",
                    "ref_id": "b32",
                    "start": 101,
                    "text": "[33]",
                    "end": 105
                },
                {
                    "type": "figure",
                    "start": 107,
                    "text": "Figures 7 and 8",
                    "end": 122
                }
            ]
        },
        {
            "section": "Sensitivity estimates",
            "text": "Among them, we also considered the possibility of multiple conversion layers. In this case, we introduce fast silicon detectors for timing, with several layers to reach a 50 ps time resolution. The photon energy resolution is degraded accordingly (see Sect. 5).",
            "paragraph_rank": 82,
            "section_rank": 23
        },
        {
            "section": "Sensitivity estimates",
            "text": "In Fig. 7 we compare different designs based on the photon conversion approach. Apart from the obvious advantage of having multiple layers, it should be noticed that a vertex detector would be only useful at very large beam rates. We do not consider the silicon vertex detector option because, according to Table 8, it would not significantly improve the expected performances. We consider instead a scenario where the extended tracker is made of silicon detectors, with the performances presented in [16], which could be the only available solution if aging effects make impossible to operate a gaseous detector.",
            "paragraph_rank": 83,
            "section_rank": 23,
            "ref_spans": [
                {
                    "type": "figure",
                    "start": 3,
                    "text": "Fig. 7",
                    "end": 9
                },
                {
                    "type": "table",
                    "start": 307,
                    "text": "Table 8",
                    "end": 314
                },
                {
                    "type": "bibr",
                    "ref_id": "b15",
                    "start": 501,
                    "text": "[16]",
                    "end": 505
                }
            ]
        },
        {
            "section": "Sensitivity estimates",
            "text": "In Fig. 8 we compare the performances of an experiment with calorimetry with the performances of the best photon conversion designs. We also show for comparison how the MEG-II detector would perform at the same beam rates. Calorimetry is definitively advantageous at low beam rate, as expected, but there is a wide range of beam intensity where this approach would be limited by the background, while the photon conversion approach would not give yet a better sensitivity, unless a very large detector with many conversion layers is built.",
            "paragraph_rank": 84,
            "section_rank": 23,
            "ref_spans": [
                {
                    "type": "figure",
                    "start": 3,
                    "text": "Fig. 8",
                    "end": 9
                }
            ]
        },
        {
            "section": "Sensitivity estimates",
            "text": "In conclusion, a 2 \u00d7 10 \u221215 limit seems to be within reach with a 10 9 muons per second stopping rate, while a further increase of the beam rate up to 10 10 would only improve the sensitivity by a factor of 2.",
            "paragraph_rank": 85,
            "section_rank": 23
        },
        {
            "text": "Conclusions",
            "section_rank": 24
        },
        {
            "section": "Conclusions",
            "text": "Efforts are ongoing to develop muon beam-lines with intensities near 10 9 and possibly approaching 10 10 muons per second, to be used for a future generation of cLFV searches in muon decays.The HiMB project at PSI aims to reach 10 10 muons per second in the next decade, while the MuSIC project at RCNP (Japan) is experimenting different approaches to increase the muon yield per unit of power of the primary proton beam. The FNAL project PIP-II could be also competitive in this field.",
            "paragraph_rank": 86,
            "section_rank": 24
        },
        {
            "section": "Conclusions",
            "text": "In this paper we investigated the experimental factors that will limit the sensitivity reach of future experiments searching for the \u03bc + \u2192 e + \u03b3 decay with a continuous muon beam at high intensity.",
            "paragraph_rank": 87,
            "section_rank": 24
        },
        {
            "section": "Conclusions",
            "text": "The most relevant issue is the choice of the photon detection technique between calorimetry and the reconstruction of the e + e \u2212 pair from photon conversion in a thin layer of high-Z material, being favored the former by the much higher detection efficiency and the latter by the far superior resolutions, along with the possibility of rejecting accidental background events by reconstructing the photon-positron vertex.",
            "paragraph_rank": 88,
            "section_rank": 24
        },
        {
            "section": "Conclusions",
            "text": "On the positron side, tracking with gaseous detectors would ideally provide the best possible resolutions, which would be eventually limited by the multiple Coulomb scattering experienced by the particle in the target and in the material in front of the tracker. On the other hand, the high occupancy in the inner part of the tracking system could severely limit the possibility of using gaseous detectors. A significant deterioration of the overall sensitivity (more than a factor 2) is expected if a silicon tracker has to be used for this reason.",
            "paragraph_rank": 89,
            "section_rank": 24
        },
        {
            "section": "Conclusions",
            "text": "Sensitivity projections show that a 3-year run with an accelerator delivering around 10 9 muons per second could allow to reach a sensitivity of a few 10 \u221215 (expected 90% upper limit on the \u03bc + \u2192 e + \u03b3 BR), with poor perspectives of going below 10 \u221215 even with 10 10 muons per second. Below 5 \u00d7 10 8 muons per second, the calorimetric approach needs to be used in order to reach this target. If a muon beam rate exceeding 10 9 muons per second is available, the much cheaper photon conversion option would be recommended and would provide similar sensitivities.",
            "paragraph_rank": 90,
            "section_rank": 24
        },
        {
            "section": "Conclusions",
            "text": "The sensitivity would be eventually limited by the fluctuation of the interaction of the particles with the detector materials: this indicates that a further step forward in the search for \u03bc + \u2192 e + \u03b3 would require a radical rethinking of the experimental concept.",
            "paragraph_rank": 91,
            "section_rank": 24
        },
        {
            "text": "Fig. 1",
            "section_rank": 25
        },
        {
            "section": "Fig. 1",
            "text": "Fig. 1Conceptual detector designs exploiting the calorimetric (left) or conversion (right) technique for the photon detection, and a tracking approach in a magnetic field for the positron reconstruction. Muons are stopped in a target (dark red ellipse) at the center of the magnet. Positron tracks from the muon decays (in black) are reconstructed in a",
            "paragraph_rank": 92,
            "section_rank": 25
        },
        {
            "text": "Fig. 2",
            "section_rank": 26
        },
        {
            "section": "Fig. 2",
            "text": "Fig. 2Sensitivity trends as a function of the beam intensity, for a calorimetry-based design (black), a photon-conversion-based design with unchanged positron resolutions (blue) and a calorimetry-based design with a factor two improvement in resolutions (red). See the text for a detailed description",
            "paragraph_rank": 93,
            "section_rank": 26
        },
        {
            "text": "Fig. 3",
            "section_rank": 27
        },
        {
            "section": "Fig. 3",
            "text": "Fig. 3The conversion efficiency (black, left axis) and the contribution to the energy resolution from the energy loss in the converter (red, right axis), for Lead (full lines) and Tungsten (dashed lines), as a function of the converter thickness (in units of radiation length). The dash-dotted line shows the asymptotic conversion probability, 7/9 times the thickness in units of radiation length",
            "paragraph_rank": 94,
            "section_rank": 27
        },
        {
            "text": "4 . 5 \u2295 3 Fig. 4",
            "section_rank": 28
        },
        {
            "section": "4 . 5 \u2295 3 Fig. 4",
            "text": "Fig. 4Vertex resolution in the Z coordinate as a function of the inner radius of the tracking detector. It gives a contribution to the \u03b8 e\u03b3 resolution which equals approximately \u03c3 Z /R \u03b3 , being R \u03b3 the radius of the photon detection point. The right axis shows this contribution for R \u03b3 = 30 cm. It has to be added to the contribution from the positron \u03b8 angle reconstruction",
            "paragraph_rank": 95,
            "section_rank": 28
        },
        {
            "text": "Fig. 6",
            "section_rank": 29
        },
        {
            "section": "Fig. 6",
            "text": "Photon TC",
            "paragraph_rank": 96,
            "section_rank": 29
        },
        {
            "text": "Fig. 7 Fig. 8",
            "section_rank": 30
        },
        {
            "section": "Fig. 7 Fig. 8",
            "text": "Fig. 7 Expected 90% C.L. upper limit on the Branching Ratio of \u03bc + \u2192 e + \u03b3 in different scenarios for a 3-year run. A few different designs based on the photon conversion technique are compared, including the TPC vertex detector option in the conservative and optimistic hypotheses. The lines turn from continuous to dashed when the number of background events exceeds 10. The horizontal dashed and dotted lines show the current MEG limit and the expected MEG-II sensitivity, respectively",
            "paragraph_rank": 97,
            "section_rank": 30
        },
        {
            "text": "Table 1",
            "section_rank": 31
        },
        {
            "section": "Table 1",
            "text": "Properties of state-of-the-art scintillators relevant for the application on \u03bc + \u2192 e + \u03b3 searches Scintillator Density (g/cm 3 ) Light yield (ph/keV) Decay time (ns)",
            "paragraph_rank": 98,
            "section_rank": 31
        },
        {
            "text": "Table 2",
            "section_rank": 32
        },
        {
            "section": "Table 2",
            "text": "Angle and energy uncertainties introduced by material effects in the target, for different target materials. A 76 \u2022 slant angle is assumed. The chosen thickness is the one providing 90% muon stopping power Material Thickness (\u00b5m) Resolutions \u03c3 \u03b8 (mrad) \u03c3 \u03c6 (mrad) \u03c3 Ee (keV)",
            "paragraph_rank": 99,
            "section_rank": 32
        },
        {
            "text": "Table 4",
            "section_rank": 33
        },
        {
            "section": "Table 4",
            "text": "Limiting factors for the efficiency and resolutions of future \u03bc + \u2192 e + \u03b3 searches",
            "paragraph_rank": 100,
            "section_rank": 33
        },
        {
            "text": "Table 5",
            "section_rank": 34
        },
        {
            "section": "Table 5",
            "text": "Photon reconstruction performances of a baseline \u03bc + \u2192 e + \u03b3 experiment with calorimetry",
            "paragraph_rank": 101,
            "section_rank": 34
        },
        {
            "text": "Table 7",
            "section_rank": 35
        },
        {
            "section": "Table 7",
            "text": "Expected performances (efficiency and resolutions) for a basic design with different options as discussed in the text",
            "paragraph_rank": 102,
            "section_rank": 35
        },
        {
            "section": "Table 7",
            "text": "In this paper we concentrate on the search for cLFV in the decay of free muons, and in particular \u03bc + \u2192 e + \u03b3 , which requires a continuous muon beam, and hence we do not discuss the efforts made to deliver very high intensity pulsed muon beams, e.g. for the search of \u03bc \u2192 e conversion in the Coulomb field of a nucleus.",
            "paragraph_rank": 103,
            "section_rank": 35
        },
        {
            "section": "Table 7",
            "text": "Acknowledgements This paper is dedicated to the memory of our colleague Giancarlo Piredda, whose inspiration was invaluable in the early stages of this work. We are also grateful to all our MEG and MEG-II colleagues for valuable discussions.",
            "paragraph_rank": 104,
            "section_rank": 37
        },
        {
            "section": "Table 7",
            "text": "Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecomm ons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. Funded by SCOAP 3 .",
            "paragraph_rank": 105,
            "section_rank": 37
        }
    ]
}