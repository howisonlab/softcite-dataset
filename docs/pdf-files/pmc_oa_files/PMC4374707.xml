<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Cytometry A</journal-id><journal-id journal-id-type="iso-abbrev">Cytometry A</journal-id><journal-id journal-id-type="publisher-id">cyto</journal-id><journal-title-group><journal-title>Cytometry</journal-title></journal-title-group><issn pub-type="ppub">1552-4922</issn><issn pub-type="epub">1552-4930</issn><publisher><publisher-name>BlackWell Publishing Ltd</publisher-name><publisher-loc>Oxford, UK</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">25573002</article-id><article-id pub-id-type="pmc">4374707</article-id><article-id pub-id-type="doi">10.1002/cyto.a.22624</article-id><article-categories><subj-group subj-group-type="heading"><subject>Original Articles</subject></subj-group></article-categories><title-group><article-title>Simulation of bright-field microscopy images depicting pap-smear specimen</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Malm</surname><given-names>Patrik</given-names></name><xref ref-type="aff" rid="au1"/><xref ref-type="corresp" rid="cor1">*</xref></contrib><contrib contrib-type="author"><name><surname>Brun</surname><given-names>Anders</given-names></name><xref ref-type="aff" rid="au1"/></contrib><contrib contrib-type="author"><name><surname>Bengtsson</surname><given-names>Ewert</given-names></name><xref ref-type="aff" rid="au1"/></contrib><aff id="au1"><institution>Division of Visual Information and Interaction Department of Information Technology, Centre for Image Analysis, Uppsala University</institution><addr-line>751 05, Uppsala, Sweden</addr-line></aff></contrib-group><author-notes><corresp id="cor1">*
Correspondence to: Patrik Malm; Division of Visual Information and Interaction, Department of Information Technology, Centre for Image Analysis, Uppsala University, 751 05 Uppsala, Sweden. E-mail: <email>patma409@gmail.com</email></corresp><fn><p>Grant sponsor: Swedish Research Council, Grant number: 2008-2738</p></fn><fn><p>Grant sponsor: VINNOVA, Grant number: 2008-01712</p></fn><fn><p>Grant sponsor: Department of Information Technology, Government of India</p></fn><fn><p>Grant sponsor: VINNOVA, Grant number: 2008-01712</p></fn><fn><p>Grant sponsor: Department of Information Technology, Government of India</p></fn></author-notes><pub-date pub-type="ppub"><month>3</month><year>2015</year></pub-date><pub-date pub-type="epub"><day>08</day><month>1</month><year>2015</year></pub-date><volume>87</volume><issue>3</issue><fpage>212</fpage><lpage>226</lpage><history><date date-type="received"><day>16</day><month>11</month><year>2013</year></date><date date-type="rev-recd"><day>30</day><month>11</month><year>2014</year></date><date date-type="accepted"><day>10</day><month>12</month><year>2014</year></date></history><permissions><copyright-statement>&#x000a9; 2015 The Authors. Published by Wiley Periodicals, Inc. on behalf of ISAC</copyright-statement><copyright-year>2015</copyright-year><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by-nc/3.0/"><license-p>This is an open access article under the terms of the Creative Commons Attribution-NonCommercial License, which permits use, distribution and reproduction in any medium, provided the original work is properly cited and is not used for commercial purposes.</license-p></license></permissions><abstract><p>As digital imaging is becoming a fundamental part of medical and biomedical research, the demand for computer-based evaluation using advanced image analysis is becoming an integral part of many research projects. A common problem when developing new image analysis algorithms is the need of large datasets with ground truth on which the algorithms can be tested and optimized. Generating such datasets is often tedious and introduces subjectivity and interindividual and intraindividual variations. An alternative to manually created ground-truth data is to generate synthetic images where the ground truth is known. The challenge then is to make the images sufficiently similar to the real ones to be useful in algorithm development. One of the first and most widely studied medical image analysis tasks is to automate screening for cervical cancer through Pap-smear analysis. As part of an effort to develop a new generation cervical cancer screening system, we have developed a framework for the creation of realistic synthetic bright-field microscopy images that can be used for algorithm development and benchmarking. The resulting framework has been assessed through a visual evaluation by experts with extensive experience of Pap-smear images. The results show that images produced using our described methods are realistic enough to be mistaken for real microscopy images. The developed simulation framework is very flexible and can be modified to mimic many other types of bright-field microscopy images. &#x000a9; 2015 The Authors. Published by Wiley Periodicals, Inc. on behalf of ISAC</p></abstract><kwd-group><kwd>synthetic image generation</kwd><kwd>Pap-smear</kwd><kwd>cervical cancer screening</kwd><kwd>bright-field microscopy</kwd></kwd-group></article-meta></front><body><p>The recent trend toward high-throughput screening in medical and biomedical research has led to a substantial increase of the amount of data produced. This development has rendered manual analysis of all the resulting data to no longer being a feasible approach. Therefore, computer-based evaluations using advanced image analysis have become an integral part of many research projects, for example, in <xref rid="b1" ref-type="bibr">1</xref>. A good example of a field where research on the use of image analysis as a diagnostic tool has been ongoing for many years is that of Papanicolaou (Pap) test analysis. Attempts at the creation of automated systems have been made since 1950s, and the problem is still subject to active research <xref rid="b2" ref-type="bibr">2</xref>.</p><p>To create an algorithm that is able to, for example, segment nuclei in an image, the developer is at some point going to need a validation dataset containing a representable selection of the material being analyzed, as well as a ground-truth segmentation for the objects of interest. This is used to measure the performance and robustness of developed algorithms. Acquiring this ground-truth data can, however, in many cases be a very difficult prospect. Aside from issues such as obscuring biological material, the image will have been subjected to aberrations linked to the modality of the acquisition technique <xref rid="b3" ref-type="bibr">3</xref>. The process of dealing with these degenerative effects can often become very complicated. When working with images acquired from a microscope, one may have to deal with issues such as uneven illumination, detector noise, and compression artefacts <xref rid="b4" ref-type="bibr">4</xref>,<xref rid="b5" ref-type="bibr">5</xref>. These errors are added to already existing aberrations related to the physical limitations of the optics <xref rid="b6" ref-type="bibr">6</xref>.</p><p>The classical way to handle the ground-truth issue is to manually try to obtain ground-truth data with the help of one or, preferably, several experts. However, this approach is notoriously prone to introduce errors in itself, due to the limitations in reproducibility for human operators <xref rid="b7" ref-type="bibr">7</xref>. Furthermore, to create a statistically sound ground-truth dataset, especially when working with biological data and its basically infinite variations, it is often necessary to manually analyze huge quantities of data. This can in many cases be an impossible task.</p><p>In this article, we describe a framework for creating realistic synthetic images intended to be used for the development of various kinds of image analysis tasks such as preprocessing and segmentation. Simulated images can fill several functions in a development pipeline, for example:</p><list list-type="order"><list-item><p>Parameter optimization <xref rid="b8" ref-type="bibr">8</xref>.</p></list-item><list-item><p>Algorithm comparison/evaluation <xref rid="b4" ref-type="bibr">4</xref>.</p></list-item><list-item><p>Benchmarking on large datasets <xref rid="b9" ref-type="bibr">9</xref>.</p></list-item></list><p>As ground truth is always readily available, it is possible to do optimizations, evaluations, and validations on amounts of data not feasible when relying on manually analyzed images. Another benefit is the ability to control the characteristics of the synthetic data both concerning imaging properties such as uneven illumination and aberrations caused by the imaging system. This allows for controlled testing of an algorithm's robustness under very specific circumstances.</p><p>Previous attempts at creating images depicting cell- or nucleus-like objects have primarily been aimed at mimicking images acquired using fluorescence microscopy. Lehmussola et al. created a complex simulator, called SIMCEP, which is able to create populations of realistic two-dimensional (2D) nucleus populations <xref rid="b4" ref-type="bibr">4</xref>. Svoboda et al. built on the concepts introduced in that article to create fully three-dimensional (3D) image data <xref rid="b5" ref-type="bibr">5</xref>,<xref rid="b10" ref-type="bibr">10</xref>. Recently, they have further extended their work to also include time-lapse simulation <xref rid="b11" ref-type="bibr">11</xref>. In common, for the work mentioned above is that they only simulate the nucleus appearance and did so using parametric methods for shape and texture generation. Zhao and Murphy <xref rid="b12" ref-type="bibr">12</xref> instead uses machine learning to generate the shape of the nucleus and the cytoplasm as well as the texture of the nucleus.</p><p>The simulation described in this article constitutes a highly flexible framework for emulating Pap-smear images taken using a standard bright-field microscope. This is, to the best of our knowledge, only the second attempt at creating realistic synthetic images emulating data collected using bright-field microscopes, the first one being our own previous work <xref rid="b8" ref-type="bibr">8</xref>. This new framework, however, improves greatly on previous work through the addition of shape and texture generation based on data obtained from an extensive database of segmented cells, the inclusion of more debris models, a more versatile method for object distribution, and an accurate approximation of the image depth of field, allowing for simulated focus stacks to be created. The resulting images have been validated using visual inspection of images by trained individuals with experience in analyzing cell images as well as cytology experts.</p><sec><title>P<sc>roblem</sc> S<sc>tatement</sc></title><p>The goal of this project was to create a simulation framework able to create realistic images containing not only cell nuclei but also cytoplasms as well as a wide variety of other objects and artifacts commonly found in Pap-test specimens. When working with biological data, one of the biggest challenges lies in trying to deal with the extensive variation present in the samples. Objects are often subjected to distortions such as overlapping and folding or obscured by material lying outside the current focus plane of the imaging system. If stains are used, it is common to experience stain intensity variations on both an intrasample and intersample basis.</p><p>For this article, objects that are not usable intermediate epithelial cells are referred to as debris or artifacts. A selection of the most common types of artifacts found in Pap-smear samples have been illustrated in <xref ref-type="fig" rid="fig01">Figure 1</xref>. These artifacts introduce an added level of difficulty when trying to achieve goals such as reliable nucleus segmentation in a high-throughput setting. When developing a synthetic image generation framework for this type of modality, it is essential that as many of these types of debris are modeled as accurately as possible and included in the final results.</p><fig id="fig01" position="float"><label>Figure 1</label><caption><p>A selection of artifacts that commonly occur in bright-field microscopy images of Pap-smears. From top to bottom: bacilli (small linear objects), WBC (small dark elliptical objects), dye specks, and OOF objects.</p></caption><graphic xlink:href="cyto0087-0212-f1"/></fig><p>The primary focus for this study was to try to imitate the appearance of samples produced using liquid-based cytology (LBC) <xref rid="b13" ref-type="bibr">13</xref>. A description of the LBC method can be found in the reference data section below. This choice was related to LBC producing cleaner specimens. Regions with well distributed and mainly free-lying cells on conventional smears look similar to LBC:s and those are reasonably well represented by our simulator. By increasing the object distribution density, the generated images will become more similar to dense regions on smears. But, the conventional smears also contain highly dense regions with many layers of cells, mucus, and other obscuring structures. Simulating that appearance properly would have required significant additional modeling efforts without adding to the usefulness of the simulator, as there are hardly any image analysis algorithms that can extract useful information from such dense regions.</p><p>Although humans analyze Pap-smears in color, computer-based systems commonly operate on monochrome images. This is because color has very little diagnostic value when analyzing specimen stained using the Pap-stain. Instead, when developing automated systems, achieving a good contrast for nucleus texture is the highest priority. Therefore, specific filters are used that produce monochrome images with maximum nucleus contrast <xref rid="b14" ref-type="bibr">14</xref>. The simulator described in this article is imitating images taken using such circumstances.</p></sec><sec><title>R<sc>eference</sc> D<sc>ata</sc></title><p>To create synthetic images that are sufficiently similar to reality, access to real data is a necessity. For the development of the framework described in this article, a large database of Pap-smear images, acquired at several focus levels, was available. In the following sections, the source material will be discussed in more detail.</p><sec><title>The Papanicolaou Test</title><p>The goal of the Papanicolaou test is the detection of neoplastic (cancerous) and proneoplastic (precancerous) cell changes in the cervix before they reach an invasive stage. Using a spatula or a brush, the area known as the transformation zone of the uterine cervix is scraped to obtain epithelial cells. The epithelium has a layered structure consisting of basal, parabasal, intermediate, and superficial cell. Out of these, the intermediate cells are the most common and have frequently been the target of automated analysis studies <xref rid="b13" ref-type="bibr">13</xref>. The collected material is smeared onto a glass slide to produce the Pap-smear. The sample is fixed and stained to enhance the contrast between nucleus and cytoplasm <xref rid="b15" ref-type="bibr">15</xref>.</p><p>Although the Pap-smear has shown its worth through decades of use, it is hampered by certain difficulties, for example, variable smear thickness, uneven cell distribution across the field of view, obscuring elements such as blood and inflammatory cells, and variable fixation and staining results. To overcome some of these problems, so-called LBC preparation methods have been developed. Using LBC, the sample is immersed in a solution that is then subjected to a number of processes that work to homogenize the sample, remove unwanted components (e.g., red blood cells) and finally deposit a suitable mono-layer sample on a glass slide <xref rid="b13" ref-type="bibr">13</xref>. These samples are considerably less cluttered and while thickness of the cells distribution still varies, it is overall far less than for the conventional smear. However, the types of debris objects described in the Problem Statement section earlier will still be present in samples prepared using an LBC protocol.</p></sec><sec sec-type="materials"><title>Materials</title><p>Data from more than 900 fields of view, acquired as focus-stacks from 82 specimens, were available for the development of the simulation method. The database contains specimen prepared using both the conventional method as well as the LBC method. Image acquisition was performed using an Olympus BX51 bright-field microscope equipped with a 40&#x000d7;, 0.95 NA lens and a Hamamatsu ORCA-05G 1.4 Mpx monochrome camera, giving a pixel size of 0.25 &#x000b5;m. The microscope light path was filtered using a 570-nm bandpass filter, a wavelength previously shown to maximize the contrast of nuclei in Pap-smears <xref rid="b14" ref-type="bibr">14</xref>. The microscope was fitted with an E-662 Piezo server controller (Physik Instrumente GmbH &#x00026; Co. KG, Karlsruhe, Germany). This allowed for <italic>z</italic>-axis step control with a 0.1 &#x000b5;m resolution during image acquisition.</p><p>The algorithms described in this article were implemented in <sc>Matlab</sc> (2011b, The MathWorks, Natick, MA) using the image processing toolbox DIPimage <xref rid="b16" ref-type="bibr">16</xref>.</p></sec></sec><sec><title>S<sc>imulation</sc> M<sc>ethods</sc></title><p>The framework described in this article includes the creation of a wide variety of objects, ranging from the individual cells to clusters of bacilli, as well as an emulation of an optical system paired with a detector. Svoboda et al. <xref rid="b5" ref-type="bibr">5</xref> suggested that the simulation process can be split into three main phases: phantom object generation, signal transmission, and finally, signal detection and image formation.</p><p>Phantom object generation refers to the creation of the primitives that constitute the main content of an image. In some cases, these objects can be quite simple point-like objects <xref rid="b17" ref-type="bibr">17</xref>, whereas others entail the creation of full 3D representations <xref rid="b5" ref-type="bibr">5</xref>. For some simulation frameworks, phantom generation includes not only the creation of single objects but also entire populations of object occurrences <xref rid="b4" ref-type="bibr">4</xref>,<xref rid="b18" ref-type="bibr">18</xref>.</p><p>The way the signal transmission is approximated is naturally highly dependent on the modality being simulated. Perhaps, the most important phenomenon is the impulse response of the system, also known as the point spread function (PSF), which is a central aspect of all types of microscopy <xref rid="b3" ref-type="bibr">3</xref>. The PSF is most often replaced by a Gaussian kernel as its generally accepted to be a good approximation <xref rid="b4" ref-type="bibr">4</xref>,<xref rid="b8" ref-type="bibr">8</xref>,<xref rid="b17" ref-type="bibr">17</xref>. Other aspects belonging to this stage are uneven illumination <xref rid="b10" ref-type="bibr">10</xref> and various kinds of chromatic aberrations <xref rid="b19" ref-type="bibr">19</xref>.</p><p>The final stage aims to emulate the performance of the device sensor and its conversion of incoming light into a digital representation. Sensors introduce Poisson noise <xref rid="b20" ref-type="bibr">20</xref> that can be seen with the naked eye. Furthermore, the A/D converter and amplification circuits introduce noticeable levels of noise <xref rid="b20" ref-type="bibr">20</xref>. Other possible aberrations include dark current noise, fixed pattern noise, and blooming effects <xref rid="b5" ref-type="bibr">5</xref>.</p><p><xref ref-type="fig" rid="fig02">Figure 2</xref> depicts a flowchart, organized as suggested by Svoboda et al., illustrating the synthesis process of the algorithm described in this article. In the following sections, we are going to describe the steps of the method in more detail.</p><fig id="fig02" position="float"><label>Figure 2</label><caption><p>A flowchart depicting the simulation framework described in this article. The simulation process is divided into three phases. In the first phase shape primitives, phantoms, are created. These objects include cell nuclei, cell cytoplasms, bacilli, WBC, OOF objects, and speckles. Once the primitives are created they are distributed over the image using a weighted distribution model. Also, each object is given a depth coordinate. In the second phase image degradation similar <italic>t</italic><sub>p</sub>, the one seen in bright-field microscopes is simulated. Finally, in phase 3, sensor noise is simulated according to the characteristics of a CCD sensor.</p></caption><graphic xlink:href="cyto0087-0212-f2"/></fig><sec><title>Squamous Intermediate Cell Phantoms</title><p>As the squamous intermediate cell is the target for most studies related to Pap-smear analysis, it is of utmost importance that it is as accurately modeled as possible. The cells can, for modeling purposes, be divided into two main components, the cytoplasm and the nucleus.</p><p>The cytoplasms appear as a mostly transparent gel-like substance. It has little stability and is thus easily deformed, resulting in variations in shape and size between cells. The cytoplasm of a healthy cell displays little in the way of a regular texture other than a fine network of fibers, these are known as the cytoskeleton.</p><p>The nucleus is in contrast to the cytoplasm a more rigid structure that has a principally elliptical shape. Because of the staining involved when preparing the Pap-smear, it is generally darker relative to the cytoplasm. The appearance of the nucleus texture is related to the distribution of the chromatin within the nucleus membrane.</p><sec><title>Shape generation</title><p>To generate the shape of the cytoplasm and nucleus phantoms as accurately as possible, we used our cell image database. From our database of some 12,000 segmented cell nuclei, we randomly selected 100 normal squamous intermediate cell nuclei. The nuclei were segmented through a manually seeded watershed algorithm. The corresponding cytoplasm was interactively segmented using the live-wire tool <xref rid="b21" ref-type="bibr">21</xref>. For each cell, the shapes of the cytoplasm and the nucleus have been parameterized using a method for Fourier shape representation described by Zhang and Lu <xref rid="b22" ref-type="bibr">22</xref>. The boundary of an object mask is sampled at a predefined number, <italic>K</italic>, points spaced at an equal arc length. Starting at an arbitrary point, (<italic>x</italic>(0), <italic>y</italic>(0)), coordinate pairs (<italic>x</italic><xref rid="b1" ref-type="bibr">1</xref>, <italic>y</italic><xref rid="b1" ref-type="bibr">1</xref>), (<italic>x</italic><xref rid="b2" ref-type="bibr">2</xref>,<italic>y</italic><xref rid="b2" ref-type="bibr">2</xref>), &#x02026;, (<italic>x</italic>(<italic>K</italic>&#x02009;&#x02212;&#x02009;1), <italic>y</italic>(<italic>K</italic>&#x02009;&#x02212;&#x02009;1)) are encountered when traversing the boundary in a preselected direction. The shape boundary coordinates can be represented as a sequence of coordinates <italic>s</italic>(<italic>k</italic>)&#x02009;=&#x02009;[<italic>x</italic>(<italic>k</italic>), <italic>y</italic>(<italic>k</italic>)], for <italic>k</italic>&#x02009;=&#x02009;0,1,2,&#x02026;, <italic>K</italic>&#x02009;&#x02212;&#x02009;1. Also, each coordinate pair can be treated as a complex number so that</p><p><disp-formula id="m1"><graphic xlink:href="cyto0087-0212-m1.jpg" mimetype="image" position="float"/><label>(1)</label></disp-formula></p><p>where <italic>i</italic> is the unit imaginary number. This reduces our 2D data to at 1D problem. We can now calculate the discrete Fourier transform of <italic>z(k)</italic> as</p><p><disp-formula id="m2"><graphic xlink:href="cyto0087-0212-m2.jpg" mimetype="image" position="float"/><label>(2)</label></disp-formula></p><p>where<inline-formula><inline-graphic xlink:href="cyto0087-0212-mu1.jpg" mimetype="image"/></inline-formula>. The complex coefficients <italic>u<sub>n</sub></italic> are called the Fourier shape descriptors (FSD) of the boundary. These descriptors represent the shape of the object in the frequency domain. We carry out this kind of FSD extraction on a representative population of nuclear shapes and thus collect a set of statistical populations of FSD. We can now use naive Bayesian theory to generate new shapes. This means that we from these populations extract the mean and standard deviation for each descriptor and use that to define a statistical distribution from which we draw samples at random. These samples define a new shape which is returned to real space through inverse Fourier transform. The FSD can be normalized with respect to size by dividing the descriptors with the magnitude of the second component,<inline-formula><inline-graphic xlink:href="cyto0087-0212-mu2.jpg" mimetype="image"/></inline-formula>, of the signal, yielding the normalized shape descriptor vector<inline-formula><inline-graphic xlink:href="cyto0087-0212-mu3.jpg" mimetype="image"/></inline-formula> as</p><p><disp-formula id="m3"><graphic xlink:href="cyto0087-0212-m3.jpg" mimetype="image" position="float"/><label>(3)</label></disp-formula></p><p>The DC component, <italic>u</italic><sub>0</sub>, depends only on the position of the shape, which in this setting is of no importance and can therefore be removed, <italic>u</italic><sub>0</sub>&#x02009;=&#x02009;0. By normalizing the size of the shapes in the database, it is now possible to add a scale parameter to the generation of the new shapes. This gives us an increased control and makes it possible to, for example, link our shape size to a pixel resolution or add controlled random size variations to the generated shapes. A few examples of randomly generated nucleus and cytoplasm shapes can be seen in <xref ref-type="fig" rid="fig03">Figure 3</xref>.</p><fig id="fig03" position="float"><label>Figure 3</label><caption><p>Examples of nucleus and cytoplasm shapes created using the FSD method.</p></caption><graphic xlink:href="cyto0087-0212-f3"/></fig></sec><sec><title>Texture synthesis</title><p>For this study, nucleus textures have been created using a texture synthesis approach, well known in computer graphics, called patch-based texture generation <xref rid="b23" ref-type="bibr">23</xref>. The goal of this method is to be able to create a texture image of any size based on a small texture sample. A schematic description of the texture generation process can be seen in <xref ref-type="fig" rid="fig04">Figure 4</xref>.</p><fig id="fig04" position="float"><label>Figure 4</label><caption><p>Conceptual illustration of patch-based texture synthesis. (Left) Sample image. (Middle) Patch evaluation based on the distance between the overlap region of two patches. (Right) Finished synthesized texture. [Color figure can be viewed in the online issue, which is available at <ext-link ext-link-type="uri" xlink:href="http://wileyonlinelibrary.com">http://wileyonlinelibrary.com</ext-link>.]</p></caption><graphic xlink:href="cyto0087-0212-f4"/></fig><p>The process is initialized by randomly selecting an initial texture patch, <italic>B</italic><sub>0</sub>, of predefined size from the sample texture, <italic>T</italic><sub>s</sub>, and placing it in a corner of the target texture,<italic>T</italic><sub>out</sub>. A boundary zone,<inline-formula><inline-graphic xlink:href="cyto0087-0212-mu4.jpg" mimetype="image"/></inline-formula>, of width, <italic>w<sub>E</sub></italic>, is defined for each patch. A random coordinate pair, (<italic>x</italic>, <italic>y</italic>), is generated in <italic>T</italic><sub>s</sub> and a patch candidate, <italic>B</italic><sub>(</sub><italic><sub>x</sub></italic><sub>,</sub><italic><sub>y</sub></italic><sub>)</sub> is acquired. If the distance between the overlap regions,<inline-formula><inline-graphic xlink:href="cyto0087-0212-mu5.jpg" mimetype="image"/></inline-formula>, is lower than a predefined distance threshold, <italic>d</italic><sub>max</sub>, the patch is accepted to be pasted to the generated texture. The distance metric used is usually the mean squared error. As a final step, the pixels in the overlap region need to be blended together to avoid sharp edges in the texture. This can be achieved using feathering <xref rid="b24" ref-type="bibr">24</xref> or a minimum error boundary cut <xref rid="b23" ref-type="bibr">23</xref>. For our implementation, we use feathering, that is, pixel intensities are weighted relative to their distance to the edges of the patches.</p><p>To add randomness to the nucleus texture generation, each new texture is generated from three different sample nuclei randomly selected from the database. This significantly reduces the risk of recurring texture details. Furthermore, we have added weighting to the patch selection so that patches that are to be placed close to the center of the phantom are more likely to be found in central parts of the sample images. An example of a generated nucleus can be seen in <xref ref-type="fig" rid="fig05">Figure 5</xref>.</p><fig id="fig05" position="float"><label>Figure 5</label><caption><p>Nucleus texture generation. (Top row) The three nuclei used as texture samples. (Bottom row) Generated nucleus texture and final generated nucleus.</p></caption><graphic xlink:href="cyto0087-0212-f5"/></fig><p>The cytoplasm texture is difficult to define as it is mainly a result of which deformations it has been exposed to. To that end, a cloth simulation algorithm <xref rid="b25" ref-type="bibr">25</xref> has been used to simulate cytoplasm deformations. The cloth simulator starts with a circular mesh, that is, a grid-like structure consisting of a number of points (vertices),<inline-formula><inline-graphic xlink:href="cyto0087-0212-mu6.jpg" mimetype="image"/></inline-formula>, connected by edges. This mesh is then deformed using a force-field that gradually shrinks to the generated shape's outer boundary and pushing on vertices that it touches on the way. The deformation of the cloth takes place in 3D with a ground plane limiting movements in a negative <italic>z</italic>-direction. In the end, the cloth object will have an outer boundary that corresponds to the generated shape, but the vertices that make up the central part of the mesh will be pushed to produced wrinkles and folds. The cloth simulation is an iterative physics simulation where each vertex in the cloth mesh is given acceleration depending on outer forces that affect it as well as inner forces decided by the distances to its neighbors. One iteration of the simulation is called a time-step. The index <italic>t</italic> gives the time that has passed as the initiation of the simulation, and &#x00394;<italic>t</italic> is used to indicate how much time is increased between iterations. At each iteration, a vertex's new position,<inline-formula><inline-graphic xlink:href="cyto0087-0212-mu7.jpg" mimetype="image"/></inline-formula>, is calculated using the Verlet integration <xref rid="b26" ref-type="bibr">26</xref>,</p><p><disp-formula id="m4"><graphic xlink:href="cyto0087-0212-m4.jpg" mimetype="image" position="float"/><label>(4)</label></disp-formula></p><p>where<inline-formula><inline-graphic xlink:href="cyto0087-0212-mu8.jpg" mimetype="image"/></inline-formula> is the acceleration of the vertex after previous iteration.</p><p>When the cloth mesh has undergone deformation, a surface render is performed to get a base texture for the cytoplasm. The cloth simulation process has been illustrated in <xref ref-type="fig" rid="fig06">Figure 6</xref>. Note that through the simulation process, a naturally looking folding pattern has been created at the edge of the cytoplasm shape which propagates into the central part of the cytoplasm phantom.</p><fig id="fig06" position="float"><label>Figure 6</label><caption><p>Illustration depicting the steps of the cloth simulation process: (a) Initial shape generated according to method described in Shape generation section that is used as the target for the deformation, (b) Initial cloth mesh prior to any deformation, (c) cloth mesh after deformation, and (d) final rendered result produced by adding a transparent material to the mesh.</p></caption><graphic xlink:href="cyto0087-0212-f6"/></fig><p>To finish the cytoplasm generation, three levels of details are added. Each of these are optional and can be excluded if sample specifications dictate it. The first level is a low frequency Gaussian noise that adds intensity variations to the texture. The second level is composed of thresholded Brownian noise, which is a correlated noise whose power spectrum decreases as a function of <italic>f</italic>&#x02009;<sup>2</sup>. This noise appears as clouds of small flecks that are unevenly distributed over the cytoplasm, which corresponds to, for superficial squamous cells, fairly commonly seen keratin precursors. The final level of detail entails the simulation of a cytoskeleton structure. The skeleton is generated by first generating a random Voronoi diagram by randomly placing points in an image. The diagram is relaxed using Lloyd's algorithm <xref rid="b27" ref-type="bibr">27</xref> to get a more evenly spaced point distribution. A radial distance transform is generated from the edge of the image to create a downward slope from the middle of the image to the edges. Random vertices of the Voronoi diagram are then selected and a line is created by following the edges of the diagram by steepest descent according to the distance transform. A random chance of branching at each vertex results in a random tree structure that is very similar in appearance to cytoskeletons observed in reference images. In <xref ref-type="fig" rid="fig07">Figure 7</xref>, the three levels of details that can be added to the cytoplasm base texture have been illustrated as well as an example of a finished textured cytoplasm.</p><fig id="fig07" position="float"><label>Figure 7</label><caption><p>(Left) The three levels of texture details (Low frequency Gaussian noise, thresholded Brownian noise, simulated cytoskeleton shape). (Right) Example of a final cytoplasm result (for this example a different base texture than the one shown in <xref ref-type="fig" rid="fig06">Fig. 6</xref> has been used).</p></caption><graphic xlink:href="cyto0087-0212-f7"/></fig></sec></sec><sec><title>Population Distribution Generation</title><p>The distribution of generated objects is an important factor of the simulated image generation process. The simplest approach to generating a coordinate pair, (<italic>x</italic>, <italic>y</italic>), for an image with dimensions (<italic>M</italic>, <italic>N</italic>) is to draw the coordinates from a uniform distribution, <italic>U</italic>(<italic>a</italic>, <italic>b</italic>) where <italic>a</italic> and <italic>b</italic> describes the interval,</p><p><disp-formula id="m20"><graphic xlink:href="cyto0087-0212-m20.jpg" mimetype="image" position="float"/></disp-formula>
<disp-formula id="m5"><graphic xlink:href="cyto0087-0212-m5.jpg" mimetype="image" position="float"/><label>(5)</label></disp-formula></p><p>The problem with this approach is that populations generated using this method will not look natural. Objects in biological samples tend to end up in more concentrated groups <xref rid="b28" ref-type="bibr">28</xref>. The problem of population generation has previously been studied as described in <xref rid="b4" ref-type="bibr">4</xref> and <xref rid="b29" ref-type="bibr">29</xref> showing meaningful results. For this study, we have instead chosen to use a different approach, a method known as rejection sampling <xref rid="b30" ref-type="bibr">30</xref>, in computer graphics also known as Russian Roulette Monte Carlo sampling <xref rid="b31" ref-type="bibr">31</xref>, to generate our distributions. The basic concept behind rejection sampling is that a coordinate pair drawn from a uniform distribution is accepted with a probability <italic>W<sub>x</sub><sub>,</sub><sub>y</sub></italic>, where<inline-formula><inline-graphic xlink:href="cyto0087-0212-mu9.jpg" mimetype="image"/></inline-formula>. We call <italic>W</italic> a weight-map and a distribution created using <italic>W</italic> a weighted distribution. New coordinate pairs are drawn until a specified number of coordinates have been accepted. This approach is simple to use and produce good results as long as <italic>W</italic> contains large enough areas with a relatively high probability score. For weight-maps, where all positions have a low probability the algorithm will take a long time to execute as the rejection rate will be high. However, with proper understanding of the method's limitations the approach works exceedingly well.</p><p>The addition of <italic>W</italic> gives us the ability to control how generated objects are distributed over an image. There are many benefits to this approach. The weight-map allows us to both customize the distribution, perhaps in an attempt to match the distribution of a specific sample image, and create random distributions with certain characteristics, for example, single cluster, multiple clusters, or perhaps a swath of material across the image. Examples of weighted distributions can be seen in <xref ref-type="fig" rid="fig08">Figure 8</xref>. In our present study, we have only used these possibilities to a limited extent generating some simple distribution patterns.</p><fig id="fig08" position="float"><label>Figure 8</label><caption><p>Result of weighted distribution generation. Two weight-maps (top) and their resulting distributions (bottom).</p></caption><graphic xlink:href="cyto0087-0212-f8"/></fig></sec><sec><title>Debris Object Generation</title><p>As has been previously stated, and illustrated in <xref ref-type="fig" rid="fig01">Figure 1</xref>, debris objects are a common problem when developing any kind of analysis algorithm. In the following sections, the types of debris that have been added to the simulation will be described in more detail.</p><sec><title>White blood cells</title><p>White blood cells (WBC), or leukocytes, are a typical indication of an inflammation of the cervix. They usually appear as dark elliptical objects, often clustered together in small groups spread over the image. In the case of more serious cases of inflammation, larger sheets of WBC can be found, often obscuring significant sections of a sample.</p><p>In <xref ref-type="fig" rid="fig09">Figure 9</xref>, the steps of the WBC phantom generation have been illustrated. The simulation process is divided in two main steps: the creation of each cell and the construction of clusters. For cell shape generation, we have used a parametric model previously used by Lehmussola et al. <xref rid="b4" ref-type="bibr">4</xref>. The shape of a cell is based on the parametric form of a circle, where each coordinate pair is written as<inline-formula><inline-graphic xlink:href="cyto0087-0212-mu10.jpg" mimetype="image"/></inline-formula> and generated by</p><p><disp-formula id="m21"><graphic xlink:href="cyto0087-0212-m21.jpg" mimetype="image" position="float"/></disp-formula></p><p><disp-formula id="m6"><graphic xlink:href="cyto0087-0212-m6.jpg" mimetype="image" position="float"/><label>(6)</label></disp-formula></p><p>where<inline-formula><inline-graphic xlink:href="cyto0087-0212-mu11.jpg" mimetype="image"/></inline-formula> is the polar angle. Perturbations to the vertices of the shape are added by</p><p><disp-formula id="m22"><graphic xlink:href="cyto0087-0212-m22.jpg" mimetype="image" position="float"/></disp-formula></p><p><disp-formula id="m7"><graphic xlink:href="cyto0087-0212-m7.jpg" mimetype="image" position="float"/><label>(7)</label></disp-formula></p><p>for <italic>i</italic>&#x02009;=&#x02009;1, &#x02026;, <italic>K</italic>, where <italic>K</italic> is the number of boundary points,<inline-formula><inline-graphic xlink:href="cyto0087-0212-mu12.jpg" mimetype="image"/></inline-formula> controls the range of values drawn from the uniform distribution and <italic>s</italic> is a scale parameter.</p><fig id="fig09" position="float"><label>Figure 9</label><caption><p>The creation process of leukocyte clusters. (Left) Shapes generated using parametric model. (Middle) Shape masks added to the final cluster. (Right) The final result with added Perlin noise.</p></caption><graphic xlink:href="cyto0087-0212-f9"/></fig><p>To distribute the generated objects in naturally looking clusters, we use the weighted distribution method described in the Population Distribution Generation section with randomly generated weight-maps. Finally, the leukocyte phantoms are textured using the common Perlin noise model <xref rid="b32" ref-type="bibr">32</xref>.</p></sec><sec><title>Bacilli</title><p>Bacilli are a fairly common occurrence in Pap-smear images, the most common kind being the Lactobacilli, or, as it is also known, D&#x000f6;derlein's vaginal bacillus <xref rid="b33" ref-type="bibr">33</xref>. They appear as simple, single line structures, and always in clusters of varying size.</p><p>The simulation process for bacilli generation starts with the generation of randomly oriented short binary lines. These line segments are then clustered in the same way as described for the WBC generation in the end of White Blood Cells section.</p></sec><sec><title>Speckles</title><p>We will define speckles as point noise that is distributed in a uniform way across an image. The cause of a single speckle can vary, with common sources being dust, glass impurities, stain particles, or other small biological objects. Regardless of the source, however, they are very similar in their appearance and can thus be grouped together as a single type of simulation. The base speckle is created as a single pixel that is then extended one pixel in a random direction. Depending on the size of speckles that is required for a specific simulation this shape can then be made bigger using binary dilation <xref rid="b3" ref-type="bibr">3</xref>.</p></sec><sec><title>Out of focus objects</title><p>It is common for images taken of Pap-smears to contain objects that lie well outside the current focus plane. The source of these objects varies. Sometimes it is biological material such as cells, WBC clusters or mucus. Other times, the cause is dirt on the cover glass of the samples or air bubbles in the fixation liquid. These artifacts can take on many forms, and it is an ambitious task to try to simulate all of them. However, because they generally are placed so far outside the focus plane, their appearance is very blurred. To that end, we have created an out of focus (OOF) debris group where an object is created using the same parametric model and textured the same way as the WBC described in White Blood Cells section. These objects are then taken to be placed at a focus plane well outside the defined space and blurred accordingly (see Impulse response section).</p></sec></sec><sec><title>Signal Transmission</title><p>The second phase of the image synthesis process is the simulation of light as it travels through the sample to the detector. Three primary factors of this problem have been considered for this project; background illumination specifications, how individual objects absorb the light, and finally the approximation of the impulse response function in three dimensions.</p><sec><title>Background illumination</title><p>Under perfect circumstances the background illumination should be a uniform function. This, however, is rarely the case. The most common kind of aberration for bright-field microscopy is uneven illumination, a low frequency light intensity variation over the field-of-view. Furthermore, for bright-field microscopy the light path has to pass through a glass slide. This will generate aberrations caused by the optical properties of glass as well as by scratches and dirt on the surface. To simulate these phenomena, two principal degradation steps have been added to the background generation process.</p><p>The uneven illumination is simulated by calculating a distance transform, <italic>I<sub>d</sub></italic>(<italic>x</italic>, <italic>y</italic>), initialized from the edge of the image. We scale the distance transform to [0,1] and add an exponent, <italic>I<sub>d</sub></italic>(<italic>x</italic>, <italic>y</italic>)<italic><sup>n</sup></italic>. The background is initialized as a uniform image, <italic>H</italic>(<italic>x</italic>, <italic>y</italic>), with a predefined intensity, <italic>H</italic>(<italic>x</italic>, <italic>y</italic>)&#x02009;=&#x02009;<italic>b</italic>. The perturbed background illumination can then be written as</p><p><disp-formula id="m8"><graphic xlink:href="cyto0087-0212-m8.jpg" mimetype="image" position="float"/><label>(8)</label></disp-formula></p><p>where the exponent, <italic>n</italic>, controls the strength of the variation. We can now add the second type of aberration which is related to light scattering in the slide. To simulate these effects, we have chosen to use a Perlin noise image, <italic>I<sub>pe</sub></italic>(<italic>x</italic>, <italic>y</italic>): [0,1], together with a constant, <italic>c<sub>pe</sub></italic>, that controls the strength of the variations. Perlin noise is a computationally efficient way of generating correlated noise <xref rid="b32" ref-type="bibr">32</xref>. It is commonly used in computer graphics to generate natural looking textures. It is not directly based on any physical model of light transport, but the results are visually similar to that caused by the light scattering effects.</p><p>The Perlin noise variations are added to the background illumination as</p><p><disp-formula id="m9"><graphic xlink:href="cyto0087-0212-m9.jpg" mimetype="image" position="float"/><label>(9)</label></disp-formula></p><p>The final step of the background generation is to calculate the logarithm of the generated image</p><p><disp-formula id="m10"><graphic xlink:href="cyto0087-0212-m10.jpg" mimetype="image" position="float"/><label>(10)</label></disp-formula></p><p>This is done to facilitate the use of absorbance values, as will be explained in the following section.</p></sec><sec><title>Absorbance</title><p>In bright-field microscopy an object's color is related to its light absorption properties. This behavior can be described using the well known Beer&#x02013;Lambert law <xref rid="b34" ref-type="bibr">34</xref>, which states that</p><p><disp-formula id="m11"><graphic xlink:href="cyto0087-0212-m11.jpg" mimetype="image" position="float"/><label>(11)</label></disp-formula></p><p>where <italic>A<sub>&#x003bb;</sub></italic> is the material's absorbance at a specific wavelength, <italic>&#x003bb;</italic>, of incoming light, <italic>I</italic><sub>0</sub> is the intensity of the light before it passes through the sample, and <italic>I</italic><sub>1</sub> is the intensity of light that remains after passing through the sample. Essentially, for the Pap-smear application, the Beer&#x02013;Lambert law relates the absorbance of the Pap-stain to its concentration</p><p><disp-formula id="m12"><graphic xlink:href="cyto0087-0212-m12.jpg" mimetype="image" position="float"/><label>(12)</label></disp-formula></p><p>where <italic>k</italic> is a constant commonly referred to as the extinction coefficient (a characteristic of the dye), <italic>c</italic> is the concentration of the dye, and <italic>l</italic> is the length of the light path.</p><p>For the simulation, each object type is given a specific absorbance value. These values can be directly based on measurements taken from source materials or selected based on a specific desired target appearance. In this project, we measured representative values from our cellular database.</p></sec><sec><title>Impulse response</title><p>The shape of the PSF for a specific bright-field microscopy setup is dependent on the NA of the objective used, the refractive index of the medium between the sample and the objective lens and the wavelength, <italic>&#x003bb;</italic>, of the image forming light <xref rid="b6" ref-type="bibr">6</xref>. Trying to mathematically determine the precise degenerative effects of the PSF for specific hardware specifications can be exceedingly difficult. For this study, we have instead chosen to simplify the process by approximating the impulse response function with a Gaussian function, <italic>G<sub>&#x003c3;</sub></italic>. Furthermore, for simplicity and speed, we have elected to separate the blurring process into a depth of focus blurring, <italic>G</italic><sub>&#x00394;</sub><italic><sub>z</sub></italic>, and an image plane blurring, <italic>G</italic><sub>&#x00394;</sub><italic><sub>x</sub></italic><sub>,</sub><italic><sub>y</sub></italic>.</p><p>Because of the availability of focus stacks as reference data, we have been able to quantifiably determine a suitable standard deviation for the Gaussian kernel related to the depth of focus. This was achieved by first studying a nucleus at the focus level at which it is in focus. This level was determined by summing the gradient magnitude values within the cell nuclei for all focus levels and choosing the level with the greatest sum. We can then compare each offset step in the focus stack to a Gaussian blurred version of the focused image, allowing us to decide which sigma yields a degradation that lies closest to the observed one. The quantification is achieved by taking the sum of the intensity difference for each pixel of the nucleus. In <xref ref-type="fig" rid="fig10">Figure 10</xref>, a plot showing the optimal ratio <italic>&#x003c3;</italic>/&#x000b5;m, relative to each focus level offset can be seen for a sample cell. The same experiment was carried out for a representative population of 10 different cells. For small focus offsets, it is, due to discretization issues, hard to get reliable measurements. However, for offsets &#x0003e;1 &#x000b5;m it becomes apparent that a reasonable approximation of the impulse response in the <italic>z</italic>-direction is<inline-formula><inline-graphic xlink:href="cyto0087-0212-mu13.jpg" mimetype="image"/></inline-formula>, where <italic>d<sub>z</sub></italic> is the <italic>z</italic>-offset in &#x000b5;m.</p><fig id="fig10" position="float"><label>Figure 10</label><caption><p>(Top) Nucleus at its focus level (Left) and its actual degeneration at a 1.2-&#x000b5;m offset (Middle image), compared to a Gaussian degeneration with <italic>&#x003c3;</italic>&#x02009;=&#x02009;1.2 (Right image). (Bottom) Plot discerning optimal ratio for <italic>&#x003c3;</italic> relative to the <italic>z</italic>-offset (&#x003bc;m) as a function of the <italic>z</italic>-offset for specific offsets.</p></caption><graphic xlink:href="cyto0087-0212-f10"/></fig><p>The impulse response in the image plane is more difficult to approximate quantifiably. Generally, the PSF is smaller in the <italic>x-y</italic> dimension relative to the <italic>z</italic>-dimension,<inline-formula><inline-graphic xlink:href="cyto0087-0212-mu14.jpg" mimetype="image"/></inline-formula>. By taking an image depicting a step function, that is, a sharp edge, and studying the first derivative of that image, it is possible to obtain an approximation of the PSF that lies close to reality. The measured PSF can then be compared to Gaussian kernels with different sigma to find the closest match. Using this approach, a suitable value for <italic>&#x003c3;<sub>x</sub><sub>,</sub><sub>y</sub></italic> for the model system used in this project was found to be 0.9 pixels corresponding to around 0.22 microns.</p></sec></sec><sec><title>Signal Detection and Digitalization</title><p>The most commonly used type of imaging sensor within microscopy is the charged coupled device (CCD) sensor. These sensors operate using a linear transfer function, that is, the output signal for each pixel is proportional to the number of photons it receives. Optical imaging sensors have, as has been previously stated, certain limitations. The dominant source of noise in sensors, known as photon noise, is related to the fact that the number of photons emitted from a constant light source over a finite time interval is stochastic. Under normal operating conditions, this noise is Poisson distributed and quite easy to simulate. A second type of sensor noise significant enough to be added to the simulation is called readout noise that is a product of phenomena related to the A/D converter and amplification circuits. This noise behaves as additive white Gaussian noise <xref rid="b35" ref-type="bibr">35</xref>.</p></sec><sec><title>Final Image Formation</title><p>The formation of the final simulated image, <italic>I<sub>f</sub></italic>, can be written as</p><p><disp-formula id="m13"><graphic xlink:href="cyto0087-0212-m13.jpg" mimetype="image" position="float"/><label>(13)</label></disp-formula></p><p>where<inline-formula><inline-graphic xlink:href="cyto0087-0212-mu15.jpg" mimetype="image"/></inline-formula> and<inline-formula><inline-graphic xlink:href="cyto0087-0212-mu16.jpg" mimetype="image"/></inline-formula> constitute the addition of Poisson and Gaussian noise, respectively, (*) denotes a convolution operation,<inline-formula><inline-graphic xlink:href="cyto0087-0212-mu17.jpg" mimetype="image"/></inline-formula> stands for the approximation of the PSF with a Gaussian kernel with sigma<inline-formula><inline-graphic xlink:href="cyto0087-0212-mu18.jpg" mimetype="image"/></inline-formula>,<inline-formula><inline-graphic xlink:href="cyto0087-0212-mu19.jpg" mimetype="image"/></inline-formula> is the background image generated by Eq. <xref rid="b10" ref-type="bibr">10</xref> and<inline-formula><inline-graphic xlink:href="cyto0087-0212-mu20.jpg" mimetype="image"/></inline-formula> is a phantom image. The phantom image contains the set of <italic>N<sub>p</sub></italic> phantom objects,<inline-formula><inline-graphic xlink:href="cyto0087-0212-mu21.jpg" mimetype="image"/></inline-formula>. To simulate the depth of field, each object, <italic>p<sub>i</sub></italic>, is assigned a <italic>z</italic> position, <italic>z<sub>i</sub></italic>, using a median filtered Perlin noise image, scaled to encompass the desired depth in the image. The generation of the phantom image can then be written as a sum of phantom objects with appropriate amounts of out-of-focus blur,</p><p><disp-formula id="m14"><graphic xlink:href="cyto0087-0212-m14.jpg" mimetype="image" position="float"/><label>(14)</label></disp-formula></p><p>The final step of the synthesis process is to remove some of the degenerative effects applied to the parts of the image displaying nucleus texture. Because the nucleus texture is a product of patch-based texture generation from source material, the texture has actually already been subjected to the degenerative effects of the optics and the sensor system. Therefore, the final image, <italic>I<sub>f</sub></italic>(<italic>x</italic>, <italic>y</italic>) is updated according to</p><p><disp-formula id="m15"><graphic xlink:href="cyto0087-0212-m15.jpg" mimetype="image" position="float"/><label>(15)</label></disp-formula></p><p>where<inline-formula><inline-graphic xlink:href="cyto0087-0212-mu22.jpg" mimetype="image"/></inline-formula> is a feathered nucleus mask generated as</p><p><disp-formula id="m23"><graphic xlink:href="cyto0087-0212-m23.jpg" mimetype="image" position="float"/></disp-formula></p><p><disp-formula id="m16"><graphic xlink:href="cyto0087-0212-m16.jpg" mimetype="image" position="float"/><label>(16)</label></disp-formula></p><p>The feathering, or blurring, of the nucleus mask,<inline-formula><inline-graphic xlink:href="cyto0087-0212-mu23.jpg" mimetype="image"/></inline-formula>, prevents the creation of sharp, unnatural edges around the nucleus texture.</p></sec></sec><sec><title>E<sc>valuation</sc></title><p>The quality and realism of the synthetic images which are generated through the described procedure needs to be evaluated. As we are generating images that can be visually inspected, a natural approach is to do a visual comparison between synthetic and real images. This approach also seems relevant since the most common way of analyzing Pap-test specimens is through visual inspection. In designing such a test, it becomes important to have realistic conditions for the visual inspection. Given unlimited time and the possibility of zooming and scrolling the images, it is in most cases possible to find out which image is real and which is synthetic. But, this is far from the conditions under which this kind of images normally are scrutinized.</p><p>We have, therefore, designed a customized evaluation test. The experimental design was inspired by a study devised by Meyer et al. <xref rid="b36" ref-type="bibr">36</xref>. In that study, users were asked to compare a real scene to an identical computer generated one. For the experiment, the subject was showed a tightly cropped view of the real and synthetic scene projected through a lightly frosted glass, to account for limitations of existing display devices. For our validation study, a simple user interface was designed. A patch of size 200 &#x000d7; 200 pixels, randomly selected, was cut out from an image that in turn was randomly selected from a database of images containing 25 synthetic images created with varying settings and 25 real images from different specimen. Before showing the image to the user, a pixel-wise Gaussian noise (<italic>&#x003c3;</italic>&#x02009;=&#x02009;0.7 graylevels) was added. This was done to make the variations in background intensity and smoothness between different real images less visually disturbing, making it easier to focus on the details in the images. The patch was shown to the test subject for 2 s, after which a nontimed prompt for an answer was displayed. In total, 120 patches were displayed to each user. However, the first two patches were training images used to get the user comfortable with the validation system and are not counted in the final result. The outcome of this study is discussed in Results section.</p><p>Another approach to evaluating the quality of the synthetic image generation algorithms, is to compare results from an automated image cytometry algorithm applied to synthetic images and real data with expert annotated ground truth <xref rid="b4" ref-type="bibr">4</xref>. Other validation approaches have included comparing results for several image cytometry tools when used on synthetic images <xref rid="b4" ref-type="bibr">4</xref> or comparing scores for different image descriptive features from synthetic and real images <xref rid="b12" ref-type="bibr">12</xref>.</p><p>Such tests can give valuable evaluations of whether the feature distributions obtained from the synthetic images are the same as those obtained from real ones. There are, however, problems in that many aspects of the synthetic images are generated from feature distributions extracted from real images. So, for many simple features such as nuclear size, we can obtain perfect agreement between normal and synthetic distributions. Another issue is the fact that manually obtaining a suitable ground truth dataset is, as has previously been discussed, a far from trivial task paired with many difficulties. We have as a complement to the visual evaluation made a comparison of the distribution of one nontrivial feature, the moments of the nuclear texture distribution. The choice is motivated by the fact that from a diagnostic perspective, the key structures in Pap-smear images are the nuclei and their chromatin structure. Following the approach taken by Svoboda et al. <xref rid="b5" ref-type="bibr">5</xref>, a number of central moments as well as an entropy score was calculated for several real and synthetic nuclei. The <italic>n</italic> th central moment is calculated as</p><p><disp-formula id="m17"><graphic xlink:href="cyto0087-0212-m17.jpg" mimetype="image" position="float"/><label>(17)</label></disp-formula></p><p>where</p><p><disp-formula id="m18"><graphic xlink:href="cyto0087-0212-m18.jpg" mimetype="image" position="float"/><label>(18)</label></disp-formula></p><p>Here, <italic>z<sub>i</sub></italic> is a discrete random variable denoting the particular intensity level present in the image. The sum covers the range of all the image intensity levels (<italic>L</italic>). The entropy defines the amount of uncertainty in the measured data and is calculated as</p><p><disp-formula id="m19"><graphic xlink:href="cyto0087-0212-m19.jpg" mimetype="image" position="float"/><label>(19)</label></disp-formula></p><p>Five central moments, <italic>n</italic> =2,&#x02026;,6, as well as the entropy was calculated for a sample of 30 nuclei from real images and an equal number from synthetic images. From this, individual quantile-quantile (Q-Q) plots have been generated for each feature (<xref ref-type="fig" rid="fig11">Fig. 11</xref>). A Q-Q plot is a probability plot that compares two distributions by plotting their quantiles against each other <xref rid="b37" ref-type="bibr">37</xref>. If the compared populations are drawn from similar distributions, the points should have an approximately linear relation.</p><fig id="fig11" position="float"><label>Figure 11</label><caption><p>Quantile-quantile plot comparison of descriptors computed from real and synthetic cervical cell nuclei. The quantile-quantile plot illustrate whether the acquired measurements belong to the same distribution. A linear relationship indicates that points belong to the same probability distribution. When the trend is steeper than 45 degrees, which is the case in the plots above, it is an indication that the data plotted on the <italic>y</italic>-axis, which refers to real data in this figure, has a larger dispersion than the <italic>x</italic>-axis data. The descriptors shown above are: (Top row, left to right) second central moment, third central moment, and fourth central moment. (Bottom row, left to right) Fifth central moment, sixth central moment, and entropy. [Color figure can be viewed in the online issue, which is available at <ext-link ext-link-type="uri" xlink:href="http://wileyonlinelibrary.com">http://wileyonlinelibrary.com</ext-link>.]</p></caption><graphic xlink:href="cyto0087-0212-f11"/></fig></sec><sec sec-type="results"><title>R<sc>esults</sc></title><p>An example of a finished synthetic image compared to a real image can be seen in <xref ref-type="fig" rid="fig12">Figure 12</xref>. The results of the visual evaluation can be seen in Table<xref ref-type="table" rid="tbl1">1</xref>. Six test subjects have been used for the evaluation. The first <xref rid="b1" ref-type="bibr">1</xref> test subject is a cytologist with over 30 year experience of cervical smear screening. Test subjects 2&#x02013;5 are cytometry algorithm developers with several year experiences from developing methods for automated Pap-smear analysis. The last test subject <xref rid="b6" ref-type="bibr">6</xref> is an algorithm developer with experience in life-science applications. This person had no experience with cytometry images and was included as a reference. Also for reference purposes, a random result subject (<italic>x</italic>) has been added to the result. For all subjects, the test was the first time they came into contact with the image generation method described in this article. All the subjects had prior experience with observing Pap-smear images in grayscale. For each user the number of true positives (TP), false positives (FP), true negatives (TN), and false negatives (FN) were counted. For this evaluation, a real image was counted as a positive and a synthetic image as a negative. Based on these values, the sensitivity, TP/(TP+FN), and specificity, TN/(TN+FP), for each user was also calculated. In this setting, the sensitivity value relates to the ability to accurately detect real images as being real and the specificity the ability to accurately detect synthetic images as synthetic. The sensitivity for the six human test subjects is not consistent with a random result (Mean: 0.7667, 95% confidence interval [0.671, 0.863]), but it is still low enough to indicate that experienced individuals had a difficult time separating real images from synthetic ones under these experimental conditions. The random assignment, &#x0201c;subject <italic>x</italic>,&#x0201d; achieved almost as good results as the actual persons, it deviated somewhat from the expected 0.50 in sensitivity and specificity as the population size was rather small. A different experimental design may have given different results. It is usually possible to tell the difference if you are given unlimited time and can zoom and scroll the image arbitrarily. But in routine cytology screening, the time available for this analysis is extremely limited so our conclusion is that our synthetic images are visually quite similar to real ones when studied under realistic conditions.</p><fig id="fig12" position="float"><label>Figure 12</label><caption><p>An example of a finished synthetic image (Left) an a real image for comparison (Right).</p></caption><graphic xlink:href="cyto0087-0212-f12"/></fig><table-wrap id="tbl1" position="float"><label>Table 1</label><caption><p>Results of evaluation of the generated synthetic images</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="1" colspan="1">Subject</th><th align="left" rowspan="1" colspan="1">TP</th><th align="left" rowspan="1" colspan="1">FP</th><th align="left" rowspan="1" colspan="1">TN</th><th align="left" rowspan="1" colspan="1">FN</th><th align="left" rowspan="1" colspan="1">Sens.</th><th align="left" rowspan="1" colspan="1">Spec.</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">1</td><td align="left" rowspan="1" colspan="1">35</td><td align="left" rowspan="1" colspan="1">29</td><td align="left" rowspan="1" colspan="1">37</td><td align="left" rowspan="1" colspan="1">17</td><td align="left" rowspan="1" colspan="1">0.67</td><td align="left" rowspan="1" colspan="1">0.56</td></tr><tr><td align="left" rowspan="1" colspan="1">2</td><td align="left" rowspan="1" colspan="1">39</td><td align="left" rowspan="1" colspan="1">29</td><td align="left" rowspan="1" colspan="1">29</td><td align="left" rowspan="1" colspan="1">21</td><td align="left" rowspan="1" colspan="1">0.65</td><td align="left" rowspan="1" colspan="1">0.50</td></tr><tr><td align="left" rowspan="1" colspan="1">3</td><td align="left" rowspan="1" colspan="1">50</td><td align="left" rowspan="1" colspan="1">16</td><td align="left" rowspan="1" colspan="1">38</td><td align="left" rowspan="1" colspan="1">14</td><td align="left" rowspan="1" colspan="1">0.78</td><td align="left" rowspan="1" colspan="1">0.70</td></tr><tr><td align="left" rowspan="1" colspan="1">4</td><td align="left" rowspan="1" colspan="1">49</td><td align="left" rowspan="1" colspan="1">20</td><td align="left" rowspan="1" colspan="1">36</td><td align="left" rowspan="1" colspan="1">13</td><td align="left" rowspan="1" colspan="1">0.79</td><td align="left" rowspan="1" colspan="1">0.64</td></tr><tr><td align="left" rowspan="1" colspan="1">5</td><td align="left" rowspan="1" colspan="1">51</td><td align="left" rowspan="1" colspan="1">17</td><td align="left" rowspan="1" colspan="1">39</td><td align="left" rowspan="1" colspan="1">11</td><td align="left" rowspan="1" colspan="1">0.82</td><td align="left" rowspan="1" colspan="1">0.70</td></tr><tr><td align="left" rowspan="1" colspan="1">6</td><td align="left" rowspan="1" colspan="1">58</td><td align="left" rowspan="1" colspan="1">32</td><td align="left" rowspan="1" colspan="1">21</td><td align="left" rowspan="1" colspan="1">7</td><td align="left" rowspan="1" colspan="1">0.89</td><td align="left" rowspan="1" colspan="1">0.40</td></tr><tr><td align="left" rowspan="1" colspan="1"><italic>x</italic></td><td align="left" rowspan="1" colspan="1"><italic>37</italic></td><td align="left" rowspan="1" colspan="1"><italic>31</italic></td><td align="left" rowspan="1" colspan="1"><italic>24</italic></td><td align="left" rowspan="1" colspan="1"><italic>26</italic></td><td align="left" rowspan="1" colspan="1"><italic>0.54</italic></td><td align="left" rowspan="1" colspan="1"><italic>0.48</italic></td></tr></tbody></table><table-wrap-foot><fn id="n1"><p>Results are shown for the six test subjects <xref rid="b1" ref-type="bibr">1</xref>&#x02013;<xref rid="b6" ref-type="bibr">6</xref> and a random result (<italic>x</italic>). The results show the number of true positives (TP), the number of false positives (FP), the number of true negatives (TN), and the number of false negatives (FN). From these numbers, the sensitivity TP/(TP+FN) and specificity TN/(TN+FP) have also been calculated.</p></fn></table-wrap-foot></table-wrap><p>The Q-Q plot in <xref ref-type="fig" rid="fig11">Figure 11</xref> show a distinct linear relationship between the synthetic and real nuclei for all features, indicating that, as is expected, the two populations are drawn from similar distributions. However, the angle of the linear dependency shows that the real data have a wider distribution than the synthetic data. This, again, is not surprising as each synthetic nucleus texture represents a combination of data from three real nuclei. The choice of using three nuclei as a sampling base stems from an effort to make the texture of the synthetic nuclei more general and not a scrambled copy of a single. This had the side effect of making the variation in the synthesized textures somewhat smaller than in the real ones. This effect would be reduced if we used a single real nucleus as a model for the texture of a synthetic one.</p><p>We have generated a small population of synthetic images and also picked an equal number of real images and cropped those to the same size as the synthetic ones and supplied these two image datasets as Supporting Information allowing the reader to evaluate the similarities and differences between the images. These images can be found as a Supporting Information.</p></sec><sec sec-type="discussion"><title>D<sc>iscussion</sc></title><p>In this article, we present a synthetic image generation framework for simulating bright-field microscopy images of cervical cell populations. The simulation method accurately models object primitives as well as the characteristics and behavior of the measurement system. In our evaluation study, even experienced cytology professionals showed rather poor performance in deciding whether an image was synthetic or real when shown the images under realistic screening conditions. A simple test on nuclear texture features indicated that they came from similar distributions.</p><p>The presented framework offers a flexible approach to image synthesis. Each block of the process is interchangeable depending on the requirements on the finished results. Furthermore, if needed, additional object types can be added with minimal effort using the methods and principles described in this article. As an example, the addition of other common cervical epithelial cell types, for example, parabasal cells or squamous superficial cells, can be achieved by creating small databases of primitives that can then be used as the basis for shape and texture generation. To illustrate this, a dataset of cells, expert classified to exhibit signs conforming to high grade intraepithelial lesions, were collected and added to the simulation pipeline. A resulting image can be seen in <xref ref-type="fig" rid="fig13">Figure 13</xref>. This flexibility indicates that the synthesis process could be adapted to mimic other types of cellular material commonly analyzed using bright-field microscopy, for example, lung or oral cavity smears.</p><fig id="fig13" position="float"><label>Figure 13</label><caption><p>Example of two simulated cells corresponding to high grade lesions added to the simulation framework.</p></caption><graphic xlink:href="cyto0087-0212-f13"/></fig><p>For the time being, the method produces one diagnostic cell type (squamous intermediate) and four levels of debris. In the future, more cell types and other types of debris should be added. Also, other common types of distortion such as folding should be included to the cytoplasm model to add even more variety in the shapes that are produced. The greatest benefit with the use of simulated images is the availability of ground truth. Using simulated images reduces the dependency on manually generated ground-truth data, which has the drawback of being expensive and time consuming to produce. Well-designed synthetic images make it possible to reserve that valuable ground truth data for final control validation. For instance, first the endless supply of synthetic data can be used to form hypotheses about how varying amount of debris or inhomogeneous background illumination will affect the qualitative performance of a segmentation algorithm. Then brute force parameter tuning, over an arbitrary large parameter space, can point out optimal parameters, a plausible range of optimal parameters or relations and dependence between different optimal parameter settings from which the algorithm designer can gain insight and form hypotheses. Then finally, a rigorous and more data economical procedure can be used for fine tuning and cross-validation on expert annotated real data to estimate the performance of an algorithm on real life data.</p><p>It is important to recognize the fact that, while synthetic images can function as a great development tool, problems such as overfitting need to be taken into account. Because synthetic images are the result of their defining parameters, there exists a limitation in the variation present in the images. Good design can, to a certain extent, alleviate the problem, but the fact remains that real data remains a necessity in the creation of any image processing algorithm aimed at real world applications. However, one can compare the risk of overfitting synthetic data with the risks of overfitting when tuning algorithms with the help of small amounts of real ground truth data. We can benefit from the great flexibility of synthetic data, while at the same time guarantee an estimate on real data if proper cross-validation is performed for the final parameter tuning using real expert annotated data.</p></sec><sec><title>A<sc>vailability</sc></title><p>The synthesis framework described in this article is available on the MATLAB file-exchange, at <ext-link ext-link-type="uri" xlink:href="http://www.mathworks.com/matlabcentral/fileexchange/48915-synthetic-bright-field-microscopy-image-generator">http://www.mathworks.com/matlabcentral/fileexchange/48915-synthetic-bright-field-microscopy-image-generator</ext-link>, as an open-source code package on publication acceptance.</p></sec></body><back><ack><p>The authors would like to thank the participants of the user study. The work was carried out within the framework of a collaboration with a research project at the Center for Advanced Computing in Thiruvananthapuram headed by Rajesh Kumar and the Regional Cancer Center, Kerala, India, headed by Dr K Sujathan, funded by the Department of Information Technology, Government of India. Ethical permit for using stained Pap smears was obtained from Indian Council of Medical Research, permit number INDO/FRC/402/2005-IHD. Funding was also provided by the Swedish Research Council (2008-2738) and VINNOVA (2008-01712).</p></ack><ref-list><title>L<sc>iterature</sc> C<sc>ited</sc></title><ref id="b1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>W&#x000e4;hlby</surname><given-names>C</given-names></name><name><surname>Kamentsky</surname><given-names>L</given-names></name><name><surname>Liu</surname><given-names>ZH</given-names></name><name><surname>Riklin-Raviv</surname><given-names>T</given-names></name><name><surname>Conery</surname><given-names>AL</given-names></name><name><surname>O'Rourke</surname><given-names>EJ</given-names></name><name><surname>Sokolnicki</surname><given-names>KL</given-names></name><name><surname>Visvikis</surname><given-names>O</given-names></name><name><surname>Ljosa</surname><given-names>V</given-names></name><name><surname>Irazoqui</surname><given-names>JE</given-names></name><name><surname>Golland</surname><given-names>P</given-names></name><name><surname>Ruvkun</surname><given-names>G</given-names></name><name><surname>Ausubel</surname><given-names>FM</given-names></name><name><surname>Carpenter</surname><given-names>AE</given-names></name></person-group><article-title>An image analysis toolbox for high-throughput C. elegans assays</article-title><source>Nat Methods</source><year>2012</year><volume>9</volume><fpage>714</fpage><lpage>716</lpage><pub-id pub-id-type="pmid">22522656</pub-id></element-citation></ref><ref id="b2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bengtsson</surname><given-names>E</given-names></name><name><surname>Malm</surname><given-names>P</given-names></name></person-group><article-title>Screening for cervical cancer using automated analysis of PAP-smears</article-title><source>Comput Math Methods Med</source><year>2014</year><volume>12</volume></element-citation></ref><ref id="b3"><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Gonzalez</surname><given-names>RC</given-names></name><name><surname>Woods</surname><given-names>ER</given-names></name></person-group><year>2008</year><comment>Upper Saddle River, NJ Digital Image Processing, 3rd ed.: Pearson Education</comment></element-citation></ref><ref id="b4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lehmussola</surname><given-names>A</given-names></name><name><surname>Ruusuvuori</surname><given-names>P</given-names></name><name><surname>Selinummi</surname><given-names>J</given-names></name><name><surname>Huttunen</surname><given-names>H</given-names></name><name><surname>Yli-Harja</surname><given-names>O</given-names></name></person-group><article-title>Computational framework for simulating fluorescence microscope images with cell populations</article-title><source>IEEE Trans Med Imaging</source><year>2007</year><volume>26</volume><fpage>1010</fpage><lpage>1016</lpage><pub-id pub-id-type="pmid">17649914</pub-id></element-citation></ref><ref id="b5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Svoboda</surname><given-names>D</given-names></name><name><surname>Kozubek</surname><given-names>M</given-names></name><name><surname>Stejskal</surname><given-names>S</given-names></name></person-group><article-title>Generation of digital phantoms of cell nuclei and simulation of image formation in 3D image cytometry</article-title><source>Cytometry Part A</source><year>2009</year><volume>75A</volume><fpage>494</fpage><lpage>509</lpage></element-citation></ref><ref id="b6"><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Ellenberger</surname><given-names>SL</given-names></name></person-group><year>2000</year><comment>CN Delft, Netherlands Delft University of Technology Influence of defocus on measurements in microscope images</comment></element-citation></ref><ref id="b7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Webb</surname><given-names>D</given-names></name><name><surname>Hamilton</surname><given-names>MA</given-names></name><name><surname>Harkin</surname><given-names>GJ</given-names></name><name><surname>Lawrence</surname><given-names>S</given-names></name><name><surname>Camper</surname><given-names>AK</given-names></name><name><surname>Lewandowski</surname><given-names>Z</given-names></name></person-group><article-title>Assessing technician effects when extracting quantities from microscope images</article-title><source>J Microbiol Methods</source><year>2003</year><volume>53</volume><fpage>97</fpage><lpage>106</lpage><pub-id pub-id-type="pmid">12609728</pub-id></element-citation></ref><ref id="b8"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Malm</surname><given-names>P</given-names></name><name><surname>Brun</surname><given-names>A</given-names></name><name><surname>Bengtsson</surname><given-names>E</given-names></name></person-group><source>PAPSYNTH: Simulated bright-field images of cervical smears. In: IEEE International Symposium on Biomedical Imaging: From Nano to Macro</source><year>2010</year><publisher-loc>Rotterdam, Netherlands</publisher-loc><comment>IEEE xplore</comment></element-citation></ref><ref id="b9"><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Ruusuvuori</surname><given-names>P</given-names></name><name><surname>Lehmussola</surname><given-names>A</given-names></name><name><surname>Selinummi</surname><given-names>J</given-names></name><name><surname>Rajala</surname><given-names>T</given-names></name><name><surname>Huttunen</surname><given-names>H</given-names></name><name><surname>Yli-Harja</surname><given-names>O</given-names></name></person-group><year>2008</year><comment>Benchmark set of synthetic images for validating cell image analysis algorithms. In: Proceedings of the 16th European Signal Processing Conference, Lausanne, Switzerland</comment></element-citation></ref><ref id="b10"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Svoboda</surname><given-names>D</given-names></name><name><surname>Kasik</surname><given-names>M</given-names></name><name><surname>Maska</surname><given-names>M</given-names></name><name><surname>Hubeny</surname><given-names>J</given-names></name><name><surname>Stejskal</surname><given-names>S</given-names></name><name><surname>Zimmermann</surname><given-names>M</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Kropatsch</surname><given-names>W</given-names></name><name><surname>Kampel</surname><given-names>M</given-names></name><name><surname>Hanbury</surname><given-names>A</given-names></name></person-group><article-title>On simulating 3D fluorescent microscope images</article-title><source>Computer Analysis of Images and Patterns</source><year>2007</year><publisher-loc>Berlin Heidelberg</publisher-loc><publisher-name>Springer</publisher-name><fpage>309</fpage><lpage>316</lpage><comment>In:, editors.. Volume 4673 of Lecture Notes in Computer Science</comment></element-citation></ref><ref id="b11"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Svoboda</surname><given-names>D</given-names></name><name><surname>Ulman</surname><given-names>V</given-names></name></person-group><person-group person-group-type="author"><name><surname>Campilho</surname><given-names>A</given-names></name><name><surname>Kamel</surname><given-names>M</given-names></name></person-group><article-title>Generation of synthetic image datasets for time-lapse fluorescence microscopy</article-title><source>Image Analysis and Recognition</source><year>2012</year><publisher-loc>Berlin Heidelberg</publisher-loc><publisher-name>Springer</publisher-name><fpage>473</fpage><lpage>482</lpage><comment>In:, editors.. Volume 7325 of Lecture Notes in Computer Science</comment></element-citation></ref><ref id="b12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname><given-names>T</given-names></name><name><surname>Murphy</surname><given-names>RF</given-names></name></person-group><article-title>Automated learning of generative models for subcellular location: Building blocks for systems biology</article-title><source>Cytometry Part A</source><year>2007</year><volume>71A</volume><fpage>978</fpage><lpage>990</lpage></element-citation></ref><ref id="b13"><element-citation publication-type="book"><person-group person-group-type="editor"><name><surname>Grohs</surname><given-names>HK</given-names></name><name><surname>Husain</surname><given-names>OAN</given-names></name></person-group><source>Automated Cervical Cancer Screening</source><year>1994</year><publisher-loc>Tokyo</publisher-loc><publisher-name>IGAKU-SHOIN Medical Publishers, Inc</publisher-name></element-citation></ref><ref id="b14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holmquist</surname><given-names>J</given-names></name><name><surname>Imasoto</surname><given-names>Y</given-names></name><name><surname>Bengtsson</surname><given-names>E</given-names></name><name><surname>Olsen</surname><given-names>B</given-names></name><name><surname>Stenkvist</surname><given-names>B</given-names></name></person-group><article-title>A microspectrophotometric study of Papanicolaou-stained cervical cells as an aid in computerized image processing</article-title><source>J Histochem Cytochem</source><year>1976</year><volume>24</volume><fpage>1218</fpage><lpage>1224</lpage><pub-id pub-id-type="pmid">63509</pub-id></element-citation></ref><ref id="b15"><element-citation publication-type="other"><collab>World Health Organization. Comprehensive cervical cancer control: A guide to essential practice. Department of Reproductive Health and Research and Department of Chronic Diseases and Health Promotion, editor. Geneva WHO Press</collab><year>2006</year></element-citation></ref><ref id="b16"><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Luengo Hendriks</surname><given-names>CL</given-names></name><name><surname>van Vliet</surname><given-names>LJ</given-names></name><name><surname>Rieger</surname><given-names>B</given-names></name><name><surname>van Ginkel</surname><given-names>M</given-names></name></person-group><year>1999</year><comment>DIPimage: A Scientific Image Processing Toolbox for MATLAB. Delft, The Netherlands: Quantitative Imaging Group, Delft University of Technology;. Available at <ext-link ext-link-type="uri" xlink:href="http://www.diplib.org/">http://www.diplib.org/</ext-link>. Accessed on November 15, 2013</comment></element-citation></ref><ref id="b17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grigoryan</surname><given-names>AM</given-names></name><name><surname>Hostetter</surname><given-names>G</given-names></name><name><surname>Kallioniemi</surname><given-names>O</given-names></name><name><surname>Dougherty</surname><given-names>ER</given-names></name></person-group><article-title>Simulation toolbox for 3D-FISH spot-counting algorithms</article-title><source>Real Time Imaging</source><year>2002</year><volume>8</volume><fpage>203</fpage><lpage>212</lpage></element-citation></ref><ref id="b18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Graner</surname><given-names>F</given-names></name><name><surname>Glazier</surname><given-names>JA</given-names></name></person-group><article-title>Simulation of biological cell sorting using a two-dimensional extended Potts model</article-title><source>Phys Rev Lett</source><year>1992</year><volume>69</volume><fpage>2013</fpage><lpage>2016</lpage><pub-id pub-id-type="pmid">10046374</pub-id></element-citation></ref><ref id="b19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kozubek</surname><given-names>M</given-names></name><name><surname>Matula</surname><given-names>P</given-names></name></person-group><article-title>An effcient algorithm for measurement and correction of chromatic aberrations in fluorescence microscopy</article-title><source>J Microsc</source><year>2000</year><volume>200</volume><fpage>206</fpage><lpage>217</lpage><pub-id pub-id-type="pmid">11106961</pub-id></element-citation></ref><ref id="b20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lockett</surname><given-names>SJ</given-names></name><name><surname>Sudar</surname><given-names>D</given-names></name><name><surname>Thompson</surname><given-names>CT</given-names></name><name><surname>Pinkel</surname><given-names>D</given-names></name><name><surname>Gray</surname><given-names>JW</given-names></name></person-group><article-title>Effcient, interactive, and three-dimensional segmentation of cell nuclei in thick tissue sections</article-title><source>Cytometry</source><year>1998</year><volume>31</volume><fpage>275</fpage><lpage>286</lpage><pub-id pub-id-type="pmid">9551603</pub-id></element-citation></ref><ref id="b21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Falc&#x000e3;o</surname><given-names>AX</given-names></name><name><surname>Udupa</surname><given-names>JK</given-names></name><name><surname>Samarasekera</surname><given-names>S</given-names></name><name><surname>Sharma</surname><given-names>S</given-names></name><name><surname>Hirsch</surname><given-names>BE</given-names></name><name><surname>Lotufo</surname><given-names>RA</given-names></name></person-group><article-title>User-steered image segmentation paradigms: Live wire and live lane</article-title><source>Graph Models Image Process</source><year>1998</year><volume>60</volume><fpage>233</fpage><lpage>260</lpage></element-citation></ref><ref id="b22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>D</given-names></name><name><surname>Lu</surname><given-names>G</given-names></name></person-group><article-title>A comparative study on shape retrieval using Fourier descriptors with Different shape signatures</article-title><source>J Vis Commun Image Represent</source><year>2003</year><volume>1</volume><fpage>41</fpage><lpage>60</lpage></element-citation></ref><ref id="b23"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Efros</surname><given-names>AA</given-names></name><name><surname>Freeman</surname><given-names>WT</given-names></name></person-group><article-title>Image quilting for texture synthesis and transfer</article-title><source>Proceedings of the 28th Annual Conference on Computer Graphics and Interactive Techniques. SIGGRAPH '01</source><year>2001</year><publisher-loc>New York, NY</publisher-loc><publisher-name>ACM</publisher-name><fpage>341</fpage><lpage>346</lpage></element-citation></ref><ref id="b24"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Szeliski</surname><given-names>R</given-names></name><name><surname>Shum</surname><given-names>HY</given-names></name></person-group><article-title>Creating full view panoramic image mosaics and environment maps</article-title><source>Proceedings of the 24th Annual Conference on Computer Graphics and Interactive Techniques. SIGGRAPH '97</source><year>1997</year><publisher-loc>New York, NY</publisher-loc><publisher-name>ACM Press/Addison-Wesley Publishing Co</publisher-name><fpage>251</fpage><lpage>258</lpage></element-citation></ref><ref id="b25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ng</surname><given-names>HN</given-names></name><name><surname>Grimsdale</surname><given-names>RL</given-names></name></person-group><article-title>Computer graphics techniques for modeling Cloth</article-title><source>IEEE Comput Graph Appl</source><year>1996</year><volume>16</volume><fpage>28</fpage><lpage>41</lpage></element-citation></ref><ref id="b26"><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Mosegaard</surname><given-names>J</given-names></name></person-group><year>2006</year><comment>Aarhus, Denmark University of Aarhus Cardiac Surgery Simulation - Graphics Hardware Meets Congenital Heart Disease. Department of Computer Science</comment></element-citation></ref><ref id="b27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Du</surname><given-names>Q</given-names></name><name><surname>Faber</surname><given-names>V</given-names></name><name><surname>Gunzburger</surname><given-names>M</given-names></name></person-group><article-title>Centroidal Voronoi tessellations: Applications and algorithms</article-title><source>SIAM Rev</source><year>1999</year><volume>41</volume><fpage>637</fpage><lpage>676</lpage></element-citation></ref><ref id="b28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kolega</surname><given-names>J</given-names></name></person-group><article-title>The movement of cell clusters in vitro: morphology and directionality</article-title><source>J Cell Sci</source><year>1981</year><volume>49</volume><fpage>15</fpage><lpage>32</lpage><pub-id pub-id-type="pmid">7031070</pub-id></element-citation></ref><ref id="b29"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Svoboda</surname><given-names>D</given-names></name><name><surname>Ulman</surname><given-names>V</given-names></name></person-group><article-title>Towards a realistic distribution of cells in synthetically generated 3d cell populations</article-title><source>Proceedings of ICIAP. Volume 8157 of Lecture Notes in ComputerScience</source><year>2013</year><publisher-loc>Heidelberg</publisher-loc><publisher-name>Springer Berlin</publisher-name><fpage>429</fpage><lpage>438</lpage></element-citation></ref><ref id="b30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>X</given-names></name></person-group><article-title>Improving the rejection sampling method in quasi-Monte Carlo methods</article-title><source>J Comput Appl Math</source><year>2000</year><volume>114</volume><fpage>231</fpage><lpage>246</lpage></element-citation></ref><ref id="b31"><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Pharr</surname><given-names>M</given-names></name><name><surname>Humphreys</surname><given-names>G</given-names></name></person-group><year>2010</year><comment>San Francisco Physically Based Rendering: From Theory to Implementation, 2nd ed.: Morgan Kaufmann</comment></element-citation></ref><ref id="b32"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Perlin</surname><given-names>K</given-names></name></person-group><article-title>An image synthesizer</article-title><source>Proceedings of the 12th Annual Conference on Computer Graphics and Interactive Techniques. SIGGRAPH '85</source><year>1985</year><volume>19</volume><publisher-loc>New York, NY</publisher-loc><fpage>287</fpage><lpage>296</lpage><comment>In:, Vol</comment></element-citation></ref><ref id="b33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cruickshank</surname><given-names>R</given-names></name></person-group><article-title>D&#x000f6;derlein Vaginal Bacillus: A contribution to the study of the Lacto-Bacilli</article-title><source>J Hyg (London)</source><year>1931</year><volume>31</volume><fpage>375</fpage><lpage>381</lpage><pub-id pub-id-type="pmid">20475100</pub-id></element-citation></ref><ref id="b34"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ingle</surname><given-names>JD</given-names></name><name><surname>Crouch</surname><given-names>SR</given-names></name></person-group><source>Spectrochemical Analysis</source><year>1988</year><publisher-loc>Upper Saddle River, NJ</publisher-loc><comment>Prentice Hall</comment></element-citation></ref><ref id="b35"><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Gavrilovic</surname><given-names>M</given-names></name></person-group><year>2011</year><comment>Uppsala, Sweden Spectral Image Processing with Applications in Biotechnology and Pathology.: Uppsala University, Centre for Image Analysis</comment></element-citation></ref><ref id="b36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyer</surname><given-names>GW</given-names></name><name><surname>Rushmeier</surname><given-names>HE</given-names></name><name><surname>Cohen</surname><given-names>MF</given-names></name><name><surname>Greenberg</surname><given-names>DP</given-names></name><name><surname>Torrance</surname><given-names>KE</given-names></name></person-group><article-title>An experimental evaluation of computer graphics imagery</article-title><source>ACM Trans Graph</source><year>1986</year><volume>5</volume><fpage>30</fpage><lpage>50</lpage></element-citation></ref><ref id="b37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilk</surname><given-names>MB</given-names></name><name><surname>Gnanadesikan</surname><given-names>R</given-names></name></person-group><article-title>Probability plotting methods for the analysis of data</article-title><source>Biometrika</source><year>1968</year><volume>55</volume><fpage>1</fpage><lpage>17</lpage><pub-id pub-id-type="pmid">5661047</pub-id></element-citation></ref></ref-list><sec sec-type="supplementary-material"><title/><p>Additional Supporting Information may be found in the online version of this article.</p><supplementary-material content-type="local-data" id="sd1"><media mimetype="zip" mime-subtype="zip" xlink:href="cyto0087-0212-sd1.zip" xlink:type="simple" id="d35e2668" position="anchor"/></supplementary-material></sec></back></article>