library(xml2)
library(tidyverse)
pos_corpus <- read_xml("https://raw.githubusercontent.com/howisonlab/softcite-dataset/master/data/corpus/softcite_corpus.tei.xml") %>% xml_ns_strip()
full_corpus <- read_xml("https://github.com/howisonlab/softcite-dataset/blob/master/data/corpus/softcite_corpus-full.tei.xml") %>% xml_ns_strip()
full_corpus <- read_xml("https://raw.githubusercontent.com/howisonlab/softcite-dataset/master/data/corpus/softcite_corpus-full.tei.xml") %>% xml_ns_strip()
pos_article_num <- xml_find_num(pos_corpus, xpath="count(//TEI[@type='article'])")
full_corpus <- read_xml("https://raw.githubusercontent.com/howisonlab/softcite-dataset/master/data/corpus/softcite_corpus-full.tei.xml") %>% xml_ns_strip()
corpus_article_num <- xml_find_num(full_corpus, xpath="count(//TEI[@type='article'])")
n_pos_article <- xml_find_num(full_corpus, xpath="count(//fileDesc[@xml:id])")
corpus_article_zero_mention <- xml_find_num(tei_doc, xpath="count(//body[not(node())])")
corpus_article_zero_mention <- xml_find_num(full_corpus, xpath="count(//body[not(node())])")
corpus_pos_article = corpus_article_num - corpus_article_zero_mention
corpus_n_p <- xml_find_num(full_corpus, xpath="count([./p/text()])")
corpus_n_p <- xml_find_num(full_corpus, xpath="count(//body[./p/text()])")
corpus_n_article <- xml_find_num(full_corpus, xpath="count(//TEI[@type='article'])")
# 1240 articles with annotated paragraphs
corpus_article_zero_mention <- xml_find_num(full_corpus, xpath="count(//body[not(node())])")
# 1240 articles with annotated paragraphs
corpus_n_neg_article <- xml_find_num(full_corpus, xpath="count(//body[not(node())])")
# 3544 articles without mentions
corpus_n_ab <- xml_find_num(full_corpus, xpath="count(//body[./ab/text()])")
# 3544 articles without mentions
corpus_n_ab <- xml_find_num(full_corpus, xpath="count(//body[./ab/text()] and //body[./p/text()])")
# 3544 articles without mentions
corpus_n_ab <- xml_find_num(full_corpus, xpath="count(//body[./ab/text() and ./p/text()])")
# 3544 articles without mentions
corpus_n_ab <- xml_find_num(full_corpus, xpath="count(//body[./ab/text()])")
# 483 articles with </ab>
corpus_n_ab_p <- xml_find_num(full_corpus, xpath="count(//body[./ab/text() and ./p/text()])")
# 483 articles with </ab>
corpus_n_ab_p <- xml_find_num(full_corpus, xpath="count(//body[./ab/text() and ./p/text()])")
# 296 articles with both </p> and </ab>
corpus_pos_article = corpus_n_article - corpus_n_neg_article
# 296 articles with both </p> and </ab>
corpus_n_only_ab = corpus_n_ab - corpus_n_ab_p
corpus_econ <- read_xml("https://raw.githubusercontent.com/howisonlab/softcite-dataset/master/data/corpus/softcite_corpus_econ.tei.xml") %>% xml_ns_strip()
econ_n_article <- xml_find_num(corpus_econ, xpath="count(//TEI[@type='article'])")
corpus_pmc <- read_xml("https://raw.githubusercontent.com/howisonlab/softcite-dataset/master/data/corpus/softcite_corpus_pmc.tei.xml") %>% xml_ns_strip()
pmc_n_article <- xml_find_num(corpus_pmc, xpath="count(//TEI[@type='article']")
pmc_n_article <- xml_find_num(corpus_pmc, xpath="count(//TEI[@type='article'])")
# 4971 articles in total
corpus_n_article_p <- xml_find_num(full_corpus, xpath="count(//body[./p/text()])")
# 3544 articles without mentions
corpus_n_article_ab <- xml_find_num(full_corpus, xpath="count(//body[./ab/text()])")
# 483 articles with </ab>
corpus_n_article_ab_p <- xml_find_num(full_corpus, xpath="count(//body[./ab/text() and ./p/text()])")
# 296 articles with both </p> and </ab>
corpus_n_only_ab = corpus_n_article_ab - corpus_n_article_ab_p
# 1427 articles
corpus_n_p <- xml_find_num(full_corpus, xpath="count(//body/p)")
# 1427 articles
corpus_n_p <- xml_find_num(full_corpus, xpath="count(//p)")
library(tidyverse)
library(xml2)
tei_doc <- read_xml("https://raw.githubusercontent.com/howisonlab/softcite-dataset/master/data/corpus/softcite_corpus-full.tei.xml") %>% xml_ns_strip()
# check the source TEI corpus
tei_source <- read_xml("https://raw.githubusercontent.com/ourresearch/software-mentions/master/resources/dataset/software/corpus/all_clean.tei.xml") %>% xml_ns_strip()
warnings()
summary(warnings())
warnings() %>% str()
warnings <- summary(warnings())
View(warnings)
as_data_frame(warnings)
as_tibble(warnings)
as.data.frame(warnings)
warnings <- warnings()
as_data_frame(warnings)
as_list(warnings)
as_data_frame(print(warnings()))
library(tidyverse)
library(stringr)
getwd()
getwd()
library(here)
mismatches <- read_lines("C:/Users/D/Documents/Academics/1-Projects/HowisonLab/softcite/softcite-dataset/code/corpus/paragraph_matching_issues.txt")
mismatches %>% head(4)
install.packages("janeaustenr")
mismatches <- read_lines_raw("C:/Users/D/Documents/Academics/1-Projects/HowisonLab/softcite/softcite-dataset/code/corpus/paragraph_matching_issues.txt")
mismatch_list <- as_tibble(mismatches)
mismatch_list <- as_tibble_col(mismatches)
sessionInfo
sessionInfo()
install.packages("tidyverse")
install.packages("tidyverse")
install.packages("tidyverse")
mismatch_list <- as_tibble_col(mismatches)
library(tidyverse)
library(stringr)
library(here)
mismatches <- read_lines_raw("C:/Users/D/Documents/Academics/1-Projects/HowisonLab/softcite/softcite-dataset/code/corpus/paragraph_matching_issues.txt")
mismatch_list <- as_tibble_col(mismatches)
mismatches <- read_lines("C:/Users/D/Documents/Academics/1-Projects/HowisonLab/softcite/softcite-dataset/code/corpus/paragraph_matching_issues.txt")
mismatch_list <- as_tibble_col(mismatches)
sessionInfo()
install.packages("tibble")
install.packages("tibble")
library(tidyverse)
library(stringr)
sessionInfo()
mismatches <- read_lines("C:/Users/D/Documents/Academics/1-Projects/HowisonLab/softcite/softcite-dataset/code/corpus/paragraph_matching_issues.txt")
mismatch_list <- as_tibble_col(mismatches)
View(mismatch_list)
article = str_extract(text, regex("PMC\\+"))
article = str_extract(text, regex("PMC\\+"))
mismatch_list %>% head(1) %>% str()
mutate(line=row_number(),
mutate(line=row_number(), article = str_extract(text, regex("PMC\\+"))
mutate(line=row_number(), article = str_extract(text, regex("PMC\\+"))
mutate(line=row_number(),article = str_extract(text, regex("PMC\\+"))
mismatch_list <- as_tibble_col(mismatches, column_name = "text") %>%
mutate(line=row_number(),article = str_extract(text, regex("PMC\\+"))
mismatch_list <- as_tibble_col(mismatches, column_name = "text") %>%
mutate(line=row_number(),article = str_extract(text, regex("PMC\\+")))
mismatch_list <- as_tibble_col(mismatches, column_name = "text") %>%
mutate(line=row_number(),article = str_extract(text, regex("PMC\\+")))
View(mismatch_list)
mismatch_list <- as_tibble_col(mismatches, column_name = "text") %>%
mutate(line=row_number(),article = str_extract(text, regex("PMC\\d+")))
mismatch_list <- as_tibble_col(mismatches, column_name = "text") %>%
mutate(line=row_number(),article = str_extract(text, regex("PMC\\d+"))) %>%
filter(!is.na(article))
View(mismatch_list)
mismatch_list <- as_tibble_col(mismatches, column_name = "text") %>%
filter(str_detect(text, "no match in"))
mismatch_list <- as_tibble_col(mismatches, column_name = "text") %>%
filter(str_sub(text, )) %>%
mutate(article=str_sub(start=11))
mismatch_list <- as_tibble_col(mismatches, column_name = "text") %>%
filter(str_sub(text, "no match in")) %>%
mutate(article=str_sub(text, start=12))
mismatch_list <- as_tibble_col(mismatches, column_name = "text") %>%
filter(str_sub(text, "no match in")) %>%
mutate(article=str_sub(text, start=13))
mismatch_list <- as_tibble_col(mismatches, column_name = "text") %>%
filter(str_sub(text, "no match in")) %>%
mutate(article=str_sub(text, start=13, end=-1))
mismatch_list <- as_tibble_col(mismatches, column_name = "text") %>%
filter(str_sub(text, "no match in")) %>%
mutate(article=str_sub(text, 13, -1))
mismatch_list <- as_tibble_col(mismatches, column_name = "text") %>%
filter(str_sub(text, "no match in")) %>%
mutate(article=str_sub(text, start=13, end=-1))
mismatch_list <- as_tibble_col(mismatches, column_name = "text") %>%
filter(str_sub(text, "no match in")) %>%
mutate(article=str_sub(text, start=13))
mismatch_list <- as_tibble_col(mismatches, column_name = "text") %>%
filter(str_detect(text, "no match in")) %>%
mutate(article=str_sub(text, start=13))
mismatches <- read_lines("C:/Users/D/Documents/Academics/1-Projects/HowisonLab/softcite/softcite-dataset/code/corpus/paragraph_matching_issues.txt")
mismatch_list <- as_tibble_col(mismatches, column_name = "text") %>%
filter(str_detect(text, "no match in")) %>%
mutate(article=str_sub(text, start=13))
mismatch_list <- as_tibble_col(mismatches, column_name = "text") %>%
filter(str_detect(text, "no match in")) %>%
mutate(article=str_sub(text, start=13)) %>%
select(article)
write_csv(mismatch_list, "C:/Users/D/Documents/Academics/1-Projects/HowisonLab/softcite/softcite-dataset/data/json-article-mismatch-with-corpus.csv")
library(tidyverse)
library(xml2)
library(here)
tei_doc <- read_xml("https://raw.githubusercontent.com/howisonlab/softcite-dataset/master/data/corpus/softcite_corpus-full.tei.xml") %>% xml_ns_strip()
# 5171 software mentions in total
software_in_p <- tei_doc %>%
xml_find_all(xpath="//p/rs[@type='software']")
software_p <- tibble(rs_txt = xml_text(software_in_p), rs_attrs = xml_attrs(software_in_p)) %>%
unnest_wider(rs_attrs) %>%
rename(software = rs_txt)
software_id <- software_p %>% pull(id)
# 1358 publisher mentions
publisher_in_p <- tei_doc %>%
xml_find_all(xpath="//p/rs[@type='publisher']")
publisher_p <- tibble(rs_txt = xml_text(publisher_in_p),
rs_attrs = xml_attrs(publisher_in_p)) %>%
unnest_wider(rs_attrs) %>%
mutate(corresp = str_sub(corresp, 2, -1)) %>%
rename(id = corresp, publisher=rs_txt) %>%
select(publisher, id) %>%
group_by(id) %>%
mutate(row = row_number()) %>%
pivot_wider(names_from = row, values_from = publisher) %>%
rename(publisher1=`1`, publisher2=`2`) %>% ungroup()
publisher_p %>% filter(!is.na(publisher2))
# 215 url mentions
url_in_p <- tei_doc %>%
xml_find_all(xpath="//p/rs[@type='url']")
url_p <- tibble(rs_txt = xml_text(url_in_p),
rs_attrs = xml_attrs(url_in_p)) %>%
unnest_wider(rs_attrs) %>%
mutate(corresp = str_sub(corresp, 2, -1)) %>%
rename(id = corresp, url = rs_txt) %>%
select(url, id)
# 1591 version mentions
version_in_p <- tei_doc %>%
xml_find_all(xpath="//p/rs[@type='version']")
version_p <- tibble(rs_txt = xml_text(version_in_p),
rs_attrs = xml_attrs(version_in_p)) %>%
unnest_wider(rs_attrs) %>%
mutate(corresp = str_sub(corresp, 2, -1)) %>%
rename(id = corresp, version = rs_txt) %>%
select(version, id) %>%
group_by(id) %>%
mutate(row = row_number()) %>%
pivot_wider(names_from = row, values_from = version) %>%
rename(version1=`1`, version2=`2`) %>% ungroup()
version_p %>% filter(!is.na(version2))
pmc_id <- tei_doc %>%
xml_find_all(xpath="//TEI[@subtype='pmc']//fileDesc") %>%
xml_attrs %>% unlist
# rectangular data of annotated software mentions in </p> parsed from TEI corpus
mentions_p <- software_p %>% left_join(version_p, by="id") %>%
left_join(publisher_p, by="id") %>%
left_join(url_p, by="id") %>%
mutate(article = str_extract(id, "[A-Za-z0-9]{10}")) %>%
mutate(article_set =
if_else(article %in% pmc_id, "PMC", "Economics"))
# excluding articles missing paragraphs during JSON conversion
mismatches <- read_lines("C:/Users/D/Documents/Academics/1-Projects/HowisonLab/softcite/softcite-dataset/code/corpus/paragraph_matching_issues.txt")
mismatch_list <- as_tibble_col(mismatches, column_name = "text") %>%
filter(str_detect(text, "no match in")) %>%
mutate(article=str_sub(text, start=13)) %>%
select(article)
View(mentions_p)
View(mismatch_list)
article_id <- xml_find_all(tei_doc, xpath="//fileDesc@xml:id")
article_id <- xml_find_all(tei_doc, xpath="//fileDesc/@xml:id")
articles <- tibble(text = xml_text(article_id), attrs = xml_attrs(article_id)) %>%
unnest_wider(attrs)
View(articles)
article_id <- xml_find_all(tei_doc, xpath="//fileDesc/@xml:id and //idno[@type="origin"]")
article_id <- xml_find_all(tei_doc, xpath="//fileDesc/@xml:id and //idno[@type='origin']")
article_id <- xml_find_all(tei_doc, xpath="//fileDesc[@xml:id]//idno[@type='origin']")
articles <- tibble(text = xml_text(article_id), attrs = xml_attrs(article_id)) %>%
unnest_wider(attrs)
View(articles)
article_id %>% head(2)
article_id <- xml_find_all(tei_doc, xpath="//fileDesc[@xml:id] and //idno[@type='origin']")
article_id <- xml_find_all(tei_doc, xpath="//fileDesc/@xml:id and //idno[@type='origin']")
article_id <- xml_find_all(tei_doc, xpath="//fileDesc/@xml:id and //idno[@type='origin']/text()")
article_id <- xml_find_all(tei_doc, xpath="//fileDesc/@xml:id")
article_id %>% head(2)
article_id <- xml_find_all(tei_doc, xpath="//fileDesc[@xml:id]//idno[@type='origin']/text()")
article_id %>% head(2)
article_id <- xml_find_all(tei_doc, xpath="//idno[@type='origin']/text()")
article_id <- xml_find_all(tei_doc, xpath="//fileDesc/@xml:id")
article_id %>% head(2)
origin_id <- xml_find_all(tei_doc, xpath="//idno[@type='origin']")
library(tidyverse)
library(xml2)
library(here)
library(stringr)
tei_doc <- read_xml("https://raw.githubusercontent.com/howisonlab/softcite-dataset/master/data/corpus/softcite_corpus-full.tei.xml") %>% xml_ns_strip()
article_no_origin <- xml_find_all(tei_doc,xpath="//fileDesc[@xml:id]//not(//idno[@type='origin']) ")
article_no_origin <- xml_find_all(tei_doc,xpath="//fileDesc[not(//idno[@type='origin'])] ")
article_no_origin <- xml_find_all(tei_doc,xpath="//fileDesc[not(.//idno[@type='origin'])] ")
View(article_no_origin)
origin_id <- xml_find_all(tei_doc, xpath="//idno[@type='origin']")
article_id <- xml_find_all(tei_doc, xpath="//fileDesc/@xml:id")
article_no_origin %>% head(2)
articles <- tibble(text = xml_text(article_no_origin), attrs = xml_attrs(article_no_origin)) %>%
unnest_wider(attrs)
View(articles)
article_no_origin <- xml_find_all(tei_doc,xpath="//fileDesc[not(.//idno[@type='origin'])]/@xml:id ")
article_no_origin %>% head(2)
articles <- tibble(text = xml_text(article_no_origin), attrs = xml_attrs(article_no_origin)) %>%
unnest_wider(attrs)
View(articles)
source_corpus <- read_xml("https://raw.githubusercontent.com/ourresearch/software-mentions/master/resources/dataset/software/corpus/all_clean.tei.xml") %>% xml_ns_strip()
View(source_corpus)
article_no_origin <- xml_find_all(source_corpus,xpath="//fileDesc[not(.//idno[@type='origin'])]/@xml:id and idno ")
View(articles)
View(article_no_origin)
article_no_origin <- xml_find_all(tei_doc,xpath="//fileDesc[not(.//idno[@type='origin'])]/@xml:id")
article_no_origin %>% head(2)
articles <- tibble(text = xml_text(article_no_origin), attrs = xml_attrs(article_no_origin)) %>%
unnest_wider(attrs)
View(articles)
articles_no_origin <- tibble(text = xml_text(article_no_origin), attrs = xml_attrs(article_no_origin)) %>%
unnest_wider(attrs)
# Auditing corpus annotations
n_software <- xml_find_num(tei_doc, xpath="count(//rs[@type='software'])")
# Auditing corpus annotations
n_software <- xml_find_num(source_corpus, xpath="count(//rs[@type='software'])")
xml_find_all(tei_doc,xpath="//fileDesc//idno[@type='origin'] and ../../../@xml:id")
article_with_origin <- xml_find_all(tei_doc,xpath="//fileDesc//idno[@type='origin'] and ../../../@xml:id")
library(here)
here()
dr_here()
set_here("./Documents/Academics/1_Project/Howisonlab")
set_here(".\Documents\Academics\1_Project\Howisonlab")
set_here("C:\Users\D\Documents\Academics\1_Project\Howisonlab")
set_here("C:/Users/D/Documents/Academics/1_Project/Howisonlab")
set_here("C:/Users/D/Documents/Academics/1_Projects/Howisonlab")
set_here("C:\Users\D\Documents\Academics\1-Projects\HowisonLab")
set_here("C:/Users/D/Documents/Academics/1-Projects/HowisonLab")
here()
library(tidyverse)
library(here)
# 1. Compare CSV and TEI summaries
# load the article ID table
included_article <- read_csv(here("software-mentions/resources/dataset/software/corpus/ids.csv"))
# 1. Compare CSV and TEI summaries
# load the article ID table
included_article <- read_csv(here("Howisonlab", "software-mentions/resources/dataset/software/corpus/ids.csv"))
library(here)
# 1. Compare CSV and TEI summaries
# load the article ID table
included_article <- read_csv(here("Howisonlab", "software-mentions/resources/dataset/software/corpus/ids.csv"))
# 1. Compare CSV and TEI summaries
# load the article ID table
included_article <- read_csv(here("https://raw.githubusercontent.com/ourresearch/software-mentions/master/resources/dataset/software/corpus/ids.csv"))
# 1. Compare CSV and TEI summaries
# load the article ID table
included_article <- read_csv("https://raw.githubusercontent.com/ourresearch/software-mentions/master/resources/dataset/software/corpus/ids.csv")
View(included_article)
library(tidyverse)
library(here)
# check top annotator results from csv files
csv_articles <- read_csv(here("data/csv_dataset/softcite_articles.csv"))
csv_mentions <- read_csv(here("data/csv_dataset/softcite_in_text_mentions.csv"))
csv_codes <- read_csv(here("data/csv_dataset/softcite_codes_applied.csv"))
csv_reference <- read_csv(here("data/csv_dataset/softcite_references.csv"))
setwd("C:/Users/D/Documents/Academics/1-Projects/HowisonLab/softcite/softcite-dataset")
# check top annotator results from csv files
csv_articles <- read_csv(here("data/csv_dataset/softcite_articles.csv"))
csv_articles <- read_csv("here("C:/Users/D/Documents/Academics/1-Projects/HowisonLab/softcite/softcite-datase/data/csv_dataset/softcite_articles.csv"))
csv_articles <- read_csv("C:/Users/D/Documents/Academics/1-Projects/HowisonLab/softcite/softcite-datase/data/csv_dataset/softcite_articles.csv"))
csv_articles <- read_csv("C:/Users/D/Documents/Academics/1-Projects/HowisonLab/softcite/softcite-datase/data/csv_dataset/softcite_articles.csv")
csv_articles <- read_csv("C:/Users/D/Documents/Academics/1-Projects/HowisonLab/softcite/softcite-dataset/data/csv_dataset/softcite_articles.csv")
csv_mentions <- read_csv("C:/Users/D/Documents/Academics/1-Projects/HowisonLab/softcite/softcite-dataset/data/csv_dataset/softcite_in_text_mentions.csv")
csv_codes <- read_csv("C:/Users/D/Documents/Academics/1-Projects/HowisonLab/softcite/softcite-dataset/data/csv_dataset/softcite_codes_applied.csv")
csv_references <- read_csv("C:/Users/D/Documents/Academics/1-Projects/HowisonLab/softcite/softcite-dataset/data/csv_dataset/softcite_references.csv")
View(csv_articles)
View(csv_mentions)
rdf_software <- csv_articles %>%
filter(article_set %in% c("pmc_article", "econ_article")) %>%
filter(no_selections_found == F) %>%
# only check articles annotated with positive results
left_join(csv_mentions, by=c("article", "coder")) %>%
filter(mention_type == "software") %>%
select(-codable, -standard_article, -quote, -tei_quote, -memo, -page) %>%
# TODO: there might be duplicated values in the fields dropped
# make sure that every record is uniquely identified
distinct()
View(rdf_software)
rdf_software %>% distinct(article)
View(included_article)
included_article %>% distinct(origin)
included_article %>% filter(is.na(origin))
included_article %>% filter(is.na(origin))
included_article %>% distinct()
included_article %>% distinct(origin)
included_article %>% filter(is.na(origin))
included_article %>% duplicated(origin)
included_article %>% group_by(origin) %>%
filter(n()>1)
included_article %>% group_by(origin) %>%
filter(n()>1) %>%
distinct(origin)
duplicated_origin <- included_article %>% group_by(origin) %>%
filter(n()>1) %>%
distinct(origin)
included_article %>%
filter(origin %in% duplicated_origin)
duplicated_origin <- included_article %>%
group_by(origin) %>%
filter(n()>1) %>%
distinct(origin) %>% pull
included_article %>%
filter(origin %in% duplicated_origin)
getwd()
included_article %>%
filter(origin %in% duplicated_origin) %>%
write_csv("data/duplicated_origin_in_id_tbl.csv")
included_article %>%
filter(origin %in% duplicated_origin) %>%
write_csv("data", "duplicated_origin_in_id_tbl.csv")
included_article %>%
filter(origin %in% duplicated_origin)
View(rdf_software)
rdf_software <- csv_articles %>%
filter(article_set %in% c("pmc_article", "econ_article")) %>%
filter(no_selections_found == F) %>%
# only check articles annotated with positive results
left_join(csv_mentions, by=c("article", "coder")) %>%
filter(mention_type == "software") %>%
select(-codable, -standard_article, -quote, -tei_quote, -memo, -page)
rdf_software <- csv_articles %>%
filter(article_set %in% c("pmc_article", "econ_article")) %>%
filter(no_selections_found == F) %>%
# only check articles annotated with positive results
left_join(csv_mentions, by=c("article", "coder")) %>%
filter(mention_type == "software") %>%
select(-codable, -standard_article, -quote, -tei_quote, -memo, -page) %>%
# TODO: there might be duplicated values in the fields dropped
# make sure that every record is uniquely identified
distinct()
