---
title: "Find quotes in PDF text"
output: html_notebook
---

```{r}
library(tidyverse)
library(data.world) # loads saved config see quickstart vignette

prefixes <- "
PREFIX bioj: <http://james.howison.name/ontologies/bio-journal-sample#>
PREFIX bioj-cited: <http://james.howison.name/ontologies/bio-journal-sample-citation#>
PREFIX ca: <http://floss.syr.edu/ontologies/2008/4/contentAnalysis.owl#>
PREFIX citec: <http://james.howison.name/ontologies/software-citation-coding#> 
PREFIX dc: <http://dublincore.org/documents/2012/06/14/dcmi-terms/>
PREFIX doap: <http://usefulinc.com/ns/doap#>
PREFIX owl: <http://www.w3.org/2002/07/owl#>
PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
PREFIX vivo: <http://vivoweb.org/ontology/core#>
PREFIX xml: <http://www.w3.org/XML/1998/namespace>
PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>
"

softcite_ds = "https://data.world/jameshowison/software-citations/"

# should pull from coding scheme
valid_codes = c("has_supplement",
"has_in_text_mention",
"coded_no_in_text_mentions",
"memo",
"full_quote",
"on_pdf_page",
"spans_pages",
"mention_type",
"software_was_used",
"software_name",
"version_number",
"version_date",
"url",
"creator",
"has_reference",
"reference_type")
```

This gets the codes from the top of the files.

```{r}
top_code_query <- data.world::qry_sparql(paste(prefixes,
      "SELECT ?article ?coder ?selection ?full_quote ?on_pdf_page ?spans_pages
WHERE {
    ?article citec:has_in_text_mention ?selection .
    ?selection ca:isTargetOf
        [ rdf:type ca:CodeApplication ;
          ca:hasCoder ?coder ;
          ca:appliesCode [ rdf:type citec:mention_type ]
        ] .
    ?selection citec:full_quote ?full_quote ;
               citec:on_pdf_page ?on_pdf_page ;
               citec:spans_pages ?spans_pages
    }"
))
top_codes <- data.world::query(top_code_query, softcite_ds)
top_codes <- as.tibble(top_codes)
```

SPARQL queries return everything as URLs, but we want just the localPart at the end.

```{r}
top_codes <- top_codes %>%
       mutate_at(vars(article, selection), funs(str_extract(.,"[#/]([^#/]+)$"))) %>%
       mutate_at(vars(article,selection), funs(str_sub(.,2)))
```


```{r}
# Focus on PMC dataset and remove newlines from full_quote
top_codes <- top_codes %>% 
  filter(str_detect(article, "PMC")) 

#%>% 
#  mutate(full_quote = str_replace_all(full_quote, "[\r\n]" , ""))


# Only retain selections from articles with multiple coders
multi_coders <- top_codes %>% 
  group_by(article) %>% 
  mutate(num_coder = n_distinct(coder)) %>% 
  ungroup() %>%
  filter(num_coder > 1)
```

Now load the pdf for each article

```{r}
library(extractr)

my_extract <- function(p) {
  pdf_t <- extract(p)
  return(BString(pdf_t$data))
}

folder <-  "/Users/howison/Documents/UTexas/Projects/SloanSoftCite/softcite-dataset/docs/pdf-files/pmc_oa_files/"
# txt <- extract(paste(folder, "PMC3808809.pdf", sep=""))
# txt$data
# print(str_c(txt, collapse = " "))

articles <- multi_coders %>% 
  select(article) %>% 
  distinct() %>% 
  mutate(path = str_c(folder, article, ".pdf", sep=""))

# with an unvectorized function use map (or use rowwise())
articles <- articles %>% 
  mutate(extract_object = map(.$path, extract),
         # just gets extract_object$data.
         pdf_as_text = map_chr(extract_object, "data")
         ) 

# lookup article text in articles df.
run_match <- function(article, full_quote) {
  # row <- multi_coders[2,]
  article_row <- articles %>% filter(article == article)
  pdf_as_xstring <- BString(article_row[[1, "pdf_as_text"]])
  mismatch_allow <- floor(str_length(full_quote) / 4)
  results <- matchPattern(full_quote, pdf_as_xstring, 
                          with.indels = T, max.mismatch = mismatch_allow)
#  results
  return(results)
}

# run_match(multi_coders[5,])

matches <- multi_coders %>% 
  rowwise() %>% 
  mutate(results = list(run_match(article, full_quote))) %>% 
  mutate(num_found = map_int(results, length))

# %>% 
  # select(full_quote, matchPattern)
  mutate(results = map2(full_quote, pdf_as_xstring, matchPattern, 
                        with.indels = T, max.mismatch = 20)) %>%
  # length, start, end are accessor functions on the result of matchPattern
  

misses <- matches %>% 
  filter(num_found == 0) %>% 
  select(selection, full_quote)

found <- matches %>% 
  filter(num_found == 1) %>% 
  mutate(start = map_int(results, start),
         end = map_int(results, end))

# select(found, num_found, start, end)

```

Next task is to locate overlapping BStrings. Bioconductor's IRanges has a findOverlaps function for just this.  For each article, create a BString, then for each full_quote define that as an IRange.  Then can use findOverlaps. One can use this directly with start and end, which I have in the found df.

```{r}
found <- found %>% 
  mutate(range = map2(start, end, IRanges))
```

Before doing overlap test need to set up data. Find possible matches (same article, different coder) and expand data frame so that each row is a possible combo.

```{r}
# get selections on same article but by a different coder.
get_possible_matches <- function(curr_article, curr_coder, data) {
  m <- data %>% filter(article == curr_article, coder != curr_coder )
  m %>% pull(selection)
}

poss_matches <- found %>%
  select(article, coder, selection, start, end) %>% 
  group_by(article, coder) %>%
  mutate(poss_match = list(get_possible_matches(article, coder, found))) %>% 
  unnest()

nrow(poss_matches)
# remove duplicates by pasting together in same order
# poss_matches <- poss_matches %>% 
#   mutate(key = paste0(pmin(selection, poss_match), 
#                       pmax(selection, poss_match))) %>% 
#   distinct(key, .keep_all = T)
# 
# nrow(poss_matches)

```

Now ready to do overlap test.

```{r}
# Must have found available
does_overlap <- function(sel, poss_overlap, found) {
  sel_range_list <- found %>% filter(selection == sel) %>% pull(range) 
  sel_range <- sel_range_list[[1]] # unlist
  poss_overlap_range_list <- found %>% 
    filter(selection == poss_overlap) %>% pull(range)
  poss_overlap_range <- poss_overlap_range_list[[1]] # unlist
  num_overlap = nrow(as.matrix(findOverlaps(sel_range, poss_overlap_range)))
  return(num_overlap != 0)
}
# does_overlap("PMC2529246_BB02", "PMC2529246_MS02", found)

poss_matches <- poss_matches %>% 
  rowwise() %>% 
  mutate(match = does_overlap(selection, poss_match, found))

poss_matches %>% group_by(match) %>% tally()

final_matches <- poss_matches %>% filter(match == T) %>% 
  rename(matching_selection = poss_match) %>% 
  select(article, coder, selection, matching_selection)

quote_lookup <- select(found, selection, full_quote)

final_matches_with_quotes <- final_matches %>% left_join(quote_lookup, by=c("matching_selection" = "selection")) %>% 
  rename(full_quote_match = full_quote) %>% 
  left_join(quote_lookup, by=c("selection" = "selection"))

nrow(final_matches_with_quotes)
View(select(final_matches_with_quotes, full_quote, full_quote_match))

# Join back to multiple coders
multi_coders_with_matches <- left_join(multi_coders, final_matches) %>% 
  mutate(matched = !is.na(matching_selection)) 

multi_coders_with_matches %>% 
  group_by(matched) %>% 
  tally()

misses <- multi_coders_with_matches %>% 
  filter(is.na(matching_selection)) %>% 
  arrange(article, coder)

View(misses)

misses %>% filter(article == "PMC3198286")

does_overlap("PMC3198286_MD01","PMC3198286_RA01", found)
# throws an error
# so the trouble is not that they don't match but that at least one wasn't found.
found %>% filter(selection == "PMC3198286_RA01")
# PMC3198286_RA01 wasn't found.

  

does_overlap("PMC3309518_RA01","PMC3309518_MS01", found)
found %>% filter(selection == "PMC3309518_MS01")

found %>% filter(article == "PMC3309518")
# Most weren't found, but some were.  Bah.

#hmmm, the selection id doesn't match the article.
top_codes %>% filter(article == "PMC3193002")

```

To map a three parameter function you have to have a data frame with just those columns. So in this I reshape the found data frame inside the mutate call.
```{r}

just_params_for_sub_str <- found %>% 
  select(pdf_as_xstring, start, end) %>% 
  rename(x = pdf_as_xstring) 

# I had issues in the below because pmap returns a list and there
# isn't the equivalent of pmap_chr for bstrings
# rowwise solves this. Documentation makes this clear:
# "Its main impact is to allow you to work with list-variables in summarise() and mutate() without having to use [[1]]."
compare <- found %>% 
  mutate(substring_xstring = pmap(just_params_for_sub_str, subseq)) %>% 
  rowwise() %>% 
  mutate(substring = as.character(substring_xstring)) %>% 
  select(selection, full_quote, substring)

View(compare)
```

Little test of IRange

```{r}
library(IRanges)

full_string <- "the cat sat on the mat"
res1 <- matchPattern("the cat sat", full_string)
range1 <- IRanges(start = start(res1), end = end(res1))
res2 <- matchPattern("cat sat on the mat", full_string)
range2 <- IRanges(start = start(res2), end = end(res2))
nrow(as.matrix(findOverlaps(range1, range2)))

res3 <- matchPattern("batman", full_string)
range3 <- IRanges(start = start(res3), width = width(res3))
nrow(as.matrix(findOverlaps(range1, range3)))
```







Ok putting it all together.

1. get top_codes
2. retain only selections from articles with multiple coders
3. get pdf_as_text for each article
4. get range for selection
5. get possible matches for selection
6. unnest
7. find overlap

```{r}

```


```{r}
multi_coders <- top_codes %>% 
  group_by(article) %>% 
  mutate(num_coder = n_distinct(coder)) %>% 
  ungroup() %>%
  filter(num_coder > 1)

get_possible_matches <- function(curr_article, curr_coder, data) {
  m <- data %>% filter(article == curr_article, coder != curr_coder )
  select(m, -article, -coder, -num_coder)
}


poss_matches <- multi_coders %>% 
  group_by(article, coder) %>%
  summarize(poss_matches = list(get_possible_matches(article, coder, multi_coders))) 

data_for_matching <- multi_coders %>% 
  select(-num_coder) %>% 
  group_by(article, coder) %>% 
  nest(.key = "selections") 


# removes any NAs
grouped_data <- left_join(poss_matches, data_for_matching)
```



```{r}
View(select(found, full_quote, substring))
full_string <- "the cat sat on the mat the cat"
res <- matchPattern("the cat", full_string, with.indels = T, max.mismatch = 10)
substr(full_string, start(res), end(res))

start(res[4])

res <- matchPattern("batman", "the cat sat on the mat")

as.data.frame(res)

start(res)


as.matrix(res)
View(test)


test2 <- left_join(articles,top_codes) %>% ungroup() %>% 
  mutate(results = map2(.$full_quote, .$pdf_as_text, matchPattern, with.indels = T, max.mismatch = 10))

test2 %>% mutate(text_only = map(.$results, "data"))

test2[2,]$results
```

```{r}
library(plyr)

# load pdfs.
my_extract <- function(p) {
  pdf_t <- extract(p)
  as_text <- pdf_t$data
  no_linebreaks <- str_replace_all(as_text, "[\\r\\n\\s]" , "")
  return(no_linebreaks)
}

articles <- top_codes %>% 
  select(article) %>% 
  distinct() %>% 
  mutate(path = str_c(folder, article, ".pdf", sep=""))

# with an unvectorized function use map (or use rowwise())
articles <- articles %>% 
  mutate(pdf_as_string = map_chr(path, my_extract)) 

# articles %>% filter(article == "PMC1747177")
```

```{r}
# for each article, run a function
match_in_article <- function(df) {
  #df <- top_codes[36, ]
  art <- df[[1, "article"]] # grouping variable
  pdf_as_string = (articles %>% filter(article == art))$pdf_as_string[[1]] 
  ddply(df, .(selection), match_selection, BString(pdf_as_string))
}

match_selection <- function(df, pdf_as_xstring) {
  full_quote <- str_sub(df[[1, "full_quote"]], 1, 40)
  # full_quote <- str_replace_all(full_quote, "[\\r\\n\\s]" , "")
  mismatch_allow <- floor(str_length(full_quote) / 4)
  results <- list(matchPattern(full_quote, pdf_as_xstring, 
                          with.indels = T, max.mismatch = mismatch_allow))
  
   df %>% mutate(num_found = map_int(results, length),
                 start = map(results, start),
                 end = map(results, end))
}

one_article <- top_codes %>% filter(article == "PMC3035800")

# top_codes[[36, "selection"]]
# 
# sel_df <- top_codes[36, ]
# 
# PMC3035800 <- articles %>% filter(article == "PMC3035800")
# PMC3035800 <- PMC3035800[[1,"pdf_as_string"]]
# PMC3035800_xstring <- BString(PMC3035800)
# 
# 
# test <- match_selection(sel_df, PMC3035800_xstring)
# 
# test <- match_in_article(sel_df)


found <- ddply(one_article, .(article), match_in_article, .progress = "text")

found %>% filter(selection == "PMC3035800_RA01")


# PMC3035800_RA01
```

