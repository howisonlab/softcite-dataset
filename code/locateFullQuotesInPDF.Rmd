---
title: "Find quotes in PDF text"
output: html_notebook
---

```{r}
# library(plyr)
library(tidyverse)
library(data.world) # loads saved config see quickstart vignette

prefixes <- "
PREFIX bioj: <http://james.howison.name/ontologies/bio-journal-sample#>
PREFIX bioj-cited: <http://james.howison.name/ontologies/bio-journal-sample-citation#>
PREFIX ca: <http://floss.syr.edu/ontologies/2008/4/contentAnalysis.owl#>
PREFIX citec: <http://james.howison.name/ontologies/software-citation-coding#> 
PREFIX dc: <http://dublincore.org/documents/2012/06/14/dcmi-terms/>
PREFIX doap: <http://usefulinc.com/ns/doap#>
PREFIX owl: <http://www.w3.org/2002/07/owl#>
PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
PREFIX vivo: <http://vivoweb.org/ontology/core#>
PREFIX xml: <http://www.w3.org/XML/1998/namespace>
PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>
"

softcite_ds = "https://data.world/jameshowison/software-citations/"

# should pull from coding scheme
valid_codes = c("has_supplement",
"has_in_text_mention",
"coded_no_in_text_mentions",
"memo",
"full_quote",
"on_pdf_page",
"spans_pages",
"mention_type",
"software_was_used",
"software_name",
"version_number",
"version_date",
"url",
"creator",
"has_reference",
"reference_type")
```

This gets the codes from the top of the files.

```{r}
top_code_query <- data.world::qry_sparql(paste(prefixes,
      "SELECT ?article ?coder ?selection ?full_quote ?on_pdf_page ?spans_pages
WHERE {
    ?article citec:has_in_text_mention ?selection .
    ?selection ca:isTargetOf
        [ rdf:type ca:CodeApplication ;
          ca:hasCoder ?coder ;
          ca:appliesCode [ rdf:type citec:mention_type ]
        ] .
    ?selection citec:full_quote ?full_quote ;
               citec:on_pdf_page ?on_pdf_page ;
               citec:spans_pages ?spans_pages
    }"
))

top_codes <- data.world::query(top_code_query, softcite_ds)
top_codes <- as.tibble(top_codes) %>% 
  filter(str_detect(article, "PMC"))

# top_codes %>%
#   group_by(article) %>%
#   summarize(num_coder = n_distinct(coder)) %>%
#   group_by(num_coder) %>%
#   tally()
```

```{r}
no_selection_query <- data.world::qry_sparql(paste(prefixes,
      "SELECT ?article ?coder 
       WHERE { ?article ca:isTargetOf
               [ rdf:type ca:CodeApplication ;
                 ca:hasCoder ?coder ;
                 ca:appliesCode [ rdf:type citec:coded_no_in_text_mentions ;
                                  citec:isPresent true ]
               ]
    }"
))

no_selection_articles <- data.world::query(no_selection_query, 
                                           dataset = softcite_ds) %>% 
  mutate(article = str_extract(article, "[#/]([^#/]+)$"),
         article = str_sub(article,2),
         matched = 0,
         unmatched = 0) %>% 
  collect()
```


```{r}
# top_codes <- read_csv("top_codes.csv")
```


SPARQL queries return everything as URLs, but we want just the localPart at the end.

```{r}
top_codes <- top_codes %>%
       mutate_at(vars(article, selection),
                 funs(str_extract(.,"[#/]([^#/]+)$"))) %>%
       mutate_at(vars(article,selection), funs(str_sub(.,2)))
```


```{r}
# Some summary stats.

top_codes %>% summarize(num_articles = n_distinct(article),
                        num_coders = n_distinct(coder),
                        num_selections = n_distinct(selection))

top_codes %>% group_by(article, coder) %>% 
  summarize(num_selections = n_distinct(selection)) %>% 
  arrange(desc(num_selections)) %>% 
  filter(article == "PMC4441238")

```

```{r}
norm_text <- function(text_to_norm){
  text_to_norm %>% 
    str_replace_all("[\\r\\n\\s]" , "") %>% 
    str_replace_all("\\(http.*?\\)" , "") %>% 
    str_to_lower()
}

test_txt = "The cat sat ON the (http://REMOVE_ME)"
norm_text(test_txt)
```


Try locating in XML files.

```{r}
library(xml2)
library(glue)

path = "/Users/howison/Documents/UTexas/Projects/SloanSoftCite/softcite-pdf-files/docs/pdf-files/pmc_oa_files/"

test_articles <- tribble(
  ~pmcid,
  "PMC5381613", 
  "PMC5421183" 
)

articles <- top_codes %>% select(article) %>% distinct()

articles <- articles %>% 
  mutate(xml_path       = glue_data(., "{path}{article}.xml"),
         article_as_xml = map(xml_path, read_xml),
         pdf_as_string  = map_chr(article_as_xml, xml_text),
         pdf_as_string  = norm_text(pdf_as_string))
                        
```

Now load the pdf for each article

```{r, eval=F}
# library(extractr)
# 
# # locate PDFs
# folder <-  "/Users/howison/Documents/UTexas/Projects/SloanSoftCite/softcite-dataset/docs/pdf-files/pmc_oa_files/"
# 
# articles <- top_codes %>% 
#   select(article) %>% 
#   distinct() %>% 
#   mutate(path = str_c(folder, article, ".pdf", sep=""))
# 
# # load pdfs.
# my_extract <- function(p) {
#   pdf_t <- extract(p)
#   as_text <- pdf_t$data
#   no_linebreaks <- str_replace_all(as_text, "[\\r\\n\\s]" , "")
#   return(no_linebreaks)
# }
# 
# # with an unvectorized function use map (or use rowwise())
# articles <- articles %>% 
#   mutate(pdf_as_string = map_chr(path, my_extract)) 

# articles %>% filter(article == "PMC1747177")

# known_problematic = c("PMC5039120_SK02", "PMC5039120_BB02",
#                       # interspersed columns
#                       "PMC3198286_MD03", 
#                       # interspersed headers
#                       "PMC4926940_MS01", "PMC4926940_SK01",
#                       # interspersed columns
#                       "PMC5039120_BB01", "PMC5039120_SK01",
#                       # interspersed columns
#                       "PMC5238813_RA08", "PMC5238813_SK28",
#                       # article has extraction issues, these two don't match
#                       "PMC5080194_MD02", "PMC5080194_RA01",
#                       # below here are those that find two matches
#                       # These two are found twice in the same article)
#                       "PMC5339831_BB01", "PMC5339831_SK01",
#                       # These two match but are same text as next two
#                       "PMC5339831_BB02", "PMC5339831_SK02",
#                       # These two match but are same as last two.
#                       "PMC3309518_RA09")
#                       # This one shows up twice.

```

Do matching using Biostrings.

```{r}
library(Biostrings)
library(tidyverse)
library(clipr)

top_codes <- top_codes %>% 
  mutate(norm_full_quote = norm_text(full_quote))

# for each article, run a function
match_in_article <- function(df) {
  #df <- top_codes[36, ]
  art <- df[[1, "article"]] # grouping variable
  pdf_as_string = (articles %>% filter(article == art))$pdf_as_string[[1]] 
  # ddply(df, .(selection), match_selection, BString(pdf_as_string))
  df %>% group_by(selection) %>% do(match_selection(., BString(pdf_as_string)))
}

match_selection <- function(df, pdf_as_xstring) {
  norm_full_quote <- df[[1, "norm_full_quote"]]
  # Attempt exact match (without indels)
  results <- matchPattern(norm_full_quote, pdf_as_xstring)
  if (length(results) == 0) {
      mismatch_allow <- floor(str_length(norm_full_quote) / 10)
      # mismatch_allow <- 10
      results <- matchPattern(norm_full_quote, pdf_as_xstring,
                          with.indels = T, max.mismatch = mismatch_allow)
  }
  
  if (length(results) == 0) {
    # warning(paste0("Not found: ", df[[1, "selection"]], "\n"))
    df %>% mutate(found = F, num_found = 0, start_val = NA, end_val = NA)
  } else {
    df %>% mutate(found    = T,
                 num_found = length(results),
                 start_val = list(start(results)),
                 end_val = list(end(results)))
  }
}

# the dot here is a pronoun for the group, ie the split up dataframe.
(found <- top_codes %>% 
  # filter(article == "PMC5042035") %>% # all match
  # filter(article == "PMC5390613") %>%  # some misses 
  # filter(article == "PMC2518490") %>% # | article == "PMC2978351") %>% 
  group_by(article) %>% 
  do(match_in_article(.)) %>% # adds the num_found, start_val, end_val
  filter(num_found == 1) %>% 
  unnest() %>% # unlists the start_val and end_val columns
  ungroup() %>% 
  select(-norm_full_quote, -num_found, -found, -spans_pages) %>% 
  collect())

# Now need to figure out which overlap with which.

# Selections can only match selections in the same article. 
# Can only match selections by another coder as well.
# Can identify matches then drop those by self (which would include matching own range)

# chain broken to allow joining back after matching

(matching <- found %>% 
  # dots below mean "data frame as passed in" it's a self join.
  inner_join(x = ., y = ., by = "article") %>% 
  # can't match own selections
  filter(coder.x != coder.y) %>%
  # overlap definition
  # from http://wiki.c2.com/?TestIfDateRangesOverlap
  # ( start1 <= end2 and start2 <= end1 )
  filter(start_val.x <= end_val.y, 
          start_val.y <= end_val.x) %>% 
  # used as a check
  # select(full_quote.x, full_quote.y) %>% 
  # unite(matched_selections, selection.x, selection.y, sep="---") %>% 
  # mutate(matched_selections = ( matched_selections %>% 
  #                                str_split("---") %>% 
  #                                str_sort() %>% 
  #                                str_join() ) ) %>%  
  select(selection = selection.x, 
         matching_selection = selection.y) %>%
 #  distinct(selection, matching_selection, keep_all=T) %>% 
  # rowid_to_column() %>% 
  # unite(matched_id, article, rowid) %>% 
  collect())

# Note that matching is doubled each way. Probably an issue.
# very likely need to create an "id" or at least unique the matched ones.
# Hmmm, the relationship is more complex, since one large quote by one coder
# could match many by the others.  Oh well, can't deal with everything.

# left join back to found to leave NAs for those that didn't match  
(found_with_matches <- found %>% 
  left_join(matching, by = "selection") %>% 
  mutate(matched = if_else(is.na(matching_selection), "unmatched", "matched")) %>% 
  collect()) # dummy op to allow commenting out steps.

# found %>% group_by(coder) %>% 
#   summarize(num_selections = n_distinct(selection)) %>% 
#   arrange(desc(num_selections))
```



```{r}


# summarize situation.
# (simple_agree_counts_by_article <- found_with_matches %>%
#   group_by(article, matched) %>% 
#   summarize(sel_count  = n_distinct(selection),
#             num_coders = n_distinct(coder)) %>% 
#   spread(matched, sel_count, fill=0) %>% 
#   mutate(matched_number   = (matched / 2), # adjust for A match B, B match A
#          total_selections = matched_number + unmatched,
#          agree_percent = (matched_number / total_selections) %>% round(2)) %>% 
#   arrange(desc(agree_percent)) %>% 
#   write_csv("simple_agree_counts_by_article.csv") %>% 
#   collect())


(match_counts <- found_with_matches %>%
  group_by(article, coder, matched) %>% 
  summarize(sel_count  = n_distinct(selection)) %>% 
  # obtain: article, coder, matched, unmatched
  spread(matched, sel_count, fill=0) %>% # 323 rows
  # add: zero counts for article/coder where no selections made.
  ungroup() %>% bind_rows(no_selection_articles) %>% # 608 rows
  collect())

match_counts %>%
  summarize(article_count = n_distinct(article))

match_counts %>%
  group_by(article) %>%
  summarize(num_coder = n_distinct(coder)) %>%
  group_by(num_coder) %>%
  tally()

my_summarize <- function(df) {
  matched = df[[1, "matched"]]
  coder_a_name = df[[1, "coder"]]
  coder_a_only = df[[1, "unmatched"]]

  if (nrow(df) > 1) {
    coder_b_name = df[[2, "coder"]]
    coder_b_only = df[[2, "unmatched"]]
    total_selections <- matched + coder_a_only + coder_b_only
    if (total_selections == 0) {
      percent_agree <- NA
    } else {
      percent_agree <- matched / total_selections %>% round(2)
    }
  } else {
    coder_b_name <-  NA
    coder_b_only <-  NA
    total_selections <- matched + coder_a_only
    percent_agree <- NA
  }

  tibble(percent_agree = percent_agree,
         matched = matched,
         coder_a_only = coder_a_only,
         coder_a_name = coder_a_name,
         coder_b_only = coder_b_only,
         coder_b_name = coder_b_name)
}

# Now obtain:
# article, matched, coder_a_only, coder_a_name, coder_b_only, coder_b_name 
simple_agree_counts_by_article <- match_counts %>%
  group_by(article) %>% 
  do(my_summarize(.)) %>%
  arrange(percent_agree)

simple_agree_counts_by_article %>% 
  ungroup() %>% 
  filter(!is.na(percent_agree)) %>% # single coded articles
  summarize(mean_percent_agree = mean(percent_agree))

# how many with 100%?
simple_agree_counts_by_article %>% 
  filter(!is.na(percent_agree)) %>% 
  mutate(ranking_group = case_when(
    percent_agree == 0 ~ "none",
    percent_agree <= 0.5 ~ "under_half",
    percent_agree < 1 ~ "over_half",
    percent_agree == 1 ~ "all"
    
  )) %>% 
  group_by(ranking_group) %>% 
  summarize(article_count = n(),
            group_mean = mean(percent_agree))


  
View(simple_agree_counts_by_article)
  
  #  # Now summarize by article, collapsing across coders 
  # group_by(article) %>% 
  # summarize(num_coder = n_distinct(coder),
  #           matched = sum(matched) / num_coder, # A match B, B match A
  #           unmatched = sum(unmatched)) %>% 
  # filter(num_coder > 1) %>% 
  # # for each article, summarize across columns
  # mutate(total_selections = matched + unmatched,
  #      agree_percent = ifelse(total_selections == 0, 
  #                             1.0, # neither found selections, full agree. 
  #                             (matched / total_selections) %>% round(2))) %>% 
  # arrange(desc(agree_percent)) %>% 
  # write_csv("simple_agree_counts_by_article.csv") %>% 
  # collect())



simple_agree_counts_by_article %>% group_by(num_coder) %>% tally()

simple_agree_counts_by_article %>% 
  ggplot() +
  geom_histogram(aes(x=percent_agree), bins=5)
```

```{r}
# (simple_agree_counts_by_article %>% 
#   ungroup() %>% 
#   filter(num_coders > 1) %>% 
#   summarize(total_selections = sum(total_selections),
#             total_match = sum(matched_number),
#             overall_agree = (total_match / total_selections) %>% round(2)) %>% 
#   collect())
```

```{r}
# per coder is a little more problematic; and only relevant on articles with 2
# coders.
# (agree_counts_per_coder <- found_with_matches %>% 
#   group_by(article) %>% 
#   mutate(num_coders_for_article = n_distinct(coder)) %>% 
#   filter(num_coders_for_article > 1) %>% 
#   ungroup() %>% 
#   group_by(coder, matched) %>% 
#   summarize(sel_count  = n_distinct(selection),
#             num_coders = n_distinct(coder)) %>% 
#   spread(matched, sel_count, fill=0) %>% 
#   mutate(matched_number   = (matched / 2), # adjust for A match B, B match A
#          total_selections = matched_number + unmatched,
#          agree_percent = (matched_number / total_selections) %>% round(2)) %>% 
#   collect())
# 
# View(agree_counts_per_coder)

# PMC2518490_MS01 matches PMC2518490_MD04
```
